{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Detection.ipynb","provenance":[{"file_id":"https://github.com/pytorch/vision/blob/temp-tutorial/tutorials/torchvision_finetuning_instance_segmentation.ipynb","timestamp":1620437437691}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"},"widgets":{"application/vnd.jupyter.widget-state+json":{"188acb3952d64de09fe9e627514695be":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_8a6614b941304aaebdf207666dd89132","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_26d71d14c1b1475082bd83dbb2162d5a","IPY_MODEL_b29ef08c377d4171a90efd53c9ab9f2d"]}},"8a6614b941304aaebdf207666dd89132":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"26d71d14c1b1475082bd83dbb2162d5a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_cd53602d510f42748f22485e61840c82","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":167502836,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":167502836,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_249e5add331c408fb38957610f0bcd24"}},"b29ef08c377d4171a90efd53c9ab9f2d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_544685dc3dcf45bf8fec50001f73e785","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 160M/160M [19:44&lt;00:00, 141kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_edc3b86a0c9a4d348ef7b1ef52933dc9"}},"cd53602d510f42748f22485e61840c82":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"249e5add331c408fb38957610f0bcd24":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"544685dc3dcf45bf8fec50001f73e785":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"edc3b86a0c9a4d348ef7b1ef52933dc9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"88ab991bba294849bee8c2764c9c05b2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_b42daf46d18b46e5a7053d7bcbc38123","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_f5c0e581df0144be91cb39fe90444855","IPY_MODEL_bb24860efedd458084209ab41a4e54b1"]}},"b42daf46d18b46e5a7053d7bcbc38123":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f5c0e581df0144be91cb39fe90444855":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_7d46e646244e470c92155bf13404544d","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":136595076,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":136595076,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_5aefa198a63242709161abfff969d803"}},"bb24860efedd458084209ab41a4e54b1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_44ca71af31074d4bba4f6a97c7303073","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 130M/130M [00:00&lt;00:00, 137MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d40a7d40d2e648c49886580a29dfd46a"}},"7d46e646244e470c92155bf13404544d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"5aefa198a63242709161abfff969d803":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"44ca71af31074d4bba4f6a97c7303073":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"d40a7d40d2e648c49886580a29dfd46a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"DfPPQ6ztJhv4"},"source":["# Object detector\n","\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8SJtmB-MyADq","executionInfo":{"status":"ok","timestamp":1621498206166,"user_tz":-180,"elapsed":23408,"user":{"displayName":"Ilja Pavlovs","photoUrl":"","userId":"13249870573819033434"}},"outputId":"a2130b90-b1d0-47d2-c322-cd7f76505902"},"source":["from google.colab import drive\n","drive.mount(\"/content/drive\", force_remount=True)\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n","Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"b0KiGNkgbX19"},"source":["Importing libraries"]},{"cell_type":"code","metadata":{"id":"DBIoe_tHTQgV"},"source":["from __future__ import print_function, division\n","import cv2\n","import torchvision\n","import math\n","import os\n","import torch\n","import random\n","from collections import Counter\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import transforms, utils\n","from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n","from PIL import Image, ImageEnhance\n","import matplotlib.patches as patches\n","import time\n","from tqdm import tqdm\n","import torchvision.transforms.functional as TF\n","import warnings\n","import torchvision.ops as ops\n","warnings.filterwarnings('ignore')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bRtfuuSEwlFF"},"source":["<h3>Import datasets</h3>"]},{"cell_type":"code","metadata":{"id":"_t4TBwhHTdkd"},"source":["# Set device\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') # set device\n","\n","# Global parameters\n","num_classes = 3\n","batch_size = 4\n","learning_rate = 1e-4\n","num_of_epochs = 10"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NDfZ3YgN1psz"},"source":["# Load Data\n","class AnimalDataset(Dataset):\n","    def __init__(self, csv_file, root_dir=None, transform = None):\n","        self.ann = pd.read_csv(csv_file)\n","        self.root_dir = root_dir\n","        self.transform = transform\n","        self.class2id = {\n","            \"29\": 1,\n","            \"38\": 2,\n","        }\n","    def __len__(self):\n","        return len(self.ann)\n","    def __getitem__(self, idx):\n","        img_path = self.root_dir + '/' + self.ann[\"id\"][idx]\n","\n","        img = np.array(Image.open(img_path))\n","        label = self.class2id[str(self.ann.loc[idx, 'labels'])]\n","        bbox = self.ann.loc[idx, 'xmin':'ymax'].tolist()\n","        sample = (img, {\"boxes\": bbox, \"labels\": label})\n","        if self.transform:\n","            sample = self.transform(sample)\n","        return sample\n","    def get_id(self, idx):\n","        return self.ann[\"id\"][idx]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-P4md6BQMBXV"},"source":["<h3>Data augmentation</h3>"]},{"cell_type":"code","metadata":{"id":"LOSzUYmGLxNN"},"source":["#Custom transforms\n","\n","class Normalize(object):\n","    def __call__(self, sample):\n","        img, _ = sample\n","        img = img.astype(np.float32) / 255\n","        img -= np.min(img)\n","        img /= np.max(img)\n","        sample = (img, sample[1])\n","        return sample\n","\n","class Rescale(object):\n","    def __init__(self, output_size):\n","        self.output_size = output_size\n","\n","    def __call__(self, sample):\n","        image, bbox = sample[0], sample[1]['boxes']\n","\n","        h, w = image.shape[:2]\n","        new_h, new_w = int(self.output_size), int(self.output_size)\n","\n","        img = cv2.resize(image,(new_h, new_w))\n","\n","        #resizing bbox\n","        bh, bw = bbox[2]-bbox[0], bbox[3]-bbox[1]\n","        center = [int(bbox[0]+bw/2), int(bbox[1]+bh/2)]\n","        bbox = bbox - np.array(center+center)\n","        bbox = np.multiply(bbox , np.array([new_w / w, new_h / h, new_w / w, new_h / h]))\n","        center = np.multiply(np.array(center+center), np.array([new_w / w, new_h / h, new_w / w, new_h / h]))\n","        bbox = bbox + center\n","\n","\n","        return (img, {'boxes': bbox, 'labels': sample[1]['labels']})\n","\n","class Random_flip(object):\n","    def __call__(self, sample):\n","        image, bbox = sample[0], sample[1]['boxes']\n","        h, w = image.shape[:2]\n","\n","        #Random horizontal flip\n","        if (random.randint(0,1)):\n","            image = cv2.flip(image, 1)\n","            bbox[0] = w - bbox[0]\n","            bbox[2] = w - bbox[2]\n","            bbox[0],bbox[2] = bbox[2],bbox[0]\n","\n","        return (image, {'boxes': bbox, 'labels': sample[1]['labels']})\n","\n","class ColorJitter(object):\n","    def __call__(self, sample):\n","        img = Image.fromarray(np.uint8(sample[0]*255)).convert('RGB')\n","\n","        rand_c = 0.9 + random.random()/2\n","        filter = ImageEnhance.Brightness(img)\n","        img = filter.enhance(rand_c)\n","\n","        filter = ImageEnhance.Contrast(img)\n","        img = filter.enhance(rand_c)\n","\n","        filter = ImageEnhance.Color(img)\n","        img = filter.enhance(rand_c)\n","\n","        img = np.array(img, dtype='uint8')/255\n","\n","        return (img, sample[1])\n","\n","class ToTensor(object):\n","    def __init__(self, size):\n","        self.size = size\n","\n","    def __call__(self, sample):\n","        img, bbox = sample[0], np.array(sample[1]['boxes'])\n","\n","        # swap color axis because\n","        # numpy image: H x W x C\n","        # torch image: C X H X W\n","        img = img.transpose((2, 0, 1))\n","\n","        # to be safe\n","        if bbox[0]<0:\n","            bbox[0]=0\n","        if bbox[1]<0:\n","          bbox[1]=0\n","        if bbox[2]>self.size:\n","          bbox[2] = self.size\n","        if bbox[3]>self.size:\n","          bbox[3] = self.size\n","        if bbox[0]>bbox[2]:\n","          bbox[0],bbox[2] = bbox[2],bbox[0]\n","        if bbox[1]>bbox[3]:\n","            bbox[1],bbox[3] = bbox[3],bbox[1]\n","\n","        return (torch.from_numpy(img).double(), {\n","            'boxes': torch.from_numpy(bbox).double(),#.to(device),\n","            'labels': torch.tensor(torch.from_numpy(np.array(sample[1][\"labels\"])), dtype = torch.long)#.to(device)\n","        })"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tRajLtnjL3S3"},"source":["class Averager:\n","    def __init__(self):\n","        self.current_total = 0.0\n","        self.iterations = 0.0\n","\n","    def send(self, value):\n","        self.current_total += value\n","        self.iterations += 1\n","\n","    @property\n","    def value(self):\n","        if self.iterations == 0:\n","            return 0\n","        else:\n","            return 1.0 * self.current_total / self.iterations\n","\n","    def reset(self):\n","        self.current_total = 0.0\n","        self.iterations = 0.0"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Zz3nFwaT3BbP"},"source":["def collate_fn(batch):\n","    return tuple(zip(*batch))\n","\n","def data_prep(data, type):\n","    images, targets = data\n","    if type=='train': #todo for some reason?>\n","        images = list(img.to(device) for img in images)\n","    elif type  =='test':\n","        images = list(img.float().to(device) for img in images)\n","\n","    targets = [{k: v.float().unsqueeze(0).to(device) for k, v in t.items()} for t in targets]\n","    for t in targets:\n","        for k,v in t.items():\n","            if k=='labels':\n","                t[k] = torch.tensor(v.to(device), dtype=torch.long)\n","\n","    return images, targets"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JS0frlu0cPUs","executionInfo":{"status":"ok","timestamp":1621499096196,"user_tz":-180,"elapsed":891,"user":{"displayName":"Ilja Pavlovs","photoUrl":"","userId":"13249870573819033434"}},"outputId":"91f861f4-663d-4066-f8ae-58834b32dbf9"},"source":["transform = transforms.Compose([Rescale(512), Normalize(), Random_flip(), ColorJitter(), ToTensor(512)])\n","print(\"Load dataset\")\n","\n","\n","dataset_train = AnimalDataset(csv_file='global_labels_notbalanced.csv',\n","                                  root_dir='/content/drive/MyDrive/TrainingData/dataset_copy',\n","                                  transform=transform\n","                                  )\n","\n","\n","data_loader_train = DataLoader(\n","    dataset = dataset_train,\n","    batch_size = batch_size,\n","    shuffle = True,\n","    num_workers=4,\n","    drop_last=True,\n","    collate_fn=collate_fn,\n",")\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Load dataset\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["188acb3952d64de09fe9e627514695be","8a6614b941304aaebdf207666dd89132","26d71d14c1b1475082bd83dbb2162d5a","b29ef08c377d4171a90efd53c9ab9f2d","cd53602d510f42748f22485e61840c82","249e5add331c408fb38957610f0bcd24","544685dc3dcf45bf8fec50001f73e785","edc3b86a0c9a4d348ef7b1ef52933dc9"]},"id":"59pZ_4qd3kpg","executionInfo":{"status":"ok","timestamp":1621401136509,"user_tz":-180,"elapsed":15477,"user":{"displayName":"Ilja Pavlovs","photoUrl":"","userId":"13249870573819033434"}},"outputId":"00cfb8e0-73a9-4ccc-f7f1-9a6cd65ba1e9"},"source":["# Model\n","model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True).to(device)\n","\n","#Input feature number for the classifier\n","in_features = model.roi_heads.box_predictor.cls_score.in_features\n","# replace the pre-trained head with a new one\n","model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n","\n","\n","params = [p for p in model.parameters() if p.requires_grad]\n","\n","#optimizer = torch.optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)\n","optimizer  = torch.optim.Adam(model.parameters(), lr=learning_rate) #todo choose optimiser\n","\n","# lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\n","lr_scheduler = None\n","\n","loss_hist = Averager()\n","model.train()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Downloading: \"https://download.pytorch.org/models/fasterrcnn_resnet50_fpn_coco-258fb6c6.pth\" to /root/.cache/torch/hub/checkpoints/fasterrcnn_resnet50_fpn_coco-258fb6c6.pth\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"188acb3952d64de09fe9e627514695be","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=167502836.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["FasterRCNN(\n","  (transform): GeneralizedRCNNTransform(\n","      Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","      Resize(min_size=(800,), max_size=1333, mode='bilinear')\n","  )\n","  (backbone): BackboneWithFPN(\n","    (body): IntermediateLayerGetter(\n","      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","      (bn1): FrozenBatchNorm2d(64, eps=0.0)\n","      (relu): ReLU(inplace=True)\n","      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","      (layer1): Sequential(\n","        (0): Bottleneck(\n","          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n","          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n","          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n","          (relu): ReLU(inplace=True)\n","          (downsample): Sequential(\n","            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): FrozenBatchNorm2d(256, eps=0.0)\n","          )\n","        )\n","        (1): Bottleneck(\n","          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n","          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n","          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n","          (relu): ReLU(inplace=True)\n","        )\n","        (2): Bottleneck(\n","          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n","          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n","          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n","          (relu): ReLU(inplace=True)\n","        )\n","      )\n","      (layer2): Sequential(\n","        (0): Bottleneck(\n","          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n","          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n","          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n","          (relu): ReLU(inplace=True)\n","          (downsample): Sequential(\n","            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","            (1): FrozenBatchNorm2d(512, eps=0.0)\n","          )\n","        )\n","        (1): Bottleneck(\n","          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n","          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n","          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n","          (relu): ReLU(inplace=True)\n","        )\n","        (2): Bottleneck(\n","          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n","          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n","          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n","          (relu): ReLU(inplace=True)\n","        )\n","        (3): Bottleneck(\n","          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n","          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n","          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n","          (relu): ReLU(inplace=True)\n","        )\n","      )\n","      (layer3): Sequential(\n","        (0): Bottleneck(\n","          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n","          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n","          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n","          (relu): ReLU(inplace=True)\n","          (downsample): Sequential(\n","            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","            (1): FrozenBatchNorm2d(1024, eps=0.0)\n","          )\n","        )\n","        (1): Bottleneck(\n","          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n","          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n","          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n","          (relu): ReLU(inplace=True)\n","        )\n","        (2): Bottleneck(\n","          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n","          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n","          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n","          (relu): ReLU(inplace=True)\n","        )\n","        (3): Bottleneck(\n","          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n","          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n","          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n","          (relu): ReLU(inplace=True)\n","        )\n","        (4): Bottleneck(\n","          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n","          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n","          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n","          (relu): ReLU(inplace=True)\n","        )\n","        (5): Bottleneck(\n","          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n","          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n","          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n","          (relu): ReLU(inplace=True)\n","        )\n","      )\n","      (layer4): Sequential(\n","        (0): Bottleneck(\n","          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n","          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n","          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n","          (relu): ReLU(inplace=True)\n","          (downsample): Sequential(\n","            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","            (1): FrozenBatchNorm2d(2048, eps=0.0)\n","          )\n","        )\n","        (1): Bottleneck(\n","          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n","          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n","          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n","          (relu): ReLU(inplace=True)\n","        )\n","        (2): Bottleneck(\n","          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n","          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n","          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n","          (relu): ReLU(inplace=True)\n","        )\n","      )\n","    )\n","    (fpn): FeaturePyramidNetwork(\n","      (inner_blocks): ModuleList(\n","        (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n","        (1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n","        (2): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n","        (3): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n","      )\n","      (layer_blocks): ModuleList(\n","        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      )\n","      (extra_blocks): LastLevelMaxPool()\n","    )\n","  )\n","  (rpn): RegionProposalNetwork(\n","    (anchor_generator): AnchorGenerator()\n","    (head): RPNHead(\n","      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (cls_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n","      (bbox_pred): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n","    )\n","  )\n","  (roi_heads): RoIHeads(\n","    (box_roi_pool): MultiScaleRoIAlign(featmap_names=['0', '1', '2', '3'], output_size=(7, 7), sampling_ratio=2)\n","    (box_head): TwoMLPHead(\n","      (fc6): Linear(in_features=12544, out_features=1024, bias=True)\n","      (fc7): Linear(in_features=1024, out_features=1024, bias=True)\n","    )\n","    (box_predictor): FastRCNNPredictor(\n","      (cls_score): Linear(in_features=1024, out_features=3, bias=True)\n","      (bbox_pred): Linear(in_features=1024, out_features=12, bias=True)\n","    )\n","  )\n",")"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zNxKXScobhB-","executionInfo":{"status":"ok","timestamp":1621402882051,"user_tz":-180,"elapsed":1982,"user":{"displayName":"Ilja Pavlovs","photoUrl":"","userId":"13249870573819033434"}},"outputId":"2ad266f7-bfed-440a-e9af-484ab6ced113"},"source":["#Load checkpoint\n","#start_epoch = 2\n","checkpoint = torch.load('/content/drive/MyDrive/TrainingData/faster8.pth')\n","\n","model.load_state_dict(checkpoint['model_state_dict'])\n","optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n","start_epoch = checkpoint['epoch']\n","#loss = checkpoint['loss']\n","#model.load_state_dict(checkpoint)\n","\n","model.to(device)\n","model.train()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["FasterRCNN(\n","  (transform): GeneralizedRCNNTransform(\n","      Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","      Resize(min_size=(800,), max_size=1333, mode='bilinear')\n","  )\n","  (backbone): BackboneWithFPN(\n","    (body): IntermediateLayerGetter(\n","      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","      (bn1): FrozenBatchNorm2d(64, eps=0.0)\n","      (relu): ReLU(inplace=True)\n","      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","      (layer1): Sequential(\n","        (0): Bottleneck(\n","          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n","          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n","          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n","          (relu): ReLU(inplace=True)\n","          (downsample): Sequential(\n","            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): FrozenBatchNorm2d(256, eps=0.0)\n","          )\n","        )\n","        (1): Bottleneck(\n","          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n","          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n","          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n","          (relu): ReLU(inplace=True)\n","        )\n","        (2): Bottleneck(\n","          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n","          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n","          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n","          (relu): ReLU(inplace=True)\n","        )\n","      )\n","      (layer2): Sequential(\n","        (0): Bottleneck(\n","          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n","          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n","          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n","          (relu): ReLU(inplace=True)\n","          (downsample): Sequential(\n","            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","            (1): FrozenBatchNorm2d(512, eps=0.0)\n","          )\n","        )\n","        (1): Bottleneck(\n","          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n","          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n","          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n","          (relu): ReLU(inplace=True)\n","        )\n","        (2): Bottleneck(\n","          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n","          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n","          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n","          (relu): ReLU(inplace=True)\n","        )\n","        (3): Bottleneck(\n","          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n","          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n","          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n","          (relu): ReLU(inplace=True)\n","        )\n","      )\n","      (layer3): Sequential(\n","        (0): Bottleneck(\n","          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n","          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n","          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n","          (relu): ReLU(inplace=True)\n","          (downsample): Sequential(\n","            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","            (1): FrozenBatchNorm2d(1024, eps=0.0)\n","          )\n","        )\n","        (1): Bottleneck(\n","          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n","          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n","          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n","          (relu): ReLU(inplace=True)\n","        )\n","        (2): Bottleneck(\n","          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n","          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n","          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n","          (relu): ReLU(inplace=True)\n","        )\n","        (3): Bottleneck(\n","          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n","          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n","          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n","          (relu): ReLU(inplace=True)\n","        )\n","        (4): Bottleneck(\n","          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n","          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n","          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n","          (relu): ReLU(inplace=True)\n","        )\n","        (5): Bottleneck(\n","          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n","          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n","          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n","          (relu): ReLU(inplace=True)\n","        )\n","      )\n","      (layer4): Sequential(\n","        (0): Bottleneck(\n","          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n","          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n","          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n","          (relu): ReLU(inplace=True)\n","          (downsample): Sequential(\n","            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","            (1): FrozenBatchNorm2d(2048, eps=0.0)\n","          )\n","        )\n","        (1): Bottleneck(\n","          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n","          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n","          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n","          (relu): ReLU(inplace=True)\n","        )\n","        (2): Bottleneck(\n","          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n","          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n","          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n","          (relu): ReLU(inplace=True)\n","        )\n","      )\n","    )\n","    (fpn): FeaturePyramidNetwork(\n","      (inner_blocks): ModuleList(\n","        (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n","        (1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n","        (2): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n","        (3): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n","      )\n","      (layer_blocks): ModuleList(\n","        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      )\n","      (extra_blocks): LastLevelMaxPool()\n","    )\n","  )\n","  (rpn): RegionProposalNetwork(\n","    (anchor_generator): AnchorGenerator()\n","    (head): RPNHead(\n","      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (cls_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n","      (bbox_pred): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n","    )\n","  )\n","  (roi_heads): RoIHeads(\n","    (box_roi_pool): MultiScaleRoIAlign(featmap_names=['0', '1', '2', '3'], output_size=(7, 7), sampling_ratio=2)\n","    (box_head): TwoMLPHead(\n","      (fc6): Linear(in_features=12544, out_features=1024, bias=True)\n","      (fc7): Linear(in_features=1024, out_features=1024, bias=True)\n","    )\n","    (box_predictor): FastRCNNPredictor(\n","      (cls_score): Linear(in_features=1024, out_features=3, bias=True)\n","      (bbox_pred): Linear(in_features=1024, out_features=12, bias=True)\n","    )\n","  )\n",")"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"markdown","metadata":{"id":"hnkQzH2ziFpJ"},"source":["<h2>Faster RCNN training</h2>"]},{"cell_type":"code","metadata":{"id":"qV_nRPsW4CZl","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621425281740,"user_tz":-180,"elapsed":22396233,"user":{"displayName":"Ilja Pavlovs","photoUrl":"","userId":"13249870573819033434"}},"outputId":"e0a36766-da4d-47c9-dee2-cdec37923348"},"source":["#----------------------------------------------TRAIN-----------------------------------------------------------------\n","#start_epoch = -1\n","itr = (start_epoch+1)*len(data_loader_train)\n","\n","for epoch in range(start_epoch+1, num_of_epochs):\n","    loss_hist.reset()\n","\n","    print(\"Epoch - {} Started\".format(epoch))\n","    st = time.time()\n","    epoch_loss = []\n","\n","    for data in data_loader_train:\n","\n","        itr += 1\n","        images, targets = data_prep(data, type='train')\n","\n","        model = model.double().to(device)\n","        loss_dict = model(images, targets)\n","        losses = sum(loss for loss in loss_dict.values())\n","        \n","        loss_hist.send(losses.item())\n","\n","        optimizer.zero_grad()\n","\n","        losses.backward()\n","\n","        optimizer.step()\n","\n","        print('Epoch: {} | Iteration: {} | Classification loss: {:1.5f} | Regression loss: {:1.5f} | Objectness loss: {:1.5f} | RPN Regression loss: {:1.5f} | Running loss: {:1.5f}'.format(\n","                epoch, itr, float(loss_dict['loss_classifier'].item()), float(loss_dict['loss_box_reg']), float(loss_dict['loss_objectness']), float(loss_dict['loss_rpn_box_reg']), float(losses)))\n","        with open('/content/drive/MyDrive/TrainingData/fasterrcnn_loss.txt', 'a') as f:\n","            f.write('Epoch: {} | Iteration: {} | Classification loss: {:1.5f} | Regression loss: {:1.5f} | Objectness loss: {:1.5f} | RPN Regression loss: {:1.5f} | Running loss: {:1.5f}\\n'.format(\n","                epoch, itr, float(loss_dict['loss_classifier'].item()), float(loss_dict['loss_box_reg']), float(loss_dict['loss_objectness']), float(loss_dict['loss_rpn_box_reg']), float(losses)))\n","        \n","\n","    # update the learning rate\n","    if lr_scheduler is not None:\n","        lr_scheduler.step()\n","\n","    et = time.time()\n","    print(\"\\n Total Time - {}\\n\".format(int(et - st)))\n","    with open('/content/drive/MyDrive/TrainingData/fasterrcnn_loss.txt', 'a') as f:\n","        f.write(\"Total Time - {}\\n\".format(int(et - st)))\n","\n","    #print(f\"Epoch #{epoch} loss: {loss_hist.value}\")\n","    #checkpoint\n","    torch.save({\n","        'epoch':epoch,\n","        'model_state_dict': model.state_dict(),\n","        'optimizer_state_dict': optimizer.state_dict(),\n","        'loss': losses}, '/content/drive/MyDrive/TrainingData/model'+str(epoch)+'epoch.pth')\n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch - 9 Started\n","Epoch: 9 | Iteration: 31366 | Classification loss: 0.02071 | Regression loss: 0.01737 | Objectness loss: 0.00677 | RPN Regression loss: 0.00240 | Running loss: 0.04725\n","Epoch: 9 | Iteration: 31367 | Classification loss: 0.02176 | Regression loss: 0.04270 | Objectness loss: 0.00016 | RPN Regression loss: 0.00135 | Running loss: 0.06598\n","Epoch: 9 | Iteration: 31368 | Classification loss: 0.03034 | Regression loss: 0.02847 | Objectness loss: 0.00323 | RPN Regression loss: 0.00207 | Running loss: 0.06411\n","Epoch: 9 | Iteration: 31369 | Classification loss: 0.01212 | Regression loss: 0.01772 | Objectness loss: 0.00001 | RPN Regression loss: 0.00106 | Running loss: 0.03092\n","Epoch: 9 | Iteration: 31370 | Classification loss: 0.01924 | Regression loss: 0.01942 | Objectness loss: 0.00003 | RPN Regression loss: 0.00091 | Running loss: 0.03960\n","Epoch: 9 | Iteration: 31371 | Classification loss: 0.01159 | Regression loss: 0.01093 | Objectness loss: 0.00039 | RPN Regression loss: 0.00130 | Running loss: 0.02422\n","Epoch: 9 | Iteration: 31372 | Classification loss: 0.01978 | Regression loss: 0.03630 | Objectness loss: 0.00014 | RPN Regression loss: 0.00295 | Running loss: 0.05917\n","Epoch: 9 | Iteration: 31373 | Classification loss: 0.02671 | Regression loss: 0.01955 | Objectness loss: 0.00050 | RPN Regression loss: 0.00479 | Running loss: 0.05155\n","Epoch: 9 | Iteration: 31374 | Classification loss: 0.01621 | Regression loss: 0.03249 | Objectness loss: 0.00002 | RPN Regression loss: 0.00094 | Running loss: 0.04966\n","Epoch: 9 | Iteration: 31375 | Classification loss: 0.01533 | Regression loss: 0.01571 | Objectness loss: 0.00008 | RPN Regression loss: 0.00061 | Running loss: 0.03172\n","Epoch: 9 | Iteration: 31376 | Classification loss: 0.01202 | Regression loss: 0.01721 | Objectness loss: 0.00005 | RPN Regression loss: 0.00140 | Running loss: 0.03068\n","Epoch: 9 | Iteration: 31377 | Classification loss: 0.00943 | Regression loss: 0.02042 | Objectness loss: 0.00005 | RPN Regression loss: 0.00145 | Running loss: 0.03135\n","Epoch: 9 | Iteration: 31378 | Classification loss: 0.01820 | Regression loss: 0.02510 | Objectness loss: 0.00126 | RPN Regression loss: 0.00081 | Running loss: 0.04536\n","Epoch: 9 | Iteration: 31379 | Classification loss: 0.04765 | Regression loss: 0.03588 | Objectness loss: 0.00077 | RPN Regression loss: 0.00314 | Running loss: 0.08744\n","Epoch: 9 | Iteration: 31380 | Classification loss: 0.01549 | Regression loss: 0.02235 | Objectness loss: 0.00356 | RPN Regression loss: 0.00087 | Running loss: 0.04227\n","Epoch: 9 | Iteration: 31381 | Classification loss: 0.02002 | Regression loss: 0.02015 | Objectness loss: 0.00002 | RPN Regression loss: 0.00052 | Running loss: 0.04071\n","Epoch: 9 | Iteration: 31382 | Classification loss: 0.02268 | Regression loss: 0.02425 | Objectness loss: 0.00011 | RPN Regression loss: 0.00339 | Running loss: 0.05044\n","Epoch: 9 | Iteration: 31383 | Classification loss: 0.01157 | Regression loss: 0.01759 | Objectness loss: 0.00226 | RPN Regression loss: 0.00212 | Running loss: 0.03353\n","Epoch: 9 | Iteration: 31384 | Classification loss: 0.00986 | Regression loss: 0.01759 | Objectness loss: 0.00041 | RPN Regression loss: 0.00207 | Running loss: 0.02993\n","Epoch: 9 | Iteration: 31385 | Classification loss: 0.01433 | Regression loss: 0.02764 | Objectness loss: 0.00013 | RPN Regression loss: 0.00040 | Running loss: 0.04250\n","Epoch: 9 | Iteration: 31386 | Classification loss: 0.02215 | Regression loss: 0.01782 | Objectness loss: 0.00014 | RPN Regression loss: 0.00249 | Running loss: 0.04260\n","Epoch: 9 | Iteration: 31387 | Classification loss: 0.03079 | Regression loss: 0.02165 | Objectness loss: 0.00133 | RPN Regression loss: 0.00076 | Running loss: 0.05453\n","Epoch: 9 | Iteration: 31388 | Classification loss: 0.01151 | Regression loss: 0.01781 | Objectness loss: 0.00176 | RPN Regression loss: 0.00137 | Running loss: 0.03245\n","Epoch: 9 | Iteration: 31389 | Classification loss: 0.02022 | Regression loss: 0.01993 | Objectness loss: 0.00002 | RPN Regression loss: 0.00067 | Running loss: 0.04084\n","Epoch: 9 | Iteration: 31390 | Classification loss: 0.01428 | Regression loss: 0.02020 | Objectness loss: 0.00011 | RPN Regression loss: 0.00050 | Running loss: 0.03509\n","Epoch: 9 | Iteration: 31391 | Classification loss: 0.01825 | Regression loss: 0.01428 | Objectness loss: 0.00029 | RPN Regression loss: 0.00151 | Running loss: 0.03433\n","Epoch: 9 | Iteration: 31392 | Classification loss: 0.02391 | Regression loss: 0.01318 | Objectness loss: 0.00015 | RPN Regression loss: 0.00037 | Running loss: 0.03761\n","Epoch: 9 | Iteration: 31393 | Classification loss: 0.00951 | Regression loss: 0.01806 | Objectness loss: 0.00002 | RPN Regression loss: 0.00071 | Running loss: 0.02830\n","Epoch: 9 | Iteration: 31394 | Classification loss: 0.02339 | Regression loss: 0.04148 | Objectness loss: 0.00022 | RPN Regression loss: 0.00073 | Running loss: 0.06582\n","Epoch: 9 | Iteration: 31395 | Classification loss: 0.00572 | Regression loss: 0.01404 | Objectness loss: 0.00005 | RPN Regression loss: 0.00133 | Running loss: 0.02114\n","Epoch: 9 | Iteration: 31396 | Classification loss: 0.02823 | Regression loss: 0.02899 | Objectness loss: 0.00175 | RPN Regression loss: 0.00077 | Running loss: 0.05974\n","Epoch: 9 | Iteration: 31397 | Classification loss: 0.01653 | Regression loss: 0.02713 | Objectness loss: 0.00185 | RPN Regression loss: 0.00259 | Running loss: 0.04809\n","Epoch: 9 | Iteration: 31398 | Classification loss: 0.01765 | Regression loss: 0.02334 | Objectness loss: 0.00040 | RPN Regression loss: 0.00415 | Running loss: 0.04553\n","Epoch: 9 | Iteration: 31399 | Classification loss: 0.01154 | Regression loss: 0.02750 | Objectness loss: 0.00176 | RPN Regression loss: 0.01090 | Running loss: 0.05168\n","Epoch: 9 | Iteration: 31400 | Classification loss: 0.00968 | Regression loss: 0.01880 | Objectness loss: 0.00054 | RPN Regression loss: 0.00072 | Running loss: 0.02973\n","Epoch: 9 | Iteration: 31401 | Classification loss: 0.01120 | Regression loss: 0.02361 | Objectness loss: 0.00002 | RPN Regression loss: 0.00082 | Running loss: 0.03565\n","Epoch: 9 | Iteration: 31402 | Classification loss: 0.01173 | Regression loss: 0.02870 | Objectness loss: 0.00011 | RPN Regression loss: 0.00154 | Running loss: 0.04208\n","Epoch: 9 | Iteration: 31403 | Classification loss: 0.02076 | Regression loss: 0.02455 | Objectness loss: 0.00013 | RPN Regression loss: 0.00156 | Running loss: 0.04699\n","Epoch: 9 | Iteration: 31404 | Classification loss: 0.01211 | Regression loss: 0.01813 | Objectness loss: 0.00012 | RPN Regression loss: 0.00126 | Running loss: 0.03163\n","Epoch: 9 | Iteration: 31405 | Classification loss: 0.00581 | Regression loss: 0.01339 | Objectness loss: 0.00019 | RPN Regression loss: 0.00122 | Running loss: 0.02061\n","Epoch: 9 | Iteration: 31406 | Classification loss: 0.01021 | Regression loss: 0.01788 | Objectness loss: 0.00038 | RPN Regression loss: 0.00358 | Running loss: 0.03205\n","Epoch: 9 | Iteration: 31407 | Classification loss: 0.02001 | Regression loss: 0.01734 | Objectness loss: 0.00003 | RPN Regression loss: 0.00104 | Running loss: 0.03842\n","Epoch: 9 | Iteration: 31408 | Classification loss: 0.01723 | Regression loss: 0.02776 | Objectness loss: 0.00020 | RPN Regression loss: 0.00081 | Running loss: 0.04600\n","Epoch: 9 | Iteration: 31409 | Classification loss: 0.00819 | Regression loss: 0.01641 | Objectness loss: 0.00327 | RPN Regression loss: 0.00189 | Running loss: 0.02976\n","Epoch: 9 | Iteration: 31410 | Classification loss: 0.01216 | Regression loss: 0.01935 | Objectness loss: 0.00161 | RPN Regression loss: 0.00236 | Running loss: 0.03548\n","Epoch: 9 | Iteration: 31411 | Classification loss: 0.00859 | Regression loss: 0.02321 | Objectness loss: 0.00002 | RPN Regression loss: 0.00068 | Running loss: 0.03250\n","Epoch: 9 | Iteration: 31412 | Classification loss: 0.00807 | Regression loss: 0.01367 | Objectness loss: 0.00002 | RPN Regression loss: 0.00085 | Running loss: 0.02261\n","Epoch: 9 | Iteration: 31413 | Classification loss: 0.01338 | Regression loss: 0.02179 | Objectness loss: 0.00002 | RPN Regression loss: 0.00140 | Running loss: 0.03660\n","Epoch: 9 | Iteration: 31414 | Classification loss: 0.02409 | Regression loss: 0.03301 | Objectness loss: 0.00120 | RPN Regression loss: 0.00268 | Running loss: 0.06098\n","Epoch: 9 | Iteration: 31415 | Classification loss: 0.00980 | Regression loss: 0.02468 | Objectness loss: 0.00006 | RPN Regression loss: 0.00104 | Running loss: 0.03557\n","Epoch: 9 | Iteration: 31416 | Classification loss: 0.01290 | Regression loss: 0.02585 | Objectness loss: 0.00006 | RPN Regression loss: 0.00097 | Running loss: 0.03978\n","Epoch: 9 | Iteration: 31417 | Classification loss: 0.03174 | Regression loss: 0.02844 | Objectness loss: 0.00130 | RPN Regression loss: 0.00347 | Running loss: 0.06495\n","Epoch: 9 | Iteration: 31418 | Classification loss: 0.02098 | Regression loss: 0.01841 | Objectness loss: 0.00015 | RPN Regression loss: 0.00116 | Running loss: 0.04070\n","Epoch: 9 | Iteration: 31419 | Classification loss: 0.01422 | Regression loss: 0.01136 | Objectness loss: 0.00001 | RPN Regression loss: 0.00048 | Running loss: 0.02608\n","Epoch: 9 | Iteration: 31420 | Classification loss: 0.00539 | Regression loss: 0.00930 | Objectness loss: 0.00004 | RPN Regression loss: 0.00117 | Running loss: 0.01591\n","Epoch: 9 | Iteration: 31421 | Classification loss: 0.01613 | Regression loss: 0.01934 | Objectness loss: 0.00005 | RPN Regression loss: 0.00337 | Running loss: 0.03890\n","Epoch: 9 | Iteration: 31422 | Classification loss: 0.01333 | Regression loss: 0.02889 | Objectness loss: 0.00021 | RPN Regression loss: 0.00139 | Running loss: 0.04382\n","Epoch: 9 | Iteration: 31423 | Classification loss: 0.00945 | Regression loss: 0.02312 | Objectness loss: 0.00008 | RPN Regression loss: 0.00055 | Running loss: 0.03320\n","Epoch: 9 | Iteration: 31424 | Classification loss: 0.04349 | Regression loss: 0.05164 | Objectness loss: 0.00010 | RPN Regression loss: 0.00406 | Running loss: 0.09927\n","Epoch: 9 | Iteration: 31425 | Classification loss: 0.03136 | Regression loss: 0.02978 | Objectness loss: 0.00064 | RPN Regression loss: 0.00084 | Running loss: 0.06262\n","Epoch: 9 | Iteration: 31426 | Classification loss: 0.03533 | Regression loss: 0.01967 | Objectness loss: 0.13770 | RPN Regression loss: 0.00747 | Running loss: 0.20016\n","Epoch: 9 | Iteration: 31427 | Classification loss: 0.00948 | Regression loss: 0.01339 | Objectness loss: 0.00041 | RPN Regression loss: 0.00057 | Running loss: 0.02385\n","Epoch: 9 | Iteration: 31428 | Classification loss: 0.00919 | Regression loss: 0.02478 | Objectness loss: 0.00124 | RPN Regression loss: 0.00179 | Running loss: 0.03701\n","Epoch: 9 | Iteration: 31429 | Classification loss: 0.01387 | Regression loss: 0.03915 | Objectness loss: 0.00026 | RPN Regression loss: 0.00075 | Running loss: 0.05402\n","Epoch: 9 | Iteration: 31430 | Classification loss: 0.00752 | Regression loss: 0.01167 | Objectness loss: 0.00028 | RPN Regression loss: 0.00079 | Running loss: 0.02025\n","Epoch: 9 | Iteration: 31431 | Classification loss: 0.00864 | Regression loss: 0.01704 | Objectness loss: 0.00010 | RPN Regression loss: 0.00201 | Running loss: 0.02780\n","Epoch: 9 | Iteration: 31432 | Classification loss: 0.00639 | Regression loss: 0.02339 | Objectness loss: 0.00015 | RPN Regression loss: 0.00352 | Running loss: 0.03345\n","Epoch: 9 | Iteration: 31433 | Classification loss: 0.01640 | Regression loss: 0.01856 | Objectness loss: 0.00296 | RPN Regression loss: 0.00061 | Running loss: 0.03852\n","Epoch: 9 | Iteration: 31434 | Classification loss: 0.01837 | Regression loss: 0.01012 | Objectness loss: 0.00119 | RPN Regression loss: 0.00260 | Running loss: 0.03228\n","Epoch: 9 | Iteration: 31435 | Classification loss: 0.01801 | Regression loss: 0.02976 | Objectness loss: 0.00028 | RPN Regression loss: 0.00183 | Running loss: 0.04987\n","Epoch: 9 | Iteration: 31436 | Classification loss: 0.05512 | Regression loss: 0.02858 | Objectness loss: 0.00425 | RPN Regression loss: 0.00075 | Running loss: 0.08870\n","Epoch: 9 | Iteration: 31437 | Classification loss: 0.01680 | Regression loss: 0.02274 | Objectness loss: 0.00056 | RPN Regression loss: 0.00056 | Running loss: 0.04066\n","Epoch: 9 | Iteration: 31438 | Classification loss: 0.02635 | Regression loss: 0.03723 | Objectness loss: 0.00014 | RPN Regression loss: 0.00069 | Running loss: 0.06441\n","Epoch: 9 | Iteration: 31439 | Classification loss: 0.02578 | Regression loss: 0.03577 | Objectness loss: 0.00022 | RPN Regression loss: 0.00114 | Running loss: 0.06290\n","Epoch: 9 | Iteration: 31440 | Classification loss: 0.02303 | Regression loss: 0.03057 | Objectness loss: 0.00013 | RPN Regression loss: 0.00074 | Running loss: 0.05446\n","Epoch: 9 | Iteration: 31441 | Classification loss: 0.01255 | Regression loss: 0.01677 | Objectness loss: 0.00015 | RPN Regression loss: 0.00075 | Running loss: 0.03022\n","Epoch: 9 | Iteration: 31442 | Classification loss: 0.03111 | Regression loss: 0.01961 | Objectness loss: 0.00312 | RPN Regression loss: 0.00194 | Running loss: 0.05578\n","Epoch: 9 | Iteration: 31443 | Classification loss: 0.01850 | Regression loss: 0.01803 | Objectness loss: 0.00029 | RPN Regression loss: 0.00040 | Running loss: 0.03722\n","Epoch: 9 | Iteration: 31444 | Classification loss: 0.02188 | Regression loss: 0.02655 | Objectness loss: 0.00030 | RPN Regression loss: 0.00149 | Running loss: 0.05022\n","Epoch: 9 | Iteration: 31445 | Classification loss: 0.02047 | Regression loss: 0.04868 | Objectness loss: 0.00269 | RPN Regression loss: 0.00171 | Running loss: 0.07355\n","Epoch: 9 | Iteration: 31446 | Classification loss: 0.02094 | Regression loss: 0.03499 | Objectness loss: 0.00207 | RPN Regression loss: 0.00607 | Running loss: 0.06408\n","Epoch: 9 | Iteration: 31447 | Classification loss: 0.02129 | Regression loss: 0.03362 | Objectness loss: 0.00059 | RPN Regression loss: 0.00336 | Running loss: 0.05886\n","Epoch: 9 | Iteration: 31448 | Classification loss: 0.04255 | Regression loss: 0.02921 | Objectness loss: 0.00018 | RPN Regression loss: 0.00269 | Running loss: 0.07463\n","Epoch: 9 | Iteration: 31449 | Classification loss: 0.01868 | Regression loss: 0.03990 | Objectness loss: 0.00343 | RPN Regression loss: 0.00098 | Running loss: 0.06299\n","Epoch: 9 | Iteration: 31450 | Classification loss: 0.00716 | Regression loss: 0.01768 | Objectness loss: 0.00038 | RPN Regression loss: 0.00060 | Running loss: 0.02582\n","Epoch: 9 | Iteration: 31451 | Classification loss: 0.02021 | Regression loss: 0.02656 | Objectness loss: 0.00070 | RPN Regression loss: 0.00182 | Running loss: 0.04929\n","Epoch: 9 | Iteration: 31452 | Classification loss: 0.01510 | Regression loss: 0.01619 | Objectness loss: 0.00027 | RPN Regression loss: 0.00129 | Running loss: 0.03286\n","Epoch: 9 | Iteration: 31453 | Classification loss: 0.00641 | Regression loss: 0.00858 | Objectness loss: 0.00018 | RPN Regression loss: 0.00187 | Running loss: 0.01705\n","Epoch: 9 | Iteration: 31454 | Classification loss: 0.01116 | Regression loss: 0.01578 | Objectness loss: 0.00041 | RPN Regression loss: 0.00161 | Running loss: 0.02896\n","Epoch: 9 | Iteration: 31455 | Classification loss: 0.02138 | Regression loss: 0.02501 | Objectness loss: 0.00019 | RPN Regression loss: 0.00033 | Running loss: 0.04691\n","Epoch: 9 | Iteration: 31456 | Classification loss: 0.01610 | Regression loss: 0.03706 | Objectness loss: 0.00039 | RPN Regression loss: 0.00075 | Running loss: 0.05431\n","Epoch: 9 | Iteration: 31457 | Classification loss: 0.01787 | Regression loss: 0.03085 | Objectness loss: 0.00167 | RPN Regression loss: 0.00278 | Running loss: 0.05316\n","Epoch: 9 | Iteration: 31458 | Classification loss: 0.02987 | Regression loss: 0.02723 | Objectness loss: 0.00048 | RPN Regression loss: 0.00167 | Running loss: 0.05925\n","Epoch: 9 | Iteration: 31459 | Classification loss: 0.01791 | Regression loss: 0.02245 | Objectness loss: 0.00116 | RPN Regression loss: 0.00083 | Running loss: 0.04236\n","Epoch: 9 | Iteration: 31460 | Classification loss: 0.06858 | Regression loss: 0.04397 | Objectness loss: 0.00202 | RPN Regression loss: 0.00252 | Running loss: 0.11709\n","Epoch: 9 | Iteration: 31461 | Classification loss: 0.01949 | Regression loss: 0.02277 | Objectness loss: 0.00021 | RPN Regression loss: 0.00043 | Running loss: 0.04290\n","Epoch: 9 | Iteration: 31462 | Classification loss: 0.00769 | Regression loss: 0.01948 | Objectness loss: 0.00035 | RPN Regression loss: 0.00312 | Running loss: 0.03064\n","Epoch: 9 | Iteration: 31463 | Classification loss: 0.02118 | Regression loss: 0.03347 | Objectness loss: 0.00048 | RPN Regression loss: 0.01201 | Running loss: 0.06714\n","Epoch: 9 | Iteration: 31464 | Classification loss: 0.02012 | Regression loss: 0.02834 | Objectness loss: 0.00088 | RPN Regression loss: 0.00160 | Running loss: 0.05094\n","Epoch: 9 | Iteration: 31465 | Classification loss: 0.00688 | Regression loss: 0.01480 | Objectness loss: 0.00016 | RPN Regression loss: 0.00092 | Running loss: 0.02277\n","Epoch: 9 | Iteration: 31466 | Classification loss: 0.00842 | Regression loss: 0.01853 | Objectness loss: 0.00030 | RPN Regression loss: 0.00086 | Running loss: 0.02810\n","Epoch: 9 | Iteration: 31467 | Classification loss: 0.01116 | Regression loss: 0.03267 | Objectness loss: 0.00048 | RPN Regression loss: 0.00186 | Running loss: 0.04617\n","Epoch: 9 | Iteration: 31468 | Classification loss: 0.02331 | Regression loss: 0.01790 | Objectness loss: 0.00019 | RPN Regression loss: 0.00025 | Running loss: 0.04165\n","Epoch: 9 | Iteration: 31469 | Classification loss: 0.01606 | Regression loss: 0.02444 | Objectness loss: 0.00043 | RPN Regression loss: 0.00312 | Running loss: 0.04405\n","Epoch: 9 | Iteration: 31470 | Classification loss: 0.03025 | Regression loss: 0.03952 | Objectness loss: 0.00133 | RPN Regression loss: 0.00169 | Running loss: 0.07279\n","Epoch: 9 | Iteration: 31471 | Classification loss: 0.01692 | Regression loss: 0.02737 | Objectness loss: 0.00035 | RPN Regression loss: 0.00250 | Running loss: 0.04713\n","Epoch: 9 | Iteration: 31472 | Classification loss: 0.01916 | Regression loss: 0.02084 | Objectness loss: 0.00025 | RPN Regression loss: 0.00085 | Running loss: 0.04109\n","Epoch: 9 | Iteration: 31473 | Classification loss: 0.00789 | Regression loss: 0.01369 | Objectness loss: 0.00036 | RPN Regression loss: 0.00144 | Running loss: 0.02338\n","Epoch: 9 | Iteration: 31474 | Classification loss: 0.01728 | Regression loss: 0.02313 | Objectness loss: 0.00054 | RPN Regression loss: 0.00171 | Running loss: 0.04266\n","Epoch: 9 | Iteration: 31475 | Classification loss: 0.01223 | Regression loss: 0.02507 | Objectness loss: 0.00011 | RPN Regression loss: 0.00188 | Running loss: 0.03930\n","Epoch: 9 | Iteration: 31476 | Classification loss: 0.02066 | Regression loss: 0.03245 | Objectness loss: 0.00024 | RPN Regression loss: 0.00237 | Running loss: 0.05572\n","Epoch: 9 | Iteration: 31477 | Classification loss: 0.01505 | Regression loss: 0.02060 | Objectness loss: 0.00503 | RPN Regression loss: 0.00957 | Running loss: 0.05024\n","Epoch: 9 | Iteration: 31478 | Classification loss: 0.00566 | Regression loss: 0.01313 | Objectness loss: 0.00008 | RPN Regression loss: 0.00218 | Running loss: 0.02105\n","Epoch: 9 | Iteration: 31479 | Classification loss: 0.01949 | Regression loss: 0.01965 | Objectness loss: 0.00014 | RPN Regression loss: 0.00120 | Running loss: 0.04048\n","Epoch: 9 | Iteration: 31480 | Classification loss: 0.02234 | Regression loss: 0.02409 | Objectness loss: 0.00189 | RPN Regression loss: 0.00123 | Running loss: 0.04955\n","Epoch: 9 | Iteration: 31481 | Classification loss: 0.02066 | Regression loss: 0.01944 | Objectness loss: 0.00467 | RPN Regression loss: 0.00113 | Running loss: 0.04591\n","Epoch: 9 | Iteration: 31482 | Classification loss: 0.02165 | Regression loss: 0.02341 | Objectness loss: 0.00007 | RPN Regression loss: 0.00053 | Running loss: 0.04567\n","Epoch: 9 | Iteration: 31483 | Classification loss: 0.02425 | Regression loss: 0.02055 | Objectness loss: 0.00013 | RPN Regression loss: 0.00051 | Running loss: 0.04544\n","Epoch: 9 | Iteration: 31484 | Classification loss: 0.01458 | Regression loss: 0.02226 | Objectness loss: 0.00025 | RPN Regression loss: 0.00238 | Running loss: 0.03948\n","Epoch: 9 | Iteration: 31485 | Classification loss: 0.03129 | Regression loss: 0.02000 | Objectness loss: 0.00007 | RPN Regression loss: 0.00085 | Running loss: 0.05220\n","Epoch: 9 | Iteration: 31486 | Classification loss: 0.01660 | Regression loss: 0.01662 | Objectness loss: 0.00003 | RPN Regression loss: 0.00099 | Running loss: 0.03424\n","Epoch: 9 | Iteration: 31487 | Classification loss: 0.01020 | Regression loss: 0.02002 | Objectness loss: 0.00008 | RPN Regression loss: 0.00052 | Running loss: 0.03081\n","Epoch: 9 | Iteration: 31488 | Classification loss: 0.01182 | Regression loss: 0.02935 | Objectness loss: 0.00005 | RPN Regression loss: 0.00099 | Running loss: 0.04221\n","Epoch: 9 | Iteration: 31489 | Classification loss: 0.02003 | Regression loss: 0.02542 | Objectness loss: 0.00003 | RPN Regression loss: 0.00048 | Running loss: 0.04596\n","Epoch: 9 | Iteration: 31490 | Classification loss: 0.02816 | Regression loss: 0.02620 | Objectness loss: 0.00052 | RPN Regression loss: 0.00108 | Running loss: 0.05596\n","Epoch: 9 | Iteration: 31491 | Classification loss: 0.01070 | Regression loss: 0.02744 | Objectness loss: 0.00010 | RPN Regression loss: 0.00076 | Running loss: 0.03900\n","Epoch: 9 | Iteration: 31492 | Classification loss: 0.01225 | Regression loss: 0.04310 | Objectness loss: 0.00003 | RPN Regression loss: 0.00053 | Running loss: 0.05591\n","Epoch: 9 | Iteration: 31493 | Classification loss: 0.01472 | Regression loss: 0.01217 | Objectness loss: 0.00070 | RPN Regression loss: 0.00448 | Running loss: 0.03207\n","Epoch: 9 | Iteration: 31494 | Classification loss: 0.01194 | Regression loss: 0.02359 | Objectness loss: 0.00003 | RPN Regression loss: 0.00107 | Running loss: 0.03663\n","Epoch: 9 | Iteration: 31495 | Classification loss: 0.01034 | Regression loss: 0.01979 | Objectness loss: 0.00022 | RPN Regression loss: 0.00373 | Running loss: 0.03408\n","Epoch: 9 | Iteration: 31496 | Classification loss: 0.01042 | Regression loss: 0.01596 | Objectness loss: 0.00008 | RPN Regression loss: 0.00190 | Running loss: 0.02837\n","Epoch: 9 | Iteration: 31497 | Classification loss: 0.00593 | Regression loss: 0.02053 | Objectness loss: 0.00379 | RPN Regression loss: 0.00277 | Running loss: 0.03302\n","Epoch: 9 | Iteration: 31498 | Classification loss: 0.03536 | Regression loss: 0.02985 | Objectness loss: 0.00223 | RPN Regression loss: 0.00936 | Running loss: 0.07680\n","Epoch: 9 | Iteration: 31499 | Classification loss: 0.01135 | Regression loss: 0.02078 | Objectness loss: 0.00007 | RPN Regression loss: 0.00035 | Running loss: 0.03255\n","Epoch: 9 | Iteration: 31500 | Classification loss: 0.00894 | Regression loss: 0.01479 | Objectness loss: 0.00310 | RPN Regression loss: 0.00070 | Running loss: 0.02753\n","Epoch: 9 | Iteration: 31501 | Classification loss: 0.01304 | Regression loss: 0.01968 | Objectness loss: 0.00027 | RPN Regression loss: 0.00147 | Running loss: 0.03446\n","Epoch: 9 | Iteration: 31502 | Classification loss: 0.02173 | Regression loss: 0.02163 | Objectness loss: 0.00056 | RPN Regression loss: 0.00124 | Running loss: 0.04517\n","Epoch: 9 | Iteration: 31503 | Classification loss: 0.01525 | Regression loss: 0.01952 | Objectness loss: 0.00005 | RPN Regression loss: 0.00042 | Running loss: 0.03523\n","Epoch: 9 | Iteration: 31504 | Classification loss: 0.03024 | Regression loss: 0.01970 | Objectness loss: 0.00014 | RPN Regression loss: 0.00073 | Running loss: 0.05081\n","Epoch: 9 | Iteration: 31505 | Classification loss: 0.00857 | Regression loss: 0.01452 | Objectness loss: 0.00011 | RPN Regression loss: 0.00041 | Running loss: 0.02361\n","Epoch: 9 | Iteration: 31506 | Classification loss: 0.01614 | Regression loss: 0.04476 | Objectness loss: 0.00006 | RPN Regression loss: 0.00133 | Running loss: 0.06230\n","Epoch: 9 | Iteration: 31507 | Classification loss: 0.00694 | Regression loss: 0.01398 | Objectness loss: 0.00012 | RPN Regression loss: 0.00076 | Running loss: 0.02179\n","Epoch: 9 | Iteration: 31508 | Classification loss: 0.01472 | Regression loss: 0.02078 | Objectness loss: 0.00034 | RPN Regression loss: 0.01466 | Running loss: 0.05050\n","Epoch: 9 | Iteration: 31509 | Classification loss: 0.01114 | Regression loss: 0.00937 | Objectness loss: 0.00002 | RPN Regression loss: 0.00050 | Running loss: 0.02103\n","Epoch: 9 | Iteration: 31510 | Classification loss: 0.04878 | Regression loss: 0.02690 | Objectness loss: 0.00301 | RPN Regression loss: 0.00070 | Running loss: 0.07939\n","Epoch: 9 | Iteration: 31511 | Classification loss: 0.01669 | Regression loss: 0.01463 | Objectness loss: 0.00021 | RPN Regression loss: 0.00374 | Running loss: 0.03527\n","Epoch: 9 | Iteration: 31512 | Classification loss: 0.02152 | Regression loss: 0.04131 | Objectness loss: 0.00028 | RPN Regression loss: 0.00097 | Running loss: 0.06408\n","Epoch: 9 | Iteration: 31513 | Classification loss: 0.00788 | Regression loss: 0.01756 | Objectness loss: 0.00020 | RPN Regression loss: 0.00296 | Running loss: 0.02860\n","Epoch: 9 | Iteration: 31514 | Classification loss: 0.02089 | Regression loss: 0.02639 | Objectness loss: 0.00003 | RPN Regression loss: 0.00139 | Running loss: 0.04870\n","Epoch: 9 | Iteration: 31515 | Classification loss: 0.02833 | Regression loss: 0.04537 | Objectness loss: 0.00002 | RPN Regression loss: 0.00128 | Running loss: 0.07501\n","Epoch: 9 | Iteration: 31516 | Classification loss: 0.02421 | Regression loss: 0.02067 | Objectness loss: 0.00055 | RPN Regression loss: 0.00082 | Running loss: 0.04626\n","Epoch: 9 | Iteration: 31517 | Classification loss: 0.00663 | Regression loss: 0.01242 | Objectness loss: 0.00016 | RPN Regression loss: 0.00103 | Running loss: 0.02024\n","Epoch: 9 | Iteration: 31518 | Classification loss: 0.00809 | Regression loss: 0.01457 | Objectness loss: 0.00007 | RPN Regression loss: 0.00058 | Running loss: 0.02331\n","Epoch: 9 | Iteration: 31519 | Classification loss: 0.02000 | Regression loss: 0.02038 | Objectness loss: 0.00034 | RPN Regression loss: 0.00230 | Running loss: 0.04302\n","Epoch: 9 | Iteration: 31520 | Classification loss: 0.01484 | Regression loss: 0.02926 | Objectness loss: 0.00314 | RPN Regression loss: 0.00267 | Running loss: 0.04991\n","Epoch: 9 | Iteration: 31521 | Classification loss: 0.02179 | Regression loss: 0.03801 | Objectness loss: 0.00176 | RPN Regression loss: 0.00100 | Running loss: 0.06256\n","Epoch: 9 | Iteration: 31522 | Classification loss: 0.01514 | Regression loss: 0.01632 | Objectness loss: 0.00026 | RPN Regression loss: 0.00041 | Running loss: 0.03213\n","Epoch: 9 | Iteration: 31523 | Classification loss: 0.02851 | Regression loss: 0.06092 | Objectness loss: 0.00233 | RPN Regression loss: 0.00338 | Running loss: 0.09514\n","Epoch: 9 | Iteration: 31524 | Classification loss: 0.02040 | Regression loss: 0.03475 | Objectness loss: 0.00078 | RPN Regression loss: 0.00205 | Running loss: 0.05798\n","Epoch: 9 | Iteration: 31525 | Classification loss: 0.01117 | Regression loss: 0.01981 | Objectness loss: 0.00327 | RPN Regression loss: 0.00483 | Running loss: 0.03907\n","Epoch: 9 | Iteration: 31526 | Classification loss: 0.00580 | Regression loss: 0.02637 | Objectness loss: 0.00018 | RPN Regression loss: 0.00159 | Running loss: 0.03395\n","Epoch: 9 | Iteration: 31527 | Classification loss: 0.02311 | Regression loss: 0.01545 | Objectness loss: 0.00011 | RPN Regression loss: 0.00123 | Running loss: 0.03989\n","Epoch: 9 | Iteration: 31528 | Classification loss: 0.01508 | Regression loss: 0.01890 | Objectness loss: 0.00022 | RPN Regression loss: 0.00046 | Running loss: 0.03466\n","Epoch: 9 | Iteration: 31529 | Classification loss: 0.00861 | Regression loss: 0.01773 | Objectness loss: 0.00049 | RPN Regression loss: 0.00380 | Running loss: 0.03063\n","Epoch: 9 | Iteration: 31530 | Classification loss: 0.01619 | Regression loss: 0.03490 | Objectness loss: 0.00682 | RPN Regression loss: 0.00488 | Running loss: 0.06279\n","Epoch: 9 | Iteration: 31531 | Classification loss: 0.03319 | Regression loss: 0.01876 | Objectness loss: 0.00409 | RPN Regression loss: 0.00571 | Running loss: 0.06176\n","Epoch: 9 | Iteration: 31532 | Classification loss: 0.02200 | Regression loss: 0.03954 | Objectness loss: 0.00090 | RPN Regression loss: 0.00483 | Running loss: 0.06726\n","Epoch: 9 | Iteration: 31533 | Classification loss: 0.01408 | Regression loss: 0.03938 | Objectness loss: 0.00048 | RPN Regression loss: 0.00136 | Running loss: 0.05530\n","Epoch: 9 | Iteration: 31534 | Classification loss: 0.00838 | Regression loss: 0.01930 | Objectness loss: 0.00127 | RPN Regression loss: 0.00082 | Running loss: 0.02978\n","Epoch: 9 | Iteration: 31535 | Classification loss: 0.01229 | Regression loss: 0.02314 | Objectness loss: 0.00005 | RPN Regression loss: 0.00142 | Running loss: 0.03691\n","Epoch: 9 | Iteration: 31536 | Classification loss: 0.00910 | Regression loss: 0.01655 | Objectness loss: 0.00118 | RPN Regression loss: 0.00039 | Running loss: 0.02723\n","Epoch: 9 | Iteration: 31537 | Classification loss: 0.00740 | Regression loss: 0.01168 | Objectness loss: 0.00059 | RPN Regression loss: 0.00161 | Running loss: 0.02128\n","Epoch: 9 | Iteration: 31538 | Classification loss: 0.01698 | Regression loss: 0.01694 | Objectness loss: 0.00005 | RPN Regression loss: 0.00070 | Running loss: 0.03468\n","Epoch: 9 | Iteration: 31539 | Classification loss: 0.01300 | Regression loss: 0.03124 | Objectness loss: 0.00006 | RPN Regression loss: 0.00114 | Running loss: 0.04544\n","Epoch: 9 | Iteration: 31540 | Classification loss: 0.04863 | Regression loss: 0.02815 | Objectness loss: 0.00038 | RPN Regression loss: 0.00056 | Running loss: 0.07772\n","Epoch: 9 | Iteration: 31541 | Classification loss: 0.01488 | Regression loss: 0.02018 | Objectness loss: 0.00259 | RPN Regression loss: 0.00188 | Running loss: 0.03953\n","Epoch: 9 | Iteration: 31542 | Classification loss: 0.00937 | Regression loss: 0.02125 | Objectness loss: 0.00025 | RPN Regression loss: 0.00107 | Running loss: 0.03195\n","Epoch: 9 | Iteration: 31543 | Classification loss: 0.02290 | Regression loss: 0.03920 | Objectness loss: 0.00015 | RPN Regression loss: 0.00187 | Running loss: 0.06412\n","Epoch: 9 | Iteration: 31544 | Classification loss: 0.01219 | Regression loss: 0.01732 | Objectness loss: 0.00125 | RPN Regression loss: 0.00053 | Running loss: 0.03130\n","Epoch: 9 | Iteration: 31545 | Classification loss: 0.02586 | Regression loss: 0.03045 | Objectness loss: 0.00005 | RPN Regression loss: 0.00227 | Running loss: 0.05863\n","Epoch: 9 | Iteration: 31546 | Classification loss: 0.01742 | Regression loss: 0.01740 | Objectness loss: 0.00004 | RPN Regression loss: 0.00143 | Running loss: 0.03628\n","Epoch: 9 | Iteration: 31547 | Classification loss: 0.01150 | Regression loss: 0.02254 | Objectness loss: 0.00002 | RPN Regression loss: 0.00176 | Running loss: 0.03582\n","Epoch: 9 | Iteration: 31548 | Classification loss: 0.00848 | Regression loss: 0.01677 | Objectness loss: 0.00008 | RPN Regression loss: 0.00222 | Running loss: 0.02754\n","Epoch: 9 | Iteration: 31549 | Classification loss: 0.01898 | Regression loss: 0.02422 | Objectness loss: 0.00161 | RPN Regression loss: 0.00176 | Running loss: 0.04657\n","Epoch: 9 | Iteration: 31550 | Classification loss: 0.01375 | Regression loss: 0.01571 | Objectness loss: 0.00226 | RPN Regression loss: 0.00146 | Running loss: 0.03318\n","Epoch: 9 | Iteration: 31551 | Classification loss: 0.01047 | Regression loss: 0.02037 | Objectness loss: 0.00022 | RPN Regression loss: 0.00248 | Running loss: 0.03353\n","Epoch: 9 | Iteration: 31552 | Classification loss: 0.01070 | Regression loss: 0.01293 | Objectness loss: 0.00048 | RPN Regression loss: 0.00140 | Running loss: 0.02552\n","Epoch: 9 | Iteration: 31553 | Classification loss: 0.01679 | Regression loss: 0.01971 | Objectness loss: 0.00010 | RPN Regression loss: 0.00151 | Running loss: 0.03811\n","Epoch: 9 | Iteration: 31554 | Classification loss: 0.01374 | Regression loss: 0.02176 | Objectness loss: 0.00006 | RPN Regression loss: 0.00130 | Running loss: 0.03686\n","Epoch: 9 | Iteration: 31555 | Classification loss: 0.00545 | Regression loss: 0.01080 | Objectness loss: 0.00047 | RPN Regression loss: 0.00052 | Running loss: 0.01725\n","Epoch: 9 | Iteration: 31556 | Classification loss: 0.00704 | Regression loss: 0.02152 | Objectness loss: 0.00162 | RPN Regression loss: 0.00608 | Running loss: 0.03626\n","Epoch: 9 | Iteration: 31557 | Classification loss: 0.00943 | Regression loss: 0.01841 | Objectness loss: 0.00163 | RPN Regression loss: 0.00080 | Running loss: 0.03027\n","Epoch: 9 | Iteration: 31558 | Classification loss: 0.00635 | Regression loss: 0.01416 | Objectness loss: 0.00031 | RPN Regression loss: 0.00056 | Running loss: 0.02137\n","Epoch: 9 | Iteration: 31559 | Classification loss: 0.02019 | Regression loss: 0.04094 | Objectness loss: 0.00077 | RPN Regression loss: 0.00181 | Running loss: 0.06371\n","Epoch: 9 | Iteration: 31560 | Classification loss: 0.01466 | Regression loss: 0.02078 | Objectness loss: 0.00012 | RPN Regression loss: 0.00069 | Running loss: 0.03625\n","Epoch: 9 | Iteration: 31561 | Classification loss: 0.01049 | Regression loss: 0.02921 | Objectness loss: 0.00083 | RPN Regression loss: 0.00151 | Running loss: 0.04204\n","Epoch: 9 | Iteration: 31562 | Classification loss: 0.01058 | Regression loss: 0.01566 | Objectness loss: 0.00048 | RPN Regression loss: 0.00337 | Running loss: 0.03008\n","Epoch: 9 | Iteration: 31563 | Classification loss: 0.01160 | Regression loss: 0.01984 | Objectness loss: 0.00023 | RPN Regression loss: 0.00186 | Running loss: 0.03352\n","Epoch: 9 | Iteration: 31564 | Classification loss: 0.02139 | Regression loss: 0.03185 | Objectness loss: 0.00014 | RPN Regression loss: 0.00079 | Running loss: 0.05417\n","Epoch: 9 | Iteration: 31565 | Classification loss: 0.01388 | Regression loss: 0.02828 | Objectness loss: 0.00009 | RPN Regression loss: 0.00280 | Running loss: 0.04504\n","Epoch: 9 | Iteration: 31566 | Classification loss: 0.04543 | Regression loss: 0.04745 | Objectness loss: 0.00281 | RPN Regression loss: 0.00206 | Running loss: 0.09775\n","Epoch: 9 | Iteration: 31567 | Classification loss: 0.02953 | Regression loss: 0.04657 | Objectness loss: 0.00014 | RPN Regression loss: 0.00132 | Running loss: 0.07756\n","Epoch: 9 | Iteration: 31568 | Classification loss: 0.01316 | Regression loss: 0.02659 | Objectness loss: 0.00001 | RPN Regression loss: 0.00052 | Running loss: 0.04027\n","Epoch: 9 | Iteration: 31569 | Classification loss: 0.01097 | Regression loss: 0.02180 | Objectness loss: 0.00156 | RPN Regression loss: 0.00176 | Running loss: 0.03609\n","Epoch: 9 | Iteration: 31570 | Classification loss: 0.00865 | Regression loss: 0.02094 | Objectness loss: 0.00008 | RPN Regression loss: 0.00055 | Running loss: 0.03022\n","Epoch: 9 | Iteration: 31571 | Classification loss: 0.00823 | Regression loss: 0.02443 | Objectness loss: 0.00014 | RPN Regression loss: 0.00082 | Running loss: 0.03362\n","Epoch: 9 | Iteration: 31572 | Classification loss: 0.01440 | Regression loss: 0.02633 | Objectness loss: 0.00002 | RPN Regression loss: 0.00046 | Running loss: 0.04121\n","Epoch: 9 | Iteration: 31573 | Classification loss: 0.01522 | Regression loss: 0.02056 | Objectness loss: 0.00315 | RPN Regression loss: 0.00200 | Running loss: 0.04092\n","Epoch: 9 | Iteration: 31574 | Classification loss: 0.01585 | Regression loss: 0.02102 | Objectness loss: 0.00010 | RPN Regression loss: 0.00100 | Running loss: 0.03797\n","Epoch: 9 | Iteration: 31575 | Classification loss: 0.03193 | Regression loss: 0.02019 | Objectness loss: 0.00001 | RPN Regression loss: 0.00066 | Running loss: 0.05279\n","Epoch: 9 | Iteration: 31576 | Classification loss: 0.01402 | Regression loss: 0.02430 | Objectness loss: 0.00008 | RPN Regression loss: 0.00059 | Running loss: 0.03899\n","Epoch: 9 | Iteration: 31577 | Classification loss: 0.01819 | Regression loss: 0.03545 | Objectness loss: 0.00533 | RPN Regression loss: 0.00207 | Running loss: 0.06105\n","Epoch: 9 | Iteration: 31578 | Classification loss: 0.00690 | Regression loss: 0.02049 | Objectness loss: 0.00015 | RPN Regression loss: 0.00160 | Running loss: 0.02914\n","Epoch: 9 | Iteration: 31579 | Classification loss: 0.03004 | Regression loss: 0.01852 | Objectness loss: 0.00008 | RPN Regression loss: 0.00134 | Running loss: 0.04998\n","Epoch: 9 | Iteration: 31580 | Classification loss: 0.01008 | Regression loss: 0.01607 | Objectness loss: 0.00049 | RPN Regression loss: 0.00077 | Running loss: 0.02742\n","Epoch: 9 | Iteration: 31581 | Classification loss: 0.00812 | Regression loss: 0.01424 | Objectness loss: 0.00034 | RPN Regression loss: 0.00097 | Running loss: 0.02367\n","Epoch: 9 | Iteration: 31582 | Classification loss: 0.00989 | Regression loss: 0.02036 | Objectness loss: 0.00022 | RPN Regression loss: 0.00317 | Running loss: 0.03363\n","Epoch: 9 | Iteration: 31583 | Classification loss: 0.00576 | Regression loss: 0.02001 | Objectness loss: 0.00049 | RPN Regression loss: 0.00230 | Running loss: 0.02856\n","Epoch: 9 | Iteration: 31584 | Classification loss: 0.00587 | Regression loss: 0.01077 | Objectness loss: 0.00010 | RPN Regression loss: 0.00147 | Running loss: 0.01821\n","Epoch: 9 | Iteration: 31585 | Classification loss: 0.00651 | Regression loss: 0.01734 | Objectness loss: 0.00026 | RPN Regression loss: 0.00067 | Running loss: 0.02478\n","Epoch: 9 | Iteration: 31586 | Classification loss: 0.01997 | Regression loss: 0.03608 | Objectness loss: 0.00152 | RPN Regression loss: 0.00129 | Running loss: 0.05886\n","Epoch: 9 | Iteration: 31587 | Classification loss: 0.00793 | Regression loss: 0.01224 | Objectness loss: 0.00010 | RPN Regression loss: 0.00088 | Running loss: 0.02115\n","Epoch: 9 | Iteration: 31588 | Classification loss: 0.00623 | Regression loss: 0.01208 | Objectness loss: 0.00016 | RPN Regression loss: 0.00371 | Running loss: 0.02219\n","Epoch: 9 | Iteration: 31589 | Classification loss: 0.01002 | Regression loss: 0.00712 | Objectness loss: 0.00067 | RPN Regression loss: 0.00118 | Running loss: 0.01898\n","Epoch: 9 | Iteration: 31590 | Classification loss: 0.00735 | Regression loss: 0.01160 | Objectness loss: 0.00041 | RPN Regression loss: 0.00084 | Running loss: 0.02020\n","Epoch: 9 | Iteration: 31591 | Classification loss: 0.00454 | Regression loss: 0.01772 | Objectness loss: 0.00006 | RPN Regression loss: 0.00038 | Running loss: 0.02271\n","Epoch: 9 | Iteration: 31592 | Classification loss: 0.01626 | Regression loss: 0.04414 | Objectness loss: 0.00002 | RPN Regression loss: 0.00105 | Running loss: 0.06147\n","Epoch: 9 | Iteration: 31593 | Classification loss: 0.00961 | Regression loss: 0.02137 | Objectness loss: 0.00006 | RPN Regression loss: 0.00198 | Running loss: 0.03302\n","Epoch: 9 | Iteration: 31594 | Classification loss: 0.03017 | Regression loss: 0.03271 | Objectness loss: 0.04501 | RPN Regression loss: 0.01486 | Running loss: 0.12276\n","Epoch: 9 | Iteration: 31595 | Classification loss: 0.01268 | Regression loss: 0.03034 | Objectness loss: 0.00033 | RPN Regression loss: 0.00364 | Running loss: 0.04699\n","Epoch: 9 | Iteration: 31596 | Classification loss: 0.01432 | Regression loss: 0.02877 | Objectness loss: 0.00004 | RPN Regression loss: 0.00127 | Running loss: 0.04439\n","Epoch: 9 | Iteration: 31597 | Classification loss: 0.00905 | Regression loss: 0.01961 | Objectness loss: 0.00166 | RPN Regression loss: 0.00197 | Running loss: 0.03229\n","Epoch: 9 | Iteration: 31598 | Classification loss: 0.02017 | Regression loss: 0.01562 | Objectness loss: 0.00371 | RPN Regression loss: 0.00090 | Running loss: 0.04040\n","Epoch: 9 | Iteration: 31599 | Classification loss: 0.00668 | Regression loss: 0.01821 | Objectness loss: 0.00005 | RPN Regression loss: 0.00101 | Running loss: 0.02595\n","Epoch: 9 | Iteration: 31600 | Classification loss: 0.02380 | Regression loss: 0.03439 | Objectness loss: 0.00667 | RPN Regression loss: 0.00385 | Running loss: 0.06871\n","Epoch: 9 | Iteration: 31601 | Classification loss: 0.00901 | Regression loss: 0.01316 | Objectness loss: 0.00028 | RPN Regression loss: 0.00088 | Running loss: 0.02333\n","Epoch: 9 | Iteration: 31602 | Classification loss: 0.00901 | Regression loss: 0.01825 | Objectness loss: 0.00019 | RPN Regression loss: 0.00055 | Running loss: 0.02799\n","Epoch: 9 | Iteration: 31603 | Classification loss: 0.01087 | Regression loss: 0.02425 | Objectness loss: 0.00192 | RPN Regression loss: 0.00081 | Running loss: 0.03785\n","Epoch: 9 | Iteration: 31604 | Classification loss: 0.02619 | Regression loss: 0.03365 | Objectness loss: 0.00204 | RPN Regression loss: 0.00112 | Running loss: 0.06300\n","Epoch: 9 | Iteration: 31605 | Classification loss: 0.03060 | Regression loss: 0.02071 | Objectness loss: 0.00050 | RPN Regression loss: 0.00239 | Running loss: 0.05419\n","Epoch: 9 | Iteration: 31606 | Classification loss: 0.00582 | Regression loss: 0.01175 | Objectness loss: 0.00019 | RPN Regression loss: 0.00078 | Running loss: 0.01853\n","Epoch: 9 | Iteration: 31607 | Classification loss: 0.01480 | Regression loss: 0.03372 | Objectness loss: 0.00348 | RPN Regression loss: 0.00569 | Running loss: 0.05769\n","Epoch: 9 | Iteration: 31608 | Classification loss: 0.01317 | Regression loss: 0.02075 | Objectness loss: 0.00125 | RPN Regression loss: 0.00152 | Running loss: 0.03669\n","Epoch: 9 | Iteration: 31609 | Classification loss: 0.01906 | Regression loss: 0.01967 | Objectness loss: 0.00199 | RPN Regression loss: 0.00208 | Running loss: 0.04281\n","Epoch: 9 | Iteration: 31610 | Classification loss: 0.02111 | Regression loss: 0.04982 | Objectness loss: 0.00013 | RPN Regression loss: 0.00320 | Running loss: 0.07426\n","Epoch: 9 | Iteration: 31611 | Classification loss: 0.02180 | Regression loss: 0.02617 | Objectness loss: 0.00193 | RPN Regression loss: 0.00056 | Running loss: 0.05047\n","Epoch: 9 | Iteration: 31612 | Classification loss: 0.00888 | Regression loss: 0.02415 | Objectness loss: 0.00046 | RPN Regression loss: 0.00096 | Running loss: 0.03446\n","Epoch: 9 | Iteration: 31613 | Classification loss: 0.01469 | Regression loss: 0.01660 | Objectness loss: 0.00031 | RPN Regression loss: 0.00108 | Running loss: 0.03268\n","Epoch: 9 | Iteration: 31614 | Classification loss: 0.01124 | Regression loss: 0.04194 | Objectness loss: 0.00187 | RPN Regression loss: 0.00070 | Running loss: 0.05574\n","Epoch: 9 | Iteration: 31615 | Classification loss: 0.01397 | Regression loss: 0.02296 | Objectness loss: 0.00042 | RPN Regression loss: 0.00108 | Running loss: 0.03843\n","Epoch: 9 | Iteration: 31616 | Classification loss: 0.01223 | Regression loss: 0.01182 | Objectness loss: 0.00047 | RPN Regression loss: 0.00389 | Running loss: 0.02841\n","Epoch: 9 | Iteration: 31617 | Classification loss: 0.00669 | Regression loss: 0.01466 | Objectness loss: 0.00115 | RPN Regression loss: 0.00048 | Running loss: 0.02298\n","Epoch: 9 | Iteration: 31618 | Classification loss: 0.01531 | Regression loss: 0.02852 | Objectness loss: 0.00034 | RPN Regression loss: 0.00076 | Running loss: 0.04493\n","Epoch: 9 | Iteration: 31619 | Classification loss: 0.02117 | Regression loss: 0.02038 | Objectness loss: 0.00039 | RPN Regression loss: 0.00152 | Running loss: 0.04346\n","Epoch: 9 | Iteration: 31620 | Classification loss: 0.01583 | Regression loss: 0.01407 | Objectness loss: 0.00007 | RPN Regression loss: 0.00422 | Running loss: 0.03419\n","Epoch: 9 | Iteration: 31621 | Classification loss: 0.01538 | Regression loss: 0.01925 | Objectness loss: 0.00044 | RPN Regression loss: 0.00094 | Running loss: 0.03601\n","Epoch: 9 | Iteration: 31622 | Classification loss: 0.01845 | Regression loss: 0.01438 | Objectness loss: 0.00090 | RPN Regression loss: 0.00068 | Running loss: 0.03441\n","Epoch: 9 | Iteration: 31623 | Classification loss: 0.01810 | Regression loss: 0.03125 | Objectness loss: 0.00351 | RPN Regression loss: 0.01760 | Running loss: 0.07046\n","Epoch: 9 | Iteration: 31624 | Classification loss: 0.03077 | Regression loss: 0.03861 | Objectness loss: 0.00103 | RPN Regression loss: 0.00269 | Running loss: 0.07309\n","Epoch: 9 | Iteration: 31625 | Classification loss: 0.01515 | Regression loss: 0.01538 | Objectness loss: 0.00005 | RPN Regression loss: 0.00068 | Running loss: 0.03126\n","Epoch: 9 | Iteration: 31626 | Classification loss: 0.03202 | Regression loss: 0.02805 | Objectness loss: 0.00006 | RPN Regression loss: 0.00117 | Running loss: 0.06131\n","Epoch: 9 | Iteration: 31627 | Classification loss: 0.02209 | Regression loss: 0.02376 | Objectness loss: 0.00016 | RPN Regression loss: 0.00215 | Running loss: 0.04816\n","Epoch: 9 | Iteration: 31628 | Classification loss: 0.01926 | Regression loss: 0.01655 | Objectness loss: 0.00115 | RPN Regression loss: 0.00088 | Running loss: 0.03785\n","Epoch: 9 | Iteration: 31629 | Classification loss: 0.00639 | Regression loss: 0.01916 | Objectness loss: 0.00303 | RPN Regression loss: 0.00299 | Running loss: 0.03157\n","Epoch: 9 | Iteration: 31630 | Classification loss: 0.01969 | Regression loss: 0.04126 | Objectness loss: 0.00019 | RPN Regression loss: 0.00064 | Running loss: 0.06178\n","Epoch: 9 | Iteration: 31631 | Classification loss: 0.00581 | Regression loss: 0.01207 | Objectness loss: 0.00016 | RPN Regression loss: 0.00307 | Running loss: 0.02111\n","Epoch: 9 | Iteration: 31632 | Classification loss: 0.02008 | Regression loss: 0.03554 | Objectness loss: 0.00003 | RPN Regression loss: 0.00056 | Running loss: 0.05621\n","Epoch: 9 | Iteration: 31633 | Classification loss: 0.02714 | Regression loss: 0.03784 | Objectness loss: 0.00225 | RPN Regression loss: 0.00197 | Running loss: 0.06921\n","Epoch: 9 | Iteration: 31634 | Classification loss: 0.00923 | Regression loss: 0.02320 | Objectness loss: 0.00001 | RPN Regression loss: 0.00093 | Running loss: 0.03338\n","Epoch: 9 | Iteration: 31635 | Classification loss: 0.00823 | Regression loss: 0.02731 | Objectness loss: 0.00049 | RPN Regression loss: 0.00388 | Running loss: 0.03992\n","Epoch: 9 | Iteration: 31636 | Classification loss: 0.01695 | Regression loss: 0.01797 | Objectness loss: 0.00013 | RPN Regression loss: 0.00052 | Running loss: 0.03558\n","Epoch: 9 | Iteration: 31637 | Classification loss: 0.01888 | Regression loss: 0.01939 | Objectness loss: 0.00008 | RPN Regression loss: 0.00069 | Running loss: 0.03904\n","Epoch: 9 | Iteration: 31638 | Classification loss: 0.01881 | Regression loss: 0.02360 | Objectness loss: 0.00005 | RPN Regression loss: 0.00158 | Running loss: 0.04403\n","Epoch: 9 | Iteration: 31639 | Classification loss: 0.00785 | Regression loss: 0.01992 | Objectness loss: 0.00009 | RPN Regression loss: 0.00057 | Running loss: 0.02843\n","Epoch: 9 | Iteration: 31640 | Classification loss: 0.00956 | Regression loss: 0.02360 | Objectness loss: 0.00044 | RPN Regression loss: 0.00180 | Running loss: 0.03540\n","Epoch: 9 | Iteration: 31641 | Classification loss: 0.01115 | Regression loss: 0.01972 | Objectness loss: 0.00007 | RPN Regression loss: 0.00102 | Running loss: 0.03196\n","Epoch: 9 | Iteration: 31642 | Classification loss: 0.00889 | Regression loss: 0.02290 | Objectness loss: 0.00023 | RPN Regression loss: 0.00248 | Running loss: 0.03451\n","Epoch: 9 | Iteration: 31643 | Classification loss: 0.01153 | Regression loss: 0.03464 | Objectness loss: 0.00004 | RPN Regression loss: 0.00065 | Running loss: 0.04685\n","Epoch: 9 | Iteration: 31644 | Classification loss: 0.01242 | Regression loss: 0.01801 | Objectness loss: 0.00022 | RPN Regression loss: 0.00136 | Running loss: 0.03200\n","Epoch: 9 | Iteration: 31645 | Classification loss: 0.00728 | Regression loss: 0.02956 | Objectness loss: 0.00065 | RPN Regression loss: 0.00510 | Running loss: 0.04258\n","Epoch: 9 | Iteration: 31646 | Classification loss: 0.01388 | Regression loss: 0.02817 | Objectness loss: 0.00028 | RPN Regression loss: 0.00314 | Running loss: 0.04547\n","Epoch: 9 | Iteration: 31647 | Classification loss: 0.01224 | Regression loss: 0.01241 | Objectness loss: 0.00070 | RPN Regression loss: 0.00038 | Running loss: 0.02572\n","Epoch: 9 | Iteration: 31648 | Classification loss: 0.00801 | Regression loss: 0.01994 | Objectness loss: 0.00009 | RPN Regression loss: 0.00097 | Running loss: 0.02901\n","Epoch: 9 | Iteration: 31649 | Classification loss: 0.00921 | Regression loss: 0.01281 | Objectness loss: 0.00048 | RPN Regression loss: 0.00075 | Running loss: 0.02323\n","Epoch: 9 | Iteration: 31650 | Classification loss: 0.01369 | Regression loss: 0.02868 | Objectness loss: 0.00002 | RPN Regression loss: 0.00084 | Running loss: 0.04323\n","Epoch: 9 | Iteration: 31651 | Classification loss: 0.01012 | Regression loss: 0.02261 | Objectness loss: 0.00021 | RPN Regression loss: 0.00253 | Running loss: 0.03547\n","Epoch: 9 | Iteration: 31652 | Classification loss: 0.03642 | Regression loss: 0.05377 | Objectness loss: 0.00167 | RPN Regression loss: 0.00442 | Running loss: 0.09628\n","Epoch: 9 | Iteration: 31653 | Classification loss: 0.01169 | Regression loss: 0.03462 | Objectness loss: 0.00026 | RPN Regression loss: 0.00148 | Running loss: 0.04804\n","Epoch: 9 | Iteration: 31654 | Classification loss: 0.01551 | Regression loss: 0.03571 | Objectness loss: 0.00002 | RPN Regression loss: 0.00110 | Running loss: 0.05233\n","Epoch: 9 | Iteration: 31655 | Classification loss: 0.00799 | Regression loss: 0.02427 | Objectness loss: 0.00095 | RPN Regression loss: 0.00096 | Running loss: 0.03417\n","Epoch: 9 | Iteration: 31656 | Classification loss: 0.02914 | Regression loss: 0.02484 | Objectness loss: 0.00813 | RPN Regression loss: 0.00841 | Running loss: 0.07053\n","Epoch: 9 | Iteration: 31657 | Classification loss: 0.00741 | Regression loss: 0.01753 | Objectness loss: 0.00002 | RPN Regression loss: 0.00139 | Running loss: 0.02635\n","Epoch: 9 | Iteration: 31658 | Classification loss: 0.01995 | Regression loss: 0.02290 | Objectness loss: 0.01030 | RPN Regression loss: 0.00050 | Running loss: 0.05365\n","Epoch: 9 | Iteration: 31659 | Classification loss: 0.01195 | Regression loss: 0.02028 | Objectness loss: 0.00017 | RPN Regression loss: 0.00119 | Running loss: 0.03359\n","Epoch: 9 | Iteration: 31660 | Classification loss: 0.02425 | Regression loss: 0.02853 | Objectness loss: 0.00001 | RPN Regression loss: 0.00109 | Running loss: 0.05388\n","Epoch: 9 | Iteration: 31661 | Classification loss: 0.00774 | Regression loss: 0.02255 | Objectness loss: 0.00003 | RPN Regression loss: 0.00037 | Running loss: 0.03068\n","Epoch: 9 | Iteration: 31662 | Classification loss: 0.01085 | Regression loss: 0.01593 | Objectness loss: 0.00452 | RPN Regression loss: 0.00280 | Running loss: 0.03410\n","Epoch: 9 | Iteration: 31663 | Classification loss: 0.00581 | Regression loss: 0.01408 | Objectness loss: 0.00003 | RPN Regression loss: 0.00062 | Running loss: 0.02053\n","Epoch: 9 | Iteration: 31664 | Classification loss: 0.01236 | Regression loss: 0.02208 | Objectness loss: 0.00023 | RPN Regression loss: 0.00251 | Running loss: 0.03718\n","Epoch: 9 | Iteration: 31665 | Classification loss: 0.01050 | Regression loss: 0.02064 | Objectness loss: 0.00013 | RPN Regression loss: 0.00084 | Running loss: 0.03210\n","Epoch: 9 | Iteration: 31666 | Classification loss: 0.02817 | Regression loss: 0.02951 | Objectness loss: 0.00010 | RPN Regression loss: 0.00154 | Running loss: 0.05931\n","Epoch: 9 | Iteration: 31667 | Classification loss: 0.00760 | Regression loss: 0.02291 | Objectness loss: 0.00005 | RPN Regression loss: 0.00071 | Running loss: 0.03126\n","Epoch: 9 | Iteration: 31668 | Classification loss: 0.02146 | Regression loss: 0.02693 | Objectness loss: 0.00184 | RPN Regression loss: 0.00163 | Running loss: 0.05185\n","Epoch: 9 | Iteration: 31669 | Classification loss: 0.01537 | Regression loss: 0.03268 | Objectness loss: 0.00072 | RPN Regression loss: 0.00372 | Running loss: 0.05248\n","Epoch: 9 | Iteration: 31670 | Classification loss: 0.00508 | Regression loss: 0.02626 | Objectness loss: 0.00010 | RPN Regression loss: 0.00066 | Running loss: 0.03210\n","Epoch: 9 | Iteration: 31671 | Classification loss: 0.03338 | Regression loss: 0.02860 | Objectness loss: 0.00013 | RPN Regression loss: 0.00085 | Running loss: 0.06295\n","Epoch: 9 | Iteration: 31672 | Classification loss: 0.01012 | Regression loss: 0.02187 | Objectness loss: 0.00020 | RPN Regression loss: 0.00186 | Running loss: 0.03405\n","Epoch: 9 | Iteration: 31673 | Classification loss: 0.02482 | Regression loss: 0.01915 | Objectness loss: 0.00043 | RPN Regression loss: 0.00209 | Running loss: 0.04649\n","Epoch: 9 | Iteration: 31674 | Classification loss: 0.01183 | Regression loss: 0.02568 | Objectness loss: 0.00034 | RPN Regression loss: 0.00097 | Running loss: 0.03882\n","Epoch: 9 | Iteration: 31675 | Classification loss: 0.02259 | Regression loss: 0.01714 | Objectness loss: 0.00401 | RPN Regression loss: 0.00067 | Running loss: 0.04441\n","Epoch: 9 | Iteration: 31676 | Classification loss: 0.03992 | Regression loss: 0.01732 | Objectness loss: 0.00022 | RPN Regression loss: 0.00180 | Running loss: 0.05926\n","Epoch: 9 | Iteration: 31677 | Classification loss: 0.02817 | Regression loss: 0.04826 | Objectness loss: 0.00063 | RPN Regression loss: 0.00272 | Running loss: 0.07977\n","Epoch: 9 | Iteration: 31678 | Classification loss: 0.00817 | Regression loss: 0.01840 | Objectness loss: 0.00131 | RPN Regression loss: 0.00106 | Running loss: 0.02894\n","Epoch: 9 | Iteration: 31679 | Classification loss: 0.00747 | Regression loss: 0.02276 | Objectness loss: 0.00437 | RPN Regression loss: 0.00195 | Running loss: 0.03655\n","Epoch: 9 | Iteration: 31680 | Classification loss: 0.02577 | Regression loss: 0.02937 | Objectness loss: 0.00051 | RPN Regression loss: 0.00133 | Running loss: 0.05698\n","Epoch: 9 | Iteration: 31681 | Classification loss: 0.01779 | Regression loss: 0.03525 | Objectness loss: 0.00017 | RPN Regression loss: 0.00173 | Running loss: 0.05494\n","Epoch: 9 | Iteration: 31682 | Classification loss: 0.02644 | Regression loss: 0.03085 | Objectness loss: 0.00079 | RPN Regression loss: 0.00137 | Running loss: 0.05944\n","Epoch: 9 | Iteration: 31683 | Classification loss: 0.01910 | Regression loss: 0.02401 | Objectness loss: 0.00056 | RPN Regression loss: 0.00165 | Running loss: 0.04532\n","Epoch: 9 | Iteration: 31684 | Classification loss: 0.00769 | Regression loss: 0.02760 | Objectness loss: 0.00005 | RPN Regression loss: 0.00074 | Running loss: 0.03608\n","Epoch: 9 | Iteration: 31685 | Classification loss: 0.02556 | Regression loss: 0.02013 | Objectness loss: 0.00013 | RPN Regression loss: 0.00141 | Running loss: 0.04722\n","Epoch: 9 | Iteration: 31686 | Classification loss: 0.01738 | Regression loss: 0.02733 | Objectness loss: 0.00023 | RPN Regression loss: 0.00152 | Running loss: 0.04646\n","Epoch: 9 | Iteration: 31687 | Classification loss: 0.01428 | Regression loss: 0.02380 | Objectness loss: 0.00022 | RPN Regression loss: 0.00192 | Running loss: 0.04022\n","Epoch: 9 | Iteration: 31688 | Classification loss: 0.02533 | Regression loss: 0.05831 | Objectness loss: 0.00042 | RPN Regression loss: 0.00306 | Running loss: 0.08713\n","Epoch: 9 | Iteration: 31689 | Classification loss: 0.01948 | Regression loss: 0.04899 | Objectness loss: 0.02453 | RPN Regression loss: 0.00624 | Running loss: 0.09924\n","Epoch: 9 | Iteration: 31690 | Classification loss: 0.02151 | Regression loss: 0.01556 | Objectness loss: 0.00005 | RPN Regression loss: 0.00028 | Running loss: 0.03740\n","Epoch: 9 | Iteration: 31691 | Classification loss: 0.02198 | Regression loss: 0.01722 | Objectness loss: 0.00067 | RPN Regression loss: 0.00100 | Running loss: 0.04087\n","Epoch: 9 | Iteration: 31692 | Classification loss: 0.01676 | Regression loss: 0.03240 | Objectness loss: 0.00007 | RPN Regression loss: 0.00103 | Running loss: 0.05026\n","Epoch: 9 | Iteration: 31693 | Classification loss: 0.01131 | Regression loss: 0.03134 | Objectness loss: 0.00006 | RPN Regression loss: 0.00115 | Running loss: 0.04387\n","Epoch: 9 | Iteration: 31694 | Classification loss: 0.00767 | Regression loss: 0.01184 | Objectness loss: 0.00017 | RPN Regression loss: 0.00055 | Running loss: 0.02023\n","Epoch: 9 | Iteration: 31695 | Classification loss: 0.01033 | Regression loss: 0.01771 | Objectness loss: 0.00014 | RPN Regression loss: 0.00089 | Running loss: 0.02907\n","Epoch: 9 | Iteration: 31696 | Classification loss: 0.01237 | Regression loss: 0.02466 | Objectness loss: 0.00321 | RPN Regression loss: 0.00436 | Running loss: 0.04461\n","Epoch: 9 | Iteration: 31697 | Classification loss: 0.08321 | Regression loss: 0.02590 | Objectness loss: 0.00279 | RPN Regression loss: 0.00120 | Running loss: 0.11310\n","Epoch: 9 | Iteration: 31698 | Classification loss: 0.01106 | Regression loss: 0.01758 | Objectness loss: 0.00004 | RPN Regression loss: 0.00091 | Running loss: 0.02959\n","Epoch: 9 | Iteration: 31699 | Classification loss: 0.01436 | Regression loss: 0.03297 | Objectness loss: 0.00011 | RPN Regression loss: 0.00121 | Running loss: 0.04865\n","Epoch: 9 | Iteration: 31700 | Classification loss: 0.01387 | Regression loss: 0.02240 | Objectness loss: 0.00011 | RPN Regression loss: 0.00145 | Running loss: 0.03783\n","Epoch: 9 | Iteration: 31701 | Classification loss: 0.00600 | Regression loss: 0.01369 | Objectness loss: 0.00150 | RPN Regression loss: 0.00052 | Running loss: 0.02171\n","Epoch: 9 | Iteration: 31702 | Classification loss: 0.00585 | Regression loss: 0.01421 | Objectness loss: 0.00007 | RPN Regression loss: 0.00065 | Running loss: 0.02078\n","Epoch: 9 | Iteration: 31703 | Classification loss: 0.01692 | Regression loss: 0.02120 | Objectness loss: 0.00008 | RPN Regression loss: 0.00234 | Running loss: 0.04053\n","Epoch: 9 | Iteration: 31704 | Classification loss: 0.02270 | Regression loss: 0.04074 | Objectness loss: 0.00046 | RPN Regression loss: 0.00130 | Running loss: 0.06520\n","Epoch: 9 | Iteration: 31705 | Classification loss: 0.01250 | Regression loss: 0.02498 | Objectness loss: 0.00017 | RPN Regression loss: 0.00224 | Running loss: 0.03988\n","Epoch: 9 | Iteration: 31706 | Classification loss: 0.01660 | Regression loss: 0.01484 | Objectness loss: 0.00007 | RPN Regression loss: 0.00108 | Running loss: 0.03259\n","Epoch: 9 | Iteration: 31707 | Classification loss: 0.02305 | Regression loss: 0.01154 | Objectness loss: 0.00020 | RPN Regression loss: 0.00018 | Running loss: 0.03498\n","Epoch: 9 | Iteration: 31708 | Classification loss: 0.03210 | Regression loss: 0.04255 | Objectness loss: 0.01140 | RPN Regression loss: 0.00083 | Running loss: 0.08688\n","Epoch: 9 | Iteration: 31709 | Classification loss: 0.00917 | Regression loss: 0.01787 | Objectness loss: 0.00066 | RPN Regression loss: 0.00206 | Running loss: 0.02975\n","Epoch: 9 | Iteration: 31710 | Classification loss: 0.00914 | Regression loss: 0.01879 | Objectness loss: 0.00005 | RPN Regression loss: 0.00069 | Running loss: 0.02868\n","Epoch: 9 | Iteration: 31711 | Classification loss: 0.02880 | Regression loss: 0.05713 | Objectness loss: 0.00016 | RPN Regression loss: 0.00425 | Running loss: 0.09034\n","Epoch: 9 | Iteration: 31712 | Classification loss: 0.01446 | Regression loss: 0.02822 | Objectness loss: 0.00182 | RPN Regression loss: 0.00426 | Running loss: 0.04876\n","Epoch: 9 | Iteration: 31713 | Classification loss: 0.02216 | Regression loss: 0.04378 | Objectness loss: 0.00060 | RPN Regression loss: 0.00202 | Running loss: 0.06857\n","Epoch: 9 | Iteration: 31714 | Classification loss: 0.01065 | Regression loss: 0.01305 | Objectness loss: 0.00011 | RPN Regression loss: 0.00051 | Running loss: 0.02433\n","Epoch: 9 | Iteration: 31715 | Classification loss: 0.01166 | Regression loss: 0.02153 | Objectness loss: 0.00064 | RPN Regression loss: 0.00111 | Running loss: 0.03495\n","Epoch: 9 | Iteration: 31716 | Classification loss: 0.00893 | Regression loss: 0.01687 | Objectness loss: 0.00494 | RPN Regression loss: 0.01062 | Running loss: 0.04135\n","Epoch: 9 | Iteration: 31717 | Classification loss: 0.00873 | Regression loss: 0.02533 | Objectness loss: 0.00512 | RPN Regression loss: 0.00423 | Running loss: 0.04342\n","Epoch: 9 | Iteration: 31718 | Classification loss: 0.01660 | Regression loss: 0.01108 | Objectness loss: 0.00005 | RPN Regression loss: 0.00080 | Running loss: 0.02853\n","Epoch: 9 | Iteration: 31719 | Classification loss: 0.01591 | Regression loss: 0.02102 | Objectness loss: 0.00109 | RPN Regression loss: 0.00168 | Running loss: 0.03969\n","Epoch: 9 | Iteration: 31720 | Classification loss: 0.01343 | Regression loss: 0.01653 | Objectness loss: 0.00010 | RPN Regression loss: 0.00212 | Running loss: 0.03218\n","Epoch: 9 | Iteration: 31721 | Classification loss: 0.01796 | Regression loss: 0.03072 | Objectness loss: 0.00041 | RPN Regression loss: 0.00266 | Running loss: 0.05177\n","Epoch: 9 | Iteration: 31722 | Classification loss: 0.01755 | Regression loss: 0.02374 | Objectness loss: 0.00023 | RPN Regression loss: 0.00117 | Running loss: 0.04269\n","Epoch: 9 | Iteration: 31723 | Classification loss: 0.01268 | Regression loss: 0.02163 | Objectness loss: 0.00143 | RPN Regression loss: 0.00214 | Running loss: 0.03788\n","Epoch: 9 | Iteration: 31724 | Classification loss: 0.00772 | Regression loss: 0.01285 | Objectness loss: 0.00063 | RPN Regression loss: 0.00163 | Running loss: 0.02283\n","Epoch: 9 | Iteration: 31725 | Classification loss: 0.01131 | Regression loss: 0.02345 | Objectness loss: 0.00026 | RPN Regression loss: 0.00250 | Running loss: 0.03752\n","Epoch: 9 | Iteration: 31726 | Classification loss: 0.00717 | Regression loss: 0.01092 | Objectness loss: 0.00005 | RPN Regression loss: 0.00206 | Running loss: 0.02020\n","Epoch: 9 | Iteration: 31727 | Classification loss: 0.00834 | Regression loss: 0.02334 | Objectness loss: 0.00060 | RPN Regression loss: 0.00097 | Running loss: 0.03324\n","Epoch: 9 | Iteration: 31728 | Classification loss: 0.00980 | Regression loss: 0.01998 | Objectness loss: 0.00012 | RPN Regression loss: 0.00134 | Running loss: 0.03123\n","Epoch: 9 | Iteration: 31729 | Classification loss: 0.01686 | Regression loss: 0.02823 | Objectness loss: 0.00210 | RPN Regression loss: 0.00263 | Running loss: 0.04982\n","Epoch: 9 | Iteration: 31730 | Classification loss: 0.01109 | Regression loss: 0.02070 | Objectness loss: 0.00080 | RPN Regression loss: 0.00027 | Running loss: 0.03287\n","Epoch: 9 | Iteration: 31731 | Classification loss: 0.03144 | Regression loss: 0.03467 | Objectness loss: 0.00153 | RPN Regression loss: 0.00071 | Running loss: 0.06835\n","Epoch: 9 | Iteration: 31732 | Classification loss: 0.02185 | Regression loss: 0.01866 | Objectness loss: 0.00005 | RPN Regression loss: 0.00191 | Running loss: 0.04248\n","Epoch: 9 | Iteration: 31733 | Classification loss: 0.01526 | Regression loss: 0.01613 | Objectness loss: 0.00198 | RPN Regression loss: 0.00231 | Running loss: 0.03568\n","Epoch: 9 | Iteration: 31734 | Classification loss: 0.02751 | Regression loss: 0.02054 | Objectness loss: 0.00006 | RPN Regression loss: 0.00224 | Running loss: 0.05034\n","Epoch: 9 | Iteration: 31735 | Classification loss: 0.02826 | Regression loss: 0.02764 | Objectness loss: 0.00012 | RPN Regression loss: 0.00050 | Running loss: 0.05651\n","Epoch: 9 | Iteration: 31736 | Classification loss: 0.01018 | Regression loss: 0.01552 | Objectness loss: 0.00002 | RPN Regression loss: 0.00126 | Running loss: 0.02697\n","Epoch: 9 | Iteration: 31737 | Classification loss: 0.02974 | Regression loss: 0.02469 | Objectness loss: 0.00023 | RPN Regression loss: 0.00266 | Running loss: 0.05731\n","Epoch: 9 | Iteration: 31738 | Classification loss: 0.03507 | Regression loss: 0.02525 | Objectness loss: 0.00104 | RPN Regression loss: 0.00181 | Running loss: 0.06317\n","Epoch: 9 | Iteration: 31739 | Classification loss: 0.01817 | Regression loss: 0.05012 | Objectness loss: 0.00650 | RPN Regression loss: 0.00149 | Running loss: 0.07628\n","Epoch: 9 | Iteration: 31740 | Classification loss: 0.01091 | Regression loss: 0.02347 | Objectness loss: 0.00022 | RPN Regression loss: 0.00666 | Running loss: 0.04127\n","Epoch: 9 | Iteration: 31741 | Classification loss: 0.01186 | Regression loss: 0.02463 | Objectness loss: 0.00002 | RPN Regression loss: 0.00088 | Running loss: 0.03739\n","Epoch: 9 | Iteration: 31742 | Classification loss: 0.02976 | Regression loss: 0.03493 | Objectness loss: 0.00042 | RPN Regression loss: 0.00085 | Running loss: 0.06595\n","Epoch: 9 | Iteration: 31743 | Classification loss: 0.01189 | Regression loss: 0.02246 | Objectness loss: 0.00054 | RPN Regression loss: 0.00206 | Running loss: 0.03694\n","Epoch: 9 | Iteration: 31744 | Classification loss: 0.01343 | Regression loss: 0.02522 | Objectness loss: 0.00003 | RPN Regression loss: 0.00050 | Running loss: 0.03918\n","Epoch: 9 | Iteration: 31745 | Classification loss: 0.00887 | Regression loss: 0.01843 | Objectness loss: 0.00101 | RPN Regression loss: 0.00108 | Running loss: 0.02939\n","Epoch: 9 | Iteration: 31746 | Classification loss: 0.02182 | Regression loss: 0.02993 | Objectness loss: 0.00002 | RPN Regression loss: 0.00199 | Running loss: 0.05376\n","Epoch: 9 | Iteration: 31747 | Classification loss: 0.01253 | Regression loss: 0.04323 | Objectness loss: 0.00053 | RPN Regression loss: 0.00077 | Running loss: 0.05706\n","Epoch: 9 | Iteration: 31748 | Classification loss: 0.02256 | Regression loss: 0.01460 | Objectness loss: 0.00561 | RPN Regression loss: 0.00159 | Running loss: 0.04436\n","Epoch: 9 | Iteration: 31749 | Classification loss: 0.00560 | Regression loss: 0.01278 | Objectness loss: 0.00007 | RPN Regression loss: 0.00100 | Running loss: 0.01945\n","Epoch: 9 | Iteration: 31750 | Classification loss: 0.04032 | Regression loss: 0.06005 | Objectness loss: 0.00054 | RPN Regression loss: 0.00089 | Running loss: 0.10181\n","Epoch: 9 | Iteration: 31751 | Classification loss: 0.01795 | Regression loss: 0.02276 | Objectness loss: 0.00023 | RPN Regression loss: 0.00150 | Running loss: 0.04245\n","Epoch: 9 | Iteration: 31752 | Classification loss: 0.00920 | Regression loss: 0.01850 | Objectness loss: 0.00046 | RPN Regression loss: 0.00143 | Running loss: 0.02959\n","Epoch: 9 | Iteration: 31753 | Classification loss: 0.01779 | Regression loss: 0.02043 | Objectness loss: 0.00002 | RPN Regression loss: 0.00118 | Running loss: 0.03943\n","Epoch: 9 | Iteration: 31754 | Classification loss: 0.01166 | Regression loss: 0.02881 | Objectness loss: 0.00038 | RPN Regression loss: 0.00154 | Running loss: 0.04239\n","Epoch: 9 | Iteration: 31755 | Classification loss: 0.02238 | Regression loss: 0.04476 | Objectness loss: 0.00006 | RPN Regression loss: 0.00105 | Running loss: 0.06825\n","Epoch: 9 | Iteration: 31756 | Classification loss: 0.00739 | Regression loss: 0.03536 | Objectness loss: 0.00008 | RPN Regression loss: 0.00091 | Running loss: 0.04374\n","Epoch: 9 | Iteration: 31757 | Classification loss: 0.01408 | Regression loss: 0.01990 | Objectness loss: 0.00009 | RPN Regression loss: 0.00200 | Running loss: 0.03608\n","Epoch: 9 | Iteration: 31758 | Classification loss: 0.00858 | Regression loss: 0.01273 | Objectness loss: 0.00003 | RPN Regression loss: 0.00100 | Running loss: 0.02234\n","Epoch: 9 | Iteration: 31759 | Classification loss: 0.01872 | Regression loss: 0.01626 | Objectness loss: 0.00007 | RPN Regression loss: 0.00172 | Running loss: 0.03677\n","Epoch: 9 | Iteration: 31760 | Classification loss: 0.01165 | Regression loss: 0.01830 | Objectness loss: 0.00010 | RPN Regression loss: 0.00096 | Running loss: 0.03101\n","Epoch: 9 | Iteration: 31761 | Classification loss: 0.01068 | Regression loss: 0.01116 | Objectness loss: 0.00007 | RPN Regression loss: 0.00176 | Running loss: 0.02366\n","Epoch: 9 | Iteration: 31762 | Classification loss: 0.02476 | Regression loss: 0.03146 | Objectness loss: 0.00029 | RPN Regression loss: 0.00216 | Running loss: 0.05868\n","Epoch: 9 | Iteration: 31763 | Classification loss: 0.03046 | Regression loss: 0.02530 | Objectness loss: 0.00008 | RPN Regression loss: 0.00096 | Running loss: 0.05680\n","Epoch: 9 | Iteration: 31764 | Classification loss: 0.01741 | Regression loss: 0.01493 | Objectness loss: 0.00007 | RPN Regression loss: 0.00196 | Running loss: 0.03438\n","Epoch: 9 | Iteration: 31765 | Classification loss: 0.02348 | Regression loss: 0.03042 | Objectness loss: 0.00047 | RPN Regression loss: 0.00116 | Running loss: 0.05553\n","Epoch: 9 | Iteration: 31766 | Classification loss: 0.02485 | Regression loss: 0.03035 | Objectness loss: 0.00023 | RPN Regression loss: 0.00090 | Running loss: 0.05632\n","Epoch: 9 | Iteration: 31767 | Classification loss: 0.00713 | Regression loss: 0.01589 | Objectness loss: 0.00002 | RPN Regression loss: 0.00038 | Running loss: 0.02342\n","Epoch: 9 | Iteration: 31768 | Classification loss: 0.01181 | Regression loss: 0.01686 | Objectness loss: 0.00003 | RPN Regression loss: 0.00070 | Running loss: 0.02940\n","Epoch: 9 | Iteration: 31769 | Classification loss: 0.02779 | Regression loss: 0.02515 | Objectness loss: 0.00021 | RPN Regression loss: 0.00133 | Running loss: 0.05447\n","Epoch: 9 | Iteration: 31770 | Classification loss: 0.02170 | Regression loss: 0.01611 | Objectness loss: 0.00175 | RPN Regression loss: 0.00078 | Running loss: 0.04033\n","Epoch: 9 | Iteration: 31771 | Classification loss: 0.04587 | Regression loss: 0.05539 | Objectness loss: 0.00012 | RPN Regression loss: 0.00179 | Running loss: 0.10317\n","Epoch: 9 | Iteration: 31772 | Classification loss: 0.01921 | Regression loss: 0.03487 | Objectness loss: 0.00024 | RPN Regression loss: 0.00062 | Running loss: 0.05494\n","Epoch: 9 | Iteration: 31773 | Classification loss: 0.00810 | Regression loss: 0.01744 | Objectness loss: 0.01088 | RPN Regression loss: 0.00783 | Running loss: 0.04425\n","Epoch: 9 | Iteration: 31774 | Classification loss: 0.01105 | Regression loss: 0.00965 | Objectness loss: 0.00004 | RPN Regression loss: 0.00036 | Running loss: 0.02110\n","Epoch: 9 | Iteration: 31775 | Classification loss: 0.04024 | Regression loss: 0.04261 | Objectness loss: 0.00060 | RPN Regression loss: 0.00269 | Running loss: 0.08613\n","Epoch: 9 | Iteration: 31776 | Classification loss: 0.02853 | Regression loss: 0.02142 | Objectness loss: 0.00054 | RPN Regression loss: 0.00142 | Running loss: 0.05191\n","Epoch: 9 | Iteration: 31777 | Classification loss: 0.00689 | Regression loss: 0.02084 | Objectness loss: 0.00006 | RPN Regression loss: 0.00425 | Running loss: 0.03204\n","Epoch: 9 | Iteration: 31778 | Classification loss: 0.03195 | Regression loss: 0.04709 | Objectness loss: 0.00009 | RPN Regression loss: 0.00260 | Running loss: 0.08173\n","Epoch: 9 | Iteration: 31779 | Classification loss: 0.01102 | Regression loss: 0.02009 | Objectness loss: 0.00007 | RPN Regression loss: 0.00077 | Running loss: 0.03194\n","Epoch: 9 | Iteration: 31780 | Classification loss: 0.01488 | Regression loss: 0.01120 | Objectness loss: 0.00006 | RPN Regression loss: 0.00159 | Running loss: 0.02772\n","Epoch: 9 | Iteration: 31781 | Classification loss: 0.03442 | Regression loss: 0.02541 | Objectness loss: 0.00560 | RPN Regression loss: 0.00061 | Running loss: 0.06604\n","Epoch: 9 | Iteration: 31782 | Classification loss: 0.00858 | Regression loss: 0.02643 | Objectness loss: 0.00096 | RPN Regression loss: 0.00182 | Running loss: 0.03779\n","Epoch: 9 | Iteration: 31783 | Classification loss: 0.02029 | Regression loss: 0.04210 | Objectness loss: 0.00088 | RPN Regression loss: 0.00128 | Running loss: 0.06454\n","Epoch: 9 | Iteration: 31784 | Classification loss: 0.00670 | Regression loss: 0.01143 | Objectness loss: 0.00021 | RPN Regression loss: 0.00064 | Running loss: 0.01898\n","Epoch: 9 | Iteration: 31785 | Classification loss: 0.00979 | Regression loss: 0.01322 | Objectness loss: 0.00068 | RPN Regression loss: 0.00103 | Running loss: 0.02472\n","Epoch: 9 | Iteration: 31786 | Classification loss: 0.01265 | Regression loss: 0.02124 | Objectness loss: 0.00012 | RPN Regression loss: 0.00386 | Running loss: 0.03787\n","Epoch: 9 | Iteration: 31787 | Classification loss: 0.01760 | Regression loss: 0.02298 | Objectness loss: 0.00075 | RPN Regression loss: 0.00259 | Running loss: 0.04392\n","Epoch: 9 | Iteration: 31788 | Classification loss: 0.01631 | Regression loss: 0.02743 | Objectness loss: 0.00003 | RPN Regression loss: 0.00065 | Running loss: 0.04442\n","Epoch: 9 | Iteration: 31789 | Classification loss: 0.06318 | Regression loss: 0.02537 | Objectness loss: 0.00007 | RPN Regression loss: 0.00200 | Running loss: 0.09062\n","Epoch: 9 | Iteration: 31790 | Classification loss: 0.02136 | Regression loss: 0.02839 | Objectness loss: 0.00003 | RPN Regression loss: 0.00241 | Running loss: 0.05219\n","Epoch: 9 | Iteration: 31791 | Classification loss: 0.00740 | Regression loss: 0.02828 | Objectness loss: 0.00002 | RPN Regression loss: 0.00123 | Running loss: 0.03693\n","Epoch: 9 | Iteration: 31792 | Classification loss: 0.00968 | Regression loss: 0.01967 | Objectness loss: 0.00093 | RPN Regression loss: 0.00156 | Running loss: 0.03184\n","Epoch: 9 | Iteration: 31793 | Classification loss: 0.01447 | Regression loss: 0.02514 | Objectness loss: 0.00021 | RPN Regression loss: 0.00220 | Running loss: 0.04201\n","Epoch: 9 | Iteration: 31794 | Classification loss: 0.02615 | Regression loss: 0.02939 | Objectness loss: 0.00006 | RPN Regression loss: 0.00120 | Running loss: 0.05680\n","Epoch: 9 | Iteration: 31795 | Classification loss: 0.01001 | Regression loss: 0.01587 | Objectness loss: 0.00006 | RPN Regression loss: 0.00087 | Running loss: 0.02682\n","Epoch: 9 | Iteration: 31796 | Classification loss: 0.02785 | Regression loss: 0.02279 | Objectness loss: 0.00008 | RPN Regression loss: 0.00054 | Running loss: 0.05126\n","Epoch: 9 | Iteration: 31797 | Classification loss: 0.01417 | Regression loss: 0.01383 | Objectness loss: 0.00001 | RPN Regression loss: 0.00313 | Running loss: 0.03113\n","Epoch: 9 | Iteration: 31798 | Classification loss: 0.00687 | Regression loss: 0.01188 | Objectness loss: 0.00013 | RPN Regression loss: 0.00059 | Running loss: 0.01946\n","Epoch: 9 | Iteration: 31799 | Classification loss: 0.02870 | Regression loss: 0.01297 | Objectness loss: 0.00118 | RPN Regression loss: 0.00057 | Running loss: 0.04342\n","Epoch: 9 | Iteration: 31800 | Classification loss: 0.03010 | Regression loss: 0.03037 | Objectness loss: 0.01105 | RPN Regression loss: 0.00037 | Running loss: 0.07190\n","Epoch: 9 | Iteration: 31801 | Classification loss: 0.00697 | Regression loss: 0.01274 | Objectness loss: 0.00193 | RPN Regression loss: 0.00136 | Running loss: 0.02300\n","Epoch: 9 | Iteration: 31802 | Classification loss: 0.02405 | Regression loss: 0.02015 | Objectness loss: 0.00498 | RPN Regression loss: 0.00124 | Running loss: 0.05041\n","Epoch: 9 | Iteration: 31803 | Classification loss: 0.05353 | Regression loss: 0.02957 | Objectness loss: 0.00412 | RPN Regression loss: 0.00297 | Running loss: 0.09019\n","Epoch: 9 | Iteration: 31804 | Classification loss: 0.01145 | Regression loss: 0.02682 | Objectness loss: 0.00665 | RPN Regression loss: 0.00056 | Running loss: 0.04549\n","Epoch: 9 | Iteration: 31805 | Classification loss: 0.05871 | Regression loss: 0.04039 | Objectness loss: 0.02264 | RPN Regression loss: 0.00231 | Running loss: 0.12404\n","Epoch: 9 | Iteration: 31806 | Classification loss: 0.02496 | Regression loss: 0.02674 | Objectness loss: 0.00182 | RPN Regression loss: 0.00118 | Running loss: 0.05470\n","Epoch: 9 | Iteration: 31807 | Classification loss: 0.01106 | Regression loss: 0.01534 | Objectness loss: 0.00009 | RPN Regression loss: 0.00245 | Running loss: 0.02895\n","Epoch: 9 | Iteration: 31808 | Classification loss: 0.01445 | Regression loss: 0.02891 | Objectness loss: 0.00061 | RPN Regression loss: 0.00551 | Running loss: 0.04948\n","Epoch: 9 | Iteration: 31809 | Classification loss: 0.02625 | Regression loss: 0.02266 | Objectness loss: 0.00290 | RPN Regression loss: 0.00224 | Running loss: 0.05405\n","Epoch: 9 | Iteration: 31810 | Classification loss: 0.02449 | Regression loss: 0.04037 | Objectness loss: 0.00021 | RPN Regression loss: 0.00111 | Running loss: 0.06618\n","Epoch: 9 | Iteration: 31811 | Classification loss: 0.00911 | Regression loss: 0.02225 | Objectness loss: 0.00081 | RPN Regression loss: 0.01143 | Running loss: 0.04360\n","Epoch: 9 | Iteration: 31812 | Classification loss: 0.01756 | Regression loss: 0.01824 | Objectness loss: 0.00006 | RPN Regression loss: 0.00113 | Running loss: 0.03699\n","Epoch: 9 | Iteration: 31813 | Classification loss: 0.00991 | Regression loss: 0.02097 | Objectness loss: 0.00003 | RPN Regression loss: 0.00051 | Running loss: 0.03142\n","Epoch: 9 | Iteration: 31814 | Classification loss: 0.01690 | Regression loss: 0.04383 | Objectness loss: 0.00751 | RPN Regression loss: 0.00116 | Running loss: 0.06940\n","Epoch: 9 | Iteration: 31815 | Classification loss: 0.00531 | Regression loss: 0.02579 | Objectness loss: 0.00019 | RPN Regression loss: 0.00059 | Running loss: 0.03187\n","Epoch: 9 | Iteration: 31816 | Classification loss: 0.01129 | Regression loss: 0.01402 | Objectness loss: 0.00024 | RPN Regression loss: 0.00188 | Running loss: 0.02744\n","Epoch: 9 | Iteration: 31817 | Classification loss: 0.02768 | Regression loss: 0.02977 | Objectness loss: 0.00040 | RPN Regression loss: 0.00357 | Running loss: 0.06143\n","Epoch: 9 | Iteration: 31818 | Classification loss: 0.02415 | Regression loss: 0.02510 | Objectness loss: 0.00056 | RPN Regression loss: 0.00170 | Running loss: 0.05152\n","Epoch: 9 | Iteration: 31819 | Classification loss: 0.02961 | Regression loss: 0.03546 | Objectness loss: 0.00143 | RPN Regression loss: 0.00196 | Running loss: 0.06846\n","Epoch: 9 | Iteration: 31820 | Classification loss: 0.00766 | Regression loss: 0.01956 | Objectness loss: 0.00054 | RPN Regression loss: 0.00141 | Running loss: 0.02917\n","Epoch: 9 | Iteration: 31821 | Classification loss: 0.03444 | Regression loss: 0.03160 | Objectness loss: 0.00003 | RPN Regression loss: 0.00077 | Running loss: 0.06683\n","Epoch: 9 | Iteration: 31822 | Classification loss: 0.01190 | Regression loss: 0.02769 | Objectness loss: 0.00138 | RPN Regression loss: 0.00180 | Running loss: 0.04277\n","Epoch: 9 | Iteration: 31823 | Classification loss: 0.02102 | Regression loss: 0.02983 | Objectness loss: 0.00043 | RPN Regression loss: 0.00050 | Running loss: 0.05178\n","Epoch: 9 | Iteration: 31824 | Classification loss: 0.01940 | Regression loss: 0.01217 | Objectness loss: 0.00044 | RPN Regression loss: 0.00096 | Running loss: 0.03297\n","Epoch: 9 | Iteration: 31825 | Classification loss: 0.01014 | Regression loss: 0.02866 | Objectness loss: 0.00315 | RPN Regression loss: 0.00084 | Running loss: 0.04280\n","Epoch: 9 | Iteration: 31826 | Classification loss: 0.03987 | Regression loss: 0.04843 | Objectness loss: 0.00158 | RPN Regression loss: 0.00229 | Running loss: 0.09217\n","Epoch: 9 | Iteration: 31827 | Classification loss: 0.04553 | Regression loss: 0.04474 | Objectness loss: 0.00152 | RPN Regression loss: 0.00100 | Running loss: 0.09278\n","Epoch: 9 | Iteration: 31828 | Classification loss: 0.02742 | Regression loss: 0.03968 | Objectness loss: 0.00001 | RPN Regression loss: 0.00083 | Running loss: 0.06794\n","Epoch: 9 | Iteration: 31829 | Classification loss: 0.01175 | Regression loss: 0.01825 | Objectness loss: 0.00003 | RPN Regression loss: 0.00045 | Running loss: 0.03048\n","Epoch: 9 | Iteration: 31830 | Classification loss: 0.03645 | Regression loss: 0.01791 | Objectness loss: 0.00156 | RPN Regression loss: 0.00129 | Running loss: 0.05721\n","Epoch: 9 | Iteration: 31831 | Classification loss: 0.01026 | Regression loss: 0.01644 | Objectness loss: 0.00157 | RPN Regression loss: 0.00060 | Running loss: 0.02888\n","Epoch: 9 | Iteration: 31832 | Classification loss: 0.00997 | Regression loss: 0.03407 | Objectness loss: 0.00271 | RPN Regression loss: 0.00311 | Running loss: 0.04986\n","Epoch: 9 | Iteration: 31833 | Classification loss: 0.03567 | Regression loss: 0.01649 | Objectness loss: 0.00054 | RPN Regression loss: 0.00171 | Running loss: 0.05442\n","Epoch: 9 | Iteration: 31834 | Classification loss: 0.01623 | Regression loss: 0.01684 | Objectness loss: 0.00003 | RPN Regression loss: 0.00157 | Running loss: 0.03467\n","Epoch: 9 | Iteration: 31835 | Classification loss: 0.01007 | Regression loss: 0.01498 | Objectness loss: 0.00191 | RPN Regression loss: 0.00154 | Running loss: 0.02850\n","Epoch: 9 | Iteration: 31836 | Classification loss: 0.01744 | Regression loss: 0.03830 | Objectness loss: 0.00012 | RPN Regression loss: 0.00091 | Running loss: 0.05676\n","Epoch: 9 | Iteration: 31837 | Classification loss: 0.01699 | Regression loss: 0.02425 | Objectness loss: 0.00019 | RPN Regression loss: 0.00158 | Running loss: 0.04301\n","Epoch: 9 | Iteration: 31838 | Classification loss: 0.03658 | Regression loss: 0.04980 | Objectness loss: 0.00399 | RPN Regression loss: 0.00196 | Running loss: 0.09233\n","Epoch: 9 | Iteration: 31839 | Classification loss: 0.01477 | Regression loss: 0.01298 | Objectness loss: 0.00022 | RPN Regression loss: 0.00184 | Running loss: 0.02982\n","Epoch: 9 | Iteration: 31840 | Classification loss: 0.02969 | Regression loss: 0.02927 | Objectness loss: 0.00025 | RPN Regression loss: 0.00183 | Running loss: 0.06104\n","Epoch: 9 | Iteration: 31841 | Classification loss: 0.01353 | Regression loss: 0.01497 | Objectness loss: 0.00039 | RPN Regression loss: 0.00128 | Running loss: 0.03016\n","Epoch: 9 | Iteration: 31842 | Classification loss: 0.00975 | Regression loss: 0.01840 | Objectness loss: 0.00002 | RPN Regression loss: 0.00036 | Running loss: 0.02853\n","Epoch: 9 | Iteration: 31843 | Classification loss: 0.02495 | Regression loss: 0.01954 | Objectness loss: 0.00227 | RPN Regression loss: 0.00145 | Running loss: 0.04821\n","Epoch: 9 | Iteration: 31844 | Classification loss: 0.02184 | Regression loss: 0.02153 | Objectness loss: 0.00132 | RPN Regression loss: 0.00091 | Running loss: 0.04560\n","Epoch: 9 | Iteration: 31845 | Classification loss: 0.00800 | Regression loss: 0.02164 | Objectness loss: 0.00329 | RPN Regression loss: 0.00109 | Running loss: 0.03401\n","Epoch: 9 | Iteration: 31846 | Classification loss: 0.01168 | Regression loss: 0.01969 | Objectness loss: 0.00006 | RPN Regression loss: 0.00062 | Running loss: 0.03205\n","Epoch: 9 | Iteration: 31847 | Classification loss: 0.01163 | Regression loss: 0.02824 | Objectness loss: 0.00019 | RPN Regression loss: 0.00100 | Running loss: 0.04106\n","Epoch: 9 | Iteration: 31848 | Classification loss: 0.01360 | Regression loss: 0.03289 | Objectness loss: 0.00427 | RPN Regression loss: 0.00214 | Running loss: 0.05290\n","Epoch: 9 | Iteration: 31849 | Classification loss: 0.00996 | Regression loss: 0.01920 | Objectness loss: 0.00006 | RPN Regression loss: 0.00063 | Running loss: 0.02985\n","Epoch: 9 | Iteration: 31850 | Classification loss: 0.01158 | Regression loss: 0.02806 | Objectness loss: 0.00011 | RPN Regression loss: 0.00143 | Running loss: 0.04118\n","Epoch: 9 | Iteration: 31851 | Classification loss: 0.00615 | Regression loss: 0.01978 | Objectness loss: 0.00094 | RPN Regression loss: 0.00101 | Running loss: 0.02788\n","Epoch: 9 | Iteration: 31852 | Classification loss: 0.00578 | Regression loss: 0.01348 | Objectness loss: 0.00109 | RPN Regression loss: 0.00468 | Running loss: 0.02503\n","Epoch: 9 | Iteration: 31853 | Classification loss: 0.03291 | Regression loss: 0.01184 | Objectness loss: 0.00008 | RPN Regression loss: 0.00167 | Running loss: 0.04650\n","Epoch: 9 | Iteration: 31854 | Classification loss: 0.01642 | Regression loss: 0.02530 | Objectness loss: 0.00092 | RPN Regression loss: 0.00218 | Running loss: 0.04482\n","Epoch: 9 | Iteration: 31855 | Classification loss: 0.01418 | Regression loss: 0.02784 | Objectness loss: 0.00057 | RPN Regression loss: 0.00113 | Running loss: 0.04372\n","Epoch: 9 | Iteration: 31856 | Classification loss: 0.00749 | Regression loss: 0.01828 | Objectness loss: 0.00007 | RPN Regression loss: 0.00038 | Running loss: 0.02622\n","Epoch: 9 | Iteration: 31857 | Classification loss: 0.01247 | Regression loss: 0.02353 | Objectness loss: 0.00020 | RPN Regression loss: 0.00164 | Running loss: 0.03785\n","Epoch: 9 | Iteration: 31858 | Classification loss: 0.01375 | Regression loss: 0.03489 | Objectness loss: 0.00012 | RPN Regression loss: 0.00129 | Running loss: 0.05005\n","Epoch: 9 | Iteration: 31859 | Classification loss: 0.01280 | Regression loss: 0.02731 | Objectness loss: 0.00048 | RPN Regression loss: 0.00074 | Running loss: 0.04134\n","Epoch: 9 | Iteration: 31860 | Classification loss: 0.02156 | Regression loss: 0.03433 | Objectness loss: 0.00028 | RPN Regression loss: 0.00118 | Running loss: 0.05736\n","Epoch: 9 | Iteration: 31861 | Classification loss: 0.00980 | Regression loss: 0.01439 | Objectness loss: 0.00085 | RPN Regression loss: 0.00179 | Running loss: 0.02683\n","Epoch: 9 | Iteration: 31862 | Classification loss: 0.02689 | Regression loss: 0.02323 | Objectness loss: 0.00004 | RPN Regression loss: 0.00103 | Running loss: 0.05119\n","Epoch: 9 | Iteration: 31863 | Classification loss: 0.01047 | Regression loss: 0.01666 | Objectness loss: 0.00011 | RPN Regression loss: 0.00123 | Running loss: 0.02846\n","Epoch: 9 | Iteration: 31864 | Classification loss: 0.00804 | Regression loss: 0.02652 | Objectness loss: 0.00071 | RPN Regression loss: 0.00117 | Running loss: 0.03644\n","Epoch: 9 | Iteration: 31865 | Classification loss: 0.02732 | Regression loss: 0.02799 | Objectness loss: 0.00036 | RPN Regression loss: 0.00149 | Running loss: 0.05717\n","Epoch: 9 | Iteration: 31866 | Classification loss: 0.00977 | Regression loss: 0.02622 | Objectness loss: 0.00004 | RPN Regression loss: 0.00078 | Running loss: 0.03681\n","Epoch: 9 | Iteration: 31867 | Classification loss: 0.01736 | Regression loss: 0.03724 | Objectness loss: 0.00009 | RPN Regression loss: 0.00247 | Running loss: 0.05717\n","Epoch: 9 | Iteration: 31868 | Classification loss: 0.01098 | Regression loss: 0.02339 | Objectness loss: 0.00337 | RPN Regression loss: 0.00625 | Running loss: 0.04399\n","Epoch: 9 | Iteration: 31869 | Classification loss: 0.02145 | Regression loss: 0.02844 | Objectness loss: 0.00655 | RPN Regression loss: 0.00178 | Running loss: 0.05821\n","Epoch: 9 | Iteration: 31870 | Classification loss: 0.02187 | Regression loss: 0.01573 | Objectness loss: 0.00006 | RPN Regression loss: 0.00107 | Running loss: 0.03872\n","Epoch: 9 | Iteration: 31871 | Classification loss: 0.00482 | Regression loss: 0.00941 | Objectness loss: 0.00045 | RPN Regression loss: 0.00077 | Running loss: 0.01545\n","Epoch: 9 | Iteration: 31872 | Classification loss: 0.02101 | Regression loss: 0.02200 | Objectness loss: 0.00029 | RPN Regression loss: 0.00255 | Running loss: 0.04585\n","Epoch: 9 | Iteration: 31873 | Classification loss: 0.03284 | Regression loss: 0.04670 | Objectness loss: 0.01429 | RPN Regression loss: 0.00614 | Running loss: 0.09998\n","Epoch: 9 | Iteration: 31874 | Classification loss: 0.01740 | Regression loss: 0.02308 | Objectness loss: 0.00422 | RPN Regression loss: 0.00038 | Running loss: 0.04508\n","Epoch: 9 | Iteration: 31875 | Classification loss: 0.00868 | Regression loss: 0.01504 | Objectness loss: 0.00005 | RPN Regression loss: 0.00062 | Running loss: 0.02439\n","Epoch: 9 | Iteration: 31876 | Classification loss: 0.02460 | Regression loss: 0.01506 | Objectness loss: 0.00035 | RPN Regression loss: 0.00125 | Running loss: 0.04126\n","Epoch: 9 | Iteration: 31877 | Classification loss: 0.01423 | Regression loss: 0.02847 | Objectness loss: 0.00002 | RPN Regression loss: 0.00058 | Running loss: 0.04330\n","Epoch: 9 | Iteration: 31878 | Classification loss: 0.01312 | Regression loss: 0.01685 | Objectness loss: 0.00004 | RPN Regression loss: 0.00045 | Running loss: 0.03045\n","Epoch: 9 | Iteration: 31879 | Classification loss: 0.00412 | Regression loss: 0.01276 | Objectness loss: 0.00063 | RPN Regression loss: 0.00114 | Running loss: 0.01864\n","Epoch: 9 | Iteration: 31880 | Classification loss: 0.02077 | Regression loss: 0.02536 | Objectness loss: 0.00049 | RPN Regression loss: 0.00131 | Running loss: 0.04792\n","Epoch: 9 | Iteration: 31881 | Classification loss: 0.01602 | Regression loss: 0.03139 | Objectness loss: 0.00071 | RPN Regression loss: 0.00348 | Running loss: 0.05160\n","Epoch: 9 | Iteration: 31882 | Classification loss: 0.01601 | Regression loss: 0.02464 | Objectness loss: 0.00023 | RPN Regression loss: 0.00330 | Running loss: 0.04418\n","Epoch: 9 | Iteration: 31883 | Classification loss: 0.00799 | Regression loss: 0.01779 | Objectness loss: 0.00041 | RPN Regression loss: 0.00346 | Running loss: 0.02965\n","Epoch: 9 | Iteration: 31884 | Classification loss: 0.01872 | Regression loss: 0.01680 | Objectness loss: 0.00019 | RPN Regression loss: 0.00275 | Running loss: 0.03846\n","Epoch: 9 | Iteration: 31885 | Classification loss: 0.01982 | Regression loss: 0.01263 | Objectness loss: 0.00001 | RPN Regression loss: 0.00049 | Running loss: 0.03295\n","Epoch: 9 | Iteration: 31886 | Classification loss: 0.01103 | Regression loss: 0.03281 | Objectness loss: 0.00178 | RPN Regression loss: 0.00166 | Running loss: 0.04728\n","Epoch: 9 | Iteration: 31887 | Classification loss: 0.02943 | Regression loss: 0.04013 | Objectness loss: 0.00355 | RPN Regression loss: 0.00108 | Running loss: 0.07418\n","Epoch: 9 | Iteration: 31888 | Classification loss: 0.00854 | Regression loss: 0.01993 | Objectness loss: 0.00012 | RPN Regression loss: 0.00045 | Running loss: 0.02904\n","Epoch: 9 | Iteration: 31889 | Classification loss: 0.00888 | Regression loss: 0.01486 | Objectness loss: 0.00203 | RPN Regression loss: 0.00097 | Running loss: 0.02674\n","Epoch: 9 | Iteration: 31890 | Classification loss: 0.02301 | Regression loss: 0.02454 | Objectness loss: 0.00004 | RPN Regression loss: 0.00039 | Running loss: 0.04799\n","Epoch: 9 | Iteration: 31891 | Classification loss: 0.01965 | Regression loss: 0.05435 | Objectness loss: 0.00066 | RPN Regression loss: 0.00250 | Running loss: 0.07716\n","Epoch: 9 | Iteration: 31892 | Classification loss: 0.00950 | Regression loss: 0.01737 | Objectness loss: 0.00039 | RPN Regression loss: 0.00063 | Running loss: 0.02789\n","Epoch: 9 | Iteration: 31893 | Classification loss: 0.02454 | Regression loss: 0.04722 | Objectness loss: 0.00002 | RPN Regression loss: 0.00063 | Running loss: 0.07242\n","Epoch: 9 | Iteration: 31894 | Classification loss: 0.00697 | Regression loss: 0.02171 | Objectness loss: 0.00007 | RPN Regression loss: 0.00062 | Running loss: 0.02937\n","Epoch: 9 | Iteration: 31895 | Classification loss: 0.03859 | Regression loss: 0.04200 | Objectness loss: 0.00061 | RPN Regression loss: 0.00098 | Running loss: 0.08218\n","Epoch: 9 | Iteration: 31896 | Classification loss: 0.01711 | Regression loss: 0.01428 | Objectness loss: 0.00118 | RPN Regression loss: 0.00116 | Running loss: 0.03372\n","Epoch: 9 | Iteration: 31897 | Classification loss: 0.02081 | Regression loss: 0.03922 | Objectness loss: 0.00481 | RPN Regression loss: 0.00689 | Running loss: 0.07173\n","Epoch: 9 | Iteration: 31898 | Classification loss: 0.02998 | Regression loss: 0.01376 | Objectness loss: 0.00004 | RPN Regression loss: 0.00039 | Running loss: 0.04418\n","Epoch: 9 | Iteration: 31899 | Classification loss: 0.01195 | Regression loss: 0.01911 | Objectness loss: 0.00003 | RPN Regression loss: 0.00034 | Running loss: 0.03143\n","Epoch: 9 | Iteration: 31900 | Classification loss: 0.01497 | Regression loss: 0.04937 | Objectness loss: 0.00041 | RPN Regression loss: 0.00212 | Running loss: 0.06687\n","Epoch: 9 | Iteration: 31901 | Classification loss: 0.00726 | Regression loss: 0.01875 | Objectness loss: 0.00004 | RPN Regression loss: 0.00284 | Running loss: 0.02889\n","Epoch: 9 | Iteration: 31902 | Classification loss: 0.02027 | Regression loss: 0.02856 | Objectness loss: 0.00871 | RPN Regression loss: 0.00130 | Running loss: 0.05884\n","Epoch: 9 | Iteration: 31903 | Classification loss: 0.01653 | Regression loss: 0.02168 | Objectness loss: 0.00066 | RPN Regression loss: 0.00053 | Running loss: 0.03940\n","Epoch: 9 | Iteration: 31904 | Classification loss: 0.02054 | Regression loss: 0.02627 | Objectness loss: 0.00106 | RPN Regression loss: 0.00321 | Running loss: 0.05107\n","Epoch: 9 | Iteration: 31905 | Classification loss: 0.02481 | Regression loss: 0.01993 | Objectness loss: 0.00019 | RPN Regression loss: 0.00057 | Running loss: 0.04549\n","Epoch: 9 | Iteration: 31906 | Classification loss: 0.01274 | Regression loss: 0.02005 | Objectness loss: 0.00005 | RPN Regression loss: 0.00099 | Running loss: 0.03383\n","Epoch: 9 | Iteration: 31907 | Classification loss: 0.01062 | Regression loss: 0.02187 | Objectness loss: 0.00014 | RPN Regression loss: 0.00082 | Running loss: 0.03345\n","Epoch: 9 | Iteration: 31908 | Classification loss: 0.03291 | Regression loss: 0.02438 | Objectness loss: 0.00043 | RPN Regression loss: 0.00151 | Running loss: 0.05923\n","Epoch: 9 | Iteration: 31909 | Classification loss: 0.00925 | Regression loss: 0.01746 | Objectness loss: 0.00002 | RPN Regression loss: 0.00063 | Running loss: 0.02735\n","Epoch: 9 | Iteration: 31910 | Classification loss: 0.00799 | Regression loss: 0.01413 | Objectness loss: 0.00002 | RPN Regression loss: 0.00150 | Running loss: 0.02364\n","Epoch: 9 | Iteration: 31911 | Classification loss: 0.02364 | Regression loss: 0.04542 | Objectness loss: 0.00010 | RPN Regression loss: 0.00211 | Running loss: 0.07128\n","Epoch: 9 | Iteration: 31912 | Classification loss: 0.02452 | Regression loss: 0.03493 | Objectness loss: 0.00024 | RPN Regression loss: 0.00225 | Running loss: 0.06194\n","Epoch: 9 | Iteration: 31913 | Classification loss: 0.02127 | Regression loss: 0.03446 | Objectness loss: 0.00014 | RPN Regression loss: 0.00104 | Running loss: 0.05691\n","Epoch: 9 | Iteration: 31914 | Classification loss: 0.00951 | Regression loss: 0.02616 | Objectness loss: 0.00003 | RPN Regression loss: 0.00208 | Running loss: 0.03778\n","Epoch: 9 | Iteration: 31915 | Classification loss: 0.01614 | Regression loss: 0.01556 | Objectness loss: 0.00016 | RPN Regression loss: 0.00181 | Running loss: 0.03366\n","Epoch: 9 | Iteration: 31916 | Classification loss: 0.01000 | Regression loss: 0.01386 | Objectness loss: 0.00007 | RPN Regression loss: 0.00072 | Running loss: 0.02465\n","Epoch: 9 | Iteration: 31917 | Classification loss: 0.00710 | Regression loss: 0.01419 | Objectness loss: 0.00006 | RPN Regression loss: 0.00075 | Running loss: 0.02209\n","Epoch: 9 | Iteration: 31918 | Classification loss: 0.01192 | Regression loss: 0.03751 | Objectness loss: 0.00372 | RPN Regression loss: 0.00087 | Running loss: 0.05401\n","Epoch: 9 | Iteration: 31919 | Classification loss: 0.01952 | Regression loss: 0.02792 | Objectness loss: 0.00003 | RPN Regression loss: 0.00081 | Running loss: 0.04828\n","Epoch: 9 | Iteration: 31920 | Classification loss: 0.02251 | Regression loss: 0.03250 | Objectness loss: 0.00078 | RPN Regression loss: 0.00175 | Running loss: 0.05754\n","Epoch: 9 | Iteration: 31921 | Classification loss: 0.01827 | Regression loss: 0.03341 | Objectness loss: 0.00049 | RPN Regression loss: 0.00375 | Running loss: 0.05592\n","Epoch: 9 | Iteration: 31922 | Classification loss: 0.04977 | Regression loss: 0.00972 | Objectness loss: 0.03226 | RPN Regression loss: 0.00173 | Running loss: 0.09349\n","Epoch: 9 | Iteration: 31923 | Classification loss: 0.01510 | Regression loss: 0.03908 | Objectness loss: 0.00002 | RPN Regression loss: 0.00242 | Running loss: 0.05661\n","Epoch: 9 | Iteration: 31924 | Classification loss: 0.01233 | Regression loss: 0.01622 | Objectness loss: 0.00205 | RPN Regression loss: 0.00188 | Running loss: 0.03247\n","Epoch: 9 | Iteration: 31925 | Classification loss: 0.02906 | Regression loss: 0.03807 | Objectness loss: 0.00667 | RPN Regression loss: 0.00234 | Running loss: 0.07614\n","Epoch: 9 | Iteration: 31926 | Classification loss: 0.02959 | Regression loss: 0.02105 | Objectness loss: 0.00134 | RPN Regression loss: 0.00148 | Running loss: 0.05346\n","Epoch: 9 | Iteration: 31927 | Classification loss: 0.04882 | Regression loss: 0.03627 | Objectness loss: 0.00090 | RPN Regression loss: 0.00150 | Running loss: 0.08750\n","Epoch: 9 | Iteration: 31928 | Classification loss: 0.01844 | Regression loss: 0.03602 | Objectness loss: 0.00057 | RPN Regression loss: 0.00141 | Running loss: 0.05645\n","Epoch: 9 | Iteration: 31929 | Classification loss: 0.00979 | Regression loss: 0.03459 | Objectness loss: 0.00043 | RPN Regression loss: 0.00139 | Running loss: 0.04620\n","Epoch: 9 | Iteration: 31930 | Classification loss: 0.01275 | Regression loss: 0.02568 | Objectness loss: 0.00736 | RPN Regression loss: 0.00534 | Running loss: 0.05113\n","Epoch: 9 | Iteration: 31931 | Classification loss: 0.02932 | Regression loss: 0.03461 | Objectness loss: 0.00026 | RPN Regression loss: 0.00141 | Running loss: 0.06560\n","Epoch: 9 | Iteration: 31932 | Classification loss: 0.02094 | Regression loss: 0.02188 | Objectness loss: 0.00029 | RPN Regression loss: 0.00182 | Running loss: 0.04494\n","Epoch: 9 | Iteration: 31933 | Classification loss: 0.01807 | Regression loss: 0.01886 | Objectness loss: 0.00421 | RPN Regression loss: 0.00165 | Running loss: 0.04279\n","Epoch: 9 | Iteration: 31934 | Classification loss: 0.04580 | Regression loss: 0.01994 | Objectness loss: 0.02742 | RPN Regression loss: 0.00618 | Running loss: 0.09934\n","Epoch: 9 | Iteration: 31935 | Classification loss: 0.02307 | Regression loss: 0.02986 | Objectness loss: 0.00008 | RPN Regression loss: 0.00054 | Running loss: 0.05355\n","Epoch: 9 | Iteration: 31936 | Classification loss: 0.01353 | Regression loss: 0.01873 | Objectness loss: 0.00260 | RPN Regression loss: 0.01813 | Running loss: 0.05300\n","Epoch: 9 | Iteration: 31937 | Classification loss: 0.01297 | Regression loss: 0.01808 | Objectness loss: 0.00056 | RPN Regression loss: 0.00125 | Running loss: 0.03286\n","Epoch: 9 | Iteration: 31938 | Classification loss: 0.01095 | Regression loss: 0.01515 | Objectness loss: 0.00053 | RPN Regression loss: 0.00153 | Running loss: 0.02816\n","Epoch: 9 | Iteration: 31939 | Classification loss: 0.00958 | Regression loss: 0.01926 | Objectness loss: 0.00037 | RPN Regression loss: 0.00089 | Running loss: 0.03010\n","Epoch: 9 | Iteration: 31940 | Classification loss: 0.03476 | Regression loss: 0.03124 | Objectness loss: 0.00107 | RPN Regression loss: 0.00091 | Running loss: 0.06798\n","Epoch: 9 | Iteration: 31941 | Classification loss: 0.01272 | Regression loss: 0.01296 | Objectness loss: 0.00032 | RPN Regression loss: 0.00096 | Running loss: 0.02695\n","Epoch: 9 | Iteration: 31942 | Classification loss: 0.01242 | Regression loss: 0.02528 | Objectness loss: 0.00058 | RPN Regression loss: 0.00080 | Running loss: 0.03909\n","Epoch: 9 | Iteration: 31943 | Classification loss: 0.01188 | Regression loss: 0.02268 | Objectness loss: 0.00033 | RPN Regression loss: 0.00174 | Running loss: 0.03663\n","Epoch: 9 | Iteration: 31944 | Classification loss: 0.01173 | Regression loss: 0.02860 | Objectness loss: 0.00065 | RPN Regression loss: 0.00032 | Running loss: 0.04130\n","Epoch: 9 | Iteration: 31945 | Classification loss: 0.00655 | Regression loss: 0.01677 | Objectness loss: 0.00074 | RPN Regression loss: 0.00099 | Running loss: 0.02505\n","Epoch: 9 | Iteration: 31946 | Classification loss: 0.02513 | Regression loss: 0.02902 | Objectness loss: 0.00053 | RPN Regression loss: 0.00208 | Running loss: 0.05676\n","Epoch: 9 | Iteration: 31947 | Classification loss: 0.00814 | Regression loss: 0.02734 | Objectness loss: 0.00256 | RPN Regression loss: 0.00106 | Running loss: 0.03911\n","Epoch: 9 | Iteration: 31948 | Classification loss: 0.00836 | Regression loss: 0.02943 | Objectness loss: 0.00016 | RPN Regression loss: 0.00044 | Running loss: 0.03839\n","Epoch: 9 | Iteration: 31949 | Classification loss: 0.01384 | Regression loss: 0.03606 | Objectness loss: 0.00011 | RPN Regression loss: 0.00138 | Running loss: 0.05138\n","Epoch: 9 | Iteration: 31950 | Classification loss: 0.02098 | Regression loss: 0.01977 | Objectness loss: 0.00029 | RPN Regression loss: 0.00092 | Running loss: 0.04196\n","Epoch: 9 | Iteration: 31951 | Classification loss: 0.01312 | Regression loss: 0.01423 | Objectness loss: 0.00038 | RPN Regression loss: 0.00082 | Running loss: 0.02855\n","Epoch: 9 | Iteration: 31952 | Classification loss: 0.02627 | Regression loss: 0.01673 | Objectness loss: 0.00008 | RPN Regression loss: 0.00116 | Running loss: 0.04424\n","Epoch: 9 | Iteration: 31953 | Classification loss: 0.02464 | Regression loss: 0.02048 | Objectness loss: 0.00013 | RPN Regression loss: 0.00198 | Running loss: 0.04724\n","Epoch: 9 | Iteration: 31954 | Classification loss: 0.01256 | Regression loss: 0.03048 | Objectness loss: 0.00112 | RPN Regression loss: 0.00757 | Running loss: 0.05173\n","Epoch: 9 | Iteration: 31955 | Classification loss: 0.01182 | Regression loss: 0.02220 | Objectness loss: 0.00053 | RPN Regression loss: 0.00121 | Running loss: 0.03576\n","Epoch: 9 | Iteration: 31956 | Classification loss: 0.01651 | Regression loss: 0.00959 | Objectness loss: 0.00043 | RPN Regression loss: 0.00299 | Running loss: 0.02952\n","Epoch: 9 | Iteration: 31957 | Classification loss: 0.01473 | Regression loss: 0.01175 | Objectness loss: 0.00029 | RPN Regression loss: 0.00074 | Running loss: 0.02751\n","Epoch: 9 | Iteration: 31958 | Classification loss: 0.02175 | Regression loss: 0.03592 | Objectness loss: 0.00022 | RPN Regression loss: 0.00127 | Running loss: 0.05916\n","Epoch: 9 | Iteration: 31959 | Classification loss: 0.01012 | Regression loss: 0.01673 | Objectness loss: 0.00024 | RPN Regression loss: 0.00051 | Running loss: 0.02761\n","Epoch: 9 | Iteration: 31960 | Classification loss: 0.02708 | Regression loss: 0.01921 | Objectness loss: 0.00004 | RPN Regression loss: 0.00123 | Running loss: 0.04756\n","Epoch: 9 | Iteration: 31961 | Classification loss: 0.01420 | Regression loss: 0.01237 | Objectness loss: 0.00010 | RPN Regression loss: 0.00223 | Running loss: 0.02889\n","Epoch: 9 | Iteration: 31962 | Classification loss: 0.00653 | Regression loss: 0.01965 | Objectness loss: 0.00242 | RPN Regression loss: 0.00093 | Running loss: 0.02952\n","Epoch: 9 | Iteration: 31963 | Classification loss: 0.03532 | Regression loss: 0.02334 | Objectness loss: 0.00002 | RPN Regression loss: 0.00103 | Running loss: 0.05970\n","Epoch: 9 | Iteration: 31964 | Classification loss: 0.02798 | Regression loss: 0.02469 | Objectness loss: 0.00260 | RPN Regression loss: 0.00342 | Running loss: 0.05869\n","Epoch: 9 | Iteration: 31965 | Classification loss: 0.01014 | Regression loss: 0.01946 | Objectness loss: 0.00383 | RPN Regression loss: 0.00311 | Running loss: 0.03654\n","Epoch: 9 | Iteration: 31966 | Classification loss: 0.01809 | Regression loss: 0.02395 | Objectness loss: 0.00062 | RPN Regression loss: 0.00081 | Running loss: 0.04347\n","Epoch: 9 | Iteration: 31967 | Classification loss: 0.00966 | Regression loss: 0.02245 | Objectness loss: 0.00002 | RPN Regression loss: 0.00081 | Running loss: 0.03293\n","Epoch: 9 | Iteration: 31968 | Classification loss: 0.05772 | Regression loss: 0.03929 | Objectness loss: 0.00043 | RPN Regression loss: 0.00321 | Running loss: 0.10065\n","Epoch: 9 | Iteration: 31969 | Classification loss: 0.00962 | Regression loss: 0.01356 | Objectness loss: 0.00232 | RPN Regression loss: 0.00229 | Running loss: 0.02779\n","Epoch: 9 | Iteration: 31970 | Classification loss: 0.01406 | Regression loss: 0.01234 | Objectness loss: 0.00012 | RPN Regression loss: 0.00056 | Running loss: 0.02709\n","Epoch: 9 | Iteration: 31971 | Classification loss: 0.01896 | Regression loss: 0.02544 | Objectness loss: 0.00135 | RPN Regression loss: 0.00077 | Running loss: 0.04651\n","Epoch: 9 | Iteration: 31972 | Classification loss: 0.02543 | Regression loss: 0.02991 | Objectness loss: 0.00221 | RPN Regression loss: 0.00172 | Running loss: 0.05927\n","Epoch: 9 | Iteration: 31973 | Classification loss: 0.02003 | Regression loss: 0.04721 | Objectness loss: 0.00017 | RPN Regression loss: 0.00188 | Running loss: 0.06928\n","Epoch: 9 | Iteration: 31974 | Classification loss: 0.03017 | Regression loss: 0.02047 | Objectness loss: 0.00018 | RPN Regression loss: 0.00107 | Running loss: 0.05189\n","Epoch: 9 | Iteration: 31975 | Classification loss: 0.00899 | Regression loss: 0.01873 | Objectness loss: 0.00003 | RPN Regression loss: 0.00056 | Running loss: 0.02831\n","Epoch: 9 | Iteration: 31976 | Classification loss: 0.01986 | Regression loss: 0.02442 | Objectness loss: 0.00009 | RPN Regression loss: 0.00110 | Running loss: 0.04548\n","Epoch: 9 | Iteration: 31977 | Classification loss: 0.00639 | Regression loss: 0.02844 | Objectness loss: 0.00040 | RPN Regression loss: 0.00308 | Running loss: 0.03832\n","Epoch: 9 | Iteration: 31978 | Classification loss: 0.02999 | Regression loss: 0.04005 | Objectness loss: 0.00821 | RPN Regression loss: 0.00163 | Running loss: 0.07989\n","Epoch: 9 | Iteration: 31979 | Classification loss: 0.04636 | Regression loss: 0.03666 | Objectness loss: 0.00198 | RPN Regression loss: 0.00197 | Running loss: 0.08698\n","Epoch: 9 | Iteration: 31980 | Classification loss: 0.02886 | Regression loss: 0.01726 | Objectness loss: 0.00235 | RPN Regression loss: 0.00255 | Running loss: 0.05101\n","Epoch: 9 | Iteration: 31981 | Classification loss: 0.01860 | Regression loss: 0.02213 | Objectness loss: 0.00005 | RPN Regression loss: 0.00141 | Running loss: 0.04219\n","Epoch: 9 | Iteration: 31982 | Classification loss: 0.00593 | Regression loss: 0.01498 | Objectness loss: 0.00004 | RPN Regression loss: 0.00036 | Running loss: 0.02132\n","Epoch: 9 | Iteration: 31983 | Classification loss: 0.02183 | Regression loss: 0.00929 | Objectness loss: 0.00025 | RPN Regression loss: 0.00045 | Running loss: 0.03182\n","Epoch: 9 | Iteration: 31984 | Classification loss: 0.04763 | Regression loss: 0.04868 | Objectness loss: 0.00049 | RPN Regression loss: 0.00288 | Running loss: 0.09968\n","Epoch: 9 | Iteration: 31985 | Classification loss: 0.01305 | Regression loss: 0.03001 | Objectness loss: 0.00012 | RPN Regression loss: 0.00132 | Running loss: 0.04450\n","Epoch: 9 | Iteration: 31986 | Classification loss: 0.02725 | Regression loss: 0.02751 | Objectness loss: 0.00076 | RPN Regression loss: 0.00073 | Running loss: 0.05626\n","Epoch: 9 | Iteration: 31987 | Classification loss: 0.01874 | Regression loss: 0.02228 | Objectness loss: 0.00015 | RPN Regression loss: 0.00060 | Running loss: 0.04177\n","Epoch: 9 | Iteration: 31988 | Classification loss: 0.01563 | Regression loss: 0.02536 | Objectness loss: 0.00134 | RPN Regression loss: 0.00142 | Running loss: 0.04375\n","Epoch: 9 | Iteration: 31989 | Classification loss: 0.04072 | Regression loss: 0.03574 | Objectness loss: 0.01298 | RPN Regression loss: 0.00567 | Running loss: 0.09511\n","Epoch: 9 | Iteration: 31990 | Classification loss: 0.01300 | Regression loss: 0.02993 | Objectness loss: 0.00399 | RPN Regression loss: 0.02533 | Running loss: 0.07224\n","Epoch: 9 | Iteration: 31991 | Classification loss: 0.02061 | Regression loss: 0.01879 | Objectness loss: 0.01148 | RPN Regression loss: 0.00137 | Running loss: 0.05224\n","Epoch: 9 | Iteration: 31992 | Classification loss: 0.02427 | Regression loss: 0.02934 | Objectness loss: 0.00445 | RPN Regression loss: 0.01348 | Running loss: 0.07155\n","Epoch: 9 | Iteration: 31993 | Classification loss: 0.01187 | Regression loss: 0.02208 | Objectness loss: 0.00012 | RPN Regression loss: 0.00211 | Running loss: 0.03617\n","Epoch: 9 | Iteration: 31994 | Classification loss: 0.01596 | Regression loss: 0.02095 | Objectness loss: 0.00375 | RPN Regression loss: 0.00066 | Running loss: 0.04133\n","Epoch: 9 | Iteration: 31995 | Classification loss: 0.03919 | Regression loss: 0.02828 | Objectness loss: 0.01817 | RPN Regression loss: 0.00107 | Running loss: 0.08672\n","Epoch: 9 | Iteration: 31996 | Classification loss: 0.01222 | Regression loss: 0.02454 | Objectness loss: 0.00100 | RPN Regression loss: 0.00141 | Running loss: 0.03917\n","Epoch: 9 | Iteration: 31997 | Classification loss: 0.01320 | Regression loss: 0.02042 | Objectness loss: 0.00009 | RPN Regression loss: 0.00094 | Running loss: 0.03464\n","Epoch: 9 | Iteration: 31998 | Classification loss: 0.01018 | Regression loss: 0.02130 | Objectness loss: 0.00009 | RPN Regression loss: 0.00080 | Running loss: 0.03236\n","Epoch: 9 | Iteration: 31999 | Classification loss: 0.01895 | Regression loss: 0.04420 | Objectness loss: 0.00239 | RPN Regression loss: 0.00107 | Running loss: 0.06660\n","Epoch: 9 | Iteration: 32000 | Classification loss: 0.01808 | Regression loss: 0.01812 | Objectness loss: 0.00187 | RPN Regression loss: 0.00121 | Running loss: 0.03927\n","Epoch: 9 | Iteration: 32001 | Classification loss: 0.01021 | Regression loss: 0.02278 | Objectness loss: 0.00011 | RPN Regression loss: 0.00151 | Running loss: 0.03461\n","Epoch: 9 | Iteration: 32002 | Classification loss: 0.02211 | Regression loss: 0.02502 | Objectness loss: 0.00017 | RPN Regression loss: 0.00052 | Running loss: 0.04782\n","Epoch: 9 | Iteration: 32003 | Classification loss: 0.02356 | Regression loss: 0.03086 | Objectness loss: 0.00073 | RPN Regression loss: 0.00395 | Running loss: 0.05910\n","Epoch: 9 | Iteration: 32004 | Classification loss: 0.00506 | Regression loss: 0.01356 | Objectness loss: 0.00111 | RPN Regression loss: 0.00145 | Running loss: 0.02118\n","Epoch: 9 | Iteration: 32005 | Classification loss: 0.01224 | Regression loss: 0.01801 | Objectness loss: 0.00009 | RPN Regression loss: 0.00056 | Running loss: 0.03090\n","Epoch: 9 | Iteration: 32006 | Classification loss: 0.02277 | Regression loss: 0.03004 | Objectness loss: 0.00130 | RPN Regression loss: 0.00038 | Running loss: 0.05449\n","Epoch: 9 | Iteration: 32007 | Classification loss: 0.01890 | Regression loss: 0.02157 | Objectness loss: 0.00080 | RPN Regression loss: 0.00271 | Running loss: 0.04398\n","Epoch: 9 | Iteration: 32008 | Classification loss: 0.01851 | Regression loss: 0.04728 | Objectness loss: 0.00032 | RPN Regression loss: 0.00097 | Running loss: 0.06708\n","Epoch: 9 | Iteration: 32009 | Classification loss: 0.02990 | Regression loss: 0.02351 | Objectness loss: 0.00095 | RPN Regression loss: 0.00118 | Running loss: 0.05554\n","Epoch: 9 | Iteration: 32010 | Classification loss: 0.02716 | Regression loss: 0.03065 | Objectness loss: 0.00233 | RPN Regression loss: 0.00253 | Running loss: 0.06266\n","Epoch: 9 | Iteration: 32011 | Classification loss: 0.00728 | Regression loss: 0.02028 | Objectness loss: 0.00009 | RPN Regression loss: 0.00110 | Running loss: 0.02875\n","Epoch: 9 | Iteration: 32012 | Classification loss: 0.02290 | Regression loss: 0.02654 | Objectness loss: 0.00005 | RPN Regression loss: 0.00095 | Running loss: 0.05043\n","Epoch: 9 | Iteration: 32013 | Classification loss: 0.03861 | Regression loss: 0.03466 | Objectness loss: 0.00037 | RPN Regression loss: 0.00065 | Running loss: 0.07428\n","Epoch: 9 | Iteration: 32014 | Classification loss: 0.01086 | Regression loss: 0.01465 | Objectness loss: 0.00012 | RPN Regression loss: 0.00062 | Running loss: 0.02625\n","Epoch: 9 | Iteration: 32015 | Classification loss: 0.00791 | Regression loss: 0.01758 | Objectness loss: 0.00079 | RPN Regression loss: 0.00033 | Running loss: 0.02661\n","Epoch: 9 | Iteration: 32016 | Classification loss: 0.02815 | Regression loss: 0.03178 | Objectness loss: 0.00518 | RPN Regression loss: 0.00241 | Running loss: 0.06752\n","Epoch: 9 | Iteration: 32017 | Classification loss: 0.01118 | Regression loss: 0.01547 | Objectness loss: 0.00002 | RPN Regression loss: 0.00130 | Running loss: 0.02797\n","Epoch: 9 | Iteration: 32018 | Classification loss: 0.00927 | Regression loss: 0.02091 | Objectness loss: 0.00003 | RPN Regression loss: 0.00044 | Running loss: 0.03066\n","Epoch: 9 | Iteration: 32019 | Classification loss: 0.02797 | Regression loss: 0.04458 | Objectness loss: 0.00035 | RPN Regression loss: 0.00851 | Running loss: 0.08141\n","Epoch: 9 | Iteration: 32020 | Classification loss: 0.01936 | Regression loss: 0.01761 | Objectness loss: 0.00892 | RPN Regression loss: 0.00146 | Running loss: 0.04735\n","Epoch: 9 | Iteration: 32021 | Classification loss: 0.01243 | Regression loss: 0.02315 | Objectness loss: 0.00049 | RPN Regression loss: 0.00631 | Running loss: 0.04238\n","Epoch: 9 | Iteration: 32022 | Classification loss: 0.02071 | Regression loss: 0.03120 | Objectness loss: 0.00530 | RPN Regression loss: 0.00226 | Running loss: 0.05948\n","Epoch: 9 | Iteration: 32023 | Classification loss: 0.00588 | Regression loss: 0.01567 | Objectness loss: 0.00009 | RPN Regression loss: 0.00034 | Running loss: 0.02198\n","Epoch: 9 | Iteration: 32024 | Classification loss: 0.00744 | Regression loss: 0.01406 | Objectness loss: 0.00015 | RPN Regression loss: 0.00082 | Running loss: 0.02247\n","Epoch: 9 | Iteration: 32025 | Classification loss: 0.01502 | Regression loss: 0.01996 | Objectness loss: 0.00020 | RPN Regression loss: 0.00311 | Running loss: 0.03828\n","Epoch: 9 | Iteration: 32026 | Classification loss: 0.00593 | Regression loss: 0.02041 | Objectness loss: 0.00102 | RPN Regression loss: 0.00398 | Running loss: 0.03133\n","Epoch: 9 | Iteration: 32027 | Classification loss: 0.01587 | Regression loss: 0.01178 | Objectness loss: 0.00034 | RPN Regression loss: 0.00103 | Running loss: 0.02902\n","Epoch: 9 | Iteration: 32028 | Classification loss: 0.00629 | Regression loss: 0.01012 | Objectness loss: 0.00037 | RPN Regression loss: 0.00173 | Running loss: 0.01851\n","Epoch: 9 | Iteration: 32029 | Classification loss: 0.00493 | Regression loss: 0.01344 | Objectness loss: 0.00107 | RPN Regression loss: 0.00291 | Running loss: 0.02234\n","Epoch: 9 | Iteration: 32030 | Classification loss: 0.00876 | Regression loss: 0.01284 | Objectness loss: 0.00004 | RPN Regression loss: 0.00056 | Running loss: 0.02219\n","Epoch: 9 | Iteration: 32031 | Classification loss: 0.01838 | Regression loss: 0.02707 | Objectness loss: 0.00024 | RPN Regression loss: 0.00313 | Running loss: 0.04882\n","Epoch: 9 | Iteration: 32032 | Classification loss: 0.04420 | Regression loss: 0.02754 | Objectness loss: 0.00312 | RPN Regression loss: 0.00211 | Running loss: 0.07698\n","Epoch: 9 | Iteration: 32033 | Classification loss: 0.00841 | Regression loss: 0.01057 | Objectness loss: 0.00009 | RPN Regression loss: 0.00064 | Running loss: 0.01972\n","Epoch: 9 | Iteration: 32034 | Classification loss: 0.01513 | Regression loss: 0.01561 | Objectness loss: 0.00010 | RPN Regression loss: 0.00060 | Running loss: 0.03143\n","Epoch: 9 | Iteration: 32035 | Classification loss: 0.02778 | Regression loss: 0.04082 | Objectness loss: 0.00061 | RPN Regression loss: 0.00134 | Running loss: 0.07054\n","Epoch: 9 | Iteration: 32036 | Classification loss: 0.02731 | Regression loss: 0.04323 | Objectness loss: 0.00976 | RPN Regression loss: 0.00332 | Running loss: 0.08363\n","Epoch: 9 | Iteration: 32037 | Classification loss: 0.02120 | Regression loss: 0.03567 | Objectness loss: 0.00020 | RPN Regression loss: 0.00163 | Running loss: 0.05870\n","Epoch: 9 | Iteration: 32038 | Classification loss: 0.00893 | Regression loss: 0.01371 | Objectness loss: 0.00010 | RPN Regression loss: 0.00051 | Running loss: 0.02325\n","Epoch: 9 | Iteration: 32039 | Classification loss: 0.02150 | Regression loss: 0.01563 | Objectness loss: 0.00065 | RPN Regression loss: 0.00205 | Running loss: 0.03982\n","Epoch: 9 | Iteration: 32040 | Classification loss: 0.01266 | Regression loss: 0.01905 | Objectness loss: 0.00022 | RPN Regression loss: 0.00073 | Running loss: 0.03266\n","Epoch: 9 | Iteration: 32041 | Classification loss: 0.01079 | Regression loss: 0.01274 | Objectness loss: 0.00011 | RPN Regression loss: 0.00080 | Running loss: 0.02444\n","Epoch: 9 | Iteration: 32042 | Classification loss: 0.01069 | Regression loss: 0.01548 | Objectness loss: 0.00004 | RPN Regression loss: 0.00192 | Running loss: 0.02813\n","Epoch: 9 | Iteration: 32043 | Classification loss: 0.00755 | Regression loss: 0.01559 | Objectness loss: 0.00010 | RPN Regression loss: 0.00079 | Running loss: 0.02403\n","Epoch: 9 | Iteration: 32044 | Classification loss: 0.01783 | Regression loss: 0.01834 | Objectness loss: 0.00022 | RPN Regression loss: 0.00300 | Running loss: 0.03939\n","Epoch: 9 | Iteration: 32045 | Classification loss: 0.01721 | Regression loss: 0.01546 | Objectness loss: 0.00108 | RPN Regression loss: 0.00263 | Running loss: 0.03637\n","Epoch: 9 | Iteration: 32046 | Classification loss: 0.01994 | Regression loss: 0.03820 | Objectness loss: 0.00071 | RPN Regression loss: 0.00322 | Running loss: 0.06208\n","Epoch: 9 | Iteration: 32047 | Classification loss: 0.01095 | Regression loss: 0.02084 | Objectness loss: 0.00042 | RPN Regression loss: 0.00153 | Running loss: 0.03374\n","Epoch: 9 | Iteration: 32048 | Classification loss: 0.01904 | Regression loss: 0.01363 | Objectness loss: 0.00027 | RPN Regression loss: 0.00034 | Running loss: 0.03329\n","Epoch: 9 | Iteration: 32049 | Classification loss: 0.00656 | Regression loss: 0.01771 | Objectness loss: 0.00194 | RPN Regression loss: 0.02729 | Running loss: 0.05350\n","Epoch: 9 | Iteration: 32050 | Classification loss: 0.01654 | Regression loss: 0.02143 | Objectness loss: 0.00078 | RPN Regression loss: 0.00149 | Running loss: 0.04023\n","Epoch: 9 | Iteration: 32051 | Classification loss: 0.01804 | Regression loss: 0.02222 | Objectness loss: 0.00232 | RPN Regression loss: 0.00088 | Running loss: 0.04346\n","Epoch: 9 | Iteration: 32052 | Classification loss: 0.02046 | Regression loss: 0.03451 | Objectness loss: 0.00015 | RPN Regression loss: 0.00078 | Running loss: 0.05592\n","Epoch: 9 | Iteration: 32053 | Classification loss: 0.00652 | Regression loss: 0.01535 | Objectness loss: 0.00073 | RPN Regression loss: 0.00281 | Running loss: 0.02542\n","Epoch: 9 | Iteration: 32054 | Classification loss: 0.01243 | Regression loss: 0.02068 | Objectness loss: 0.00174 | RPN Regression loss: 0.00128 | Running loss: 0.03612\n","Epoch: 9 | Iteration: 32055 | Classification loss: 0.01158 | Regression loss: 0.02052 | Objectness loss: 0.00003 | RPN Regression loss: 0.00080 | Running loss: 0.03294\n","Epoch: 9 | Iteration: 32056 | Classification loss: 0.00980 | Regression loss: 0.01753 | Objectness loss: 0.00011 | RPN Regression loss: 0.00541 | Running loss: 0.03285\n","Epoch: 9 | Iteration: 32057 | Classification loss: 0.01375 | Regression loss: 0.01853 | Objectness loss: 0.00007 | RPN Regression loss: 0.00111 | Running loss: 0.03346\n","Epoch: 9 | Iteration: 32058 | Classification loss: 0.01776 | Regression loss: 0.02165 | Objectness loss: 0.00005 | RPN Regression loss: 0.00099 | Running loss: 0.04046\n","Epoch: 9 | Iteration: 32059 | Classification loss: 0.00917 | Regression loss: 0.01690 | Objectness loss: 0.00003 | RPN Regression loss: 0.00038 | Running loss: 0.02648\n","Epoch: 9 | Iteration: 32060 | Classification loss: 0.02185 | Regression loss: 0.03286 | Objectness loss: 0.00034 | RPN Regression loss: 0.00235 | Running loss: 0.05740\n","Epoch: 9 | Iteration: 32061 | Classification loss: 0.03693 | Regression loss: 0.02282 | Objectness loss: 0.00013 | RPN Regression loss: 0.00073 | Running loss: 0.06060\n","Epoch: 9 | Iteration: 32062 | Classification loss: 0.00644 | Regression loss: 0.01291 | Objectness loss: 0.00005 | RPN Regression loss: 0.00083 | Running loss: 0.02022\n","Epoch: 9 | Iteration: 32063 | Classification loss: 0.03548 | Regression loss: 0.06033 | Objectness loss: 0.00935 | RPN Regression loss: 0.00184 | Running loss: 0.10700\n","Epoch: 9 | Iteration: 32064 | Classification loss: 0.01555 | Regression loss: 0.02890 | Objectness loss: 0.00013 | RPN Regression loss: 0.00070 | Running loss: 0.04527\n","Epoch: 9 | Iteration: 32065 | Classification loss: 0.01083 | Regression loss: 0.01943 | Objectness loss: 0.00316 | RPN Regression loss: 0.00557 | Running loss: 0.03900\n","Epoch: 9 | Iteration: 32066 | Classification loss: 0.00953 | Regression loss: 0.01745 | Objectness loss: 0.00011 | RPN Regression loss: 0.00095 | Running loss: 0.02804\n","Epoch: 9 | Iteration: 32067 | Classification loss: 0.01793 | Regression loss: 0.02799 | Objectness loss: 0.00016 | RPN Regression loss: 0.00059 | Running loss: 0.04667\n","Epoch: 9 | Iteration: 32068 | Classification loss: 0.01178 | Regression loss: 0.04751 | Objectness loss: 0.00010 | RPN Regression loss: 0.00156 | Running loss: 0.06095\n","Epoch: 9 | Iteration: 32069 | Classification loss: 0.01304 | Regression loss: 0.01792 | Objectness loss: 0.00017 | RPN Regression loss: 0.00064 | Running loss: 0.03176\n","Epoch: 9 | Iteration: 32070 | Classification loss: 0.01095 | Regression loss: 0.01628 | Objectness loss: 0.03232 | RPN Regression loss: 0.04584 | Running loss: 0.10539\n","Epoch: 9 | Iteration: 32071 | Classification loss: 0.00960 | Regression loss: 0.02946 | Objectness loss: 0.00048 | RPN Regression loss: 0.00052 | Running loss: 0.04005\n","Epoch: 9 | Iteration: 32072 | Classification loss: 0.00817 | Regression loss: 0.01374 | Objectness loss: 0.00029 | RPN Regression loss: 0.00068 | Running loss: 0.02288\n","Epoch: 9 | Iteration: 32073 | Classification loss: 0.02201 | Regression loss: 0.03326 | Objectness loss: 0.00035 | RPN Regression loss: 0.00143 | Running loss: 0.05705\n","Epoch: 9 | Iteration: 32074 | Classification loss: 0.03006 | Regression loss: 0.02312 | Objectness loss: 0.00662 | RPN Regression loss: 0.00400 | Running loss: 0.06379\n","Epoch: 9 | Iteration: 32075 | Classification loss: 0.01433 | Regression loss: 0.01884 | Objectness loss: 0.00193 | RPN Regression loss: 0.00270 | Running loss: 0.03779\n","Epoch: 9 | Iteration: 32076 | Classification loss: 0.01618 | Regression loss: 0.01556 | Objectness loss: 0.00061 | RPN Regression loss: 0.00074 | Running loss: 0.03309\n","Epoch: 9 | Iteration: 32077 | Classification loss: 0.01129 | Regression loss: 0.01620 | Objectness loss: 0.00030 | RPN Regression loss: 0.00286 | Running loss: 0.03065\n","Epoch: 9 | Iteration: 32078 | Classification loss: 0.01757 | Regression loss: 0.01782 | Objectness loss: 0.00007 | RPN Regression loss: 0.00091 | Running loss: 0.03636\n","Epoch: 9 | Iteration: 32079 | Classification loss: 0.01552 | Regression loss: 0.01766 | Objectness loss: 0.00217 | RPN Regression loss: 0.00353 | Running loss: 0.03888\n","Epoch: 9 | Iteration: 32080 | Classification loss: 0.01236 | Regression loss: 0.02448 | Objectness loss: 0.00014 | RPN Regression loss: 0.00187 | Running loss: 0.03885\n","Epoch: 9 | Iteration: 32081 | Classification loss: 0.01356 | Regression loss: 0.02448 | Objectness loss: 0.00219 | RPN Regression loss: 0.00055 | Running loss: 0.04079\n","Epoch: 9 | Iteration: 32082 | Classification loss: 0.01682 | Regression loss: 0.01372 | Objectness loss: 0.00008 | RPN Regression loss: 0.00236 | Running loss: 0.03297\n","Epoch: 9 | Iteration: 32083 | Classification loss: 0.03244 | Regression loss: 0.03454 | Objectness loss: 0.00175 | RPN Regression loss: 0.00085 | Running loss: 0.06958\n","Epoch: 9 | Iteration: 32084 | Classification loss: 0.03504 | Regression loss: 0.02500 | Objectness loss: 0.00018 | RPN Regression loss: 0.00070 | Running loss: 0.06091\n","Epoch: 9 | Iteration: 32085 | Classification loss: 0.01742 | Regression loss: 0.02053 | Objectness loss: 0.00129 | RPN Regression loss: 0.00161 | Running loss: 0.04085\n","Epoch: 9 | Iteration: 32086 | Classification loss: 0.01064 | Regression loss: 0.00909 | Objectness loss: 0.00004 | RPN Regression loss: 0.00055 | Running loss: 0.02032\n","Epoch: 9 | Iteration: 32087 | Classification loss: 0.00896 | Regression loss: 0.02260 | Objectness loss: 0.00437 | RPN Regression loss: 0.00233 | Running loss: 0.03826\n","Epoch: 9 | Iteration: 32088 | Classification loss: 0.02230 | Regression loss: 0.01974 | Objectness loss: 0.00703 | RPN Regression loss: 0.00459 | Running loss: 0.05367\n","Epoch: 9 | Iteration: 32089 | Classification loss: 0.03332 | Regression loss: 0.02790 | Objectness loss: 0.00676 | RPN Regression loss: 0.00073 | Running loss: 0.06870\n","Epoch: 9 | Iteration: 32090 | Classification loss: 0.01568 | Regression loss: 0.02504 | Objectness loss: 0.00040 | RPN Regression loss: 0.00082 | Running loss: 0.04195\n","Epoch: 9 | Iteration: 32091 | Classification loss: 0.02556 | Regression loss: 0.02100 | Objectness loss: 0.00011 | RPN Regression loss: 0.00137 | Running loss: 0.04804\n","Epoch: 9 | Iteration: 32092 | Classification loss: 0.00887 | Regression loss: 0.01934 | Objectness loss: 0.00614 | RPN Regression loss: 0.00193 | Running loss: 0.03627\n","Epoch: 9 | Iteration: 32093 | Classification loss: 0.01339 | Regression loss: 0.03601 | Objectness loss: 0.00592 | RPN Regression loss: 0.00133 | Running loss: 0.05665\n","Epoch: 9 | Iteration: 32094 | Classification loss: 0.01160 | Regression loss: 0.02195 | Objectness loss: 0.00004 | RPN Regression loss: 0.00058 | Running loss: 0.03417\n","Epoch: 9 | Iteration: 32095 | Classification loss: 0.01860 | Regression loss: 0.05252 | Objectness loss: 0.00841 | RPN Regression loss: 0.00239 | Running loss: 0.08193\n","Epoch: 9 | Iteration: 32096 | Classification loss: 0.00545 | Regression loss: 0.01469 | Objectness loss: 0.00376 | RPN Regression loss: 0.00073 | Running loss: 0.02463\n","Epoch: 9 | Iteration: 32097 | Classification loss: 0.01201 | Regression loss: 0.01658 | Objectness loss: 0.00015 | RPN Regression loss: 0.00140 | Running loss: 0.03013\n","Epoch: 9 | Iteration: 32098 | Classification loss: 0.00888 | Regression loss: 0.02354 | Objectness loss: 0.00154 | RPN Regression loss: 0.00206 | Running loss: 0.03601\n","Epoch: 9 | Iteration: 32099 | Classification loss: 0.01937 | Regression loss: 0.01407 | Objectness loss: 0.00004 | RPN Regression loss: 0.00131 | Running loss: 0.03480\n","Epoch: 9 | Iteration: 32100 | Classification loss: 0.01155 | Regression loss: 0.01217 | Objectness loss: 0.00031 | RPN Regression loss: 0.00148 | Running loss: 0.02551\n","Epoch: 9 | Iteration: 32101 | Classification loss: 0.02711 | Regression loss: 0.01949 | Objectness loss: 0.00023 | RPN Regression loss: 0.00067 | Running loss: 0.04750\n","Epoch: 9 | Iteration: 32102 | Classification loss: 0.01253 | Regression loss: 0.01461 | Objectness loss: 0.00015 | RPN Regression loss: 0.00306 | Running loss: 0.03035\n","Epoch: 9 | Iteration: 32103 | Classification loss: 0.00994 | Regression loss: 0.01695 | Objectness loss: 0.00005 | RPN Regression loss: 0.00026 | Running loss: 0.02720\n","Epoch: 9 | Iteration: 32104 | Classification loss: 0.06914 | Regression loss: 0.04252 | Objectness loss: 0.00729 | RPN Regression loss: 0.00150 | Running loss: 0.12046\n","Epoch: 9 | Iteration: 32105 | Classification loss: 0.03022 | Regression loss: 0.02765 | Objectness loss: 0.00075 | RPN Regression loss: 0.00041 | Running loss: 0.05903\n","Epoch: 9 | Iteration: 32106 | Classification loss: 0.01813 | Regression loss: 0.02920 | Objectness loss: 0.00015 | RPN Regression loss: 0.00114 | Running loss: 0.04862\n","Epoch: 9 | Iteration: 32107 | Classification loss: 0.00774 | Regression loss: 0.02140 | Objectness loss: 0.00099 | RPN Regression loss: 0.00238 | Running loss: 0.03251\n","Epoch: 9 | Iteration: 32108 | Classification loss: 0.01960 | Regression loss: 0.01914 | Objectness loss: 0.00012 | RPN Regression loss: 0.00095 | Running loss: 0.03981\n","Epoch: 9 | Iteration: 32109 | Classification loss: 0.01079 | Regression loss: 0.02197 | Objectness loss: 0.00023 | RPN Regression loss: 0.00326 | Running loss: 0.03625\n","Epoch: 9 | Iteration: 32110 | Classification loss: 0.02963 | Regression loss: 0.03240 | Objectness loss: 0.00072 | RPN Regression loss: 0.00109 | Running loss: 0.06384\n","Epoch: 9 | Iteration: 32111 | Classification loss: 0.01011 | Regression loss: 0.02752 | Objectness loss: 0.00015 | RPN Regression loss: 0.00064 | Running loss: 0.03842\n","Epoch: 9 | Iteration: 32112 | Classification loss: 0.00472 | Regression loss: 0.01359 | Objectness loss: 0.00009 | RPN Regression loss: 0.00285 | Running loss: 0.02126\n","Epoch: 9 | Iteration: 32113 | Classification loss: 0.02421 | Regression loss: 0.01898 | Objectness loss: 0.00004 | RPN Regression loss: 0.00045 | Running loss: 0.04369\n","Epoch: 9 | Iteration: 32114 | Classification loss: 0.01262 | Regression loss: 0.01954 | Objectness loss: 0.00033 | RPN Regression loss: 0.01364 | Running loss: 0.04612\n","Epoch: 9 | Iteration: 32115 | Classification loss: 0.00644 | Regression loss: 0.00956 | Objectness loss: 0.00047 | RPN Regression loss: 0.00058 | Running loss: 0.01705\n","Epoch: 9 | Iteration: 32116 | Classification loss: 0.03183 | Regression loss: 0.01461 | Objectness loss: 0.00001 | RPN Regression loss: 0.00125 | Running loss: 0.04771\n","Epoch: 9 | Iteration: 32117 | Classification loss: 0.00759 | Regression loss: 0.01958 | Objectness loss: 0.00010 | RPN Regression loss: 0.00077 | Running loss: 0.02804\n","Epoch: 9 | Iteration: 32118 | Classification loss: 0.00581 | Regression loss: 0.01521 | Objectness loss: 0.00006 | RPN Regression loss: 0.00123 | Running loss: 0.02230\n","Epoch: 9 | Iteration: 32119 | Classification loss: 0.00932 | Regression loss: 0.02496 | Objectness loss: 0.00002 | RPN Regression loss: 0.00074 | Running loss: 0.03505\n","Epoch: 9 | Iteration: 32120 | Classification loss: 0.01437 | Regression loss: 0.02594 | Objectness loss: 0.00008 | RPN Regression loss: 0.00054 | Running loss: 0.04092\n","Epoch: 9 | Iteration: 32121 | Classification loss: 0.03079 | Regression loss: 0.04518 | Objectness loss: 0.00024 | RPN Regression loss: 0.00130 | Running loss: 0.07751\n","Epoch: 9 | Iteration: 32122 | Classification loss: 0.03358 | Regression loss: 0.02807 | Objectness loss: 0.00005 | RPN Regression loss: 0.00356 | Running loss: 0.06526\n","Epoch: 9 | Iteration: 32123 | Classification loss: 0.01049 | Regression loss: 0.02066 | Objectness loss: 0.00002 | RPN Regression loss: 0.00122 | Running loss: 0.03239\n","Epoch: 9 | Iteration: 32124 | Classification loss: 0.01069 | Regression loss: 0.00960 | Objectness loss: 0.00195 | RPN Regression loss: 0.00210 | Running loss: 0.02434\n","Epoch: 9 | Iteration: 32125 | Classification loss: 0.01227 | Regression loss: 0.02374 | Objectness loss: 0.00042 | RPN Regression loss: 0.00280 | Running loss: 0.03923\n","Epoch: 9 | Iteration: 32126 | Classification loss: 0.01635 | Regression loss: 0.02157 | Objectness loss: 0.00003 | RPN Regression loss: 0.00123 | Running loss: 0.03918\n","Epoch: 9 | Iteration: 32127 | Classification loss: 0.02336 | Regression loss: 0.03963 | Objectness loss: 0.00266 | RPN Regression loss: 0.00258 | Running loss: 0.06824\n","Epoch: 9 | Iteration: 32128 | Classification loss: 0.00766 | Regression loss: 0.02178 | Objectness loss: 0.00058 | RPN Regression loss: 0.00126 | Running loss: 0.03127\n","Epoch: 9 | Iteration: 32129 | Classification loss: 0.01121 | Regression loss: 0.02020 | Objectness loss: 0.00007 | RPN Regression loss: 0.00224 | Running loss: 0.03372\n","Epoch: 9 | Iteration: 32130 | Classification loss: 0.01291 | Regression loss: 0.02887 | Objectness loss: 0.00452 | RPN Regression loss: 0.00069 | Running loss: 0.04700\n","Epoch: 9 | Iteration: 32131 | Classification loss: 0.00744 | Regression loss: 0.01688 | Objectness loss: 0.00031 | RPN Regression loss: 0.00038 | Running loss: 0.02502\n","Epoch: 9 | Iteration: 32132 | Classification loss: 0.01025 | Regression loss: 0.02238 | Objectness loss: 0.00089 | RPN Regression loss: 0.00030 | Running loss: 0.03382\n","Epoch: 9 | Iteration: 32133 | Classification loss: 0.01383 | Regression loss: 0.02426 | Objectness loss: 0.00020 | RPN Regression loss: 0.00075 | Running loss: 0.03905\n","Epoch: 9 | Iteration: 32134 | Classification loss: 0.01437 | Regression loss: 0.01467 | Objectness loss: 0.00019 | RPN Regression loss: 0.00077 | Running loss: 0.03001\n","Epoch: 9 | Iteration: 32135 | Classification loss: 0.01318 | Regression loss: 0.02452 | Objectness loss: 0.00033 | RPN Regression loss: 0.00128 | Running loss: 0.03931\n","Epoch: 9 | Iteration: 32136 | Classification loss: 0.00688 | Regression loss: 0.01328 | Objectness loss: 0.00053 | RPN Regression loss: 0.00471 | Running loss: 0.02539\n","Epoch: 9 | Iteration: 32137 | Classification loss: 0.01632 | Regression loss: 0.02109 | Objectness loss: 0.00196 | RPN Regression loss: 0.00360 | Running loss: 0.04297\n","Epoch: 9 | Iteration: 32138 | Classification loss: 0.00911 | Regression loss: 0.02995 | Objectness loss: 0.00025 | RPN Regression loss: 0.00053 | Running loss: 0.03983\n","Epoch: 9 | Iteration: 32139 | Classification loss: 0.01649 | Regression loss: 0.01985 | Objectness loss: 0.00044 | RPN Regression loss: 0.00243 | Running loss: 0.03920\n","Epoch: 9 | Iteration: 32140 | Classification loss: 0.05037 | Regression loss: 0.02196 | Objectness loss: 0.00060 | RPN Regression loss: 0.00409 | Running loss: 0.07703\n","Epoch: 9 | Iteration: 32141 | Classification loss: 0.00662 | Regression loss: 0.02476 | Objectness loss: 0.00019 | RPN Regression loss: 0.00079 | Running loss: 0.03235\n","Epoch: 9 | Iteration: 32142 | Classification loss: 0.00915 | Regression loss: 0.01989 | Objectness loss: 0.00027 | RPN Regression loss: 0.00074 | Running loss: 0.03006\n","Epoch: 9 | Iteration: 32143 | Classification loss: 0.02420 | Regression loss: 0.01775 | Objectness loss: 0.00047 | RPN Regression loss: 0.00657 | Running loss: 0.04899\n","Epoch: 9 | Iteration: 32144 | Classification loss: 0.03398 | Regression loss: 0.04285 | Objectness loss: 0.00153 | RPN Regression loss: 0.00405 | Running loss: 0.08241\n","Epoch: 9 | Iteration: 32145 | Classification loss: 0.01807 | Regression loss: 0.04197 | Objectness loss: 0.00116 | RPN Regression loss: 0.00192 | Running loss: 0.06311\n","Epoch: 9 | Iteration: 32146 | Classification loss: 0.01028 | Regression loss: 0.02826 | Objectness loss: 0.00021 | RPN Regression loss: 0.00069 | Running loss: 0.03944\n","Epoch: 9 | Iteration: 32147 | Classification loss: 0.00465 | Regression loss: 0.01233 | Objectness loss: 0.00001 | RPN Regression loss: 0.00038 | Running loss: 0.01737\n","Epoch: 9 | Iteration: 32148 | Classification loss: 0.01655 | Regression loss: 0.03556 | Objectness loss: 0.00006 | RPN Regression loss: 0.00078 | Running loss: 0.05295\n","Epoch: 9 | Iteration: 32149 | Classification loss: 0.00526 | Regression loss: 0.01194 | Objectness loss: 0.00002 | RPN Regression loss: 0.00067 | Running loss: 0.01789\n","Epoch: 9 | Iteration: 32150 | Classification loss: 0.01294 | Regression loss: 0.03030 | Objectness loss: 0.00011 | RPN Regression loss: 0.00156 | Running loss: 0.04492\n","Epoch: 9 | Iteration: 32151 | Classification loss: 0.01738 | Regression loss: 0.02871 | Objectness loss: 0.00005 | RPN Regression loss: 0.00072 | Running loss: 0.04686\n","Epoch: 9 | Iteration: 32152 | Classification loss: 0.03687 | Regression loss: 0.01409 | Objectness loss: 0.07347 | RPN Regression loss: 0.00582 | Running loss: 0.13025\n","Epoch: 9 | Iteration: 32153 | Classification loss: 0.00766 | Regression loss: 0.01423 | Objectness loss: 0.00334 | RPN Regression loss: 0.00078 | Running loss: 0.02602\n","Epoch: 9 | Iteration: 32154 | Classification loss: 0.00616 | Regression loss: 0.01043 | Objectness loss: 0.00288 | RPN Regression loss: 0.00419 | Running loss: 0.02366\n","Epoch: 9 | Iteration: 32155 | Classification loss: 0.01958 | Regression loss: 0.02336 | Objectness loss: 0.00010 | RPN Regression loss: 0.00144 | Running loss: 0.04448\n","Epoch: 9 | Iteration: 32156 | Classification loss: 0.00767 | Regression loss: 0.02577 | Objectness loss: 0.00042 | RPN Regression loss: 0.00343 | Running loss: 0.03729\n","Epoch: 9 | Iteration: 32157 | Classification loss: 0.01106 | Regression loss: 0.01535 | Objectness loss: 0.00008 | RPN Regression loss: 0.00102 | Running loss: 0.02751\n","Epoch: 9 | Iteration: 32158 | Classification loss: 0.00736 | Regression loss: 0.01371 | Objectness loss: 0.00036 | RPN Regression loss: 0.00149 | Running loss: 0.02293\n","Epoch: 9 | Iteration: 32159 | Classification loss: 0.03410 | Regression loss: 0.03587 | Objectness loss: 0.00654 | RPN Regression loss: 0.00292 | Running loss: 0.07943\n","Epoch: 9 | Iteration: 32160 | Classification loss: 0.00673 | Regression loss: 0.01562 | Objectness loss: 0.00006 | RPN Regression loss: 0.00054 | Running loss: 0.02296\n","Epoch: 9 | Iteration: 32161 | Classification loss: 0.00886 | Regression loss: 0.01980 | Objectness loss: 0.00008 | RPN Regression loss: 0.00051 | Running loss: 0.02925\n","Epoch: 9 | Iteration: 32162 | Classification loss: 0.01130 | Regression loss: 0.02465 | Objectness loss: 0.00026 | RPN Regression loss: 0.00258 | Running loss: 0.03880\n","Epoch: 9 | Iteration: 32163 | Classification loss: 0.01895 | Regression loss: 0.01559 | Objectness loss: 0.00035 | RPN Regression loss: 0.00101 | Running loss: 0.03590\n","Epoch: 9 | Iteration: 32164 | Classification loss: 0.01090 | Regression loss: 0.01824 | Objectness loss: 0.00026 | RPN Regression loss: 0.00091 | Running loss: 0.03031\n","Epoch: 9 | Iteration: 32165 | Classification loss: 0.01476 | Regression loss: 0.02014 | Objectness loss: 0.00211 | RPN Regression loss: 0.00242 | Running loss: 0.03942\n","Epoch: 9 | Iteration: 32166 | Classification loss: 0.00775 | Regression loss: 0.01792 | Objectness loss: 0.00161 | RPN Regression loss: 0.00268 | Running loss: 0.02996\n","Epoch: 9 | Iteration: 32167 | Classification loss: 0.00780 | Regression loss: 0.01147 | Objectness loss: 0.00101 | RPN Regression loss: 0.00086 | Running loss: 0.02115\n","Epoch: 9 | Iteration: 32168 | Classification loss: 0.01137 | Regression loss: 0.01644 | Objectness loss: 0.00137 | RPN Regression loss: 0.00028 | Running loss: 0.02946\n","Epoch: 9 | Iteration: 32169 | Classification loss: 0.01264 | Regression loss: 0.02497 | Objectness loss: 0.00389 | RPN Regression loss: 0.00593 | Running loss: 0.04742\n","Epoch: 9 | Iteration: 32170 | Classification loss: 0.01941 | Regression loss: 0.03880 | Objectness loss: 0.00079 | RPN Regression loss: 0.00349 | Running loss: 0.06248\n","Epoch: 9 | Iteration: 32171 | Classification loss: 0.00768 | Regression loss: 0.01470 | Objectness loss: 0.00046 | RPN Regression loss: 0.00181 | Running loss: 0.02465\n","Epoch: 9 | Iteration: 32172 | Classification loss: 0.00801 | Regression loss: 0.01893 | Objectness loss: 0.00053 | RPN Regression loss: 0.00047 | Running loss: 0.02795\n","Epoch: 9 | Iteration: 32173 | Classification loss: 0.01111 | Regression loss: 0.01909 | Objectness loss: 0.00036 | RPN Regression loss: 0.00359 | Running loss: 0.03415\n","Epoch: 9 | Iteration: 32174 | Classification loss: 0.01185 | Regression loss: 0.02070 | Objectness loss: 0.00615 | RPN Regression loss: 0.00034 | Running loss: 0.03904\n","Epoch: 9 | Iteration: 32175 | Classification loss: 0.00960 | Regression loss: 0.01040 | Objectness loss: 0.00047 | RPN Regression loss: 0.00196 | Running loss: 0.02242\n","Epoch: 9 | Iteration: 32176 | Classification loss: 0.01552 | Regression loss: 0.01264 | Objectness loss: 0.00110 | RPN Regression loss: 0.00026 | Running loss: 0.02952\n","Epoch: 9 | Iteration: 32177 | Classification loss: 0.03631 | Regression loss: 0.03045 | Objectness loss: 0.00074 | RPN Regression loss: 0.00128 | Running loss: 0.06878\n","Epoch: 9 | Iteration: 32178 | Classification loss: 0.00765 | Regression loss: 0.01137 | Objectness loss: 0.00018 | RPN Regression loss: 0.00071 | Running loss: 0.01992\n","Epoch: 9 | Iteration: 32179 | Classification loss: 0.00966 | Regression loss: 0.01779 | Objectness loss: 0.00058 | RPN Regression loss: 0.00033 | Running loss: 0.02836\n","Epoch: 9 | Iteration: 32180 | Classification loss: 0.00869 | Regression loss: 0.01989 | Objectness loss: 0.00015 | RPN Regression loss: 0.00208 | Running loss: 0.03081\n","Epoch: 9 | Iteration: 32181 | Classification loss: 0.01938 | Regression loss: 0.01551 | Objectness loss: 0.00088 | RPN Regression loss: 0.00096 | Running loss: 0.03673\n","Epoch: 9 | Iteration: 32182 | Classification loss: 0.04480 | Regression loss: 0.02376 | Objectness loss: 0.00652 | RPN Regression loss: 0.00093 | Running loss: 0.07602\n","Epoch: 9 | Iteration: 32183 | Classification loss: 0.01981 | Regression loss: 0.02595 | Objectness loss: 0.00010 | RPN Regression loss: 0.00113 | Running loss: 0.04698\n","Epoch: 9 | Iteration: 32184 | Classification loss: 0.02135 | Regression loss: 0.02696 | Objectness loss: 0.00520 | RPN Regression loss: 0.00085 | Running loss: 0.05436\n","Epoch: 9 | Iteration: 32185 | Classification loss: 0.03554 | Regression loss: 0.02524 | Objectness loss: 0.00052 | RPN Regression loss: 0.00191 | Running loss: 0.06321\n","Epoch: 9 | Iteration: 32186 | Classification loss: 0.01199 | Regression loss: 0.02170 | Objectness loss: 0.00345 | RPN Regression loss: 0.01679 | Running loss: 0.05393\n","Epoch: 9 | Iteration: 32187 | Classification loss: 0.01332 | Regression loss: 0.02457 | Objectness loss: 0.00096 | RPN Regression loss: 0.00296 | Running loss: 0.04181\n","Epoch: 9 | Iteration: 32188 | Classification loss: 0.00855 | Regression loss: 0.01945 | Objectness loss: 0.00092 | RPN Regression loss: 0.00135 | Running loss: 0.03027\n","Epoch: 9 | Iteration: 32189 | Classification loss: 0.01347 | Regression loss: 0.01713 | Objectness loss: 0.00059 | RPN Regression loss: 0.00237 | Running loss: 0.03355\n","Epoch: 9 | Iteration: 32190 | Classification loss: 0.00615 | Regression loss: 0.01739 | Objectness loss: 0.00006 | RPN Regression loss: 0.00061 | Running loss: 0.02422\n","Epoch: 9 | Iteration: 32191 | Classification loss: 0.01407 | Regression loss: 0.02296 | Objectness loss: 0.00035 | RPN Regression loss: 0.00082 | Running loss: 0.03820\n","Epoch: 9 | Iteration: 32192 | Classification loss: 0.01796 | Regression loss: 0.01913 | Objectness loss: 0.00338 | RPN Regression loss: 0.00107 | Running loss: 0.04154\n","Epoch: 9 | Iteration: 32193 | Classification loss: 0.00845 | Regression loss: 0.01440 | Objectness loss: 0.01308 | RPN Regression loss: 0.01657 | Running loss: 0.05250\n","Epoch: 9 | Iteration: 32194 | Classification loss: 0.01065 | Regression loss: 0.02775 | Objectness loss: 0.00037 | RPN Regression loss: 0.00092 | Running loss: 0.03970\n","Epoch: 9 | Iteration: 32195 | Classification loss: 0.00973 | Regression loss: 0.01372 | Objectness loss: 0.00012 | RPN Regression loss: 0.00174 | Running loss: 0.02532\n","Epoch: 9 | Iteration: 32196 | Classification loss: 0.01014 | Regression loss: 0.02973 | Objectness loss: 0.00031 | RPN Regression loss: 0.00081 | Running loss: 0.04099\n","Epoch: 9 | Iteration: 32197 | Classification loss: 0.01255 | Regression loss: 0.01475 | Objectness loss: 0.00279 | RPN Regression loss: 0.00268 | Running loss: 0.03278\n","Epoch: 9 | Iteration: 32198 | Classification loss: 0.01241 | Regression loss: 0.01182 | Objectness loss: 0.00019 | RPN Regression loss: 0.00047 | Running loss: 0.02489\n","Epoch: 9 | Iteration: 32199 | Classification loss: 0.02012 | Regression loss: 0.03063 | Objectness loss: 0.00159 | RPN Regression loss: 0.00225 | Running loss: 0.05459\n","Epoch: 9 | Iteration: 32200 | Classification loss: 0.02989 | Regression loss: 0.02379 | Objectness loss: 0.01913 | RPN Regression loss: 0.00351 | Running loss: 0.07632\n","Epoch: 9 | Iteration: 32201 | Classification loss: 0.01560 | Regression loss: 0.03400 | Objectness loss: 0.00020 | RPN Regression loss: 0.00123 | Running loss: 0.05104\n","Epoch: 9 | Iteration: 32202 | Classification loss: 0.01411 | Regression loss: 0.02545 | Objectness loss: 0.00061 | RPN Regression loss: 0.00114 | Running loss: 0.04131\n","Epoch: 9 | Iteration: 32203 | Classification loss: 0.02448 | Regression loss: 0.03542 | Objectness loss: 0.00050 | RPN Regression loss: 0.00084 | Running loss: 0.06124\n","Epoch: 9 | Iteration: 32204 | Classification loss: 0.02160 | Regression loss: 0.02240 | Objectness loss: 0.00031 | RPN Regression loss: 0.00139 | Running loss: 0.04569\n","Epoch: 9 | Iteration: 32205 | Classification loss: 0.01709 | Regression loss: 0.01881 | Objectness loss: 0.00253 | RPN Regression loss: 0.00121 | Running loss: 0.03964\n","Epoch: 9 | Iteration: 32206 | Classification loss: 0.02873 | Regression loss: 0.05703 | Objectness loss: 0.00091 | RPN Regression loss: 0.00074 | Running loss: 0.08741\n","Epoch: 9 | Iteration: 32207 | Classification loss: 0.02007 | Regression loss: 0.01525 | Objectness loss: 0.00031 | RPN Regression loss: 0.00214 | Running loss: 0.03778\n","Epoch: 9 | Iteration: 32208 | Classification loss: 0.01272 | Regression loss: 0.03228 | Objectness loss: 0.00083 | RPN Regression loss: 0.00065 | Running loss: 0.04647\n","Epoch: 9 | Iteration: 32209 | Classification loss: 0.01411 | Regression loss: 0.03617 | Objectness loss: 0.00034 | RPN Regression loss: 0.00114 | Running loss: 0.05176\n","Epoch: 9 | Iteration: 32210 | Classification loss: 0.02270 | Regression loss: 0.03082 | Objectness loss: 0.00215 | RPN Regression loss: 0.00215 | Running loss: 0.05781\n","Epoch: 9 | Iteration: 32211 | Classification loss: 0.02607 | Regression loss: 0.04237 | Objectness loss: 0.00159 | RPN Regression loss: 0.00204 | Running loss: 0.07207\n","Epoch: 9 | Iteration: 32212 | Classification loss: 0.03254 | Regression loss: 0.02385 | Objectness loss: 0.00719 | RPN Regression loss: 0.00290 | Running loss: 0.06647\n","Epoch: 9 | Iteration: 32213 | Classification loss: 0.00766 | Regression loss: 0.01388 | Objectness loss: 0.00017 | RPN Regression loss: 0.00053 | Running loss: 0.02224\n","Epoch: 9 | Iteration: 32214 | Classification loss: 0.02761 | Regression loss: 0.01697 | Objectness loss: 0.00072 | RPN Regression loss: 0.00607 | Running loss: 0.05136\n","Epoch: 9 | Iteration: 32215 | Classification loss: 0.01420 | Regression loss: 0.01344 | Objectness loss: 0.00032 | RPN Regression loss: 0.00036 | Running loss: 0.02832\n","Epoch: 9 | Iteration: 32216 | Classification loss: 0.02409 | Regression loss: 0.02978 | Objectness loss: 0.00168 | RPN Regression loss: 0.00086 | Running loss: 0.05642\n","Epoch: 9 | Iteration: 32217 | Classification loss: 0.02445 | Regression loss: 0.01861 | Objectness loss: 0.00221 | RPN Regression loss: 0.00233 | Running loss: 0.04759\n","Epoch: 9 | Iteration: 32218 | Classification loss: 0.00658 | Regression loss: 0.01006 | Objectness loss: 0.00011 | RPN Regression loss: 0.00054 | Running loss: 0.01728\n","Epoch: 9 | Iteration: 32219 | Classification loss: 0.00925 | Regression loss: 0.01799 | Objectness loss: 0.00028 | RPN Regression loss: 0.00545 | Running loss: 0.03296\n","Epoch: 9 | Iteration: 32220 | Classification loss: 0.01555 | Regression loss: 0.02457 | Objectness loss: 0.00059 | RPN Regression loss: 0.00141 | Running loss: 0.04212\n","Epoch: 9 | Iteration: 32221 | Classification loss: 0.01064 | Regression loss: 0.01835 | Objectness loss: 0.00023 | RPN Regression loss: 0.00281 | Running loss: 0.03203\n","Epoch: 9 | Iteration: 32222 | Classification loss: 0.01586 | Regression loss: 0.03211 | Objectness loss: 0.00168 | RPN Regression loss: 0.00363 | Running loss: 0.05329\n","Epoch: 9 | Iteration: 32223 | Classification loss: 0.01600 | Regression loss: 0.01485 | Objectness loss: 0.00008 | RPN Regression loss: 0.00066 | Running loss: 0.03159\n","Epoch: 9 | Iteration: 32224 | Classification loss: 0.00870 | Regression loss: 0.01306 | Objectness loss: 0.00050 | RPN Regression loss: 0.00094 | Running loss: 0.02320\n","Epoch: 9 | Iteration: 32225 | Classification loss: 0.01890 | Regression loss: 0.01604 | Objectness loss: 0.00140 | RPN Regression loss: 0.00450 | Running loss: 0.04084\n","Epoch: 9 | Iteration: 32226 | Classification loss: 0.01655 | Regression loss: 0.03322 | Objectness loss: 0.00151 | RPN Regression loss: 0.00354 | Running loss: 0.05483\n","Epoch: 9 | Iteration: 32227 | Classification loss: 0.00560 | Regression loss: 0.02096 | Objectness loss: 0.00018 | RPN Regression loss: 0.00291 | Running loss: 0.02965\n","Epoch: 9 | Iteration: 32228 | Classification loss: 0.01119 | Regression loss: 0.01959 | Objectness loss: 0.00024 | RPN Regression loss: 0.00139 | Running loss: 0.03241\n","Epoch: 9 | Iteration: 32229 | Classification loss: 0.03084 | Regression loss: 0.03254 | Objectness loss: 0.00129 | RPN Regression loss: 0.00107 | Running loss: 0.06573\n","Epoch: 9 | Iteration: 32230 | Classification loss: 0.03172 | Regression loss: 0.03026 | Objectness loss: 0.00022 | RPN Regression loss: 0.00070 | Running loss: 0.06290\n","Epoch: 9 | Iteration: 32231 | Classification loss: 0.01240 | Regression loss: 0.01774 | Objectness loss: 0.00160 | RPN Regression loss: 0.00151 | Running loss: 0.03325\n","Epoch: 9 | Iteration: 32232 | Classification loss: 0.00955 | Regression loss: 0.01956 | Objectness loss: 0.00031 | RPN Regression loss: 0.00141 | Running loss: 0.03082\n","Epoch: 9 | Iteration: 32233 | Classification loss: 0.01380 | Regression loss: 0.01874 | Objectness loss: 0.00030 | RPN Regression loss: 0.00041 | Running loss: 0.03326\n","Epoch: 9 | Iteration: 32234 | Classification loss: 0.00965 | Regression loss: 0.01285 | Objectness loss: 0.00074 | RPN Regression loss: 0.00104 | Running loss: 0.02428\n","Epoch: 9 | Iteration: 32235 | Classification loss: 0.02495 | Regression loss: 0.03032 | Objectness loss: 0.00036 | RPN Regression loss: 0.00113 | Running loss: 0.05676\n","Epoch: 9 | Iteration: 32236 | Classification loss: 0.01403 | Regression loss: 0.01293 | Objectness loss: 0.00172 | RPN Regression loss: 0.00075 | Running loss: 0.02943\n","Epoch: 9 | Iteration: 32237 | Classification loss: 0.00551 | Regression loss: 0.01216 | Objectness loss: 0.00021 | RPN Regression loss: 0.00086 | Running loss: 0.01874\n","Epoch: 9 | Iteration: 32238 | Classification loss: 0.01532 | Regression loss: 0.04422 | Objectness loss: 0.00040 | RPN Regression loss: 0.00171 | Running loss: 0.06164\n","Epoch: 9 | Iteration: 32239 | Classification loss: 0.01806 | Regression loss: 0.02343 | Objectness loss: 0.00007 | RPN Regression loss: 0.00083 | Running loss: 0.04239\n","Epoch: 9 | Iteration: 32240 | Classification loss: 0.01164 | Regression loss: 0.02250 | Objectness loss: 0.00716 | RPN Regression loss: 0.00716 | Running loss: 0.04847\n","Epoch: 9 | Iteration: 32241 | Classification loss: 0.01859 | Regression loss: 0.02521 | Objectness loss: 0.00080 | RPN Regression loss: 0.00155 | Running loss: 0.04616\n","Epoch: 9 | Iteration: 32242 | Classification loss: 0.00927 | Regression loss: 0.02346 | Objectness loss: 0.00005 | RPN Regression loss: 0.00086 | Running loss: 0.03364\n","Epoch: 9 | Iteration: 32243 | Classification loss: 0.02308 | Regression loss: 0.02269 | Objectness loss: 0.00083 | RPN Regression loss: 0.00126 | Running loss: 0.04786\n","Epoch: 9 | Iteration: 32244 | Classification loss: 0.01760 | Regression loss: 0.03257 | Objectness loss: 0.00530 | RPN Regression loss: 0.00384 | Running loss: 0.05930\n","Epoch: 9 | Iteration: 32245 | Classification loss: 0.00903 | Regression loss: 0.02108 | Objectness loss: 0.00022 | RPN Regression loss: 0.00068 | Running loss: 0.03101\n","Epoch: 9 | Iteration: 32246 | Classification loss: 0.01408 | Regression loss: 0.01213 | Objectness loss: 0.00042 | RPN Regression loss: 0.00266 | Running loss: 0.02928\n","Epoch: 9 | Iteration: 32247 | Classification loss: 0.02415 | Regression loss: 0.02612 | Objectness loss: 0.00012 | RPN Regression loss: 0.00112 | Running loss: 0.05152\n","Epoch: 9 | Iteration: 32248 | Classification loss: 0.02268 | Regression loss: 0.03113 | Objectness loss: 0.00124 | RPN Regression loss: 0.00194 | Running loss: 0.05699\n","Epoch: 9 | Iteration: 32249 | Classification loss: 0.00651 | Regression loss: 0.01370 | Objectness loss: 0.00037 | RPN Regression loss: 0.00126 | Running loss: 0.02184\n","Epoch: 9 | Iteration: 32250 | Classification loss: 0.02344 | Regression loss: 0.01368 | Objectness loss: 0.00349 | RPN Regression loss: 0.00052 | Running loss: 0.04114\n","Epoch: 9 | Iteration: 32251 | Classification loss: 0.02040 | Regression loss: 0.02524 | Objectness loss: 0.00025 | RPN Regression loss: 0.00186 | Running loss: 0.04775\n","Epoch: 9 | Iteration: 32252 | Classification loss: 0.00643 | Regression loss: 0.01672 | Objectness loss: 0.00147 | RPN Regression loss: 0.00053 | Running loss: 0.02514\n","Epoch: 9 | Iteration: 32253 | Classification loss: 0.02509 | Regression loss: 0.02699 | Objectness loss: 0.00309 | RPN Regression loss: 0.00105 | Running loss: 0.05622\n","Epoch: 9 | Iteration: 32254 | Classification loss: 0.00576 | Regression loss: 0.01222 | Objectness loss: 0.00007 | RPN Regression loss: 0.00361 | Running loss: 0.02165\n","Epoch: 9 | Iteration: 32255 | Classification loss: 0.01035 | Regression loss: 0.00863 | Objectness loss: 0.00576 | RPN Regression loss: 0.01221 | Running loss: 0.03696\n","Epoch: 9 | Iteration: 32256 | Classification loss: 0.01222 | Regression loss: 0.01498 | Objectness loss: 0.00234 | RPN Regression loss: 0.00310 | Running loss: 0.03264\n","Epoch: 9 | Iteration: 32257 | Classification loss: 0.00952 | Regression loss: 0.01596 | Objectness loss: 0.00033 | RPN Regression loss: 0.00108 | Running loss: 0.02689\n","Epoch: 9 | Iteration: 32258 | Classification loss: 0.01919 | Regression loss: 0.01030 | Objectness loss: 0.00009 | RPN Regression loss: 0.00091 | Running loss: 0.03049\n","Epoch: 9 | Iteration: 32259 | Classification loss: 0.00858 | Regression loss: 0.01005 | Objectness loss: 0.00136 | RPN Regression loss: 0.00187 | Running loss: 0.02187\n","Epoch: 9 | Iteration: 32260 | Classification loss: 0.03855 | Regression loss: 0.01848 | Objectness loss: 0.01114 | RPN Regression loss: 0.00305 | Running loss: 0.07123\n","Epoch: 9 | Iteration: 32261 | Classification loss: 0.01232 | Regression loss: 0.03992 | Objectness loss: 0.00202 | RPN Regression loss: 0.00083 | Running loss: 0.05510\n","Epoch: 9 | Iteration: 32262 | Classification loss: 0.00682 | Regression loss: 0.01305 | Objectness loss: 0.00014 | RPN Regression loss: 0.00217 | Running loss: 0.02218\n","Epoch: 9 | Iteration: 32263 | Classification loss: 0.02135 | Regression loss: 0.01828 | Objectness loss: 0.00266 | RPN Regression loss: 0.00058 | Running loss: 0.04287\n","Epoch: 9 | Iteration: 32264 | Classification loss: 0.00939 | Regression loss: 0.01671 | Objectness loss: 0.00051 | RPN Regression loss: 0.00055 | Running loss: 0.02717\n","Epoch: 9 | Iteration: 32265 | Classification loss: 0.01105 | Regression loss: 0.01671 | Objectness loss: 0.00116 | RPN Regression loss: 0.00079 | Running loss: 0.02972\n","Epoch: 9 | Iteration: 32266 | Classification loss: 0.01606 | Regression loss: 0.03251 | Objectness loss: 0.00084 | RPN Regression loss: 0.00137 | Running loss: 0.05078\n","Epoch: 9 | Iteration: 32267 | Classification loss: 0.02371 | Regression loss: 0.02798 | Objectness loss: 0.00189 | RPN Regression loss: 0.00321 | Running loss: 0.05678\n","Epoch: 9 | Iteration: 32268 | Classification loss: 0.00420 | Regression loss: 0.01474 | Objectness loss: 0.00018 | RPN Regression loss: 0.00043 | Running loss: 0.01956\n","Epoch: 9 | Iteration: 32269 | Classification loss: 0.02111 | Regression loss: 0.01606 | Objectness loss: 0.00021 | RPN Regression loss: 0.00134 | Running loss: 0.03872\n","Epoch: 9 | Iteration: 32270 | Classification loss: 0.00692 | Regression loss: 0.01522 | Objectness loss: 0.00355 | RPN Regression loss: 0.00044 | Running loss: 0.02612\n","Epoch: 9 | Iteration: 32271 | Classification loss: 0.01650 | Regression loss: 0.01533 | Objectness loss: 0.00076 | RPN Regression loss: 0.00073 | Running loss: 0.03333\n","Epoch: 9 | Iteration: 32272 | Classification loss: 0.02307 | Regression loss: 0.03384 | Objectness loss: 0.00027 | RPN Regression loss: 0.00087 | Running loss: 0.05804\n","Epoch: 9 | Iteration: 32273 | Classification loss: 0.01488 | Regression loss: 0.01784 | Objectness loss: 0.00005 | RPN Regression loss: 0.00089 | Running loss: 0.03365\n","Epoch: 9 | Iteration: 32274 | Classification loss: 0.02830 | Regression loss: 0.03071 | Objectness loss: 0.00033 | RPN Regression loss: 0.00124 | Running loss: 0.06058\n","Epoch: 9 | Iteration: 32275 | Classification loss: 0.03109 | Regression loss: 0.05912 | Objectness loss: 0.00034 | RPN Regression loss: 0.00141 | Running loss: 0.09196\n","Epoch: 9 | Iteration: 32276 | Classification loss: 0.01346 | Regression loss: 0.01421 | Objectness loss: 0.00041 | RPN Regression loss: 0.00061 | Running loss: 0.02868\n","Epoch: 9 | Iteration: 32277 | Classification loss: 0.03191 | Regression loss: 0.03509 | Objectness loss: 0.00015 | RPN Regression loss: 0.00117 | Running loss: 0.06832\n","Epoch: 9 | Iteration: 32278 | Classification loss: 0.02832 | Regression loss: 0.02543 | Objectness loss: 0.00393 | RPN Regression loss: 0.00078 | Running loss: 0.05846\n","Epoch: 9 | Iteration: 32279 | Classification loss: 0.01098 | Regression loss: 0.01871 | Objectness loss: 0.00005 | RPN Regression loss: 0.00052 | Running loss: 0.03027\n","Epoch: 9 | Iteration: 32280 | Classification loss: 0.01692 | Regression loss: 0.00780 | Objectness loss: 0.00152 | RPN Regression loss: 0.00157 | Running loss: 0.02781\n","Epoch: 9 | Iteration: 32281 | Classification loss: 0.01826 | Regression loss: 0.02324 | Objectness loss: 0.00217 | RPN Regression loss: 0.00209 | Running loss: 0.04576\n","Epoch: 9 | Iteration: 32282 | Classification loss: 0.01530 | Regression loss: 0.02311 | Objectness loss: 0.00019 | RPN Regression loss: 0.00033 | Running loss: 0.03893\n","Epoch: 9 | Iteration: 32283 | Classification loss: 0.00869 | Regression loss: 0.01558 | Objectness loss: 0.00017 | RPN Regression loss: 0.00146 | Running loss: 0.02590\n","Epoch: 9 | Iteration: 32284 | Classification loss: 0.00595 | Regression loss: 0.01552 | Objectness loss: 0.00092 | RPN Regression loss: 0.00146 | Running loss: 0.02385\n","Epoch: 9 | Iteration: 32285 | Classification loss: 0.00605 | Regression loss: 0.01297 | Objectness loss: 0.00024 | RPN Regression loss: 0.00139 | Running loss: 0.02065\n","Epoch: 9 | Iteration: 32286 | Classification loss: 0.01906 | Regression loss: 0.03543 | Objectness loss: 0.00013 | RPN Regression loss: 0.00268 | Running loss: 0.05729\n","Epoch: 9 | Iteration: 32287 | Classification loss: 0.01381 | Regression loss: 0.02492 | Objectness loss: 0.00081 | RPN Regression loss: 0.00176 | Running loss: 0.04130\n","Epoch: 9 | Iteration: 32288 | Classification loss: 0.02021 | Regression loss: 0.01304 | Objectness loss: 0.00003 | RPN Regression loss: 0.00228 | Running loss: 0.03557\n","Epoch: 9 | Iteration: 32289 | Classification loss: 0.00798 | Regression loss: 0.01332 | Objectness loss: 0.00341 | RPN Regression loss: 0.00254 | Running loss: 0.02724\n","Epoch: 9 | Iteration: 32290 | Classification loss: 0.00753 | Regression loss: 0.01713 | Objectness loss: 0.00019 | RPN Regression loss: 0.00349 | Running loss: 0.02834\n","Epoch: 9 | Iteration: 32291 | Classification loss: 0.01003 | Regression loss: 0.02774 | Objectness loss: 0.00375 | RPN Regression loss: 0.00107 | Running loss: 0.04259\n","Epoch: 9 | Iteration: 32292 | Classification loss: 0.01229 | Regression loss: 0.01540 | Objectness loss: 0.00517 | RPN Regression loss: 0.00139 | Running loss: 0.03426\n","Epoch: 9 | Iteration: 32293 | Classification loss: 0.03100 | Regression loss: 0.02811 | Objectness loss: 0.00128 | RPN Regression loss: 0.00623 | Running loss: 0.06662\n","Epoch: 9 | Iteration: 32294 | Classification loss: 0.00839 | Regression loss: 0.01048 | Objectness loss: 0.00109 | RPN Regression loss: 0.00038 | Running loss: 0.02034\n","Epoch: 9 | Iteration: 32295 | Classification loss: 0.00607 | Regression loss: 0.01537 | Objectness loss: 0.00006 | RPN Regression loss: 0.00049 | Running loss: 0.02199\n","Epoch: 9 | Iteration: 32296 | Classification loss: 0.02203 | Regression loss: 0.02258 | Objectness loss: 0.00004 | RPN Regression loss: 0.00054 | Running loss: 0.04519\n","Epoch: 9 | Iteration: 32297 | Classification loss: 0.00903 | Regression loss: 0.02744 | Objectness loss: 0.00041 | RPN Regression loss: 0.00094 | Running loss: 0.03782\n","Epoch: 9 | Iteration: 32298 | Classification loss: 0.01057 | Regression loss: 0.01667 | Objectness loss: 0.00009 | RPN Regression loss: 0.00036 | Running loss: 0.02770\n","Epoch: 9 | Iteration: 32299 | Classification loss: 0.03045 | Regression loss: 0.03054 | Objectness loss: 0.00163 | RPN Regression loss: 0.00116 | Running loss: 0.06378\n","Epoch: 9 | Iteration: 32300 | Classification loss: 0.00887 | Regression loss: 0.01642 | Objectness loss: 0.00009 | RPN Regression loss: 0.00106 | Running loss: 0.02645\n","Epoch: 9 | Iteration: 32301 | Classification loss: 0.01246 | Regression loss: 0.02103 | Objectness loss: 0.00326 | RPN Regression loss: 0.00466 | Running loss: 0.04141\n","Epoch: 9 | Iteration: 32302 | Classification loss: 0.01179 | Regression loss: 0.02002 | Objectness loss: 0.00012 | RPN Regression loss: 0.00118 | Running loss: 0.03311\n","Epoch: 9 | Iteration: 32303 | Classification loss: 0.01499 | Regression loss: 0.01831 | Objectness loss: 0.00048 | RPN Regression loss: 0.00246 | Running loss: 0.03624\n","Epoch: 9 | Iteration: 32304 | Classification loss: 0.00626 | Regression loss: 0.01164 | Objectness loss: 0.00016 | RPN Regression loss: 0.00085 | Running loss: 0.01892\n","Epoch: 9 | Iteration: 32305 | Classification loss: 0.02933 | Regression loss: 0.02889 | Objectness loss: 0.00028 | RPN Regression loss: 0.00042 | Running loss: 0.05892\n","Epoch: 9 | Iteration: 32306 | Classification loss: 0.00845 | Regression loss: 0.02637 | Objectness loss: 0.00005 | RPN Regression loss: 0.00217 | Running loss: 0.03705\n","Epoch: 9 | Iteration: 32307 | Classification loss: 0.02032 | Regression loss: 0.02280 | Objectness loss: 0.00168 | RPN Regression loss: 0.00194 | Running loss: 0.04673\n","Epoch: 9 | Iteration: 32308 | Classification loss: 0.03436 | Regression loss: 0.02995 | Objectness loss: 0.00338 | RPN Regression loss: 0.03286 | Running loss: 0.10054\n","Epoch: 9 | Iteration: 32309 | Classification loss: 0.01024 | Regression loss: 0.02567 | Objectness loss: 0.00030 | RPN Regression loss: 0.00045 | Running loss: 0.03666\n","Epoch: 9 | Iteration: 32310 | Classification loss: 0.01655 | Regression loss: 0.02417 | Objectness loss: 0.00228 | RPN Regression loss: 0.00666 | Running loss: 0.04966\n","Epoch: 9 | Iteration: 32311 | Classification loss: 0.00756 | Regression loss: 0.01612 | Objectness loss: 0.00215 | RPN Regression loss: 0.00040 | Running loss: 0.02623\n","Epoch: 9 | Iteration: 32312 | Classification loss: 0.00304 | Regression loss: 0.01435 | Objectness loss: 0.00002 | RPN Regression loss: 0.00076 | Running loss: 0.01817\n","Epoch: 9 | Iteration: 32313 | Classification loss: 0.00913 | Regression loss: 0.01894 | Objectness loss: 0.00052 | RPN Regression loss: 0.00185 | Running loss: 0.03043\n","Epoch: 9 | Iteration: 32314 | Classification loss: 0.01467 | Regression loss: 0.02213 | Objectness loss: 0.00004 | RPN Regression loss: 0.00082 | Running loss: 0.03765\n","Epoch: 9 | Iteration: 32315 | Classification loss: 0.01166 | Regression loss: 0.02714 | Objectness loss: 0.00005 | RPN Regression loss: 0.00159 | Running loss: 0.04044\n","Epoch: 9 | Iteration: 32316 | Classification loss: 0.00626 | Regression loss: 0.01584 | Objectness loss: 0.00003 | RPN Regression loss: 0.00117 | Running loss: 0.02331\n","Epoch: 9 | Iteration: 32317 | Classification loss: 0.03017 | Regression loss: 0.02111 | Objectness loss: 0.00007 | RPN Regression loss: 0.00112 | Running loss: 0.05246\n","Epoch: 9 | Iteration: 32318 | Classification loss: 0.01631 | Regression loss: 0.02051 | Objectness loss: 0.00009 | RPN Regression loss: 0.00378 | Running loss: 0.04069\n","Epoch: 9 | Iteration: 32319 | Classification loss: 0.00760 | Regression loss: 0.01357 | Objectness loss: 0.00004 | RPN Regression loss: 0.00064 | Running loss: 0.02185\n","Epoch: 9 | Iteration: 32320 | Classification loss: 0.00958 | Regression loss: 0.02290 | Objectness loss: 0.00001 | RPN Regression loss: 0.00101 | Running loss: 0.03350\n","Epoch: 9 | Iteration: 32321 | Classification loss: 0.02408 | Regression loss: 0.01920 | Objectness loss: 0.01797 | RPN Regression loss: 0.00812 | Running loss: 0.06937\n","Epoch: 9 | Iteration: 32322 | Classification loss: 0.01702 | Regression loss: 0.02744 | Objectness loss: 0.00005 | RPN Regression loss: 0.00111 | Running loss: 0.04561\n","Epoch: 9 | Iteration: 32323 | Classification loss: 0.00640 | Regression loss: 0.01274 | Objectness loss: 0.00069 | RPN Regression loss: 0.00270 | Running loss: 0.02252\n","Epoch: 9 | Iteration: 32324 | Classification loss: 0.00761 | Regression loss: 0.01885 | Objectness loss: 0.00139 | RPN Regression loss: 0.00428 | Running loss: 0.03212\n","Epoch: 9 | Iteration: 32325 | Classification loss: 0.01413 | Regression loss: 0.01467 | Objectness loss: 0.00009 | RPN Regression loss: 0.00085 | Running loss: 0.02975\n","Epoch: 9 | Iteration: 32326 | Classification loss: 0.01251 | Regression loss: 0.02328 | Objectness loss: 0.00195 | RPN Regression loss: 0.00487 | Running loss: 0.04261\n","Epoch: 9 | Iteration: 32327 | Classification loss: 0.02980 | Regression loss: 0.02840 | Objectness loss: 0.00927 | RPN Regression loss: 0.00169 | Running loss: 0.06916\n","Epoch: 9 | Iteration: 32328 | Classification loss: 0.03567 | Regression loss: 0.01631 | Objectness loss: 0.00046 | RPN Regression loss: 0.00103 | Running loss: 0.05347\n","Epoch: 9 | Iteration: 32329 | Classification loss: 0.01308 | Regression loss: 0.01257 | Objectness loss: 0.00008 | RPN Regression loss: 0.00074 | Running loss: 0.02646\n","Epoch: 9 | Iteration: 32330 | Classification loss: 0.01116 | Regression loss: 0.01801 | Objectness loss: 0.00588 | RPN Regression loss: 0.00694 | Running loss: 0.04199\n","Epoch: 9 | Iteration: 32331 | Classification loss: 0.00686 | Regression loss: 0.02216 | Objectness loss: 0.00002 | RPN Regression loss: 0.00107 | Running loss: 0.03011\n","Epoch: 9 | Iteration: 32332 | Classification loss: 0.03387 | Regression loss: 0.02141 | Objectness loss: 0.00042 | RPN Regression loss: 0.00245 | Running loss: 0.05816\n","Epoch: 9 | Iteration: 32333 | Classification loss: 0.01793 | Regression loss: 0.01435 | Objectness loss: 0.00017 | RPN Regression loss: 0.00194 | Running loss: 0.03439\n","Epoch: 9 | Iteration: 32334 | Classification loss: 0.02814 | Regression loss: 0.03934 | Objectness loss: 0.00017 | RPN Regression loss: 0.00306 | Running loss: 0.07071\n","Epoch: 9 | Iteration: 32335 | Classification loss: 0.02697 | Regression loss: 0.02617 | Objectness loss: 0.00398 | RPN Regression loss: 0.00686 | Running loss: 0.06398\n","Epoch: 9 | Iteration: 32336 | Classification loss: 0.01869 | Regression loss: 0.02371 | Objectness loss: 0.00079 | RPN Regression loss: 0.00237 | Running loss: 0.04555\n","Epoch: 9 | Iteration: 32337 | Classification loss: 0.02465 | Regression loss: 0.03041 | Objectness loss: 0.00083 | RPN Regression loss: 0.00057 | Running loss: 0.05645\n","Epoch: 9 | Iteration: 32338 | Classification loss: 0.00844 | Regression loss: 0.01698 | Objectness loss: 0.00310 | RPN Regression loss: 0.00204 | Running loss: 0.03055\n","Epoch: 9 | Iteration: 32339 | Classification loss: 0.01443 | Regression loss: 0.02517 | Objectness loss: 0.00086 | RPN Regression loss: 0.00110 | Running loss: 0.04155\n","Epoch: 9 | Iteration: 32340 | Classification loss: 0.00456 | Regression loss: 0.01597 | Objectness loss: 0.00014 | RPN Regression loss: 0.00104 | Running loss: 0.02170\n","Epoch: 9 | Iteration: 32341 | Classification loss: 0.04341 | Regression loss: 0.02634 | Objectness loss: 0.00008 | RPN Regression loss: 0.00084 | Running loss: 0.07067\n","Epoch: 9 | Iteration: 32342 | Classification loss: 0.01046 | Regression loss: 0.02000 | Objectness loss: 0.00070 | RPN Regression loss: 0.00347 | Running loss: 0.03464\n","Epoch: 9 | Iteration: 32343 | Classification loss: 0.01094 | Regression loss: 0.01923 | Objectness loss: 0.00008 | RPN Regression loss: 0.00058 | Running loss: 0.03083\n","Epoch: 9 | Iteration: 32344 | Classification loss: 0.01762 | Regression loss: 0.01836 | Objectness loss: 0.00007 | RPN Regression loss: 0.00071 | Running loss: 0.03675\n","Epoch: 9 | Iteration: 32345 | Classification loss: 0.01330 | Regression loss: 0.01624 | Objectness loss: 0.00049 | RPN Regression loss: 0.00074 | Running loss: 0.03077\n","Epoch: 9 | Iteration: 32346 | Classification loss: 0.01812 | Regression loss: 0.03405 | Objectness loss: 0.00207 | RPN Regression loss: 0.00560 | Running loss: 0.05985\n","Epoch: 9 | Iteration: 32347 | Classification loss: 0.02960 | Regression loss: 0.02927 | Objectness loss: 0.00349 | RPN Regression loss: 0.00167 | Running loss: 0.06402\n","Epoch: 9 | Iteration: 32348 | Classification loss: 0.01355 | Regression loss: 0.01546 | Objectness loss: 0.00022 | RPN Regression loss: 0.00056 | Running loss: 0.02979\n","Epoch: 9 | Iteration: 32349 | Classification loss: 0.01305 | Regression loss: 0.01897 | Objectness loss: 0.00112 | RPN Regression loss: 0.00181 | Running loss: 0.03496\n","Epoch: 9 | Iteration: 32350 | Classification loss: 0.01855 | Regression loss: 0.01844 | Objectness loss: 0.00062 | RPN Regression loss: 0.00203 | Running loss: 0.03964\n","Epoch: 9 | Iteration: 32351 | Classification loss: 0.02017 | Regression loss: 0.03868 | Objectness loss: 0.00009 | RPN Regression loss: 0.00116 | Running loss: 0.06010\n","Epoch: 9 | Iteration: 32352 | Classification loss: 0.01431 | Regression loss: 0.01461 | Objectness loss: 0.00004 | RPN Regression loss: 0.00070 | Running loss: 0.02966\n","Epoch: 9 | Iteration: 32353 | Classification loss: 0.01174 | Regression loss: 0.01382 | Objectness loss: 0.00132 | RPN Regression loss: 0.00404 | Running loss: 0.03091\n","Epoch: 9 | Iteration: 32354 | Classification loss: 0.00614 | Regression loss: 0.01398 | Objectness loss: 0.00026 | RPN Regression loss: 0.00075 | Running loss: 0.02114\n","Epoch: 9 | Iteration: 32355 | Classification loss: 0.00821 | Regression loss: 0.02053 | Objectness loss: 0.00007 | RPN Regression loss: 0.00075 | Running loss: 0.02955\n","Epoch: 9 | Iteration: 32356 | Classification loss: 0.00758 | Regression loss: 0.02093 | Objectness loss: 0.00014 | RPN Regression loss: 0.00057 | Running loss: 0.02922\n","Epoch: 9 | Iteration: 32357 | Classification loss: 0.02957 | Regression loss: 0.03244 | Objectness loss: 0.00395 | RPN Regression loss: 0.00268 | Running loss: 0.06864\n","Epoch: 9 | Iteration: 32358 | Classification loss: 0.00892 | Regression loss: 0.01070 | Objectness loss: 0.00002 | RPN Regression loss: 0.00080 | Running loss: 0.02044\n","Epoch: 9 | Iteration: 32359 | Classification loss: 0.00842 | Regression loss: 0.01880 | Objectness loss: 0.00025 | RPN Regression loss: 0.00070 | Running loss: 0.02817\n","Epoch: 9 | Iteration: 32360 | Classification loss: 0.01912 | Regression loss: 0.02538 | Objectness loss: 0.00007 | RPN Regression loss: 0.00081 | Running loss: 0.04539\n","Epoch: 9 | Iteration: 32361 | Classification loss: 0.01805 | Regression loss: 0.02007 | Objectness loss: 0.00107 | RPN Regression loss: 0.00263 | Running loss: 0.04181\n","Epoch: 9 | Iteration: 32362 | Classification loss: 0.01489 | Regression loss: 0.02676 | Objectness loss: 0.00088 | RPN Regression loss: 0.00110 | Running loss: 0.04363\n","Epoch: 9 | Iteration: 32363 | Classification loss: 0.02382 | Regression loss: 0.04318 | Objectness loss: 0.00063 | RPN Regression loss: 0.00187 | Running loss: 0.06951\n","Epoch: 9 | Iteration: 32364 | Classification loss: 0.01680 | Regression loss: 0.02715 | Objectness loss: 0.00030 | RPN Regression loss: 0.00252 | Running loss: 0.04676\n","Epoch: 9 | Iteration: 32365 | Classification loss: 0.01222 | Regression loss: 0.02464 | Objectness loss: 0.00063 | RPN Regression loss: 0.00102 | Running loss: 0.03851\n","Epoch: 9 | Iteration: 32366 | Classification loss: 0.01248 | Regression loss: 0.02638 | Objectness loss: 0.00011 | RPN Regression loss: 0.00144 | Running loss: 0.04041\n","Epoch: 9 | Iteration: 32367 | Classification loss: 0.01621 | Regression loss: 0.01770 | Objectness loss: 0.00104 | RPN Regression loss: 0.00425 | Running loss: 0.03920\n","Epoch: 9 | Iteration: 32368 | Classification loss: 0.00785 | Regression loss: 0.01054 | Objectness loss: 0.00025 | RPN Regression loss: 0.00196 | Running loss: 0.02060\n","Epoch: 9 | Iteration: 32369 | Classification loss: 0.02870 | Regression loss: 0.02587 | Objectness loss: 0.00018 | RPN Regression loss: 0.00105 | Running loss: 0.05580\n","Epoch: 9 | Iteration: 32370 | Classification loss: 0.02636 | Regression loss: 0.01254 | Objectness loss: 0.00145 | RPN Regression loss: 0.00408 | Running loss: 0.04442\n","Epoch: 9 | Iteration: 32371 | Classification loss: 0.01265 | Regression loss: 0.01728 | Objectness loss: 0.00024 | RPN Regression loss: 0.00061 | Running loss: 0.03077\n","Epoch: 9 | Iteration: 32372 | Classification loss: 0.01775 | Regression loss: 0.03369 | Objectness loss: 0.00003 | RPN Regression loss: 0.00160 | Running loss: 0.05308\n","Epoch: 9 | Iteration: 32373 | Classification loss: 0.01981 | Regression loss: 0.03251 | Objectness loss: 0.00007 | RPN Regression loss: 0.00092 | Running loss: 0.05330\n","Epoch: 9 | Iteration: 32374 | Classification loss: 0.02620 | Regression loss: 0.02554 | Objectness loss: 0.00017 | RPN Regression loss: 0.00207 | Running loss: 0.05399\n","Epoch: 9 | Iteration: 32375 | Classification loss: 0.01469 | Regression loss: 0.01206 | Objectness loss: 0.00003 | RPN Regression loss: 0.00085 | Running loss: 0.02764\n","Epoch: 9 | Iteration: 32376 | Classification loss: 0.02067 | Regression loss: 0.01393 | Objectness loss: 0.00081 | RPN Regression loss: 0.00077 | Running loss: 0.03619\n","Epoch: 9 | Iteration: 32377 | Classification loss: 0.00923 | Regression loss: 0.01997 | Objectness loss: 0.00054 | RPN Regression loss: 0.00424 | Running loss: 0.03398\n","Epoch: 9 | Iteration: 32378 | Classification loss: 0.03267 | Regression loss: 0.02444 | Objectness loss: 0.00007 | RPN Regression loss: 0.00052 | Running loss: 0.05770\n","Epoch: 9 | Iteration: 32379 | Classification loss: 0.00546 | Regression loss: 0.01212 | Objectness loss: 0.00007 | RPN Regression loss: 0.00094 | Running loss: 0.01858\n","Epoch: 9 | Iteration: 32380 | Classification loss: 0.00577 | Regression loss: 0.01661 | Objectness loss: 0.00003 | RPN Regression loss: 0.00069 | Running loss: 0.02310\n","Epoch: 9 | Iteration: 32381 | Classification loss: 0.02469 | Regression loss: 0.01918 | Objectness loss: 0.00072 | RPN Regression loss: 0.00236 | Running loss: 0.04695\n","Epoch: 9 | Iteration: 32382 | Classification loss: 0.01131 | Regression loss: 0.01536 | Objectness loss: 0.00126 | RPN Regression loss: 0.00063 | Running loss: 0.02856\n","Epoch: 9 | Iteration: 32383 | Classification loss: 0.01313 | Regression loss: 0.01540 | Objectness loss: 0.00011 | RPN Regression loss: 0.00311 | Running loss: 0.03175\n","Epoch: 9 | Iteration: 32384 | Classification loss: 0.03672 | Regression loss: 0.01529 | Objectness loss: 0.00074 | RPN Regression loss: 0.00096 | Running loss: 0.05371\n","Epoch: 9 | Iteration: 32385 | Classification loss: 0.02926 | Regression loss: 0.03415 | Objectness loss: 0.00179 | RPN Regression loss: 0.00269 | Running loss: 0.06789\n","Epoch: 9 | Iteration: 32386 | Classification loss: 0.01539 | Regression loss: 0.01729 | Objectness loss: 0.00161 | RPN Regression loss: 0.00953 | Running loss: 0.04383\n","Epoch: 9 | Iteration: 32387 | Classification loss: 0.00711 | Regression loss: 0.01773 | Objectness loss: 0.00016 | RPN Regression loss: 0.00105 | Running loss: 0.02605\n","Epoch: 9 | Iteration: 32388 | Classification loss: 0.01041 | Regression loss: 0.01478 | Objectness loss: 0.00042 | RPN Regression loss: 0.00033 | Running loss: 0.02594\n","Epoch: 9 | Iteration: 32389 | Classification loss: 0.00859 | Regression loss: 0.01696 | Objectness loss: 0.00004 | RPN Regression loss: 0.00241 | Running loss: 0.02800\n","Epoch: 9 | Iteration: 32390 | Classification loss: 0.01342 | Regression loss: 0.05115 | Objectness loss: 0.02234 | RPN Regression loss: 0.03275 | Running loss: 0.11966\n","Epoch: 9 | Iteration: 32391 | Classification loss: 0.00357 | Regression loss: 0.00850 | Objectness loss: 0.00011 | RPN Regression loss: 0.00189 | Running loss: 0.01408\n","Epoch: 9 | Iteration: 32392 | Classification loss: 0.00965 | Regression loss: 0.03033 | Objectness loss: 0.00036 | RPN Regression loss: 0.00172 | Running loss: 0.04206\n","Epoch: 9 | Iteration: 32393 | Classification loss: 0.01121 | Regression loss: 0.02894 | Objectness loss: 0.00073 | RPN Regression loss: 0.00114 | Running loss: 0.04203\n","Epoch: 9 | Iteration: 32394 | Classification loss: 0.01257 | Regression loss: 0.02098 | Objectness loss: 0.00018 | RPN Regression loss: 0.00047 | Running loss: 0.03420\n","Epoch: 9 | Iteration: 32395 | Classification loss: 0.03098 | Regression loss: 0.02238 | Objectness loss: 0.00045 | RPN Regression loss: 0.00177 | Running loss: 0.05558\n","Epoch: 9 | Iteration: 32396 | Classification loss: 0.03319 | Regression loss: 0.01716 | Objectness loss: 0.00635 | RPN Regression loss: 0.00075 | Running loss: 0.05745\n","Epoch: 9 | Iteration: 32397 | Classification loss: 0.00919 | Regression loss: 0.02261 | Objectness loss: 0.00101 | RPN Regression loss: 0.00280 | Running loss: 0.03561\n","Epoch: 9 | Iteration: 32398 | Classification loss: 0.01861 | Regression loss: 0.01790 | Objectness loss: 0.00305 | RPN Regression loss: 0.00105 | Running loss: 0.04061\n","Epoch: 9 | Iteration: 32399 | Classification loss: 0.00730 | Regression loss: 0.00956 | Objectness loss: 0.00337 | RPN Regression loss: 0.00113 | Running loss: 0.02136\n","Epoch: 9 | Iteration: 32400 | Classification loss: 0.01878 | Regression loss: 0.02929 | Objectness loss: 0.00047 | RPN Regression loss: 0.00109 | Running loss: 0.04964\n","Epoch: 9 | Iteration: 32401 | Classification loss: 0.02976 | Regression loss: 0.02026 | Objectness loss: 0.00008 | RPN Regression loss: 0.00048 | Running loss: 0.05059\n","Epoch: 9 | Iteration: 32402 | Classification loss: 0.02465 | Regression loss: 0.07356 | Objectness loss: 0.00036 | RPN Regression loss: 0.00267 | Running loss: 0.10125\n","Epoch: 9 | Iteration: 32403 | Classification loss: 0.01472 | Regression loss: 0.02988 | Objectness loss: 0.00002 | RPN Regression loss: 0.00060 | Running loss: 0.04521\n","Epoch: 9 | Iteration: 32404 | Classification loss: 0.00865 | Regression loss: 0.01820 | Objectness loss: 0.00055 | RPN Regression loss: 0.00169 | Running loss: 0.02909\n","Epoch: 9 | Iteration: 32405 | Classification loss: 0.03547 | Regression loss: 0.03271 | Objectness loss: 0.00183 | RPN Regression loss: 0.00078 | Running loss: 0.07079\n","Epoch: 9 | Iteration: 32406 | Classification loss: 0.01012 | Regression loss: 0.01537 | Objectness loss: 0.00005 | RPN Regression loss: 0.00111 | Running loss: 0.02666\n","Epoch: 9 | Iteration: 32407 | Classification loss: 0.01975 | Regression loss: 0.03053 | Objectness loss: 0.00005 | RPN Regression loss: 0.00067 | Running loss: 0.05100\n","Epoch: 9 | Iteration: 32408 | Classification loss: 0.01200 | Regression loss: 0.01912 | Objectness loss: 0.00178 | RPN Regression loss: 0.00145 | Running loss: 0.03435\n","Epoch: 9 | Iteration: 32409 | Classification loss: 0.00785 | Regression loss: 0.01481 | Objectness loss: 0.00029 | RPN Regression loss: 0.00196 | Running loss: 0.02490\n","Epoch: 9 | Iteration: 32410 | Classification loss: 0.00686 | Regression loss: 0.01635 | Objectness loss: 0.00006 | RPN Regression loss: 0.00263 | Running loss: 0.02590\n","Epoch: 9 | Iteration: 32411 | Classification loss: 0.02307 | Regression loss: 0.03541 | Objectness loss: 0.00053 | RPN Regression loss: 0.00071 | Running loss: 0.05972\n","Epoch: 9 | Iteration: 32412 | Classification loss: 0.01301 | Regression loss: 0.01816 | Objectness loss: 0.00095 | RPN Regression loss: 0.00342 | Running loss: 0.03554\n","Epoch: 9 | Iteration: 32413 | Classification loss: 0.01497 | Regression loss: 0.02202 | Objectness loss: 0.00039 | RPN Regression loss: 0.00427 | Running loss: 0.04165\n","Epoch: 9 | Iteration: 32414 | Classification loss: 0.01222 | Regression loss: 0.03157 | Objectness loss: 0.00048 | RPN Regression loss: 0.00114 | Running loss: 0.04541\n","Epoch: 9 | Iteration: 32415 | Classification loss: 0.01365 | Regression loss: 0.02355 | Objectness loss: 0.00171 | RPN Regression loss: 0.00202 | Running loss: 0.04092\n","Epoch: 9 | Iteration: 32416 | Classification loss: 0.00687 | Regression loss: 0.01579 | Objectness loss: 0.00020 | RPN Regression loss: 0.00119 | Running loss: 0.02405\n","Epoch: 9 | Iteration: 32417 | Classification loss: 0.01068 | Regression loss: 0.02605 | Objectness loss: 0.00007 | RPN Regression loss: 0.00189 | Running loss: 0.03870\n","Epoch: 9 | Iteration: 32418 | Classification loss: 0.01194 | Regression loss: 0.01751 | Objectness loss: 0.00013 | RPN Regression loss: 0.00071 | Running loss: 0.03029\n","Epoch: 9 | Iteration: 32419 | Classification loss: 0.03048 | Regression loss: 0.03332 | Objectness loss: 0.00053 | RPN Regression loss: 0.00357 | Running loss: 0.06790\n","Epoch: 9 | Iteration: 32420 | Classification loss: 0.00704 | Regression loss: 0.01700 | Objectness loss: 0.00020 | RPN Regression loss: 0.00116 | Running loss: 0.02539\n","Epoch: 9 | Iteration: 32421 | Classification loss: 0.00799 | Regression loss: 0.01200 | Objectness loss: 0.00004 | RPN Regression loss: 0.00031 | Running loss: 0.02034\n","Epoch: 9 | Iteration: 32422 | Classification loss: 0.02831 | Regression loss: 0.01368 | Objectness loss: 0.00310 | RPN Regression loss: 0.00027 | Running loss: 0.04536\n","Epoch: 9 | Iteration: 32423 | Classification loss: 0.00588 | Regression loss: 0.01765 | Objectness loss: 0.00011 | RPN Regression loss: 0.00121 | Running loss: 0.02486\n","Epoch: 9 | Iteration: 32424 | Classification loss: 0.02574 | Regression loss: 0.02696 | Objectness loss: 0.00011 | RPN Regression loss: 0.00119 | Running loss: 0.05400\n","Epoch: 9 | Iteration: 32425 | Classification loss: 0.02133 | Regression loss: 0.02294 | Objectness loss: 0.00004 | RPN Regression loss: 0.00039 | Running loss: 0.04470\n","Epoch: 9 | Iteration: 32426 | Classification loss: 0.00845 | Regression loss: 0.01382 | Objectness loss: 0.00007 | RPN Regression loss: 0.00041 | Running loss: 0.02276\n","Epoch: 9 | Iteration: 32427 | Classification loss: 0.02926 | Regression loss: 0.05348 | Objectness loss: 0.00030 | RPN Regression loss: 0.00143 | Running loss: 0.08448\n","Epoch: 9 | Iteration: 32428 | Classification loss: 0.01827 | Regression loss: 0.03347 | Objectness loss: 0.00031 | RPN Regression loss: 0.00084 | Running loss: 0.05290\n","Epoch: 9 | Iteration: 32429 | Classification loss: 0.00504 | Regression loss: 0.01791 | Objectness loss: 0.00002 | RPN Regression loss: 0.00079 | Running loss: 0.02376\n","Epoch: 9 | Iteration: 32430 | Classification loss: 0.01350 | Regression loss: 0.01970 | Objectness loss: 0.00015 | RPN Regression loss: 0.00295 | Running loss: 0.03630\n","Epoch: 9 | Iteration: 32431 | Classification loss: 0.02356 | Regression loss: 0.03156 | Objectness loss: 0.00008 | RPN Regression loss: 0.00219 | Running loss: 0.05740\n","Epoch: 9 | Iteration: 32432 | Classification loss: 0.01798 | Regression loss: 0.03405 | Objectness loss: 0.00036 | RPN Regression loss: 0.00273 | Running loss: 0.05513\n","Epoch: 9 | Iteration: 32433 | Classification loss: 0.00799 | Regression loss: 0.01856 | Objectness loss: 0.00048 | RPN Regression loss: 0.00184 | Running loss: 0.02887\n","Epoch: 9 | Iteration: 32434 | Classification loss: 0.01674 | Regression loss: 0.02120 | Objectness loss: 0.00006 | RPN Regression loss: 0.00136 | Running loss: 0.03936\n","Epoch: 9 | Iteration: 32435 | Classification loss: 0.02186 | Regression loss: 0.02807 | Objectness loss: 0.00063 | RPN Regression loss: 0.00048 | Running loss: 0.05105\n","Epoch: 9 | Iteration: 32436 | Classification loss: 0.03576 | Regression loss: 0.03340 | Objectness loss: 0.00961 | RPN Regression loss: 0.00168 | Running loss: 0.08045\n","Epoch: 9 | Iteration: 32437 | Classification loss: 0.01391 | Regression loss: 0.01606 | Objectness loss: 0.00005 | RPN Regression loss: 0.00078 | Running loss: 0.03080\n","Epoch: 9 | Iteration: 32438 | Classification loss: 0.01629 | Regression loss: 0.02051 | Objectness loss: 0.00112 | RPN Regression loss: 0.00432 | Running loss: 0.04225\n","Epoch: 9 | Iteration: 32439 | Classification loss: 0.03467 | Regression loss: 0.03800 | Objectness loss: 0.00114 | RPN Regression loss: 0.00354 | Running loss: 0.07735\n","Epoch: 9 | Iteration: 32440 | Classification loss: 0.01669 | Regression loss: 0.03110 | Objectness loss: 0.00106 | RPN Regression loss: 0.00094 | Running loss: 0.04979\n","Epoch: 9 | Iteration: 32441 | Classification loss: 0.01493 | Regression loss: 0.02220 | Objectness loss: 0.00003 | RPN Regression loss: 0.00061 | Running loss: 0.03777\n","Epoch: 9 | Iteration: 32442 | Classification loss: 0.01781 | Regression loss: 0.02900 | Objectness loss: 0.00029 | RPN Regression loss: 0.00086 | Running loss: 0.04796\n","Epoch: 9 | Iteration: 32443 | Classification loss: 0.00663 | Regression loss: 0.01652 | Objectness loss: 0.00039 | RPN Regression loss: 0.00037 | Running loss: 0.02392\n","Epoch: 9 | Iteration: 32444 | Classification loss: 0.01365 | Regression loss: 0.02580 | Objectness loss: 0.00185 | RPN Regression loss: 0.00516 | Running loss: 0.04646\n","Epoch: 9 | Iteration: 32445 | Classification loss: 0.03999 | Regression loss: 0.03250 | Objectness loss: 0.00664 | RPN Regression loss: 0.00135 | Running loss: 0.08048\n","Epoch: 9 | Iteration: 32446 | Classification loss: 0.02617 | Regression loss: 0.02447 | Objectness loss: 0.00087 | RPN Regression loss: 0.00101 | Running loss: 0.05252\n","Epoch: 9 | Iteration: 32447 | Classification loss: 0.02254 | Regression loss: 0.03255 | Objectness loss: 0.00889 | RPN Regression loss: 0.00164 | Running loss: 0.06561\n","Epoch: 9 | Iteration: 32448 | Classification loss: 0.01429 | Regression loss: 0.03281 | Objectness loss: 0.00006 | RPN Regression loss: 0.00108 | Running loss: 0.04824\n","Epoch: 9 | Iteration: 32449 | Classification loss: 0.00951 | Regression loss: 0.02255 | Objectness loss: 0.00040 | RPN Regression loss: 0.00090 | Running loss: 0.03335\n","Epoch: 9 | Iteration: 32450 | Classification loss: 0.00943 | Regression loss: 0.01878 | Objectness loss: 0.00066 | RPN Regression loss: 0.00175 | Running loss: 0.03063\n","Epoch: 9 | Iteration: 32451 | Classification loss: 0.02545 | Regression loss: 0.02894 | Objectness loss: 0.00008 | RPN Regression loss: 0.00135 | Running loss: 0.05582\n","Epoch: 9 | Iteration: 32452 | Classification loss: 0.04255 | Regression loss: 0.05086 | Objectness loss: 0.00362 | RPN Regression loss: 0.00802 | Running loss: 0.10505\n","Epoch: 9 | Iteration: 32453 | Classification loss: 0.00768 | Regression loss: 0.03091 | Objectness loss: 0.00010 | RPN Regression loss: 0.00119 | Running loss: 0.03988\n","Epoch: 9 | Iteration: 32454 | Classification loss: 0.03037 | Regression loss: 0.04852 | Objectness loss: 0.00043 | RPN Regression loss: 0.00147 | Running loss: 0.08079\n","Epoch: 9 | Iteration: 32455 | Classification loss: 0.00844 | Regression loss: 0.01596 | Objectness loss: 0.00047 | RPN Regression loss: 0.00252 | Running loss: 0.02739\n","Epoch: 9 | Iteration: 32456 | Classification loss: 0.00931 | Regression loss: 0.01974 | Objectness loss: 0.00019 | RPN Regression loss: 0.00097 | Running loss: 0.03020\n","Epoch: 9 | Iteration: 32457 | Classification loss: 0.02760 | Regression loss: 0.04976 | Objectness loss: 0.00176 | RPN Regression loss: 0.00121 | Running loss: 0.08033\n","Epoch: 9 | Iteration: 32458 | Classification loss: 0.02418 | Regression loss: 0.03678 | Objectness loss: 0.00215 | RPN Regression loss: 0.00100 | Running loss: 0.06411\n","Epoch: 9 | Iteration: 32459 | Classification loss: 0.02651 | Regression loss: 0.03046 | Objectness loss: 0.00125 | RPN Regression loss: 0.00228 | Running loss: 0.06051\n","Epoch: 9 | Iteration: 32460 | Classification loss: 0.01762 | Regression loss: 0.02394 | Objectness loss: 0.00013 | RPN Regression loss: 0.00259 | Running loss: 0.04428\n","Epoch: 9 | Iteration: 32461 | Classification loss: 0.03083 | Regression loss: 0.04247 | Objectness loss: 0.00015 | RPN Regression loss: 0.00220 | Running loss: 0.07565\n","Epoch: 9 | Iteration: 32462 | Classification loss: 0.02281 | Regression loss: 0.01719 | Objectness loss: 0.00020 | RPN Regression loss: 0.00099 | Running loss: 0.04119\n","Epoch: 9 | Iteration: 32463 | Classification loss: 0.01398 | Regression loss: 0.02066 | Objectness loss: 0.00038 | RPN Regression loss: 0.00166 | Running loss: 0.03668\n","Epoch: 9 | Iteration: 32464 | Classification loss: 0.01882 | Regression loss: 0.06352 | Objectness loss: 0.00033 | RPN Regression loss: 0.00117 | Running loss: 0.08385\n","Epoch: 9 | Iteration: 32465 | Classification loss: 0.01060 | Regression loss: 0.02059 | Objectness loss: 0.00225 | RPN Regression loss: 0.00062 | Running loss: 0.03406\n","Epoch: 9 | Iteration: 32466 | Classification loss: 0.01312 | Regression loss: 0.01915 | Objectness loss: 0.00072 | RPN Regression loss: 0.00036 | Running loss: 0.03335\n","Epoch: 9 | Iteration: 32467 | Classification loss: 0.03932 | Regression loss: 0.03971 | Objectness loss: 0.00004 | RPN Regression loss: 0.00109 | Running loss: 0.08016\n","Epoch: 9 | Iteration: 32468 | Classification loss: 0.02313 | Regression loss: 0.03182 | Objectness loss: 0.00012 | RPN Regression loss: 0.00089 | Running loss: 0.05595\n","Epoch: 9 | Iteration: 32469 | Classification loss: 0.03603 | Regression loss: 0.02523 | Objectness loss: 0.00340 | RPN Regression loss: 0.00076 | Running loss: 0.06543\n","Epoch: 9 | Iteration: 32470 | Classification loss: 0.01721 | Regression loss: 0.01897 | Objectness loss: 0.00001 | RPN Regression loss: 0.00072 | Running loss: 0.03692\n","Epoch: 9 | Iteration: 32471 | Classification loss: 0.01294 | Regression loss: 0.03004 | Objectness loss: 0.00001 | RPN Regression loss: 0.00112 | Running loss: 0.04411\n","Epoch: 9 | Iteration: 32472 | Classification loss: 0.04363 | Regression loss: 0.03050 | Objectness loss: 0.00450 | RPN Regression loss: 0.00118 | Running loss: 0.07980\n","Epoch: 9 | Iteration: 32473 | Classification loss: 0.01864 | Regression loss: 0.02350 | Objectness loss: 0.00164 | RPN Regression loss: 0.00196 | Running loss: 0.04573\n","Epoch: 9 | Iteration: 32474 | Classification loss: 0.02254 | Regression loss: 0.02376 | Objectness loss: 0.00045 | RPN Regression loss: 0.00213 | Running loss: 0.04888\n","Epoch: 9 | Iteration: 32475 | Classification loss: 0.01959 | Regression loss: 0.02469 | Objectness loss: 0.00186 | RPN Regression loss: 0.00188 | Running loss: 0.04802\n","Epoch: 9 | Iteration: 32476 | Classification loss: 0.00858 | Regression loss: 0.01166 | Objectness loss: 0.00453 | RPN Regression loss: 0.00089 | Running loss: 0.02567\n","Epoch: 9 | Iteration: 32477 | Classification loss: 0.03236 | Regression loss: 0.02219 | Objectness loss: 0.00142 | RPN Regression loss: 0.00082 | Running loss: 0.05679\n","Epoch: 9 | Iteration: 32478 | Classification loss: 0.03549 | Regression loss: 0.04636 | Objectness loss: 0.00343 | RPN Regression loss: 0.00113 | Running loss: 0.08641\n","Epoch: 9 | Iteration: 32479 | Classification loss: 0.00713 | Regression loss: 0.02547 | Objectness loss: 0.00040 | RPN Regression loss: 0.00118 | Running loss: 0.03418\n","Epoch: 9 | Iteration: 32480 | Classification loss: 0.00981 | Regression loss: 0.01695 | Objectness loss: 0.00337 | RPN Regression loss: 0.00078 | Running loss: 0.03090\n","Epoch: 9 | Iteration: 32481 | Classification loss: 0.01114 | Regression loss: 0.02885 | Objectness loss: 0.00045 | RPN Regression loss: 0.00097 | Running loss: 0.04141\n","Epoch: 9 | Iteration: 32482 | Classification loss: 0.01562 | Regression loss: 0.02159 | Objectness loss: 0.00612 | RPN Regression loss: 0.00102 | Running loss: 0.04435\n","Epoch: 9 | Iteration: 32483 | Classification loss: 0.03100 | Regression loss: 0.02172 | Objectness loss: 0.00010 | RPN Regression loss: 0.00402 | Running loss: 0.05684\n","Epoch: 9 | Iteration: 32484 | Classification loss: 0.01158 | Regression loss: 0.02206 | Objectness loss: 0.00068 | RPN Regression loss: 0.00305 | Running loss: 0.03736\n","Epoch: 9 | Iteration: 32485 | Classification loss: 0.02607 | Regression loss: 0.03383 | Objectness loss: 0.00030 | RPN Regression loss: 0.00199 | Running loss: 0.06218\n","Epoch: 9 | Iteration: 32486 | Classification loss: 0.00904 | Regression loss: 0.01580 | Objectness loss: 0.00005 | RPN Regression loss: 0.00030 | Running loss: 0.02518\n","Epoch: 9 | Iteration: 32487 | Classification loss: 0.01240 | Regression loss: 0.01843 | Objectness loss: 0.00016 | RPN Regression loss: 0.00119 | Running loss: 0.03218\n","Epoch: 9 | Iteration: 32488 | Classification loss: 0.01523 | Regression loss: 0.04382 | Objectness loss: 0.00245 | RPN Regression loss: 0.00377 | Running loss: 0.06528\n","Epoch: 9 | Iteration: 32489 | Classification loss: 0.01773 | Regression loss: 0.03934 | Objectness loss: 0.01284 | RPN Regression loss: 0.01128 | Running loss: 0.08119\n","Epoch: 9 | Iteration: 32490 | Classification loss: 0.01222 | Regression loss: 0.02766 | Objectness loss: 0.00573 | RPN Regression loss: 0.00303 | Running loss: 0.04863\n","Epoch: 9 | Iteration: 32491 | Classification loss: 0.02108 | Regression loss: 0.02205 | Objectness loss: 0.00137 | RPN Regression loss: 0.00220 | Running loss: 0.04671\n","Epoch: 9 | Iteration: 32492 | Classification loss: 0.01852 | Regression loss: 0.03328 | Objectness loss: 0.00020 | RPN Regression loss: 0.00253 | Running loss: 0.05453\n","Epoch: 9 | Iteration: 32493 | Classification loss: 0.02060 | Regression loss: 0.02434 | Objectness loss: 0.00178 | RPN Regression loss: 0.00092 | Running loss: 0.04764\n","Epoch: 9 | Iteration: 32494 | Classification loss: 0.01556 | Regression loss: 0.03003 | Objectness loss: 0.00019 | RPN Regression loss: 0.00051 | Running loss: 0.04629\n","Epoch: 9 | Iteration: 32495 | Classification loss: 0.01351 | Regression loss: 0.01550 | Objectness loss: 0.00028 | RPN Regression loss: 0.00148 | Running loss: 0.03077\n","Epoch: 9 | Iteration: 32496 | Classification loss: 0.00947 | Regression loss: 0.02364 | Objectness loss: 0.00113 | RPN Regression loss: 0.00290 | Running loss: 0.03714\n","Epoch: 9 | Iteration: 32497 | Classification loss: 0.01113 | Regression loss: 0.02315 | Objectness loss: 0.00210 | RPN Regression loss: 0.00098 | Running loss: 0.03736\n","Epoch: 9 | Iteration: 32498 | Classification loss: 0.00870 | Regression loss: 0.01563 | Objectness loss: 0.00216 | RPN Regression loss: 0.00410 | Running loss: 0.03060\n","Epoch: 9 | Iteration: 32499 | Classification loss: 0.02090 | Regression loss: 0.03593 | Objectness loss: 0.00435 | RPN Regression loss: 0.00251 | Running loss: 0.06369\n","Epoch: 9 | Iteration: 32500 | Classification loss: 0.02140 | Regression loss: 0.02125 | Objectness loss: 0.00565 | RPN Regression loss: 0.00054 | Running loss: 0.04884\n","Epoch: 9 | Iteration: 32501 | Classification loss: 0.00978 | Regression loss: 0.02867 | Objectness loss: 0.00227 | RPN Regression loss: 0.00136 | Running loss: 0.04208\n","Epoch: 9 | Iteration: 32502 | Classification loss: 0.02836 | Regression loss: 0.03389 | Objectness loss: 0.00006 | RPN Regression loss: 0.00062 | Running loss: 0.06292\n","Epoch: 9 | Iteration: 32503 | Classification loss: 0.02510 | Regression loss: 0.03362 | Objectness loss: 0.00026 | RPN Regression loss: 0.00093 | Running loss: 0.05991\n","Epoch: 9 | Iteration: 32504 | Classification loss: 0.01403 | Regression loss: 0.02509 | Objectness loss: 0.00492 | RPN Regression loss: 0.00426 | Running loss: 0.04830\n","Epoch: 9 | Iteration: 32505 | Classification loss: 0.05445 | Regression loss: 0.07159 | Objectness loss: 0.00964 | RPN Regression loss: 0.00553 | Running loss: 0.14121\n","Epoch: 9 | Iteration: 32506 | Classification loss: 0.00729 | Regression loss: 0.01841 | Objectness loss: 0.00003 | RPN Regression loss: 0.00076 | Running loss: 0.02649\n","Epoch: 9 | Iteration: 32507 | Classification loss: 0.02323 | Regression loss: 0.02778 | Objectness loss: 0.00011 | RPN Regression loss: 0.00077 | Running loss: 0.05190\n","Epoch: 9 | Iteration: 32508 | Classification loss: 0.01318 | Regression loss: 0.01698 | Objectness loss: 0.00616 | RPN Regression loss: 0.00567 | Running loss: 0.04199\n","Epoch: 9 | Iteration: 32509 | Classification loss: 0.00792 | Regression loss: 0.01467 | Objectness loss: 0.00027 | RPN Regression loss: 0.00104 | Running loss: 0.02389\n","Epoch: 9 | Iteration: 32510 | Classification loss: 0.01184 | Regression loss: 0.03505 | Objectness loss: 0.00067 | RPN Regression loss: 0.00131 | Running loss: 0.04888\n","Epoch: 9 | Iteration: 32511 | Classification loss: 0.03859 | Regression loss: 0.03332 | Objectness loss: 0.00010 | RPN Regression loss: 0.00138 | Running loss: 0.07339\n","Epoch: 9 | Iteration: 32512 | Classification loss: 0.02277 | Regression loss: 0.05765 | Objectness loss: 0.00119 | RPN Regression loss: 0.00222 | Running loss: 0.08382\n","Epoch: 9 | Iteration: 32513 | Classification loss: 0.01545 | Regression loss: 0.02170 | Objectness loss: 0.00012 | RPN Regression loss: 0.00055 | Running loss: 0.03782\n","Epoch: 9 | Iteration: 32514 | Classification loss: 0.02941 | Regression loss: 0.03675 | Objectness loss: 0.00172 | RPN Regression loss: 0.00152 | Running loss: 0.06940\n","Epoch: 9 | Iteration: 32515 | Classification loss: 0.00987 | Regression loss: 0.02475 | Objectness loss: 0.00003 | RPN Regression loss: 0.00065 | Running loss: 0.03529\n","Epoch: 9 | Iteration: 32516 | Classification loss: 0.02342 | Regression loss: 0.02314 | Objectness loss: 0.00355 | RPN Regression loss: 0.00082 | Running loss: 0.05093\n","Epoch: 9 | Iteration: 32517 | Classification loss: 0.01172 | Regression loss: 0.01134 | Objectness loss: 0.00022 | RPN Regression loss: 0.00134 | Running loss: 0.02462\n","Epoch: 9 | Iteration: 32518 | Classification loss: 0.03900 | Regression loss: 0.03454 | Objectness loss: 0.00128 | RPN Regression loss: 0.00183 | Running loss: 0.07665\n","Epoch: 9 | Iteration: 32519 | Classification loss: 0.00841 | Regression loss: 0.01136 | Objectness loss: 0.00004 | RPN Regression loss: 0.00154 | Running loss: 0.02134\n","Epoch: 9 | Iteration: 32520 | Classification loss: 0.01599 | Regression loss: 0.02795 | Objectness loss: 0.00008 | RPN Regression loss: 0.00125 | Running loss: 0.04527\n","Epoch: 9 | Iteration: 32521 | Classification loss: 0.01427 | Regression loss: 0.02069 | Objectness loss: 0.00638 | RPN Regression loss: 0.00344 | Running loss: 0.04478\n","Epoch: 9 | Iteration: 32522 | Classification loss: 0.00737 | Regression loss: 0.01723 | Objectness loss: 0.00099 | RPN Regression loss: 0.00167 | Running loss: 0.02726\n","Epoch: 9 | Iteration: 32523 | Classification loss: 0.01893 | Regression loss: 0.02748 | Objectness loss: 0.00265 | RPN Regression loss: 0.00199 | Running loss: 0.05106\n","Epoch: 9 | Iteration: 32524 | Classification loss: 0.00827 | Regression loss: 0.01688 | Objectness loss: 0.00150 | RPN Regression loss: 0.00150 | Running loss: 0.02816\n","Epoch: 9 | Iteration: 32525 | Classification loss: 0.01211 | Regression loss: 0.02973 | Objectness loss: 0.00046 | RPN Regression loss: 0.00376 | Running loss: 0.04605\n","Epoch: 9 | Iteration: 32526 | Classification loss: 0.03033 | Regression loss: 0.03758 | Objectness loss: 0.00014 | RPN Regression loss: 0.00172 | Running loss: 0.06977\n","Epoch: 9 | Iteration: 32527 | Classification loss: 0.01376 | Regression loss: 0.03470 | Objectness loss: 0.00002 | RPN Regression loss: 0.00177 | Running loss: 0.05026\n","Epoch: 9 | Iteration: 32528 | Classification loss: 0.01052 | Regression loss: 0.02052 | Objectness loss: 0.00006 | RPN Regression loss: 0.00059 | Running loss: 0.03169\n","Epoch: 9 | Iteration: 32529 | Classification loss: 0.04449 | Regression loss: 0.04123 | Objectness loss: 0.00212 | RPN Regression loss: 0.00153 | Running loss: 0.08937\n","Epoch: 9 | Iteration: 32530 | Classification loss: 0.00788 | Regression loss: 0.02253 | Objectness loss: 0.00012 | RPN Regression loss: 0.00095 | Running loss: 0.03147\n","Epoch: 9 | Iteration: 32531 | Classification loss: 0.02524 | Regression loss: 0.03631 | Objectness loss: 0.00049 | RPN Regression loss: 0.00096 | Running loss: 0.06299\n","Epoch: 9 | Iteration: 32532 | Classification loss: 0.01017 | Regression loss: 0.01441 | Objectness loss: 0.00006 | RPN Regression loss: 0.00071 | Running loss: 0.02536\n","Epoch: 9 | Iteration: 32533 | Classification loss: 0.01226 | Regression loss: 0.02507 | Objectness loss: 0.00039 | RPN Regression loss: 0.00287 | Running loss: 0.04059\n","Epoch: 9 | Iteration: 32534 | Classification loss: 0.01855 | Regression loss: 0.01774 | Objectness loss: 0.00012 | RPN Regression loss: 0.00116 | Running loss: 0.03757\n","Epoch: 9 | Iteration: 32535 | Classification loss: 0.01390 | Regression loss: 0.02044 | Objectness loss: 0.00002 | RPN Regression loss: 0.00097 | Running loss: 0.03533\n","Epoch: 9 | Iteration: 32536 | Classification loss: 0.03110 | Regression loss: 0.02372 | Objectness loss: 0.00603 | RPN Regression loss: 0.00075 | Running loss: 0.06160\n","Epoch: 9 | Iteration: 32537 | Classification loss: 0.01298 | Regression loss: 0.02041 | Objectness loss: 0.00037 | RPN Regression loss: 0.00133 | Running loss: 0.03509\n","Epoch: 9 | Iteration: 32538 | Classification loss: 0.00852 | Regression loss: 0.01175 | Objectness loss: 0.00039 | RPN Regression loss: 0.00073 | Running loss: 0.02138\n","Epoch: 9 | Iteration: 32539 | Classification loss: 0.00878 | Regression loss: 0.01782 | Objectness loss: 0.00001 | RPN Regression loss: 0.00086 | Running loss: 0.02748\n","Epoch: 9 | Iteration: 32540 | Classification loss: 0.01329 | Regression loss: 0.01796 | Objectness loss: 0.00017 | RPN Regression loss: 0.00053 | Running loss: 0.03195\n","Epoch: 9 | Iteration: 32541 | Classification loss: 0.01121 | Regression loss: 0.01785 | Objectness loss: 0.00003 | RPN Regression loss: 0.00107 | Running loss: 0.03015\n","Epoch: 9 | Iteration: 32542 | Classification loss: 0.02482 | Regression loss: 0.03092 | Objectness loss: 0.00009 | RPN Regression loss: 0.00183 | Running loss: 0.05766\n","Epoch: 9 | Iteration: 32543 | Classification loss: 0.01795 | Regression loss: 0.02590 | Objectness loss: 0.00120 | RPN Regression loss: 0.00151 | Running loss: 0.04657\n","Epoch: 9 | Iteration: 32544 | Classification loss: 0.00488 | Regression loss: 0.02309 | Objectness loss: 0.00006 | RPN Regression loss: 0.00805 | Running loss: 0.03608\n","Epoch: 9 | Iteration: 32545 | Classification loss: 0.02554 | Regression loss: 0.02820 | Objectness loss: 0.00036 | RPN Regression loss: 0.00341 | Running loss: 0.05751\n","Epoch: 9 | Iteration: 32546 | Classification loss: 0.01028 | Regression loss: 0.01408 | Objectness loss: 0.00016 | RPN Regression loss: 0.00058 | Running loss: 0.02510\n","Epoch: 9 | Iteration: 32547 | Classification loss: 0.01873 | Regression loss: 0.05683 | Objectness loss: 0.00081 | RPN Regression loss: 0.00190 | Running loss: 0.07826\n","Epoch: 9 | Iteration: 32548 | Classification loss: 0.04465 | Regression loss: 0.02270 | Objectness loss: 0.00462 | RPN Regression loss: 0.00052 | Running loss: 0.07249\n","Epoch: 9 | Iteration: 32549 | Classification loss: 0.02104 | Regression loss: 0.01530 | Objectness loss: 0.00050 | RPN Regression loss: 0.00054 | Running loss: 0.03738\n","Epoch: 9 | Iteration: 32550 | Classification loss: 0.00854 | Regression loss: 0.02036 | Objectness loss: 0.00109 | RPN Regression loss: 0.00135 | Running loss: 0.03133\n","Epoch: 9 | Iteration: 32551 | Classification loss: 0.01216 | Regression loss: 0.02435 | Objectness loss: 0.00276 | RPN Regression loss: 0.00114 | Running loss: 0.04040\n","Epoch: 9 | Iteration: 32552 | Classification loss: 0.01900 | Regression loss: 0.02821 | Objectness loss: 0.00258 | RPN Regression loss: 0.00190 | Running loss: 0.05169\n","Epoch: 9 | Iteration: 32553 | Classification loss: 0.00344 | Regression loss: 0.00937 | Objectness loss: 0.00035 | RPN Regression loss: 0.00069 | Running loss: 0.01385\n","Epoch: 9 | Iteration: 32554 | Classification loss: 0.01187 | Regression loss: 0.02034 | Objectness loss: 0.00009 | RPN Regression loss: 0.00114 | Running loss: 0.03344\n","Epoch: 9 | Iteration: 32555 | Classification loss: 0.01323 | Regression loss: 0.02983 | Objectness loss: 0.00074 | RPN Regression loss: 0.00162 | Running loss: 0.04544\n","Epoch: 9 | Iteration: 32556 | Classification loss: 0.02542 | Regression loss: 0.03763 | Objectness loss: 0.00005 | RPN Regression loss: 0.00093 | Running loss: 0.06402\n","Epoch: 9 | Iteration: 32557 | Classification loss: 0.01068 | Regression loss: 0.01494 | Objectness loss: 0.00048 | RPN Regression loss: 0.00208 | Running loss: 0.02819\n","Epoch: 9 | Iteration: 32558 | Classification loss: 0.01945 | Regression loss: 0.01327 | Objectness loss: 0.00046 | RPN Regression loss: 0.00237 | Running loss: 0.03555\n","Epoch: 9 | Iteration: 32559 | Classification loss: 0.01291 | Regression loss: 0.01353 | Objectness loss: 0.00002 | RPN Regression loss: 0.00048 | Running loss: 0.02695\n","Epoch: 9 | Iteration: 32560 | Classification loss: 0.02124 | Regression loss: 0.03459 | Objectness loss: 0.00006 | RPN Regression loss: 0.00189 | Running loss: 0.05778\n","Epoch: 9 | Iteration: 32561 | Classification loss: 0.01664 | Regression loss: 0.01991 | Objectness loss: 0.00051 | RPN Regression loss: 0.00166 | Running loss: 0.03872\n","Epoch: 9 | Iteration: 32562 | Classification loss: 0.02941 | Regression loss: 0.04576 | Objectness loss: 0.00150 | RPN Regression loss: 0.00350 | Running loss: 0.08017\n","Epoch: 9 | Iteration: 32563 | Classification loss: 0.04157 | Regression loss: 0.05650 | Objectness loss: 0.00426 | RPN Regression loss: 0.00081 | Running loss: 0.10314\n","Epoch: 9 | Iteration: 32564 | Classification loss: 0.00760 | Regression loss: 0.02430 | Objectness loss: 0.00029 | RPN Regression loss: 0.00095 | Running loss: 0.03314\n","Epoch: 9 | Iteration: 32565 | Classification loss: 0.01080 | Regression loss: 0.03517 | Objectness loss: 0.00021 | RPN Regression loss: 0.00069 | Running loss: 0.04686\n","Epoch: 9 | Iteration: 32566 | Classification loss: 0.01618 | Regression loss: 0.02996 | Objectness loss: 0.00010 | RPN Regression loss: 0.00115 | Running loss: 0.04740\n","Epoch: 9 | Iteration: 32567 | Classification loss: 0.01077 | Regression loss: 0.03354 | Objectness loss: 0.00013 | RPN Regression loss: 0.00311 | Running loss: 0.04755\n","Epoch: 9 | Iteration: 32568 | Classification loss: 0.01919 | Regression loss: 0.01960 | Objectness loss: 0.00148 | RPN Regression loss: 0.00197 | Running loss: 0.04224\n","Epoch: 9 | Iteration: 32569 | Classification loss: 0.02571 | Regression loss: 0.02205 | Objectness loss: 0.00006 | RPN Regression loss: 0.00175 | Running loss: 0.04957\n","Epoch: 9 | Iteration: 32570 | Classification loss: 0.01162 | Regression loss: 0.01544 | Objectness loss: 0.00178 | RPN Regression loss: 0.00088 | Running loss: 0.02972\n","Epoch: 9 | Iteration: 32571 | Classification loss: 0.02701 | Regression loss: 0.02098 | Objectness loss: 0.00367 | RPN Regression loss: 0.00083 | Running loss: 0.05249\n","Epoch: 9 | Iteration: 32572 | Classification loss: 0.03017 | Regression loss: 0.03481 | Objectness loss: 0.00012 | RPN Regression loss: 0.00220 | Running loss: 0.06730\n","Epoch: 9 | Iteration: 32573 | Classification loss: 0.01354 | Regression loss: 0.03435 | Objectness loss: 0.00011 | RPN Regression loss: 0.00109 | Running loss: 0.04908\n","Epoch: 9 | Iteration: 32574 | Classification loss: 0.00830 | Regression loss: 0.01821 | Objectness loss: 0.00001 | RPN Regression loss: 0.00047 | Running loss: 0.02698\n","Epoch: 9 | Iteration: 32575 | Classification loss: 0.03402 | Regression loss: 0.04173 | Objectness loss: 0.00134 | RPN Regression loss: 0.00232 | Running loss: 0.07942\n","Epoch: 9 | Iteration: 32576 | Classification loss: 0.02405 | Regression loss: 0.01381 | Objectness loss: 0.00006 | RPN Regression loss: 0.00088 | Running loss: 0.03879\n","Epoch: 9 | Iteration: 32577 | Classification loss: 0.00373 | Regression loss: 0.01629 | Objectness loss: 0.00156 | RPN Regression loss: 0.00039 | Running loss: 0.02197\n","Epoch: 9 | Iteration: 32578 | Classification loss: 0.01198 | Regression loss: 0.02536 | Objectness loss: 0.00215 | RPN Regression loss: 0.00405 | Running loss: 0.04354\n","Epoch: 9 | Iteration: 32579 | Classification loss: 0.01401 | Regression loss: 0.01295 | Objectness loss: 0.00004 | RPN Regression loss: 0.00102 | Running loss: 0.02803\n","Epoch: 9 | Iteration: 32580 | Classification loss: 0.00487 | Regression loss: 0.01703 | Objectness loss: 0.00005 | RPN Regression loss: 0.00082 | Running loss: 0.02277\n","Epoch: 9 | Iteration: 32581 | Classification loss: 0.00977 | Regression loss: 0.02880 | Objectness loss: 0.00082 | RPN Regression loss: 0.00104 | Running loss: 0.04043\n","Epoch: 9 | Iteration: 32582 | Classification loss: 0.01989 | Regression loss: 0.03822 | Objectness loss: 0.00021 | RPN Regression loss: 0.00073 | Running loss: 0.05904\n","Epoch: 9 | Iteration: 32583 | Classification loss: 0.01296 | Regression loss: 0.02106 | Objectness loss: 0.00009 | RPN Regression loss: 0.00087 | Running loss: 0.03499\n","Epoch: 9 | Iteration: 32584 | Classification loss: 0.05274 | Regression loss: 0.04087 | Objectness loss: 0.00656 | RPN Regression loss: 0.00189 | Running loss: 0.10205\n","Epoch: 9 | Iteration: 32585 | Classification loss: 0.01215 | Regression loss: 0.02185 | Objectness loss: 0.00143 | RPN Regression loss: 0.00108 | Running loss: 0.03651\n","Epoch: 9 | Iteration: 32586 | Classification loss: 0.00820 | Regression loss: 0.02052 | Objectness loss: 0.00016 | RPN Regression loss: 0.00051 | Running loss: 0.02939\n","Epoch: 9 | Iteration: 32587 | Classification loss: 0.00618 | Regression loss: 0.02411 | Objectness loss: 0.00003 | RPN Regression loss: 0.00042 | Running loss: 0.03074\n","Epoch: 9 | Iteration: 32588 | Classification loss: 0.02585 | Regression loss: 0.04423 | Objectness loss: 0.00125 | RPN Regression loss: 0.00106 | Running loss: 0.07239\n","Epoch: 9 | Iteration: 32589 | Classification loss: 0.03650 | Regression loss: 0.02127 | Objectness loss: 0.00200 | RPN Regression loss: 0.00051 | Running loss: 0.06028\n","Epoch: 9 | Iteration: 32590 | Classification loss: 0.00740 | Regression loss: 0.01017 | Objectness loss: 0.00093 | RPN Regression loss: 0.00070 | Running loss: 0.01920\n","Epoch: 9 | Iteration: 32591 | Classification loss: 0.01709 | Regression loss: 0.02006 | Objectness loss: 0.00262 | RPN Regression loss: 0.00175 | Running loss: 0.04153\n","Epoch: 9 | Iteration: 32592 | Classification loss: 0.00973 | Regression loss: 0.01186 | Objectness loss: 0.00036 | RPN Regression loss: 0.00129 | Running loss: 0.02324\n","Epoch: 9 | Iteration: 32593 | Classification loss: 0.02812 | Regression loss: 0.01930 | Objectness loss: 0.00043 | RPN Regression loss: 0.00183 | Running loss: 0.04968\n","Epoch: 9 | Iteration: 32594 | Classification loss: 0.02043 | Regression loss: 0.04353 | Objectness loss: 0.00082 | RPN Regression loss: 0.00235 | Running loss: 0.06714\n","Epoch: 9 | Iteration: 32595 | Classification loss: 0.01822 | Regression loss: 0.03157 | Objectness loss: 0.00721 | RPN Regression loss: 0.00109 | Running loss: 0.05809\n","Epoch: 9 | Iteration: 32596 | Classification loss: 0.00912 | Regression loss: 0.02492 | Objectness loss: 0.00004 | RPN Regression loss: 0.00029 | Running loss: 0.03437\n","Epoch: 9 | Iteration: 32597 | Classification loss: 0.01106 | Regression loss: 0.03014 | Objectness loss: 0.00002 | RPN Regression loss: 0.00067 | Running loss: 0.04189\n","Epoch: 9 | Iteration: 32598 | Classification loss: 0.01748 | Regression loss: 0.01125 | Objectness loss: 0.00521 | RPN Regression loss: 0.00118 | Running loss: 0.03511\n","Epoch: 9 | Iteration: 32599 | Classification loss: 0.01019 | Regression loss: 0.01820 | Objectness loss: 0.00011 | RPN Regression loss: 0.00248 | Running loss: 0.03098\n","Epoch: 9 | Iteration: 32600 | Classification loss: 0.00965 | Regression loss: 0.02304 | Objectness loss: 0.00426 | RPN Regression loss: 0.00332 | Running loss: 0.04027\n","Epoch: 9 | Iteration: 32601 | Classification loss: 0.02517 | Regression loss: 0.01278 | Objectness loss: 0.00003 | RPN Regression loss: 0.00061 | Running loss: 0.03860\n","Epoch: 9 | Iteration: 32602 | Classification loss: 0.01044 | Regression loss: 0.01297 | Objectness loss: 0.00023 | RPN Regression loss: 0.00131 | Running loss: 0.02494\n","Epoch: 9 | Iteration: 32603 | Classification loss: 0.02081 | Regression loss: 0.01647 | Objectness loss: 0.00432 | RPN Regression loss: 0.00037 | Running loss: 0.04197\n","Epoch: 9 | Iteration: 32604 | Classification loss: 0.04185 | Regression loss: 0.03869 | Objectness loss: 0.00014 | RPN Regression loss: 0.00225 | Running loss: 0.08293\n","Epoch: 9 | Iteration: 32605 | Classification loss: 0.01913 | Regression loss: 0.04769 | Objectness loss: 0.00118 | RPN Regression loss: 0.00140 | Running loss: 0.06940\n","Epoch: 9 | Iteration: 32606 | Classification loss: 0.01716 | Regression loss: 0.03497 | Objectness loss: 0.00026 | RPN Regression loss: 0.00048 | Running loss: 0.05287\n","Epoch: 9 | Iteration: 32607 | Classification loss: 0.00808 | Regression loss: 0.01934 | Objectness loss: 0.00077 | RPN Regression loss: 0.00144 | Running loss: 0.02963\n","Epoch: 9 | Iteration: 32608 | Classification loss: 0.03482 | Regression loss: 0.05321 | Objectness loss: 0.00503 | RPN Regression loss: 0.00273 | Running loss: 0.09580\n","Epoch: 9 | Iteration: 32609 | Classification loss: 0.02627 | Regression loss: 0.01959 | Objectness loss: 0.00297 | RPN Regression loss: 0.00083 | Running loss: 0.04966\n","Epoch: 9 | Iteration: 32610 | Classification loss: 0.02292 | Regression loss: 0.02021 | Objectness loss: 0.00010 | RPN Regression loss: 0.00099 | Running loss: 0.04421\n","Epoch: 9 | Iteration: 32611 | Classification loss: 0.01736 | Regression loss: 0.01988 | Objectness loss: 0.00705 | RPN Regression loss: 0.00103 | Running loss: 0.04532\n","Epoch: 9 | Iteration: 32612 | Classification loss: 0.03200 | Regression loss: 0.03966 | Objectness loss: 0.00006 | RPN Regression loss: 0.00283 | Running loss: 0.07453\n","Epoch: 9 | Iteration: 32613 | Classification loss: 0.00836 | Regression loss: 0.01493 | Objectness loss: 0.00220 | RPN Regression loss: 0.00052 | Running loss: 0.02600\n","Epoch: 9 | Iteration: 32614 | Classification loss: 0.01910 | Regression loss: 0.03235 | Objectness loss: 0.00007 | RPN Regression loss: 0.00096 | Running loss: 0.05249\n","Epoch: 9 | Iteration: 32615 | Classification loss: 0.02330 | Regression loss: 0.01853 | Objectness loss: 0.00048 | RPN Regression loss: 0.00110 | Running loss: 0.04341\n","Epoch: 9 | Iteration: 32616 | Classification loss: 0.01609 | Regression loss: 0.02148 | Objectness loss: 0.00014 | RPN Regression loss: 0.00155 | Running loss: 0.03925\n","Epoch: 9 | Iteration: 32617 | Classification loss: 0.01241 | Regression loss: 0.02893 | Objectness loss: 0.00004 | RPN Regression loss: 0.00065 | Running loss: 0.04203\n","Epoch: 9 | Iteration: 32618 | Classification loss: 0.02519 | Regression loss: 0.02106 | Objectness loss: 0.00037 | RPN Regression loss: 0.00712 | Running loss: 0.05374\n","Epoch: 9 | Iteration: 32619 | Classification loss: 0.02571 | Regression loss: 0.02888 | Objectness loss: 0.00251 | RPN Regression loss: 0.00088 | Running loss: 0.05798\n","Epoch: 9 | Iteration: 32620 | Classification loss: 0.01221 | Regression loss: 0.03033 | Objectness loss: 0.00016 | RPN Regression loss: 0.00213 | Running loss: 0.04484\n","Epoch: 9 | Iteration: 32621 | Classification loss: 0.01965 | Regression loss: 0.01969 | Objectness loss: 0.00006 | RPN Regression loss: 0.00108 | Running loss: 0.04048\n","Epoch: 9 | Iteration: 32622 | Classification loss: 0.02090 | Regression loss: 0.04512 | Objectness loss: 0.00010 | RPN Regression loss: 0.00195 | Running loss: 0.06808\n","Epoch: 9 | Iteration: 32623 | Classification loss: 0.01984 | Regression loss: 0.02052 | Objectness loss: 0.00009 | RPN Regression loss: 0.00194 | Running loss: 0.04240\n","Epoch: 9 | Iteration: 32624 | Classification loss: 0.03944 | Regression loss: 0.06616 | Objectness loss: 0.01824 | RPN Regression loss: 0.00205 | Running loss: 0.12588\n","Epoch: 9 | Iteration: 32625 | Classification loss: 0.02009 | Regression loss: 0.03468 | Objectness loss: 0.00190 | RPN Regression loss: 0.00401 | Running loss: 0.06069\n","Epoch: 9 | Iteration: 32626 | Classification loss: 0.00566 | Regression loss: 0.01402 | Objectness loss: 0.00028 | RPN Regression loss: 0.00073 | Running loss: 0.02069\n","Epoch: 9 | Iteration: 32627 | Classification loss: 0.03326 | Regression loss: 0.02972 | Objectness loss: 0.00124 | RPN Regression loss: 0.00508 | Running loss: 0.06931\n","Epoch: 9 | Iteration: 32628 | Classification loss: 0.01660 | Regression loss: 0.02976 | Objectness loss: 0.00006 | RPN Regression loss: 0.00319 | Running loss: 0.04961\n","Epoch: 9 | Iteration: 32629 | Classification loss: 0.04338 | Regression loss: 0.01623 | Objectness loss: 0.00548 | RPN Regression loss: 0.00289 | Running loss: 0.06798\n","Epoch: 9 | Iteration: 32630 | Classification loss: 0.01371 | Regression loss: 0.01869 | Objectness loss: 0.00014 | RPN Regression loss: 0.00132 | Running loss: 0.03387\n","Epoch: 9 | Iteration: 32631 | Classification loss: 0.00641 | Regression loss: 0.01606 | Objectness loss: 0.00032 | RPN Regression loss: 0.00411 | Running loss: 0.02690\n","Epoch: 9 | Iteration: 32632 | Classification loss: 0.00851 | Regression loss: 0.01364 | Objectness loss: 0.00003 | RPN Regression loss: 0.00065 | Running loss: 0.02282\n","Epoch: 9 | Iteration: 32633 | Classification loss: 0.01605 | Regression loss: 0.02961 | Objectness loss: 0.00466 | RPN Regression loss: 0.01280 | Running loss: 0.06313\n","Epoch: 9 | Iteration: 32634 | Classification loss: 0.01263 | Regression loss: 0.01912 | Objectness loss: 0.00428 | RPN Regression loss: 0.00161 | Running loss: 0.03763\n","Epoch: 9 | Iteration: 32635 | Classification loss: 0.02975 | Regression loss: 0.02368 | Objectness loss: 0.00008 | RPN Regression loss: 0.00032 | Running loss: 0.05383\n","Epoch: 9 | Iteration: 32636 | Classification loss: 0.01238 | Regression loss: 0.01644 | Objectness loss: 0.00117 | RPN Regression loss: 0.00074 | Running loss: 0.03073\n","Epoch: 9 | Iteration: 32637 | Classification loss: 0.02300 | Regression loss: 0.01849 | Objectness loss: 0.00003 | RPN Regression loss: 0.00057 | Running loss: 0.04209\n","Epoch: 9 | Iteration: 32638 | Classification loss: 0.00877 | Regression loss: 0.01485 | Objectness loss: 0.00031 | RPN Regression loss: 0.00385 | Running loss: 0.02778\n","Epoch: 9 | Iteration: 32639 | Classification loss: 0.02103 | Regression loss: 0.04407 | Objectness loss: 0.00013 | RPN Regression loss: 0.00458 | Running loss: 0.06981\n","Epoch: 9 | Iteration: 32640 | Classification loss: 0.00931 | Regression loss: 0.01990 | Objectness loss: 0.00016 | RPN Regression loss: 0.00081 | Running loss: 0.03017\n","Epoch: 9 | Iteration: 32641 | Classification loss: 0.00865 | Regression loss: 0.02438 | Objectness loss: 0.00079 | RPN Regression loss: 0.00089 | Running loss: 0.03471\n","Epoch: 9 | Iteration: 32642 | Classification loss: 0.01144 | Regression loss: 0.00889 | Objectness loss: 0.00065 | RPN Regression loss: 0.00368 | Running loss: 0.02466\n","Epoch: 9 | Iteration: 32643 | Classification loss: 0.03226 | Regression loss: 0.02432 | Objectness loss: 0.00309 | RPN Regression loss: 0.00111 | Running loss: 0.06078\n","Epoch: 9 | Iteration: 32644 | Classification loss: 0.01416 | Regression loss: 0.02079 | Objectness loss: 0.00008 | RPN Regression loss: 0.00100 | Running loss: 0.03603\n","Epoch: 9 | Iteration: 32645 | Classification loss: 0.01163 | Regression loss: 0.01575 | Objectness loss: 0.00021 | RPN Regression loss: 0.00151 | Running loss: 0.02910\n","Epoch: 9 | Iteration: 32646 | Classification loss: 0.02674 | Regression loss: 0.04750 | Objectness loss: 0.00051 | RPN Regression loss: 0.00072 | Running loss: 0.07547\n","Epoch: 9 | Iteration: 32647 | Classification loss: 0.01309 | Regression loss: 0.02922 | Objectness loss: 0.00009 | RPN Regression loss: 0.00315 | Running loss: 0.04555\n","Epoch: 9 | Iteration: 32648 | Classification loss: 0.02197 | Regression loss: 0.02105 | Objectness loss: 0.00303 | RPN Regression loss: 0.00072 | Running loss: 0.04677\n","Epoch: 9 | Iteration: 32649 | Classification loss: 0.03549 | Regression loss: 0.03716 | Objectness loss: 0.00361 | RPN Regression loss: 0.00045 | Running loss: 0.07671\n","Epoch: 9 | Iteration: 32650 | Classification loss: 0.03051 | Regression loss: 0.03499 | Objectness loss: 0.00006 | RPN Regression loss: 0.00055 | Running loss: 0.06611\n","Epoch: 9 | Iteration: 32651 | Classification loss: 0.00984 | Regression loss: 0.02922 | Objectness loss: 0.00002 | RPN Regression loss: 0.00082 | Running loss: 0.03990\n","Epoch: 9 | Iteration: 32652 | Classification loss: 0.02197 | Regression loss: 0.02606 | Objectness loss: 0.00180 | RPN Regression loss: 0.00209 | Running loss: 0.05192\n","Epoch: 9 | Iteration: 32653 | Classification loss: 0.01843 | Regression loss: 0.04538 | Objectness loss: 0.00014 | RPN Regression loss: 0.00083 | Running loss: 0.06478\n","Epoch: 9 | Iteration: 32654 | Classification loss: 0.01155 | Regression loss: 0.01461 | Objectness loss: 0.00001 | RPN Regression loss: 0.00123 | Running loss: 0.02740\n","Epoch: 9 | Iteration: 32655 | Classification loss: 0.02074 | Regression loss: 0.02855 | Objectness loss: 0.00027 | RPN Regression loss: 0.00429 | Running loss: 0.05384\n","Epoch: 9 | Iteration: 32656 | Classification loss: 0.01537 | Regression loss: 0.02098 | Objectness loss: 0.00322 | RPN Regression loss: 0.00092 | Running loss: 0.04049\n","Epoch: 9 | Iteration: 32657 | Classification loss: 0.01087 | Regression loss: 0.02021 | Objectness loss: 0.00001 | RPN Regression loss: 0.00039 | Running loss: 0.03148\n","Epoch: 9 | Iteration: 32658 | Classification loss: 0.00805 | Regression loss: 0.01261 | Objectness loss: 0.00479 | RPN Regression loss: 0.00155 | Running loss: 0.02699\n","Epoch: 9 | Iteration: 32659 | Classification loss: 0.01485 | Regression loss: 0.01803 | Objectness loss: 0.00004 | RPN Regression loss: 0.00080 | Running loss: 0.03371\n","Epoch: 9 | Iteration: 32660 | Classification loss: 0.01503 | Regression loss: 0.01558 | Objectness loss: 0.00006 | RPN Regression loss: 0.00111 | Running loss: 0.03178\n","Epoch: 9 | Iteration: 32661 | Classification loss: 0.01805 | Regression loss: 0.02615 | Objectness loss: 0.00008 | RPN Regression loss: 0.00259 | Running loss: 0.04687\n","Epoch: 9 | Iteration: 32662 | Classification loss: 0.02156 | Regression loss: 0.01743 | Objectness loss: 0.00022 | RPN Regression loss: 0.00112 | Running loss: 0.04034\n","Epoch: 9 | Iteration: 32663 | Classification loss: 0.00884 | Regression loss: 0.02554 | Objectness loss: 0.00024 | RPN Regression loss: 0.00099 | Running loss: 0.03560\n","Epoch: 9 | Iteration: 32664 | Classification loss: 0.01600 | Regression loss: 0.02910 | Objectness loss: 0.00014 | RPN Regression loss: 0.00062 | Running loss: 0.04586\n","Epoch: 9 | Iteration: 32665 | Classification loss: 0.01500 | Regression loss: 0.03683 | Objectness loss: 0.00010 | RPN Regression loss: 0.00224 | Running loss: 0.05417\n","Epoch: 9 | Iteration: 32666 | Classification loss: 0.03258 | Regression loss: 0.04209 | Objectness loss: 0.00307 | RPN Regression loss: 0.00329 | Running loss: 0.08103\n","Epoch: 9 | Iteration: 32667 | Classification loss: 0.03444 | Regression loss: 0.04606 | Objectness loss: 0.00009 | RPN Regression loss: 0.00130 | Running loss: 0.08188\n","Epoch: 9 | Iteration: 32668 | Classification loss: 0.03567 | Regression loss: 0.03185 | Objectness loss: 0.00010 | RPN Regression loss: 0.00096 | Running loss: 0.06857\n","Epoch: 9 | Iteration: 32669 | Classification loss: 0.00750 | Regression loss: 0.01922 | Objectness loss: 0.00097 | RPN Regression loss: 0.00262 | Running loss: 0.03031\n","Epoch: 9 | Iteration: 32670 | Classification loss: 0.01362 | Regression loss: 0.02306 | Objectness loss: 0.00008 | RPN Regression loss: 0.00077 | Running loss: 0.03753\n","Epoch: 9 | Iteration: 32671 | Classification loss: 0.00931 | Regression loss: 0.02226 | Objectness loss: 0.00008 | RPN Regression loss: 0.00094 | Running loss: 0.03259\n","Epoch: 9 | Iteration: 32672 | Classification loss: 0.01037 | Regression loss: 0.01780 | Objectness loss: 0.00007 | RPN Regression loss: 0.00050 | Running loss: 0.02874\n","Epoch: 9 | Iteration: 32673 | Classification loss: 0.01571 | Regression loss: 0.02534 | Objectness loss: 0.00092 | RPN Regression loss: 0.00091 | Running loss: 0.04289\n","Epoch: 9 | Iteration: 32674 | Classification loss: 0.00761 | Regression loss: 0.01598 | Objectness loss: 0.00002 | RPN Regression loss: 0.00072 | Running loss: 0.02433\n","Epoch: 9 | Iteration: 32675 | Classification loss: 0.03437 | Regression loss: 0.04093 | Objectness loss: 0.00014 | RPN Regression loss: 0.00084 | Running loss: 0.07629\n","Epoch: 9 | Iteration: 32676 | Classification loss: 0.02479 | Regression loss: 0.04223 | Objectness loss: 0.00029 | RPN Regression loss: 0.00128 | Running loss: 0.06859\n","Epoch: 9 | Iteration: 32677 | Classification loss: 0.03847 | Regression loss: 0.04086 | Objectness loss: 0.00007 | RPN Regression loss: 0.00087 | Running loss: 0.08027\n","Epoch: 9 | Iteration: 32678 | Classification loss: 0.01821 | Regression loss: 0.02841 | Objectness loss: 0.00051 | RPN Regression loss: 0.00135 | Running loss: 0.04848\n","Epoch: 9 | Iteration: 32679 | Classification loss: 0.00668 | Regression loss: 0.01532 | Objectness loss: 0.00034 | RPN Regression loss: 0.00223 | Running loss: 0.02457\n","Epoch: 9 | Iteration: 32680 | Classification loss: 0.00767 | Regression loss: 0.02127 | Objectness loss: 0.00001 | RPN Regression loss: 0.00054 | Running loss: 0.02948\n","Epoch: 9 | Iteration: 32681 | Classification loss: 0.01938 | Regression loss: 0.04286 | Objectness loss: 0.00302 | RPN Regression loss: 0.00202 | Running loss: 0.06727\n","Epoch: 9 | Iteration: 32682 | Classification loss: 0.01840 | Regression loss: 0.03580 | Objectness loss: 0.00007 | RPN Regression loss: 0.00085 | Running loss: 0.05512\n","Epoch: 9 | Iteration: 32683 | Classification loss: 0.02042 | Regression loss: 0.01762 | Objectness loss: 0.00053 | RPN Regression loss: 0.00218 | Running loss: 0.04075\n","Epoch: 9 | Iteration: 32684 | Classification loss: 0.02956 | Regression loss: 0.02316 | Objectness loss: 0.00074 | RPN Regression loss: 0.00265 | Running loss: 0.05611\n","Epoch: 9 | Iteration: 32685 | Classification loss: 0.00967 | Regression loss: 0.01861 | Objectness loss: 0.00026 | RPN Regression loss: 0.00095 | Running loss: 0.02948\n","Epoch: 9 | Iteration: 32686 | Classification loss: 0.01157 | Regression loss: 0.02934 | Objectness loss: 0.00027 | RPN Regression loss: 0.00046 | Running loss: 0.04164\n","Epoch: 9 | Iteration: 32687 | Classification loss: 0.01760 | Regression loss: 0.01861 | Objectness loss: 0.00838 | RPN Regression loss: 0.00057 | Running loss: 0.04516\n","Epoch: 9 | Iteration: 32688 | Classification loss: 0.01915 | Regression loss: 0.02765 | Objectness loss: 0.00264 | RPN Regression loss: 0.00062 | Running loss: 0.05006\n","Epoch: 9 | Iteration: 32689 | Classification loss: 0.01422 | Regression loss: 0.02364 | Objectness loss: 0.00012 | RPN Regression loss: 0.00529 | Running loss: 0.04327\n","Epoch: 9 | Iteration: 32690 | Classification loss: 0.01400 | Regression loss: 0.03461 | Objectness loss: 0.00036 | RPN Regression loss: 0.00094 | Running loss: 0.04991\n","Epoch: 9 | Iteration: 32691 | Classification loss: 0.02606 | Regression loss: 0.02096 | Objectness loss: 0.00115 | RPN Regression loss: 0.00036 | Running loss: 0.04852\n","Epoch: 9 | Iteration: 32692 | Classification loss: 0.02652 | Regression loss: 0.01816 | Objectness loss: 0.00032 | RPN Regression loss: 0.00287 | Running loss: 0.04786\n","Epoch: 9 | Iteration: 32693 | Classification loss: 0.02749 | Regression loss: 0.03368 | Objectness loss: 0.00283 | RPN Regression loss: 0.00297 | Running loss: 0.06697\n","Epoch: 9 | Iteration: 32694 | Classification loss: 0.01845 | Regression loss: 0.01273 | Objectness loss: 0.00067 | RPN Regression loss: 0.00143 | Running loss: 0.03328\n","Epoch: 9 | Iteration: 32695 | Classification loss: 0.01146 | Regression loss: 0.02284 | Objectness loss: 0.00011 | RPN Regression loss: 0.00088 | Running loss: 0.03529\n","Epoch: 9 | Iteration: 32696 | Classification loss: 0.02652 | Regression loss: 0.02807 | Objectness loss: 0.00672 | RPN Regression loss: 0.00176 | Running loss: 0.06307\n","Epoch: 9 | Iteration: 32697 | Classification loss: 0.01826 | Regression loss: 0.01485 | Objectness loss: 0.00002 | RPN Regression loss: 0.00092 | Running loss: 0.03405\n","Epoch: 9 | Iteration: 32698 | Classification loss: 0.01421 | Regression loss: 0.01828 | Objectness loss: 0.00002 | RPN Regression loss: 0.00090 | Running loss: 0.03342\n","Epoch: 9 | Iteration: 32699 | Classification loss: 0.01911 | Regression loss: 0.03842 | Objectness loss: 0.00161 | RPN Regression loss: 0.00146 | Running loss: 0.06059\n","Epoch: 9 | Iteration: 32700 | Classification loss: 0.01559 | Regression loss: 0.02833 | Objectness loss: 0.00005 | RPN Regression loss: 0.00085 | Running loss: 0.04483\n","Epoch: 9 | Iteration: 32701 | Classification loss: 0.00372 | Regression loss: 0.01541 | Objectness loss: 0.00045 | RPN Regression loss: 0.00279 | Running loss: 0.02237\n","Epoch: 9 | Iteration: 32702 | Classification loss: 0.02326 | Regression loss: 0.03704 | Objectness loss: 0.00026 | RPN Regression loss: 0.00222 | Running loss: 0.06278\n","Epoch: 9 | Iteration: 32703 | Classification loss: 0.01300 | Regression loss: 0.03304 | Objectness loss: 0.00006 | RPN Regression loss: 0.00145 | Running loss: 0.04754\n","Epoch: 9 | Iteration: 32704 | Classification loss: 0.02544 | Regression loss: 0.01841 | Objectness loss: 0.00006 | RPN Regression loss: 0.00098 | Running loss: 0.04490\n","Epoch: 9 | Iteration: 32705 | Classification loss: 0.01234 | Regression loss: 0.01859 | Objectness loss: 0.00048 | RPN Regression loss: 0.00236 | Running loss: 0.03377\n","Epoch: 9 | Iteration: 32706 | Classification loss: 0.01503 | Regression loss: 0.03516 | Objectness loss: 0.00054 | RPN Regression loss: 0.00189 | Running loss: 0.05262\n","Epoch: 9 | Iteration: 32707 | Classification loss: 0.01047 | Regression loss: 0.01478 | Objectness loss: 0.00334 | RPN Regression loss: 0.00148 | Running loss: 0.03007\n","Epoch: 9 | Iteration: 32708 | Classification loss: 0.00842 | Regression loss: 0.02779 | Objectness loss: 0.00015 | RPN Regression loss: 0.00147 | Running loss: 0.03783\n","Epoch: 9 | Iteration: 32709 | Classification loss: 0.02024 | Regression loss: 0.01638 | Objectness loss: 0.00017 | RPN Regression loss: 0.00051 | Running loss: 0.03730\n","Epoch: 9 | Iteration: 32710 | Classification loss: 0.01610 | Regression loss: 0.02141 | Objectness loss: 0.00039 | RPN Regression loss: 0.00293 | Running loss: 0.04084\n","Epoch: 9 | Iteration: 32711 | Classification loss: 0.01989 | Regression loss: 0.02238 | Objectness loss: 0.00007 | RPN Regression loss: 0.00035 | Running loss: 0.04269\n","Epoch: 9 | Iteration: 32712 | Classification loss: 0.01801 | Regression loss: 0.03840 | Objectness loss: 0.00120 | RPN Regression loss: 0.00135 | Running loss: 0.05896\n","Epoch: 9 | Iteration: 32713 | Classification loss: 0.02638 | Regression loss: 0.02122 | Objectness loss: 0.01261 | RPN Regression loss: 0.00514 | Running loss: 0.06534\n","Epoch: 9 | Iteration: 32714 | Classification loss: 0.00699 | Regression loss: 0.01459 | Objectness loss: 0.00283 | RPN Regression loss: 0.00756 | Running loss: 0.03197\n","Epoch: 9 | Iteration: 32715 | Classification loss: 0.01887 | Regression loss: 0.02853 | Objectness loss: 0.00056 | RPN Regression loss: 0.00048 | Running loss: 0.04844\n","Epoch: 9 | Iteration: 32716 | Classification loss: 0.01873 | Regression loss: 0.02024 | Objectness loss: 0.00548 | RPN Regression loss: 0.00062 | Running loss: 0.04507\n","Epoch: 9 | Iteration: 32717 | Classification loss: 0.00546 | Regression loss: 0.01802 | Objectness loss: 0.00008 | RPN Regression loss: 0.00184 | Running loss: 0.02539\n","Epoch: 9 | Iteration: 32718 | Classification loss: 0.01046 | Regression loss: 0.01765 | Objectness loss: 0.00003 | RPN Regression loss: 0.00028 | Running loss: 0.02841\n","Epoch: 9 | Iteration: 32719 | Classification loss: 0.01819 | Regression loss: 0.05510 | Objectness loss: 0.00247 | RPN Regression loss: 0.00073 | Running loss: 0.07650\n","Epoch: 9 | Iteration: 32720 | Classification loss: 0.01690 | Regression loss: 0.02357 | Objectness loss: 0.00012 | RPN Regression loss: 0.00056 | Running loss: 0.04114\n","Epoch: 9 | Iteration: 32721 | Classification loss: 0.02039 | Regression loss: 0.03084 | Objectness loss: 0.00005 | RPN Regression loss: 0.00068 | Running loss: 0.05196\n","Epoch: 9 | Iteration: 32722 | Classification loss: 0.03021 | Regression loss: 0.04277 | Objectness loss: 0.00006 | RPN Regression loss: 0.00234 | Running loss: 0.07538\n","Epoch: 9 | Iteration: 32723 | Classification loss: 0.03027 | Regression loss: 0.01931 | Objectness loss: 0.00024 | RPN Regression loss: 0.00189 | Running loss: 0.05171\n","Epoch: 9 | Iteration: 32724 | Classification loss: 0.01082 | Regression loss: 0.01806 | Objectness loss: 0.00002 | RPN Regression loss: 0.00252 | Running loss: 0.03142\n","Epoch: 9 | Iteration: 32725 | Classification loss: 0.01047 | Regression loss: 0.01947 | Objectness loss: 0.00068 | RPN Regression loss: 0.00084 | Running loss: 0.03146\n","Epoch: 9 | Iteration: 32726 | Classification loss: 0.02479 | Regression loss: 0.01428 | Objectness loss: 0.00006 | RPN Regression loss: 0.00090 | Running loss: 0.04003\n","Epoch: 9 | Iteration: 32727 | Classification loss: 0.01580 | Regression loss: 0.01864 | Objectness loss: 0.00011 | RPN Regression loss: 0.00104 | Running loss: 0.03560\n","Epoch: 9 | Iteration: 32728 | Classification loss: 0.02321 | Regression loss: 0.02134 | Objectness loss: 0.00051 | RPN Regression loss: 0.00050 | Running loss: 0.04556\n","Epoch: 9 | Iteration: 32729 | Classification loss: 0.01641 | Regression loss: 0.02501 | Objectness loss: 0.00038 | RPN Regression loss: 0.00938 | Running loss: 0.05119\n","Epoch: 9 | Iteration: 32730 | Classification loss: 0.02884 | Regression loss: 0.03229 | Objectness loss: 0.00048 | RPN Regression loss: 0.00086 | Running loss: 0.06247\n","Epoch: 9 | Iteration: 32731 | Classification loss: 0.03315 | Regression loss: 0.04067 | Objectness loss: 0.00052 | RPN Regression loss: 0.00226 | Running loss: 0.07660\n","Epoch: 9 | Iteration: 32732 | Classification loss: 0.00884 | Regression loss: 0.02105 | Objectness loss: 0.00006 | RPN Regression loss: 0.00120 | Running loss: 0.03115\n","Epoch: 9 | Iteration: 32733 | Classification loss: 0.01601 | Regression loss: 0.02955 | Objectness loss: 0.00026 | RPN Regression loss: 0.00242 | Running loss: 0.04824\n","Epoch: 9 | Iteration: 32734 | Classification loss: 0.00899 | Regression loss: 0.02846 | Objectness loss: 0.00004 | RPN Regression loss: 0.00087 | Running loss: 0.03836\n","Epoch: 9 | Iteration: 32735 | Classification loss: 0.02953 | Regression loss: 0.03854 | Objectness loss: 0.00012 | RPN Regression loss: 0.00090 | Running loss: 0.06910\n","Epoch: 9 | Iteration: 32736 | Classification loss: 0.00741 | Regression loss: 0.01703 | Objectness loss: 0.00035 | RPN Regression loss: 0.00035 | Running loss: 0.02514\n","Epoch: 9 | Iteration: 32737 | Classification loss: 0.02596 | Regression loss: 0.03923 | Objectness loss: 0.00208 | RPN Regression loss: 0.00131 | Running loss: 0.06858\n","Epoch: 9 | Iteration: 32738 | Classification loss: 0.00998 | Regression loss: 0.01451 | Objectness loss: 0.00003 | RPN Regression loss: 0.00125 | Running loss: 0.02577\n","Epoch: 9 | Iteration: 32739 | Classification loss: 0.00968 | Regression loss: 0.01732 | Objectness loss: 0.00003 | RPN Regression loss: 0.00117 | Running loss: 0.02820\n","Epoch: 9 | Iteration: 32740 | Classification loss: 0.00959 | Regression loss: 0.01231 | Objectness loss: 0.00005 | RPN Regression loss: 0.00034 | Running loss: 0.02230\n","Epoch: 9 | Iteration: 32741 | Classification loss: 0.00797 | Regression loss: 0.01696 | Objectness loss: 0.00004 | RPN Regression loss: 0.00051 | Running loss: 0.02548\n","Epoch: 9 | Iteration: 32742 | Classification loss: 0.01191 | Regression loss: 0.03470 | Objectness loss: 0.00006 | RPN Regression loss: 0.00106 | Running loss: 0.04772\n","Epoch: 9 | Iteration: 32743 | Classification loss: 0.01167 | Regression loss: 0.01948 | Objectness loss: 0.00061 | RPN Regression loss: 0.00138 | Running loss: 0.03314\n","Epoch: 9 | Iteration: 32744 | Classification loss: 0.00787 | Regression loss: 0.02086 | Objectness loss: 0.00005 | RPN Regression loss: 0.00137 | Running loss: 0.03015\n","Epoch: 9 | Iteration: 32745 | Classification loss: 0.01750 | Regression loss: 0.01624 | Objectness loss: 0.00187 | RPN Regression loss: 0.00109 | Running loss: 0.03670\n","Epoch: 9 | Iteration: 32746 | Classification loss: 0.00665 | Regression loss: 0.01424 | Objectness loss: 0.00009 | RPN Regression loss: 0.00088 | Running loss: 0.02186\n","Epoch: 9 | Iteration: 32747 | Classification loss: 0.02317 | Regression loss: 0.02451 | Objectness loss: 0.00519 | RPN Regression loss: 0.00187 | Running loss: 0.05474\n","Epoch: 9 | Iteration: 32748 | Classification loss: 0.00929 | Regression loss: 0.02184 | Objectness loss: 0.00146 | RPN Regression loss: 0.00085 | Running loss: 0.03344\n","Epoch: 9 | Iteration: 32749 | Classification loss: 0.00670 | Regression loss: 0.01629 | Objectness loss: 0.00005 | RPN Regression loss: 0.00053 | Running loss: 0.02357\n","Epoch: 9 | Iteration: 32750 | Classification loss: 0.02396 | Regression loss: 0.02443 | Objectness loss: 0.00014 | RPN Regression loss: 0.00056 | Running loss: 0.04909\n","Epoch: 9 | Iteration: 32751 | Classification loss: 0.01553 | Regression loss: 0.01769 | Objectness loss: 0.00004 | RPN Regression loss: 0.00104 | Running loss: 0.03431\n","Epoch: 9 | Iteration: 32752 | Classification loss: 0.02874 | Regression loss: 0.02557 | Objectness loss: 0.00142 | RPN Regression loss: 0.00073 | Running loss: 0.05646\n","Epoch: 9 | Iteration: 32753 | Classification loss: 0.00677 | Regression loss: 0.02294 | Objectness loss: 0.00021 | RPN Regression loss: 0.00160 | Running loss: 0.03153\n","Epoch: 9 | Iteration: 32754 | Classification loss: 0.04038 | Regression loss: 0.02903 | Objectness loss: 0.00167 | RPN Regression loss: 0.00156 | Running loss: 0.07264\n","Epoch: 9 | Iteration: 32755 | Classification loss: 0.00960 | Regression loss: 0.01901 | Objectness loss: 0.00013 | RPN Regression loss: 0.00095 | Running loss: 0.02969\n","Epoch: 9 | Iteration: 32756 | Classification loss: 0.02699 | Regression loss: 0.01522 | Objectness loss: 0.00099 | RPN Regression loss: 0.00071 | Running loss: 0.04391\n","Epoch: 9 | Iteration: 32757 | Classification loss: 0.01866 | Regression loss: 0.03032 | Objectness loss: 0.00350 | RPN Regression loss: 0.00200 | Running loss: 0.05449\n","Epoch: 9 | Iteration: 32758 | Classification loss: 0.02743 | Regression loss: 0.02815 | Objectness loss: 0.00034 | RPN Regression loss: 0.00215 | Running loss: 0.05807\n","Epoch: 9 | Iteration: 32759 | Classification loss: 0.00948 | Regression loss: 0.01577 | Objectness loss: 0.00183 | RPN Regression loss: 0.00088 | Running loss: 0.02794\n","Epoch: 9 | Iteration: 32760 | Classification loss: 0.01112 | Regression loss: 0.02221 | Objectness loss: 0.00048 | RPN Regression loss: 0.00268 | Running loss: 0.03649\n","Epoch: 9 | Iteration: 32761 | Classification loss: 0.00968 | Regression loss: 0.01497 | Objectness loss: 0.00002 | RPN Regression loss: 0.00057 | Running loss: 0.02523\n","Epoch: 9 | Iteration: 32762 | Classification loss: 0.02330 | Regression loss: 0.02559 | Objectness loss: 0.00005 | RPN Regression loss: 0.00593 | Running loss: 0.05487\n","Epoch: 9 | Iteration: 32763 | Classification loss: 0.00849 | Regression loss: 0.02060 | Objectness loss: 0.00130 | RPN Regression loss: 0.00128 | Running loss: 0.03166\n","Epoch: 9 | Iteration: 32764 | Classification loss: 0.01272 | Regression loss: 0.01827 | Objectness loss: 0.00008 | RPN Regression loss: 0.00103 | Running loss: 0.03210\n","Epoch: 9 | Iteration: 32765 | Classification loss: 0.03838 | Regression loss: 0.02796 | Objectness loss: 0.01497 | RPN Regression loss: 0.00279 | Running loss: 0.08410\n","Epoch: 9 | Iteration: 32766 | Classification loss: 0.02907 | Regression loss: 0.02434 | Objectness loss: 0.00374 | RPN Regression loss: 0.00118 | Running loss: 0.05833\n","Epoch: 9 | Iteration: 32767 | Classification loss: 0.02438 | Regression loss: 0.01847 | Objectness loss: 0.00046 | RPN Regression loss: 0.00408 | Running loss: 0.04740\n","Epoch: 9 | Iteration: 32768 | Classification loss: 0.01880 | Regression loss: 0.02977 | Objectness loss: 0.00005 | RPN Regression loss: 0.00113 | Running loss: 0.04974\n","Epoch: 9 | Iteration: 32769 | Classification loss: 0.02791 | Regression loss: 0.03580 | Objectness loss: 0.00260 | RPN Regression loss: 0.00207 | Running loss: 0.06839\n","Epoch: 9 | Iteration: 32770 | Classification loss: 0.00861 | Regression loss: 0.01503 | Objectness loss: 0.00013 | RPN Regression loss: 0.00104 | Running loss: 0.02481\n","Epoch: 9 | Iteration: 32771 | Classification loss: 0.00999 | Regression loss: 0.01767 | Objectness loss: 0.00200 | RPN Regression loss: 0.00120 | Running loss: 0.03087\n","Epoch: 9 | Iteration: 32772 | Classification loss: 0.01504 | Regression loss: 0.03741 | Objectness loss: 0.00011 | RPN Regression loss: 0.00137 | Running loss: 0.05393\n","Epoch: 9 | Iteration: 32773 | Classification loss: 0.01995 | Regression loss: 0.03470 | Objectness loss: 0.00020 | RPN Regression loss: 0.00062 | Running loss: 0.05548\n","Epoch: 9 | Iteration: 32774 | Classification loss: 0.01833 | Regression loss: 0.01912 | Objectness loss: 0.00010 | RPN Regression loss: 0.00864 | Running loss: 0.04619\n","Epoch: 9 | Iteration: 32775 | Classification loss: 0.01151 | Regression loss: 0.01557 | Objectness loss: 0.00078 | RPN Regression loss: 0.00111 | Running loss: 0.02897\n","Epoch: 9 | Iteration: 32776 | Classification loss: 0.00674 | Regression loss: 0.02065 | Objectness loss: 0.00374 | RPN Regression loss: 0.00166 | Running loss: 0.03279\n","Epoch: 9 | Iteration: 32777 | Classification loss: 0.01161 | Regression loss: 0.01441 | Objectness loss: 0.00014 | RPN Regression loss: 0.00229 | Running loss: 0.02846\n","Epoch: 9 | Iteration: 32778 | Classification loss: 0.02404 | Regression loss: 0.02779 | Objectness loss: 0.00341 | RPN Regression loss: 0.00608 | Running loss: 0.06132\n","Epoch: 9 | Iteration: 32779 | Classification loss: 0.01043 | Regression loss: 0.02241 | Objectness loss: 0.00007 | RPN Regression loss: 0.00128 | Running loss: 0.03419\n","Epoch: 9 | Iteration: 32780 | Classification loss: 0.02361 | Regression loss: 0.02333 | Objectness loss: 0.00020 | RPN Regression loss: 0.00069 | Running loss: 0.04783\n","Epoch: 9 | Iteration: 32781 | Classification loss: 0.01632 | Regression loss: 0.03239 | Objectness loss: 0.00026 | RPN Regression loss: 0.00151 | Running loss: 0.05048\n","Epoch: 9 | Iteration: 32782 | Classification loss: 0.00563 | Regression loss: 0.02078 | Objectness loss: 0.00006 | RPN Regression loss: 0.00121 | Running loss: 0.02768\n","Epoch: 9 | Iteration: 32783 | Classification loss: 0.03700 | Regression loss: 0.03141 | Objectness loss: 0.00188 | RPN Regression loss: 0.00286 | Running loss: 0.07315\n","Epoch: 9 | Iteration: 32784 | Classification loss: 0.01415 | Regression loss: 0.03896 | Objectness loss: 0.00023 | RPN Regression loss: 0.00272 | Running loss: 0.05606\n","Epoch: 9 | Iteration: 32785 | Classification loss: 0.03309 | Regression loss: 0.04293 | Objectness loss: 0.00234 | RPN Regression loss: 0.00114 | Running loss: 0.07949\n","Epoch: 9 | Iteration: 32786 | Classification loss: 0.02569 | Regression loss: 0.01012 | Objectness loss: 0.00326 | RPN Regression loss: 0.00491 | Running loss: 0.04398\n","Epoch: 9 | Iteration: 32787 | Classification loss: 0.01398 | Regression loss: 0.02561 | Objectness loss: 0.00094 | RPN Regression loss: 0.00583 | Running loss: 0.04637\n","Epoch: 9 | Iteration: 32788 | Classification loss: 0.02346 | Regression loss: 0.02455 | Objectness loss: 0.00111 | RPN Regression loss: 0.00166 | Running loss: 0.05078\n","Epoch: 9 | Iteration: 32789 | Classification loss: 0.00990 | Regression loss: 0.01910 | Objectness loss: 0.00005 | RPN Regression loss: 0.00097 | Running loss: 0.03002\n","Epoch: 9 | Iteration: 32790 | Classification loss: 0.01695 | Regression loss: 0.03717 | Objectness loss: 0.00006 | RPN Regression loss: 0.00101 | Running loss: 0.05519\n","Epoch: 9 | Iteration: 32791 | Classification loss: 0.01207 | Regression loss: 0.02688 | Objectness loss: 0.00010 | RPN Regression loss: 0.00142 | Running loss: 0.04046\n","Epoch: 9 | Iteration: 32792 | Classification loss: 0.02549 | Regression loss: 0.01382 | Objectness loss: 0.00018 | RPN Regression loss: 0.00070 | Running loss: 0.04018\n","Epoch: 9 | Iteration: 32793 | Classification loss: 0.01398 | Regression loss: 0.02631 | Objectness loss: 0.00022 | RPN Regression loss: 0.00062 | Running loss: 0.04113\n","Epoch: 9 | Iteration: 32794 | Classification loss: 0.01309 | Regression loss: 0.02932 | Objectness loss: 0.00001 | RPN Regression loss: 0.00063 | Running loss: 0.04305\n","Epoch: 9 | Iteration: 32795 | Classification loss: 0.01198 | Regression loss: 0.02239 | Objectness loss: 0.00001 | RPN Regression loss: 0.00062 | Running loss: 0.03500\n","Epoch: 9 | Iteration: 32796 | Classification loss: 0.01198 | Regression loss: 0.02043 | Objectness loss: 0.00009 | RPN Regression loss: 0.00105 | Running loss: 0.03355\n","Epoch: 9 | Iteration: 32797 | Classification loss: 0.01152 | Regression loss: 0.03830 | Objectness loss: 0.00008 | RPN Regression loss: 0.00174 | Running loss: 0.05163\n","Epoch: 9 | Iteration: 32798 | Classification loss: 0.00674 | Regression loss: 0.02239 | Objectness loss: 0.00001 | RPN Regression loss: 0.00140 | Running loss: 0.03055\n","Epoch: 9 | Iteration: 32799 | Classification loss: 0.01010 | Regression loss: 0.02619 | Objectness loss: 0.00013 | RPN Regression loss: 0.00333 | Running loss: 0.03974\n","Epoch: 9 | Iteration: 32800 | Classification loss: 0.02257 | Regression loss: 0.02440 | Objectness loss: 0.00037 | RPN Regression loss: 0.00130 | Running loss: 0.04864\n","Epoch: 9 | Iteration: 32801 | Classification loss: 0.01367 | Regression loss: 0.02540 | Objectness loss: 0.00002 | RPN Regression loss: 0.00053 | Running loss: 0.03961\n","Epoch: 9 | Iteration: 32802 | Classification loss: 0.00907 | Regression loss: 0.02300 | Objectness loss: 0.00096 | RPN Regression loss: 0.00161 | Running loss: 0.03464\n","Epoch: 9 | Iteration: 32803 | Classification loss: 0.06565 | Regression loss: 0.04774 | Objectness loss: 0.00846 | RPN Regression loss: 0.00262 | Running loss: 0.12447\n","Epoch: 9 | Iteration: 32804 | Classification loss: 0.02434 | Regression loss: 0.01634 | Objectness loss: 0.00039 | RPN Regression loss: 0.00121 | Running loss: 0.04228\n","Epoch: 9 | Iteration: 32805 | Classification loss: 0.02357 | Regression loss: 0.02737 | Objectness loss: 0.00053 | RPN Regression loss: 0.00103 | Running loss: 0.05250\n","Epoch: 9 | Iteration: 32806 | Classification loss: 0.01390 | Regression loss: 0.02459 | Objectness loss: 0.00036 | RPN Regression loss: 0.00074 | Running loss: 0.03959\n","Epoch: 9 | Iteration: 32807 | Classification loss: 0.00835 | Regression loss: 0.03140 | Objectness loss: 0.00006 | RPN Regression loss: 0.00412 | Running loss: 0.04393\n","Epoch: 9 | Iteration: 32808 | Classification loss: 0.01990 | Regression loss: 0.02803 | Objectness loss: 0.00170 | RPN Regression loss: 0.00413 | Running loss: 0.05377\n","Epoch: 9 | Iteration: 32809 | Classification loss: 0.01026 | Regression loss: 0.02618 | Objectness loss: 0.00122 | RPN Regression loss: 0.00024 | Running loss: 0.03789\n","Epoch: 9 | Iteration: 32810 | Classification loss: 0.01063 | Regression loss: 0.02404 | Objectness loss: 0.00023 | RPN Regression loss: 0.00308 | Running loss: 0.03798\n","Epoch: 9 | Iteration: 32811 | Classification loss: 0.02013 | Regression loss: 0.03750 | Objectness loss: 0.00163 | RPN Regression loss: 0.00339 | Running loss: 0.06266\n","Epoch: 9 | Iteration: 32812 | Classification loss: 0.02741 | Regression loss: 0.05971 | Objectness loss: 0.00157 | RPN Regression loss: 0.00324 | Running loss: 0.09192\n","Epoch: 9 | Iteration: 32813 | Classification loss: 0.01550 | Regression loss: 0.02032 | Objectness loss: 0.00001 | RPN Regression loss: 0.00092 | Running loss: 0.03675\n","Epoch: 9 | Iteration: 32814 | Classification loss: 0.01361 | Regression loss: 0.01106 | Objectness loss: 0.00008 | RPN Regression loss: 0.00071 | Running loss: 0.02546\n","Epoch: 9 | Iteration: 32815 | Classification loss: 0.01164 | Regression loss: 0.01976 | Objectness loss: 0.00238 | RPN Regression loss: 0.00152 | Running loss: 0.03530\n","Epoch: 9 | Iteration: 32816 | Classification loss: 0.01259 | Regression loss: 0.03337 | Objectness loss: 0.00013 | RPN Regression loss: 0.00119 | Running loss: 0.04728\n","Epoch: 9 | Iteration: 32817 | Classification loss: 0.01184 | Regression loss: 0.01829 | Objectness loss: 0.00054 | RPN Regression loss: 0.00290 | Running loss: 0.03357\n","Epoch: 9 | Iteration: 32818 | Classification loss: 0.02350 | Regression loss: 0.01559 | Objectness loss: 0.00003 | RPN Regression loss: 0.00074 | Running loss: 0.03986\n","Epoch: 9 | Iteration: 32819 | Classification loss: 0.00838 | Regression loss: 0.01750 | Objectness loss: 0.00010 | RPN Regression loss: 0.00137 | Running loss: 0.02735\n","Epoch: 9 | Iteration: 32820 | Classification loss: 0.02599 | Regression loss: 0.02181 | Objectness loss: 0.00042 | RPN Regression loss: 0.00086 | Running loss: 0.04907\n","Epoch: 9 | Iteration: 32821 | Classification loss: 0.01014 | Regression loss: 0.02896 | Objectness loss: 0.00003 | RPN Regression loss: 0.00054 | Running loss: 0.03968\n","Epoch: 9 | Iteration: 32822 | Classification loss: 0.02797 | Regression loss: 0.03561 | Objectness loss: 0.00403 | RPN Regression loss: 0.00145 | Running loss: 0.06906\n","Epoch: 9 | Iteration: 32823 | Classification loss: 0.00661 | Regression loss: 0.01771 | Objectness loss: 0.00013 | RPN Regression loss: 0.00092 | Running loss: 0.02537\n","Epoch: 9 | Iteration: 32824 | Classification loss: 0.01157 | Regression loss: 0.02920 | Objectness loss: 0.00036 | RPN Regression loss: 0.00109 | Running loss: 0.04222\n","Epoch: 9 | Iteration: 32825 | Classification loss: 0.00731 | Regression loss: 0.01488 | Objectness loss: 0.00574 | RPN Regression loss: 0.00077 | Running loss: 0.02871\n","Epoch: 9 | Iteration: 32826 | Classification loss: 0.01140 | Regression loss: 0.01985 | Objectness loss: 0.00007 | RPN Regression loss: 0.00161 | Running loss: 0.03293\n","Epoch: 9 | Iteration: 32827 | Classification loss: 0.01188 | Regression loss: 0.02720 | Objectness loss: 0.00338 | RPN Regression loss: 0.01085 | Running loss: 0.05331\n","Epoch: 9 | Iteration: 32828 | Classification loss: 0.05685 | Regression loss: 0.02494 | Objectness loss: 0.01178 | RPN Regression loss: 0.00348 | Running loss: 0.09705\n","Epoch: 9 | Iteration: 32829 | Classification loss: 0.01626 | Regression loss: 0.01645 | Objectness loss: 0.00014 | RPN Regression loss: 0.00050 | Running loss: 0.03335\n","Epoch: 9 | Iteration: 32830 | Classification loss: 0.03809 | Regression loss: 0.04122 | Objectness loss: 0.00012 | RPN Regression loss: 0.00140 | Running loss: 0.08083\n","Epoch: 9 | Iteration: 32831 | Classification loss: 0.01136 | Regression loss: 0.02821 | Objectness loss: 0.00007 | RPN Regression loss: 0.00162 | Running loss: 0.04126\n","Epoch: 9 | Iteration: 32832 | Classification loss: 0.03447 | Regression loss: 0.03784 | Objectness loss: 0.00373 | RPN Regression loss: 0.00174 | Running loss: 0.07778\n","Epoch: 9 | Iteration: 32833 | Classification loss: 0.01361 | Regression loss: 0.02730 | Objectness loss: 0.00059 | RPN Regression loss: 0.00250 | Running loss: 0.04401\n","Epoch: 9 | Iteration: 32834 | Classification loss: 0.02252 | Regression loss: 0.01934 | Objectness loss: 0.00389 | RPN Regression loss: 0.00123 | Running loss: 0.04698\n","Epoch: 9 | Iteration: 32835 | Classification loss: 0.01556 | Regression loss: 0.02207 | Objectness loss: 0.00014 | RPN Regression loss: 0.00286 | Running loss: 0.04063\n","Epoch: 9 | Iteration: 32836 | Classification loss: 0.00948 | Regression loss: 0.01367 | Objectness loss: 0.00013 | RPN Regression loss: 0.00355 | Running loss: 0.02682\n","Epoch: 9 | Iteration: 32837 | Classification loss: 0.01028 | Regression loss: 0.03821 | Objectness loss: 0.00007 | RPN Regression loss: 0.00174 | Running loss: 0.05030\n","Epoch: 9 | Iteration: 32838 | Classification loss: 0.00968 | Regression loss: 0.01277 | Objectness loss: 0.00011 | RPN Regression loss: 0.00067 | Running loss: 0.02323\n","Epoch: 9 | Iteration: 32839 | Classification loss: 0.04646 | Regression loss: 0.04955 | Objectness loss: 0.00024 | RPN Regression loss: 0.00317 | Running loss: 0.09943\n","Epoch: 9 | Iteration: 32840 | Classification loss: 0.01696 | Regression loss: 0.01074 | Objectness loss: 0.00092 | RPN Regression loss: 0.00081 | Running loss: 0.02942\n","Epoch: 9 | Iteration: 32841 | Classification loss: 0.02148 | Regression loss: 0.03409 | Objectness loss: 0.00068 | RPN Regression loss: 0.00164 | Running loss: 0.05789\n","Epoch: 9 | Iteration: 32842 | Classification loss: 0.00670 | Regression loss: 0.01842 | Objectness loss: 0.00006 | RPN Regression loss: 0.00331 | Running loss: 0.02848\n","Epoch: 9 | Iteration: 32843 | Classification loss: 0.02320 | Regression loss: 0.02717 | Objectness loss: 0.00163 | RPN Regression loss: 0.00064 | Running loss: 0.05265\n","Epoch: 9 | Iteration: 32844 | Classification loss: 0.01644 | Regression loss: 0.01321 | Objectness loss: 0.00028 | RPN Regression loss: 0.00179 | Running loss: 0.03172\n","Epoch: 9 | Iteration: 32845 | Classification loss: 0.02805 | Regression loss: 0.02168 | Objectness loss: 0.00094 | RPN Regression loss: 0.00302 | Running loss: 0.05369\n","Epoch: 9 | Iteration: 32846 | Classification loss: 0.02407 | Regression loss: 0.03810 | Objectness loss: 0.00258 | RPN Regression loss: 0.00120 | Running loss: 0.06594\n","Epoch: 9 | Iteration: 32847 | Classification loss: 0.02486 | Regression loss: 0.05035 | Objectness loss: 0.00180 | RPN Regression loss: 0.00218 | Running loss: 0.07918\n","Epoch: 9 | Iteration: 32848 | Classification loss: 0.01351 | Regression loss: 0.03252 | Objectness loss: 0.00004 | RPN Regression loss: 0.00082 | Running loss: 0.04689\n","Epoch: 9 | Iteration: 32849 | Classification loss: 0.03149 | Regression loss: 0.04115 | Objectness loss: 0.00010 | RPN Regression loss: 0.00253 | Running loss: 0.07527\n","Epoch: 9 | Iteration: 32850 | Classification loss: 0.00924 | Regression loss: 0.01577 | Objectness loss: 0.00100 | RPN Regression loss: 0.00173 | Running loss: 0.02774\n","Epoch: 9 | Iteration: 32851 | Classification loss: 0.00701 | Regression loss: 0.04122 | Objectness loss: 0.00498 | RPN Regression loss: 0.00120 | Running loss: 0.05441\n","Epoch: 9 | Iteration: 32852 | Classification loss: 0.04419 | Regression loss: 0.03257 | Objectness loss: 0.00166 | RPN Regression loss: 0.00124 | Running loss: 0.07966\n","Epoch: 9 | Iteration: 32853 | Classification loss: 0.01646 | Regression loss: 0.02968 | Objectness loss: 0.00115 | RPN Regression loss: 0.00061 | Running loss: 0.04790\n","Epoch: 9 | Iteration: 32854 | Classification loss: 0.02463 | Regression loss: 0.02074 | Objectness loss: 0.00006 | RPN Regression loss: 0.00079 | Running loss: 0.04621\n","Epoch: 9 | Iteration: 32855 | Classification loss: 0.00680 | Regression loss: 0.02268 | Objectness loss: 0.00040 | RPN Regression loss: 0.00105 | Running loss: 0.03093\n","Epoch: 9 | Iteration: 32856 | Classification loss: 0.01357 | Regression loss: 0.02403 | Objectness loss: 0.00083 | RPN Regression loss: 0.00159 | Running loss: 0.04001\n","Epoch: 9 | Iteration: 32857 | Classification loss: 0.02272 | Regression loss: 0.01440 | Objectness loss: 0.00334 | RPN Regression loss: 0.00213 | Running loss: 0.04258\n","Epoch: 9 | Iteration: 32858 | Classification loss: 0.00751 | Regression loss: 0.01078 | Objectness loss: 0.00001 | RPN Regression loss: 0.00117 | Running loss: 0.01947\n","Epoch: 9 | Iteration: 32859 | Classification loss: 0.00805 | Regression loss: 0.01874 | Objectness loss: 0.00491 | RPN Regression loss: 0.00497 | Running loss: 0.03668\n","Epoch: 9 | Iteration: 32860 | Classification loss: 0.02221 | Regression loss: 0.04278 | Objectness loss: 0.00008 | RPN Regression loss: 0.00049 | Running loss: 0.06556\n","Epoch: 9 | Iteration: 32861 | Classification loss: 0.01041 | Regression loss: 0.02916 | Objectness loss: 0.00014 | RPN Regression loss: 0.00396 | Running loss: 0.04368\n","Epoch: 9 | Iteration: 32862 | Classification loss: 0.01082 | Regression loss: 0.01359 | Objectness loss: 0.00010 | RPN Regression loss: 0.00124 | Running loss: 0.02576\n","Epoch: 9 | Iteration: 32863 | Classification loss: 0.01079 | Regression loss: 0.01919 | Objectness loss: 0.00019 | RPN Regression loss: 0.00143 | Running loss: 0.03160\n","Epoch: 9 | Iteration: 32864 | Classification loss: 0.02317 | Regression loss: 0.02458 | Objectness loss: 0.00031 | RPN Regression loss: 0.00440 | Running loss: 0.05246\n","Epoch: 9 | Iteration: 32865 | Classification loss: 0.00945 | Regression loss: 0.02364 | Objectness loss: 0.00008 | RPN Regression loss: 0.00063 | Running loss: 0.03380\n","Epoch: 9 | Iteration: 32866 | Classification loss: 0.00787 | Regression loss: 0.01678 | Objectness loss: 0.00009 | RPN Regression loss: 0.00178 | Running loss: 0.02652\n","Epoch: 9 | Iteration: 32867 | Classification loss: 0.03413 | Regression loss: 0.04270 | Objectness loss: 0.00427 | RPN Regression loss: 0.00255 | Running loss: 0.08365\n","Epoch: 9 | Iteration: 32868 | Classification loss: 0.03773 | Regression loss: 0.02143 | Objectness loss: 0.00008 | RPN Regression loss: 0.00213 | Running loss: 0.06137\n","Epoch: 9 | Iteration: 32869 | Classification loss: 0.01530 | Regression loss: 0.02202 | Objectness loss: 0.00012 | RPN Regression loss: 0.00070 | Running loss: 0.03814\n","Epoch: 9 | Iteration: 32870 | Classification loss: 0.00705 | Regression loss: 0.01646 | Objectness loss: 0.00016 | RPN Regression loss: 0.00049 | Running loss: 0.02416\n","Epoch: 9 | Iteration: 32871 | Classification loss: 0.00700 | Regression loss: 0.02127 | Objectness loss: 0.00043 | RPN Regression loss: 0.00099 | Running loss: 0.02970\n","Epoch: 9 | Iteration: 32872 | Classification loss: 0.03374 | Regression loss: 0.04627 | Objectness loss: 0.00019 | RPN Regression loss: 0.00138 | Running loss: 0.08158\n","Epoch: 9 | Iteration: 32873 | Classification loss: 0.01583 | Regression loss: 0.02598 | Objectness loss: 0.00002 | RPN Regression loss: 0.00075 | Running loss: 0.04259\n","Epoch: 9 | Iteration: 32874 | Classification loss: 0.02784 | Regression loss: 0.02657 | Objectness loss: 0.00010 | RPN Regression loss: 0.00114 | Running loss: 0.05565\n","Epoch: 9 | Iteration: 32875 | Classification loss: 0.03606 | Regression loss: 0.04928 | Objectness loss: 0.00812 | RPN Regression loss: 0.00233 | Running loss: 0.09578\n","Epoch: 9 | Iteration: 32876 | Classification loss: 0.03046 | Regression loss: 0.02449 | Objectness loss: 0.00043 | RPN Regression loss: 0.00168 | Running loss: 0.05707\n","Epoch: 9 | Iteration: 32877 | Classification loss: 0.00724 | Regression loss: 0.01191 | Objectness loss: 0.00015 | RPN Regression loss: 0.00218 | Running loss: 0.02147\n","Epoch: 9 | Iteration: 32878 | Classification loss: 0.01988 | Regression loss: 0.02073 | Objectness loss: 0.00281 | RPN Regression loss: 0.00148 | Running loss: 0.04490\n","Epoch: 9 | Iteration: 32879 | Classification loss: 0.00781 | Regression loss: 0.01640 | Objectness loss: 0.00014 | RPN Regression loss: 0.00123 | Running loss: 0.02558\n","Epoch: 9 | Iteration: 32880 | Classification loss: 0.00769 | Regression loss: 0.02074 | Objectness loss: 0.00269 | RPN Regression loss: 0.00078 | Running loss: 0.03191\n","Epoch: 9 | Iteration: 32881 | Classification loss: 0.00504 | Regression loss: 0.01146 | Objectness loss: 0.00047 | RPN Regression loss: 0.00257 | Running loss: 0.01954\n","Epoch: 9 | Iteration: 32882 | Classification loss: 0.05062 | Regression loss: 0.04985 | Objectness loss: 0.00025 | RPN Regression loss: 0.00157 | Running loss: 0.10229\n","Epoch: 9 | Iteration: 32883 | Classification loss: 0.02252 | Regression loss: 0.02393 | Objectness loss: 0.00002 | RPN Regression loss: 0.00120 | Running loss: 0.04767\n","Epoch: 9 | Iteration: 32884 | Classification loss: 0.01324 | Regression loss: 0.01522 | Objectness loss: 0.00018 | RPN Regression loss: 0.00155 | Running loss: 0.03019\n","Epoch: 9 | Iteration: 32885 | Classification loss: 0.03334 | Regression loss: 0.03165 | Objectness loss: 0.00150 | RPN Regression loss: 0.00554 | Running loss: 0.07203\n","Epoch: 9 | Iteration: 32886 | Classification loss: 0.00783 | Regression loss: 0.01283 | Objectness loss: 0.00025 | RPN Regression loss: 0.00293 | Running loss: 0.02384\n","Epoch: 9 | Iteration: 32887 | Classification loss: 0.03998 | Regression loss: 0.02857 | Objectness loss: 0.00042 | RPN Regression loss: 0.00137 | Running loss: 0.07035\n","Epoch: 9 | Iteration: 32888 | Classification loss: 0.02252 | Regression loss: 0.02396 | Objectness loss: 0.00004 | RPN Regression loss: 0.00110 | Running loss: 0.04762\n","Epoch: 9 | Iteration: 32889 | Classification loss: 0.00800 | Regression loss: 0.01788 | Objectness loss: 0.00037 | RPN Regression loss: 0.00075 | Running loss: 0.02699\n","Epoch: 9 | Iteration: 32890 | Classification loss: 0.01335 | Regression loss: 0.03165 | Objectness loss: 0.00010 | RPN Regression loss: 0.00063 | Running loss: 0.04573\n","Epoch: 9 | Iteration: 32891 | Classification loss: 0.03333 | Regression loss: 0.02576 | Objectness loss: 0.00325 | RPN Regression loss: 0.00153 | Running loss: 0.06388\n","Epoch: 9 | Iteration: 32892 | Classification loss: 0.00945 | Regression loss: 0.01911 | Objectness loss: 0.00003 | RPN Regression loss: 0.00037 | Running loss: 0.02896\n","Epoch: 9 | Iteration: 32893 | Classification loss: 0.01019 | Regression loss: 0.01174 | Objectness loss: 0.00003 | RPN Regression loss: 0.00061 | Running loss: 0.02258\n","Epoch: 9 | Iteration: 32894 | Classification loss: 0.00768 | Regression loss: 0.02206 | Objectness loss: 0.01019 | RPN Regression loss: 0.00162 | Running loss: 0.04154\n","Epoch: 9 | Iteration: 32895 | Classification loss: 0.00854 | Regression loss: 0.01495 | Objectness loss: 0.00002 | RPN Regression loss: 0.00241 | Running loss: 0.02592\n","Epoch: 9 | Iteration: 32896 | Classification loss: 0.00982 | Regression loss: 0.02120 | Objectness loss: 0.00006 | RPN Regression loss: 0.00212 | Running loss: 0.03320\n","Epoch: 9 | Iteration: 32897 | Classification loss: 0.00908 | Regression loss: 0.01272 | Objectness loss: 0.00010 | RPN Regression loss: 0.00140 | Running loss: 0.02330\n","Epoch: 9 | Iteration: 32898 | Classification loss: 0.00758 | Regression loss: 0.01964 | Objectness loss: 0.00003 | RPN Regression loss: 0.00149 | Running loss: 0.02874\n","Epoch: 9 | Iteration: 32899 | Classification loss: 0.02116 | Regression loss: 0.01834 | Objectness loss: 0.00003 | RPN Regression loss: 0.00075 | Running loss: 0.04028\n","Epoch: 9 | Iteration: 32900 | Classification loss: 0.00917 | Regression loss: 0.02495 | Objectness loss: 0.00024 | RPN Regression loss: 0.00100 | Running loss: 0.03535\n","Epoch: 9 | Iteration: 32901 | Classification loss: 0.02293 | Regression loss: 0.01961 | Objectness loss: 0.00062 | RPN Regression loss: 0.00111 | Running loss: 0.04428\n","Epoch: 9 | Iteration: 32902 | Classification loss: 0.01093 | Regression loss: 0.01980 | Objectness loss: 0.00013 | RPN Regression loss: 0.00172 | Running loss: 0.03258\n","Epoch: 9 | Iteration: 32903 | Classification loss: 0.01856 | Regression loss: 0.02469 | Objectness loss: 0.00056 | RPN Regression loss: 0.00117 | Running loss: 0.04499\n","Epoch: 9 | Iteration: 32904 | Classification loss: 0.01012 | Regression loss: 0.01774 | Objectness loss: 0.00038 | RPN Regression loss: 0.00122 | Running loss: 0.02946\n","Epoch: 9 | Iteration: 32905 | Classification loss: 0.02307 | Regression loss: 0.02233 | Objectness loss: 0.00853 | RPN Regression loss: 0.00171 | Running loss: 0.05564\n","Epoch: 9 | Iteration: 32906 | Classification loss: 0.01612 | Regression loss: 0.03931 | Objectness loss: 0.00008 | RPN Regression loss: 0.00216 | Running loss: 0.05766\n","Epoch: 9 | Iteration: 32907 | Classification loss: 0.01083 | Regression loss: 0.01996 | Objectness loss: 0.00103 | RPN Regression loss: 0.00025 | Running loss: 0.03207\n","Epoch: 9 | Iteration: 32908 | Classification loss: 0.02361 | Regression loss: 0.01909 | Objectness loss: 0.00110 | RPN Regression loss: 0.00062 | Running loss: 0.04443\n","Epoch: 9 | Iteration: 32909 | Classification loss: 0.01955 | Regression loss: 0.02554 | Objectness loss: 0.00086 | RPN Regression loss: 0.00327 | Running loss: 0.04923\n","Epoch: 9 | Iteration: 32910 | Classification loss: 0.02753 | Regression loss: 0.02279 | Objectness loss: 0.00040 | RPN Regression loss: 0.00080 | Running loss: 0.05151\n","Epoch: 9 | Iteration: 32911 | Classification loss: 0.00926 | Regression loss: 0.02330 | Objectness loss: 0.00007 | RPN Regression loss: 0.00183 | Running loss: 0.03446\n","Epoch: 9 | Iteration: 32912 | Classification loss: 0.00870 | Regression loss: 0.01851 | Objectness loss: 0.00003 | RPN Regression loss: 0.00034 | Running loss: 0.02758\n","Epoch: 9 | Iteration: 32913 | Classification loss: 0.02189 | Regression loss: 0.02365 | Objectness loss: 0.00021 | RPN Regression loss: 0.00099 | Running loss: 0.04674\n","Epoch: 9 | Iteration: 32914 | Classification loss: 0.00704 | Regression loss: 0.01885 | Objectness loss: 0.00214 | RPN Regression loss: 0.00291 | Running loss: 0.03093\n","Epoch: 9 | Iteration: 32915 | Classification loss: 0.02419 | Regression loss: 0.02288 | Objectness loss: 0.00007 | RPN Regression loss: 0.00244 | Running loss: 0.04957\n","Epoch: 9 | Iteration: 32916 | Classification loss: 0.01957 | Regression loss: 0.01030 | Objectness loss: 0.00121 | RPN Regression loss: 0.00093 | Running loss: 0.03202\n","Epoch: 9 | Iteration: 32917 | Classification loss: 0.00796 | Regression loss: 0.01719 | Objectness loss: 0.00010 | RPN Regression loss: 0.00054 | Running loss: 0.02578\n","Epoch: 9 | Iteration: 32918 | Classification loss: 0.01707 | Regression loss: 0.01910 | Objectness loss: 0.00030 | RPN Regression loss: 0.00137 | Running loss: 0.03784\n","Epoch: 9 | Iteration: 32919 | Classification loss: 0.01926 | Regression loss: 0.02571 | Objectness loss: 0.00142 | RPN Regression loss: 0.00241 | Running loss: 0.04880\n","Epoch: 9 | Iteration: 32920 | Classification loss: 0.01581 | Regression loss: 0.01565 | Objectness loss: 0.00016 | RPN Regression loss: 0.00442 | Running loss: 0.03604\n","Epoch: 9 | Iteration: 32921 | Classification loss: 0.01108 | Regression loss: 0.01979 | Objectness loss: 0.00011 | RPN Regression loss: 0.00070 | Running loss: 0.03167\n","Epoch: 9 | Iteration: 32922 | Classification loss: 0.03253 | Regression loss: 0.02173 | Objectness loss: 0.00570 | RPN Regression loss: 0.00073 | Running loss: 0.06069\n","Epoch: 9 | Iteration: 32923 | Classification loss: 0.01054 | Regression loss: 0.02041 | Objectness loss: 0.00002 | RPN Regression loss: 0.00034 | Running loss: 0.03130\n","Epoch: 9 | Iteration: 32924 | Classification loss: 0.00624 | Regression loss: 0.01447 | Objectness loss: 0.00038 | RPN Regression loss: 0.00052 | Running loss: 0.02162\n","Epoch: 9 | Iteration: 32925 | Classification loss: 0.01199 | Regression loss: 0.03017 | Objectness loss: 0.00034 | RPN Regression loss: 0.00160 | Running loss: 0.04410\n","Epoch: 9 | Iteration: 32926 | Classification loss: 0.02139 | Regression loss: 0.03321 | Objectness loss: 0.00007 | RPN Regression loss: 0.00056 | Running loss: 0.05524\n","Epoch: 9 | Iteration: 32927 | Classification loss: 0.04172 | Regression loss: 0.05594 | Objectness loss: 0.00103 | RPN Regression loss: 0.00123 | Running loss: 0.09992\n","Epoch: 9 | Iteration: 32928 | Classification loss: 0.01089 | Regression loss: 0.01835 | Objectness loss: 0.00204 | RPN Regression loss: 0.00066 | Running loss: 0.03194\n","Epoch: 9 | Iteration: 32929 | Classification loss: 0.07121 | Regression loss: 0.02348 | Objectness loss: 0.00519 | RPN Regression loss: 0.00213 | Running loss: 0.10201\n","Epoch: 9 | Iteration: 32930 | Classification loss: 0.02447 | Regression loss: 0.01775 | Objectness loss: 0.00191 | RPN Regression loss: 0.00085 | Running loss: 0.04499\n","Epoch: 9 | Iteration: 32931 | Classification loss: 0.02612 | Regression loss: 0.03430 | Objectness loss: 0.00060 | RPN Regression loss: 0.00132 | Running loss: 0.06235\n","Epoch: 9 | Iteration: 32932 | Classification loss: 0.02133 | Regression loss: 0.01719 | Objectness loss: 0.00016 | RPN Regression loss: 0.00052 | Running loss: 0.03921\n","Epoch: 9 | Iteration: 32933 | Classification loss: 0.02851 | Regression loss: 0.06123 | Objectness loss: 0.00073 | RPN Regression loss: 0.00375 | Running loss: 0.09422\n","Epoch: 9 | Iteration: 32934 | Classification loss: 0.02933 | Regression loss: 0.02114 | Objectness loss: 0.00008 | RPN Regression loss: 0.00118 | Running loss: 0.05173\n","Epoch: 9 | Iteration: 32935 | Classification loss: 0.00619 | Regression loss: 0.01423 | Objectness loss: 0.00015 | RPN Regression loss: 0.00111 | Running loss: 0.02168\n","Epoch: 9 | Iteration: 32936 | Classification loss: 0.01398 | Regression loss: 0.01136 | Objectness loss: 0.00567 | RPN Regression loss: 0.00070 | Running loss: 0.03172\n","Epoch: 9 | Iteration: 32937 | Classification loss: 0.02225 | Regression loss: 0.03995 | Objectness loss: 0.01038 | RPN Regression loss: 0.00143 | Running loss: 0.07400\n","Epoch: 9 | Iteration: 32938 | Classification loss: 0.01206 | Regression loss: 0.01726 | Objectness loss: 0.00015 | RPN Regression loss: 0.00071 | Running loss: 0.03018\n","Epoch: 9 | Iteration: 32939 | Classification loss: 0.02814 | Regression loss: 0.03284 | Objectness loss: 0.00031 | RPN Regression loss: 0.00089 | Running loss: 0.06218\n","Epoch: 9 | Iteration: 32940 | Classification loss: 0.01787 | Regression loss: 0.01982 | Objectness loss: 0.00019 | RPN Regression loss: 0.00255 | Running loss: 0.04042\n","Epoch: 9 | Iteration: 32941 | Classification loss: 0.01311 | Regression loss: 0.02264 | Objectness loss: 0.00008 | RPN Regression loss: 0.00103 | Running loss: 0.03685\n","Epoch: 9 | Iteration: 32942 | Classification loss: 0.02263 | Regression loss: 0.02799 | Objectness loss: 0.00088 | RPN Regression loss: 0.00127 | Running loss: 0.05277\n","Epoch: 9 | Iteration: 32943 | Classification loss: 0.01112 | Regression loss: 0.02206 | Objectness loss: 0.00022 | RPN Regression loss: 0.00114 | Running loss: 0.03454\n","Epoch: 9 | Iteration: 32944 | Classification loss: 0.01929 | Regression loss: 0.03469 | Objectness loss: 0.00189 | RPN Regression loss: 0.00292 | Running loss: 0.05879\n","Epoch: 9 | Iteration: 32945 | Classification loss: 0.02500 | Regression loss: 0.01615 | Objectness loss: 0.00011 | RPN Regression loss: 0.00108 | Running loss: 0.04233\n","Epoch: 9 | Iteration: 32946 | Classification loss: 0.01232 | Regression loss: 0.02775 | Objectness loss: 0.00085 | RPN Regression loss: 0.00200 | Running loss: 0.04291\n","Epoch: 9 | Iteration: 32947 | Classification loss: 0.00926 | Regression loss: 0.02814 | Objectness loss: 0.00006 | RPN Regression loss: 0.00070 | Running loss: 0.03816\n","Epoch: 9 | Iteration: 32948 | Classification loss: 0.01889 | Regression loss: 0.02190 | Objectness loss: 0.00011 | RPN Regression loss: 0.00043 | Running loss: 0.04133\n","Epoch: 9 | Iteration: 32949 | Classification loss: 0.02136 | Regression loss: 0.02194 | Objectness loss: 0.00085 | RPN Regression loss: 0.00073 | Running loss: 0.04489\n","Epoch: 9 | Iteration: 32950 | Classification loss: 0.01289 | Regression loss: 0.02169 | Objectness loss: 0.00002 | RPN Regression loss: 0.00068 | Running loss: 0.03528\n","Epoch: 9 | Iteration: 32951 | Classification loss: 0.01306 | Regression loss: 0.03278 | Objectness loss: 0.00090 | RPN Regression loss: 0.00106 | Running loss: 0.04779\n","Epoch: 9 | Iteration: 32952 | Classification loss: 0.01401 | Regression loss: 0.02260 | Objectness loss: 0.00009 | RPN Regression loss: 0.00101 | Running loss: 0.03771\n","Epoch: 9 | Iteration: 32953 | Classification loss: 0.00715 | Regression loss: 0.03178 | Objectness loss: 0.00621 | RPN Regression loss: 0.00329 | Running loss: 0.04843\n","Epoch: 9 | Iteration: 32954 | Classification loss: 0.01934 | Regression loss: 0.01335 | Objectness loss: 0.00013 | RPN Regression loss: 0.00100 | Running loss: 0.03382\n","Epoch: 9 | Iteration: 32955 | Classification loss: 0.00989 | Regression loss: 0.01179 | Objectness loss: 0.00011 | RPN Regression loss: 0.00197 | Running loss: 0.02376\n","Epoch: 9 | Iteration: 32956 | Classification loss: 0.00721 | Regression loss: 0.02562 | Objectness loss: 0.00067 | RPN Regression loss: 0.00065 | Running loss: 0.03414\n","Epoch: 9 | Iteration: 32957 | Classification loss: 0.00531 | Regression loss: 0.01369 | Objectness loss: 0.00016 | RPN Regression loss: 0.00070 | Running loss: 0.01986\n","Epoch: 9 | Iteration: 32958 | Classification loss: 0.00846 | Regression loss: 0.01011 | Objectness loss: 0.00002 | RPN Regression loss: 0.00054 | Running loss: 0.01911\n","Epoch: 9 | Iteration: 32959 | Classification loss: 0.04372 | Regression loss: 0.04389 | Objectness loss: 0.00822 | RPN Regression loss: 0.00508 | Running loss: 0.10090\n","Epoch: 9 | Iteration: 32960 | Classification loss: 0.02604 | Regression loss: 0.04326 | Objectness loss: 0.00105 | RPN Regression loss: 0.00149 | Running loss: 0.07183\n","Epoch: 9 | Iteration: 32961 | Classification loss: 0.01133 | Regression loss: 0.01223 | Objectness loss: 0.00561 | RPN Regression loss: 0.00046 | Running loss: 0.02962\n","Epoch: 9 | Iteration: 32962 | Classification loss: 0.01955 | Regression loss: 0.01601 | Objectness loss: 0.00004 | RPN Regression loss: 0.00066 | Running loss: 0.03626\n","Epoch: 9 | Iteration: 32963 | Classification loss: 0.00963 | Regression loss: 0.02290 | Objectness loss: 0.00036 | RPN Regression loss: 0.00094 | Running loss: 0.03382\n","Epoch: 9 | Iteration: 32964 | Classification loss: 0.00970 | Regression loss: 0.01775 | Objectness loss: 0.00002 | RPN Regression loss: 0.00038 | Running loss: 0.02785\n","Epoch: 9 | Iteration: 32965 | Classification loss: 0.01618 | Regression loss: 0.02805 | Objectness loss: 0.00003 | RPN Regression loss: 0.00098 | Running loss: 0.04524\n","Epoch: 9 | Iteration: 32966 | Classification loss: 0.00952 | Regression loss: 0.02978 | Objectness loss: 0.00004 | RPN Regression loss: 0.00080 | Running loss: 0.04014\n","Epoch: 9 | Iteration: 32967 | Classification loss: 0.01279 | Regression loss: 0.03294 | Objectness loss: 0.00029 | RPN Regression loss: 0.00430 | Running loss: 0.05032\n","Epoch: 9 | Iteration: 32968 | Classification loss: 0.01618 | Regression loss: 0.03997 | Objectness loss: 0.00033 | RPN Regression loss: 0.00145 | Running loss: 0.05794\n","Epoch: 9 | Iteration: 32969 | Classification loss: 0.03794 | Regression loss: 0.01644 | Objectness loss: 0.00013 | RPN Regression loss: 0.00039 | Running loss: 0.05490\n","Epoch: 9 | Iteration: 32970 | Classification loss: 0.00998 | Regression loss: 0.02232 | Objectness loss: 0.00004 | RPN Regression loss: 0.00076 | Running loss: 0.03310\n","Epoch: 9 | Iteration: 32971 | Classification loss: 0.02694 | Regression loss: 0.03415 | Objectness loss: 0.00020 | RPN Regression loss: 0.00357 | Running loss: 0.06486\n","Epoch: 9 | Iteration: 32972 | Classification loss: 0.01377 | Regression loss: 0.02433 | Objectness loss: 0.00001 | RPN Regression loss: 0.00045 | Running loss: 0.03857\n","Epoch: 9 | Iteration: 32973 | Classification loss: 0.02175 | Regression loss: 0.04822 | Objectness loss: 0.00297 | RPN Regression loss: 0.00280 | Running loss: 0.07573\n","Epoch: 9 | Iteration: 32974 | Classification loss: 0.01491 | Regression loss: 0.03492 | Objectness loss: 0.00137 | RPN Regression loss: 0.00094 | Running loss: 0.05214\n","Epoch: 9 | Iteration: 32975 | Classification loss: 0.04265 | Regression loss: 0.08525 | Objectness loss: 0.00296 | RPN Regression loss: 0.00182 | Running loss: 0.13268\n","Epoch: 9 | Iteration: 32976 | Classification loss: 0.01549 | Regression loss: 0.02801 | Objectness loss: 0.00022 | RPN Regression loss: 0.00092 | Running loss: 0.04464\n","Epoch: 9 | Iteration: 32977 | Classification loss: 0.02932 | Regression loss: 0.02265 | Objectness loss: 0.00003 | RPN Regression loss: 0.00044 | Running loss: 0.05245\n","Epoch: 9 | Iteration: 32978 | Classification loss: 0.01326 | Regression loss: 0.02732 | Objectness loss: 0.00005 | RPN Regression loss: 0.00034 | Running loss: 0.04098\n","Epoch: 9 | Iteration: 32979 | Classification loss: 0.02890 | Regression loss: 0.03858 | Objectness loss: 0.00054 | RPN Regression loss: 0.00205 | Running loss: 0.07007\n","Epoch: 9 | Iteration: 32980 | Classification loss: 0.00576 | Regression loss: 0.02182 | Objectness loss: 0.00001 | RPN Regression loss: 0.00210 | Running loss: 0.02969\n","Epoch: 9 | Iteration: 32981 | Classification loss: 0.01162 | Regression loss: 0.02025 | Objectness loss: 0.00074 | RPN Regression loss: 0.00223 | Running loss: 0.03483\n","Epoch: 9 | Iteration: 32982 | Classification loss: 0.01216 | Regression loss: 0.03518 | Objectness loss: 0.00044 | RPN Regression loss: 0.00155 | Running loss: 0.04933\n","Epoch: 9 | Iteration: 32983 | Classification loss: 0.01560 | Regression loss: 0.04064 | Objectness loss: 0.00159 | RPN Regression loss: 0.00117 | Running loss: 0.05900\n","Epoch: 9 | Iteration: 32984 | Classification loss: 0.00593 | Regression loss: 0.01349 | Objectness loss: 0.00007 | RPN Regression loss: 0.00156 | Running loss: 0.02105\n","Epoch: 9 | Iteration: 32985 | Classification loss: 0.00954 | Regression loss: 0.02346 | Objectness loss: 0.00006 | RPN Regression loss: 0.00048 | Running loss: 0.03355\n","Epoch: 9 | Iteration: 32986 | Classification loss: 0.01782 | Regression loss: 0.03059 | Objectness loss: 0.00265 | RPN Regression loss: 0.00537 | Running loss: 0.05643\n","Epoch: 9 | Iteration: 32987 | Classification loss: 0.02812 | Regression loss: 0.02594 | Objectness loss: 0.00008 | RPN Regression loss: 0.00367 | Running loss: 0.05781\n","Epoch: 9 | Iteration: 32988 | Classification loss: 0.01831 | Regression loss: 0.02081 | Objectness loss: 0.00072 | RPN Regression loss: 0.00805 | Running loss: 0.04789\n","Epoch: 9 | Iteration: 32989 | Classification loss: 0.00840 | Regression loss: 0.02296 | Objectness loss: 0.00085 | RPN Regression loss: 0.00443 | Running loss: 0.03663\n","Epoch: 9 | Iteration: 32990 | Classification loss: 0.04548 | Regression loss: 0.02205 | Objectness loss: 0.00036 | RPN Regression loss: 0.00090 | Running loss: 0.06879\n","Epoch: 9 | Iteration: 32991 | Classification loss: 0.00902 | Regression loss: 0.03360 | Objectness loss: 0.00039 | RPN Regression loss: 0.00151 | Running loss: 0.04452\n","Epoch: 9 | Iteration: 32992 | Classification loss: 0.01916 | Regression loss: 0.01764 | Objectness loss: 0.00180 | RPN Regression loss: 0.00299 | Running loss: 0.04159\n","Epoch: 9 | Iteration: 32993 | Classification loss: 0.01652 | Regression loss: 0.05346 | Objectness loss: 0.00002 | RPN Regression loss: 0.00132 | Running loss: 0.07133\n","Epoch: 9 | Iteration: 32994 | Classification loss: 0.02569 | Regression loss: 0.06855 | Objectness loss: 0.00009 | RPN Regression loss: 0.00057 | Running loss: 0.09491\n","Epoch: 9 | Iteration: 32995 | Classification loss: 0.03621 | Regression loss: 0.04613 | Objectness loss: 0.00162 | RPN Regression loss: 0.00264 | Running loss: 0.08660\n","Epoch: 9 | Iteration: 32996 | Classification loss: 0.00774 | Regression loss: 0.01394 | Objectness loss: 0.00103 | RPN Regression loss: 0.00036 | Running loss: 0.02307\n","Epoch: 9 | Iteration: 32997 | Classification loss: 0.00911 | Regression loss: 0.02400 | Objectness loss: 0.00218 | RPN Regression loss: 0.00044 | Running loss: 0.03573\n","Epoch: 9 | Iteration: 32998 | Classification loss: 0.06665 | Regression loss: 0.05927 | Objectness loss: 0.00024 | RPN Regression loss: 0.00166 | Running loss: 0.12782\n","Epoch: 9 | Iteration: 32999 | Classification loss: 0.01187 | Regression loss: 0.01867 | Objectness loss: 0.00004 | RPN Regression loss: 0.00077 | Running loss: 0.03134\n","Epoch: 9 | Iteration: 33000 | Classification loss: 0.02738 | Regression loss: 0.03082 | Objectness loss: 0.00015 | RPN Regression loss: 0.00278 | Running loss: 0.06114\n","Epoch: 9 | Iteration: 33001 | Classification loss: 0.01209 | Regression loss: 0.01757 | Objectness loss: 0.00070 | RPN Regression loss: 0.00128 | Running loss: 0.03164\n","Epoch: 9 | Iteration: 33002 | Classification loss: 0.02098 | Regression loss: 0.01946 | Objectness loss: 0.00933 | RPN Regression loss: 0.00259 | Running loss: 0.05236\n","Epoch: 9 | Iteration: 33003 | Classification loss: 0.02257 | Regression loss: 0.03071 | Objectness loss: 0.00004 | RPN Regression loss: 0.00066 | Running loss: 0.05397\n","Epoch: 9 | Iteration: 33004 | Classification loss: 0.01032 | Regression loss: 0.01832 | Objectness loss: 0.00008 | RPN Regression loss: 0.00106 | Running loss: 0.02979\n","Epoch: 9 | Iteration: 33005 | Classification loss: 0.01130 | Regression loss: 0.02311 | Objectness loss: 0.00160 | RPN Regression loss: 0.00105 | Running loss: 0.03706\n","Epoch: 9 | Iteration: 33006 | Classification loss: 0.01762 | Regression loss: 0.02241 | Objectness loss: 0.00044 | RPN Regression loss: 0.00140 | Running loss: 0.04187\n","Epoch: 9 | Iteration: 33007 | Classification loss: 0.00705 | Regression loss: 0.02698 | Objectness loss: 0.00047 | RPN Regression loss: 0.00279 | Running loss: 0.03730\n","Epoch: 9 | Iteration: 33008 | Classification loss: 0.01576 | Regression loss: 0.02779 | Objectness loss: 0.00007 | RPN Regression loss: 0.00136 | Running loss: 0.04499\n","Epoch: 9 | Iteration: 33009 | Classification loss: 0.03193 | Regression loss: 0.03195 | Objectness loss: 0.00625 | RPN Regression loss: 0.00098 | Running loss: 0.07112\n","Epoch: 9 | Iteration: 33010 | Classification loss: 0.02836 | Regression loss: 0.01705 | Objectness loss: 0.00188 | RPN Regression loss: 0.00037 | Running loss: 0.04766\n","Epoch: 9 | Iteration: 33011 | Classification loss: 0.02457 | Regression loss: 0.04449 | Objectness loss: 0.00222 | RPN Regression loss: 0.00099 | Running loss: 0.07227\n","Epoch: 9 | Iteration: 33012 | Classification loss: 0.01866 | Regression loss: 0.02131 | Objectness loss: 0.00010 | RPN Regression loss: 0.00166 | Running loss: 0.04174\n","Epoch: 9 | Iteration: 33013 | Classification loss: 0.00826 | Regression loss: 0.01743 | Objectness loss: 0.00006 | RPN Regression loss: 0.00032 | Running loss: 0.02607\n","Epoch: 9 | Iteration: 33014 | Classification loss: 0.03414 | Regression loss: 0.01890 | Objectness loss: 0.00004 | RPN Regression loss: 0.00050 | Running loss: 0.05359\n","Epoch: 9 | Iteration: 33015 | Classification loss: 0.02392 | Regression loss: 0.02660 | Objectness loss: 0.00354 | RPN Regression loss: 0.00264 | Running loss: 0.05670\n","Epoch: 9 | Iteration: 33016 | Classification loss: 0.01202 | Regression loss: 0.02235 | Objectness loss: 0.00048 | RPN Regression loss: 0.00098 | Running loss: 0.03583\n","Epoch: 9 | Iteration: 33017 | Classification loss: 0.01898 | Regression loss: 0.03438 | Objectness loss: 0.00073 | RPN Regression loss: 0.00269 | Running loss: 0.05678\n","Epoch: 9 | Iteration: 33018 | Classification loss: 0.01250 | Regression loss: 0.01933 | Objectness loss: 0.00058 | RPN Regression loss: 0.00040 | Running loss: 0.03282\n","Epoch: 9 | Iteration: 33019 | Classification loss: 0.03089 | Regression loss: 0.01736 | Objectness loss: 0.00108 | RPN Regression loss: 0.00214 | Running loss: 0.05147\n","Epoch: 9 | Iteration: 33020 | Classification loss: 0.01461 | Regression loss: 0.03452 | Objectness loss: 0.00271 | RPN Regression loss: 0.00135 | Running loss: 0.05319\n","Epoch: 9 | Iteration: 33021 | Classification loss: 0.01649 | Regression loss: 0.02189 | Objectness loss: 0.00013 | RPN Regression loss: 0.00236 | Running loss: 0.04088\n","Epoch: 9 | Iteration: 33022 | Classification loss: 0.03345 | Regression loss: 0.02315 | Objectness loss: 0.00016 | RPN Regression loss: 0.00159 | Running loss: 0.05835\n","Epoch: 9 | Iteration: 33023 | Classification loss: 0.01120 | Regression loss: 0.02346 | Objectness loss: 0.00001 | RPN Regression loss: 0.00102 | Running loss: 0.03569\n","Epoch: 9 | Iteration: 33024 | Classification loss: 0.00830 | Regression loss: 0.01425 | Objectness loss: 0.00008 | RPN Regression loss: 0.00068 | Running loss: 0.02332\n","Epoch: 9 | Iteration: 33025 | Classification loss: 0.01338 | Regression loss: 0.01799 | Objectness loss: 0.00094 | RPN Regression loss: 0.00258 | Running loss: 0.03489\n","Epoch: 9 | Iteration: 33026 | Classification loss: 0.02250 | Regression loss: 0.03210 | Objectness loss: 0.00167 | RPN Regression loss: 0.00309 | Running loss: 0.05935\n","Epoch: 9 | Iteration: 33027 | Classification loss: 0.01235 | Regression loss: 0.04496 | Objectness loss: 0.00005 | RPN Regression loss: 0.00059 | Running loss: 0.05796\n","Epoch: 9 | Iteration: 33028 | Classification loss: 0.06666 | Regression loss: 0.07930 | Objectness loss: 0.00188 | RPN Regression loss: 0.00283 | Running loss: 0.15067\n","Epoch: 9 | Iteration: 33029 | Classification loss: 0.02409 | Regression loss: 0.01639 | Objectness loss: 0.00050 | RPN Regression loss: 0.00272 | Running loss: 0.04369\n","Epoch: 9 | Iteration: 33030 | Classification loss: 0.02263 | Regression loss: 0.02178 | Objectness loss: 0.00345 | RPN Regression loss: 0.00170 | Running loss: 0.04956\n","Epoch: 9 | Iteration: 33031 | Classification loss: 0.03209 | Regression loss: 0.02544 | Objectness loss: 0.00035 | RPN Regression loss: 0.00153 | Running loss: 0.05942\n","Epoch: 9 | Iteration: 33032 | Classification loss: 0.01693 | Regression loss: 0.03923 | Objectness loss: 0.00067 | RPN Regression loss: 0.00321 | Running loss: 0.06005\n","Epoch: 9 | Iteration: 33033 | Classification loss: 0.01024 | Regression loss: 0.01826 | Objectness loss: 0.00027 | RPN Regression loss: 0.00100 | Running loss: 0.02977\n","Epoch: 9 | Iteration: 33034 | Classification loss: 0.02320 | Regression loss: 0.01485 | Objectness loss: 0.00238 | RPN Regression loss: 0.00145 | Running loss: 0.04188\n","Epoch: 9 | Iteration: 33035 | Classification loss: 0.00812 | Regression loss: 0.01175 | Objectness loss: 0.00011 | RPN Regression loss: 0.00176 | Running loss: 0.02174\n","Epoch: 9 | Iteration: 33036 | Classification loss: 0.01485 | Regression loss: 0.03645 | Objectness loss: 0.00524 | RPN Regression loss: 0.00684 | Running loss: 0.06338\n","Epoch: 9 | Iteration: 33037 | Classification loss: 0.06396 | Regression loss: 0.04405 | Objectness loss: 0.01048 | RPN Regression loss: 0.00258 | Running loss: 0.12108\n","Epoch: 9 | Iteration: 33038 | Classification loss: 0.01124 | Regression loss: 0.02182 | Objectness loss: 0.00008 | RPN Regression loss: 0.00064 | Running loss: 0.03378\n","Epoch: 9 | Iteration: 33039 | Classification loss: 0.04071 | Regression loss: 0.04036 | Objectness loss: 0.00193 | RPN Regression loss: 0.00047 | Running loss: 0.08347\n","Epoch: 9 | Iteration: 33040 | Classification loss: 0.01395 | Regression loss: 0.01650 | Objectness loss: 0.00037 | RPN Regression loss: 0.00209 | Running loss: 0.03291\n","Epoch: 9 | Iteration: 33041 | Classification loss: 0.01941 | Regression loss: 0.01590 | Objectness loss: 0.00014 | RPN Regression loss: 0.00055 | Running loss: 0.03600\n","Epoch: 9 | Iteration: 33042 | Classification loss: 0.01232 | Regression loss: 0.02592 | Objectness loss: 0.00014 | RPN Regression loss: 0.00127 | Running loss: 0.03965\n","Epoch: 9 | Iteration: 33043 | Classification loss: 0.02447 | Regression loss: 0.04115 | Objectness loss: 0.00057 | RPN Regression loss: 0.00261 | Running loss: 0.06879\n","Epoch: 9 | Iteration: 33044 | Classification loss: 0.01153 | Regression loss: 0.01934 | Objectness loss: 0.00015 | RPN Regression loss: 0.00301 | Running loss: 0.03404\n","Epoch: 9 | Iteration: 33045 | Classification loss: 0.01000 | Regression loss: 0.01510 | Objectness loss: 0.00004 | RPN Regression loss: 0.00131 | Running loss: 0.02644\n","Epoch: 9 | Iteration: 33046 | Classification loss: 0.00975 | Regression loss: 0.01758 | Objectness loss: 0.00238 | RPN Regression loss: 0.00262 | Running loss: 0.03233\n","Epoch: 9 | Iteration: 33047 | Classification loss: 0.01902 | Regression loss: 0.02775 | Objectness loss: 0.00114 | RPN Regression loss: 0.00057 | Running loss: 0.04847\n","Epoch: 9 | Iteration: 33048 | Classification loss: 0.01681 | Regression loss: 0.01716 | Objectness loss: 0.00007 | RPN Regression loss: 0.00198 | Running loss: 0.03601\n","Epoch: 9 | Iteration: 33049 | Classification loss: 0.02163 | Regression loss: 0.02296 | Objectness loss: 0.00018 | RPN Regression loss: 0.00169 | Running loss: 0.04646\n","Epoch: 9 | Iteration: 33050 | Classification loss: 0.01154 | Regression loss: 0.01477 | Objectness loss: 0.00211 | RPN Regression loss: 0.00101 | Running loss: 0.02942\n","Epoch: 9 | Iteration: 33051 | Classification loss: 0.01877 | Regression loss: 0.02029 | Objectness loss: 0.00012 | RPN Regression loss: 0.00056 | Running loss: 0.03974\n","Epoch: 9 | Iteration: 33052 | Classification loss: 0.01320 | Regression loss: 0.02107 | Objectness loss: 0.00028 | RPN Regression loss: 0.00415 | Running loss: 0.03869\n","Epoch: 9 | Iteration: 33053 | Classification loss: 0.00800 | Regression loss: 0.01791 | Objectness loss: 0.00040 | RPN Regression loss: 0.00339 | Running loss: 0.02971\n","Epoch: 9 | Iteration: 33054 | Classification loss: 0.02017 | Regression loss: 0.01598 | Objectness loss: 0.00006 | RPN Regression loss: 0.00264 | Running loss: 0.03885\n","Epoch: 9 | Iteration: 33055 | Classification loss: 0.02621 | Regression loss: 0.05770 | Objectness loss: 0.00757 | RPN Regression loss: 0.00393 | Running loss: 0.09541\n","Epoch: 9 | Iteration: 33056 | Classification loss: 0.02862 | Regression loss: 0.03311 | Objectness loss: 0.00008 | RPN Regression loss: 0.00071 | Running loss: 0.06252\n","Epoch: 9 | Iteration: 33057 | Classification loss: 0.03293 | Regression loss: 0.04158 | Objectness loss: 0.00879 | RPN Regression loss: 0.00140 | Running loss: 0.08469\n","Epoch: 9 | Iteration: 33058 | Classification loss: 0.01177 | Regression loss: 0.01411 | Objectness loss: 0.00745 | RPN Regression loss: 0.00335 | Running loss: 0.03669\n","Epoch: 9 | Iteration: 33059 | Classification loss: 0.00904 | Regression loss: 0.01920 | Objectness loss: 0.00009 | RPN Regression loss: 0.00081 | Running loss: 0.02914\n","Epoch: 9 | Iteration: 33060 | Classification loss: 0.01604 | Regression loss: 0.01956 | Objectness loss: 0.00019 | RPN Regression loss: 0.00108 | Running loss: 0.03688\n","Epoch: 9 | Iteration: 33061 | Classification loss: 0.02752 | Regression loss: 0.04491 | Objectness loss: 0.00027 | RPN Regression loss: 0.00175 | Running loss: 0.07445\n","Epoch: 9 | Iteration: 33062 | Classification loss: 0.02036 | Regression loss: 0.02656 | Objectness loss: 0.00006 | RPN Regression loss: 0.00061 | Running loss: 0.04759\n","Epoch: 9 | Iteration: 33063 | Classification loss: 0.02658 | Regression loss: 0.02901 | Objectness loss: 0.00462 | RPN Regression loss: 0.00032 | Running loss: 0.06052\n","Epoch: 9 | Iteration: 33064 | Classification loss: 0.01075 | Regression loss: 0.02122 | Objectness loss: 0.00045 | RPN Regression loss: 0.00211 | Running loss: 0.03453\n","Epoch: 9 | Iteration: 33065 | Classification loss: 0.01035 | Regression loss: 0.01923 | Objectness loss: 0.00001 | RPN Regression loss: 0.00042 | Running loss: 0.03000\n","Epoch: 9 | Iteration: 33066 | Classification loss: 0.01534 | Regression loss: 0.03757 | Objectness loss: 0.00134 | RPN Regression loss: 0.00235 | Running loss: 0.05660\n","Epoch: 9 | Iteration: 33067 | Classification loss: 0.02341 | Regression loss: 0.01797 | Objectness loss: 0.00150 | RPN Regression loss: 0.00039 | Running loss: 0.04326\n","Epoch: 9 | Iteration: 33068 | Classification loss: 0.01052 | Regression loss: 0.02783 | Objectness loss: 0.00055 | RPN Regression loss: 0.00217 | Running loss: 0.04107\n","Epoch: 9 | Iteration: 33069 | Classification loss: 0.03287 | Regression loss: 0.02528 | Objectness loss: 0.00379 | RPN Regression loss: 0.00110 | Running loss: 0.06303\n","Epoch: 9 | Iteration: 33070 | Classification loss: 0.02445 | Regression loss: 0.04325 | Objectness loss: 0.00062 | RPN Regression loss: 0.00524 | Running loss: 0.07356\n","Epoch: 9 | Iteration: 33071 | Classification loss: 0.00927 | Regression loss: 0.02182 | Objectness loss: 0.00084 | RPN Regression loss: 0.00144 | Running loss: 0.03337\n","Epoch: 9 | Iteration: 33072 | Classification loss: 0.00403 | Regression loss: 0.01820 | Objectness loss: 0.00030 | RPN Regression loss: 0.00045 | Running loss: 0.02298\n","Epoch: 9 | Iteration: 33073 | Classification loss: 0.01649 | Regression loss: 0.01469 | Objectness loss: 0.00017 | RPN Regression loss: 0.00065 | Running loss: 0.03200\n","Epoch: 9 | Iteration: 33074 | Classification loss: 0.01326 | Regression loss: 0.01861 | Objectness loss: 0.00019 | RPN Regression loss: 0.00186 | Running loss: 0.03391\n","Epoch: 9 | Iteration: 33075 | Classification loss: 0.02552 | Regression loss: 0.03175 | Objectness loss: 0.00658 | RPN Regression loss: 0.01118 | Running loss: 0.07502\n","Epoch: 9 | Iteration: 33076 | Classification loss: 0.01478 | Regression loss: 0.01632 | Objectness loss: 0.00073 | RPN Regression loss: 0.00146 | Running loss: 0.03329\n","Epoch: 9 | Iteration: 33077 | Classification loss: 0.02300 | Regression loss: 0.02280 | Objectness loss: 0.00066 | RPN Regression loss: 0.00032 | Running loss: 0.04678\n","Epoch: 9 | Iteration: 33078 | Classification loss: 0.00747 | Regression loss: 0.02158 | Objectness loss: 0.00166 | RPN Regression loss: 0.00318 | Running loss: 0.03389\n","Epoch: 9 | Iteration: 33079 | Classification loss: 0.00912 | Regression loss: 0.02277 | Objectness loss: 0.00005 | RPN Regression loss: 0.00115 | Running loss: 0.03310\n","Epoch: 9 | Iteration: 33080 | Classification loss: 0.01842 | Regression loss: 0.02817 | Objectness loss: 0.00024 | RPN Regression loss: 0.00288 | Running loss: 0.04971\n","Epoch: 9 | Iteration: 33081 | Classification loss: 0.00334 | Regression loss: 0.01257 | Objectness loss: 0.00032 | RPN Regression loss: 0.00129 | Running loss: 0.01752\n","Epoch: 9 | Iteration: 33082 | Classification loss: 0.02175 | Regression loss: 0.02120 | Objectness loss: 0.00034 | RPN Regression loss: 0.00101 | Running loss: 0.04429\n","Epoch: 9 | Iteration: 33083 | Classification loss: 0.02114 | Regression loss: 0.03894 | Objectness loss: 0.00735 | RPN Regression loss: 0.00818 | Running loss: 0.07561\n","Epoch: 9 | Iteration: 33084 | Classification loss: 0.01063 | Regression loss: 0.02353 | Objectness loss: 0.00003 | RPN Regression loss: 0.00134 | Running loss: 0.03553\n","Epoch: 9 | Iteration: 33085 | Classification loss: 0.02075 | Regression loss: 0.02495 | Objectness loss: 0.00017 | RPN Regression loss: 0.00177 | Running loss: 0.04764\n","Epoch: 9 | Iteration: 33086 | Classification loss: 0.01390 | Regression loss: 0.03734 | Objectness loss: 0.00003 | RPN Regression loss: 0.00105 | Running loss: 0.05233\n","Epoch: 9 | Iteration: 33087 | Classification loss: 0.00897 | Regression loss: 0.02059 | Objectness loss: 0.00020 | RPN Regression loss: 0.00057 | Running loss: 0.03032\n","Epoch: 9 | Iteration: 33088 | Classification loss: 0.00944 | Regression loss: 0.02237 | Objectness loss: 0.00028 | RPN Regression loss: 0.00138 | Running loss: 0.03347\n","Epoch: 9 | Iteration: 33089 | Classification loss: 0.01161 | Regression loss: 0.01831 | Objectness loss: 0.00115 | RPN Regression loss: 0.00154 | Running loss: 0.03261\n","Epoch: 9 | Iteration: 33090 | Classification loss: 0.01049 | Regression loss: 0.02450 | Objectness loss: 0.00006 | RPN Regression loss: 0.00236 | Running loss: 0.03741\n","Epoch: 9 | Iteration: 33091 | Classification loss: 0.00474 | Regression loss: 0.01360 | Objectness loss: 0.00001 | RPN Regression loss: 0.00136 | Running loss: 0.01971\n","Epoch: 9 | Iteration: 33092 | Classification loss: 0.08527 | Regression loss: 0.03944 | Objectness loss: 0.04784 | RPN Regression loss: 0.01726 | Running loss: 0.18981\n","Epoch: 9 | Iteration: 33093 | Classification loss: 0.01299 | Regression loss: 0.01714 | Objectness loss: 0.00007 | RPN Regression loss: 0.00114 | Running loss: 0.03135\n","Epoch: 9 | Iteration: 33094 | Classification loss: 0.01381 | Regression loss: 0.01605 | Objectness loss: 0.00004 | RPN Regression loss: 0.00390 | Running loss: 0.03380\n","Epoch: 9 | Iteration: 33095 | Classification loss: 0.01106 | Regression loss: 0.02756 | Objectness loss: 0.00052 | RPN Regression loss: 0.00125 | Running loss: 0.04039\n","Epoch: 9 | Iteration: 33096 | Classification loss: 0.01424 | Regression loss: 0.01143 | Objectness loss: 0.00010 | RPN Regression loss: 0.00069 | Running loss: 0.02645\n","Epoch: 9 | Iteration: 33097 | Classification loss: 0.00758 | Regression loss: 0.01183 | Objectness loss: 0.00024 | RPN Regression loss: 0.00087 | Running loss: 0.02052\n","Epoch: 9 | Iteration: 33098 | Classification loss: 0.01899 | Regression loss: 0.01819 | Objectness loss: 0.00306 | RPN Regression loss: 0.00060 | Running loss: 0.04084\n","Epoch: 9 | Iteration: 33099 | Classification loss: 0.02169 | Regression loss: 0.02406 | Objectness loss: 0.00293 | RPN Regression loss: 0.00140 | Running loss: 0.05008\n","Epoch: 9 | Iteration: 33100 | Classification loss: 0.01148 | Regression loss: 0.01773 | Objectness loss: 0.00093 | RPN Regression loss: 0.00090 | Running loss: 0.03105\n","Epoch: 9 | Iteration: 33101 | Classification loss: 0.03057 | Regression loss: 0.04222 | Objectness loss: 0.00626 | RPN Regression loss: 0.00083 | Running loss: 0.07987\n","Epoch: 9 | Iteration: 33102 | Classification loss: 0.01282 | Regression loss: 0.01537 | Objectness loss: 0.00606 | RPN Regression loss: 0.00153 | Running loss: 0.03578\n","Epoch: 9 | Iteration: 33103 | Classification loss: 0.02313 | Regression loss: 0.01578 | Objectness loss: 0.00185 | RPN Regression loss: 0.00252 | Running loss: 0.04328\n","Epoch: 9 | Iteration: 33104 | Classification loss: 0.04130 | Regression loss: 0.02837 | Objectness loss: 0.00360 | RPN Regression loss: 0.01316 | Running loss: 0.08643\n","Epoch: 9 | Iteration: 33105 | Classification loss: 0.00698 | Regression loss: 0.01230 | Objectness loss: 0.00016 | RPN Regression loss: 0.00076 | Running loss: 0.02020\n","Epoch: 9 | Iteration: 33106 | Classification loss: 0.01523 | Regression loss: 0.01799 | Objectness loss: 0.00254 | RPN Regression loss: 0.00142 | Running loss: 0.03718\n","Epoch: 9 | Iteration: 33107 | Classification loss: 0.02253 | Regression loss: 0.02857 | Objectness loss: 0.00273 | RPN Regression loss: 0.00116 | Running loss: 0.05499\n","Epoch: 9 | Iteration: 33108 | Classification loss: 0.02668 | Regression loss: 0.02409 | Objectness loss: 0.00085 | RPN Regression loss: 0.00040 | Running loss: 0.05202\n","Epoch: 9 | Iteration: 33109 | Classification loss: 0.01078 | Regression loss: 0.01634 | Objectness loss: 0.00171 | RPN Regression loss: 0.00048 | Running loss: 0.02931\n","Epoch: 9 | Iteration: 33110 | Classification loss: 0.01412 | Regression loss: 0.01685 | Objectness loss: 0.00134 | RPN Regression loss: 0.00058 | Running loss: 0.03289\n","Epoch: 9 | Iteration: 33111 | Classification loss: 0.01542 | Regression loss: 0.02782 | Objectness loss: 0.00153 | RPN Regression loss: 0.00065 | Running loss: 0.04542\n","Epoch: 9 | Iteration: 33112 | Classification loss: 0.02628 | Regression loss: 0.02981 | Objectness loss: 0.00148 | RPN Regression loss: 0.00146 | Running loss: 0.05902\n","Epoch: 9 | Iteration: 33113 | Classification loss: 0.01202 | Regression loss: 0.02658 | Objectness loss: 0.00005 | RPN Regression loss: 0.00115 | Running loss: 0.03979\n","Epoch: 9 | Iteration: 33114 | Classification loss: 0.03331 | Regression loss: 0.03063 | Objectness loss: 0.00582 | RPN Regression loss: 0.00161 | Running loss: 0.07136\n","Epoch: 9 | Iteration: 33115 | Classification loss: 0.00900 | Regression loss: 0.01257 | Objectness loss: 0.00028 | RPN Regression loss: 0.00259 | Running loss: 0.02444\n","Epoch: 9 | Iteration: 33116 | Classification loss: 0.02013 | Regression loss: 0.01637 | Objectness loss: 0.00110 | RPN Regression loss: 0.00070 | Running loss: 0.03829\n","Epoch: 9 | Iteration: 33117 | Classification loss: 0.01714 | Regression loss: 0.04344 | Objectness loss: 0.00034 | RPN Regression loss: 0.00172 | Running loss: 0.06264\n","Epoch: 9 | Iteration: 33118 | Classification loss: 0.04312 | Regression loss: 0.04764 | Objectness loss: 0.00027 | RPN Regression loss: 0.00109 | Running loss: 0.09212\n","Epoch: 9 | Iteration: 33119 | Classification loss: 0.02212 | Regression loss: 0.01895 | Objectness loss: 0.00099 | RPN Regression loss: 0.00112 | Running loss: 0.04319\n","Epoch: 9 | Iteration: 33120 | Classification loss: 0.01859 | Regression loss: 0.03048 | Objectness loss: 0.00009 | RPN Regression loss: 0.00093 | Running loss: 0.05008\n","Epoch: 9 | Iteration: 33121 | Classification loss: 0.04010 | Regression loss: 0.05135 | Objectness loss: 0.00019 | RPN Regression loss: 0.00288 | Running loss: 0.09452\n","Epoch: 9 | Iteration: 33122 | Classification loss: 0.04798 | Regression loss: 0.02381 | Objectness loss: 0.00022 | RPN Regression loss: 0.00076 | Running loss: 0.07277\n","Epoch: 9 | Iteration: 33123 | Classification loss: 0.01234 | Regression loss: 0.03364 | Objectness loss: 0.00051 | RPN Regression loss: 0.00078 | Running loss: 0.04726\n","Epoch: 9 | Iteration: 33124 | Classification loss: 0.02788 | Regression loss: 0.04627 | Objectness loss: 0.00003 | RPN Regression loss: 0.00046 | Running loss: 0.07464\n","Epoch: 9 | Iteration: 33125 | Classification loss: 0.02188 | Regression loss: 0.03289 | Objectness loss: 0.00014 | RPN Regression loss: 0.02689 | Running loss: 0.08180\n","Epoch: 9 | Iteration: 33126 | Classification loss: 0.01853 | Regression loss: 0.02700 | Objectness loss: 0.00081 | RPN Regression loss: 0.00175 | Running loss: 0.04810\n","Epoch: 9 | Iteration: 33127 | Classification loss: 0.03544 | Regression loss: 0.04364 | Objectness loss: 0.00041 | RPN Regression loss: 0.00243 | Running loss: 0.08192\n","Epoch: 9 | Iteration: 33128 | Classification loss: 0.01130 | Regression loss: 0.02298 | Objectness loss: 0.00010 | RPN Regression loss: 0.00155 | Running loss: 0.03593\n","Epoch: 9 | Iteration: 33129 | Classification loss: 0.00885 | Regression loss: 0.01851 | Objectness loss: 0.00070 | RPN Regression loss: 0.00037 | Running loss: 0.02843\n","Epoch: 9 | Iteration: 33130 | Classification loss: 0.03184 | Regression loss: 0.02738 | Objectness loss: 0.00290 | RPN Regression loss: 0.00139 | Running loss: 0.06350\n","Epoch: 9 | Iteration: 33131 | Classification loss: 0.01618 | Regression loss: 0.04146 | Objectness loss: 0.00153 | RPN Regression loss: 0.00129 | Running loss: 0.06045\n","Epoch: 9 | Iteration: 33132 | Classification loss: 0.00768 | Regression loss: 0.01646 | Objectness loss: 0.00031 | RPN Regression loss: 0.00193 | Running loss: 0.02639\n","Epoch: 9 | Iteration: 33133 | Classification loss: 0.01030 | Regression loss: 0.02596 | Objectness loss: 0.00006 | RPN Regression loss: 0.00066 | Running loss: 0.03698\n","Epoch: 9 | Iteration: 33134 | Classification loss: 0.00990 | Regression loss: 0.02445 | Objectness loss: 0.00104 | RPN Regression loss: 0.00164 | Running loss: 0.03703\n","Epoch: 9 | Iteration: 33135 | Classification loss: 0.01028 | Regression loss: 0.01541 | Objectness loss: 0.00008 | RPN Regression loss: 0.00134 | Running loss: 0.02710\n","Epoch: 9 | Iteration: 33136 | Classification loss: 0.04192 | Regression loss: 0.02136 | Objectness loss: 0.00150 | RPN Regression loss: 0.00133 | Running loss: 0.06611\n","Epoch: 9 | Iteration: 33137 | Classification loss: 0.01208 | Regression loss: 0.01585 | Objectness loss: 0.00018 | RPN Regression loss: 0.00041 | Running loss: 0.02852\n","Epoch: 9 | Iteration: 33138 | Classification loss: 0.01933 | Regression loss: 0.02967 | Objectness loss: 0.00074 | RPN Regression loss: 0.00071 | Running loss: 0.05045\n","Epoch: 9 | Iteration: 33139 | Classification loss: 0.03153 | Regression loss: 0.04215 | Objectness loss: 0.00856 | RPN Regression loss: 0.00376 | Running loss: 0.08600\n","Epoch: 9 | Iteration: 33140 | Classification loss: 0.01365 | Regression loss: 0.02845 | Objectness loss: 0.00066 | RPN Regression loss: 0.00561 | Running loss: 0.04836\n","Epoch: 9 | Iteration: 33141 | Classification loss: 0.01881 | Regression loss: 0.02974 | Objectness loss: 0.01018 | RPN Regression loss: 0.00153 | Running loss: 0.06026\n","Epoch: 9 | Iteration: 33142 | Classification loss: 0.01227 | Regression loss: 0.02733 | Objectness loss: 0.00073 | RPN Regression loss: 0.00166 | Running loss: 0.04199\n","Epoch: 9 | Iteration: 33143 | Classification loss: 0.02680 | Regression loss: 0.02278 | Objectness loss: 0.00006 | RPN Regression loss: 0.00085 | Running loss: 0.05049\n","Epoch: 9 | Iteration: 33144 | Classification loss: 0.00699 | Regression loss: 0.01586 | Objectness loss: 0.00034 | RPN Regression loss: 0.00082 | Running loss: 0.02400\n","Epoch: 9 | Iteration: 33145 | Classification loss: 0.01680 | Regression loss: 0.02384 | Objectness loss: 0.00076 | RPN Regression loss: 0.00035 | Running loss: 0.04175\n","Epoch: 9 | Iteration: 33146 | Classification loss: 0.02963 | Regression loss: 0.01415 | Objectness loss: 0.00011 | RPN Regression loss: 0.00110 | Running loss: 0.04499\n","Epoch: 9 | Iteration: 33147 | Classification loss: 0.00958 | Regression loss: 0.01675 | Objectness loss: 0.00076 | RPN Regression loss: 0.00091 | Running loss: 0.02799\n","Epoch: 9 | Iteration: 33148 | Classification loss: 0.01376 | Regression loss: 0.02295 | Objectness loss: 0.00035 | RPN Regression loss: 0.00103 | Running loss: 0.03808\n","Epoch: 9 | Iteration: 33149 | Classification loss: 0.06749 | Regression loss: 0.05618 | Objectness loss: 0.00030 | RPN Regression loss: 0.00241 | Running loss: 0.12638\n","Epoch: 9 | Iteration: 33150 | Classification loss: 0.03664 | Regression loss: 0.01871 | Objectness loss: 0.00225 | RPN Regression loss: 0.00165 | Running loss: 0.05925\n","Epoch: 9 | Iteration: 33151 | Classification loss: 0.00781 | Regression loss: 0.01545 | Objectness loss: 0.00013 | RPN Regression loss: 0.00049 | Running loss: 0.02389\n","Epoch: 9 | Iteration: 33152 | Classification loss: 0.00744 | Regression loss: 0.01729 | Objectness loss: 0.00020 | RPN Regression loss: 0.00065 | Running loss: 0.02558\n","Epoch: 9 | Iteration: 33153 | Classification loss: 0.02571 | Regression loss: 0.03175 | Objectness loss: 0.00041 | RPN Regression loss: 0.00172 | Running loss: 0.05958\n","Epoch: 9 | Iteration: 33154 | Classification loss: 0.00986 | Regression loss: 0.02983 | Objectness loss: 0.00007 | RPN Regression loss: 0.00115 | Running loss: 0.04091\n","Epoch: 9 | Iteration: 33155 | Classification loss: 0.00898 | Regression loss: 0.01288 | Objectness loss: 0.00023 | RPN Regression loss: 0.00099 | Running loss: 0.02308\n","Epoch: 9 | Iteration: 33156 | Classification loss: 0.02335 | Regression loss: 0.02640 | Objectness loss: 0.00060 | RPN Regression loss: 0.00190 | Running loss: 0.05225\n","Epoch: 9 | Iteration: 33157 | Classification loss: 0.01848 | Regression loss: 0.03372 | Objectness loss: 0.00082 | RPN Regression loss: 0.00288 | Running loss: 0.05591\n","Epoch: 9 | Iteration: 33158 | Classification loss: 0.01460 | Regression loss: 0.02528 | Objectness loss: 0.00111 | RPN Regression loss: 0.00092 | Running loss: 0.04191\n","Epoch: 9 | Iteration: 33159 | Classification loss: 0.01020 | Regression loss: 0.02157 | Objectness loss: 0.00154 | RPN Regression loss: 0.00088 | Running loss: 0.03419\n","Epoch: 9 | Iteration: 33160 | Classification loss: 0.01614 | Regression loss: 0.02607 | Objectness loss: 0.00003 | RPN Regression loss: 0.00097 | Running loss: 0.04320\n","Epoch: 9 | Iteration: 33161 | Classification loss: 0.10828 | Regression loss: 0.05014 | Objectness loss: 0.00006 | RPN Regression loss: 0.00307 | Running loss: 0.16154\n","Epoch: 9 | Iteration: 33162 | Classification loss: 0.01828 | Regression loss: 0.02902 | Objectness loss: 0.00003 | RPN Regression loss: 0.00096 | Running loss: 0.04829\n","Epoch: 9 | Iteration: 33163 | Classification loss: 0.00531 | Regression loss: 0.01520 | Objectness loss: 0.00006 | RPN Regression loss: 0.00105 | Running loss: 0.02161\n","Epoch: 9 | Iteration: 33164 | Classification loss: 0.01527 | Regression loss: 0.01711 | Objectness loss: 0.00201 | RPN Regression loss: 0.00366 | Running loss: 0.03805\n","Epoch: 9 | Iteration: 33165 | Classification loss: 0.01335 | Regression loss: 0.02775 | Objectness loss: 0.00032 | RPN Regression loss: 0.00072 | Running loss: 0.04214\n","Epoch: 9 | Iteration: 33166 | Classification loss: 0.00811 | Regression loss: 0.02110 | Objectness loss: 0.00004 | RPN Regression loss: 0.00044 | Running loss: 0.02970\n","Epoch: 9 | Iteration: 33167 | Classification loss: 0.01656 | Regression loss: 0.04959 | Objectness loss: 0.00020 | RPN Regression loss: 0.00378 | Running loss: 0.07013\n","Epoch: 9 | Iteration: 33168 | Classification loss: 0.02355 | Regression loss: 0.03047 | Objectness loss: 0.02213 | RPN Regression loss: 0.02383 | Running loss: 0.09998\n","Epoch: 9 | Iteration: 33169 | Classification loss: 0.01229 | Regression loss: 0.02906 | Objectness loss: 0.00021 | RPN Regression loss: 0.00118 | Running loss: 0.04274\n","Epoch: 9 | Iteration: 33170 | Classification loss: 0.01529 | Regression loss: 0.02057 | Objectness loss: 0.00309 | RPN Regression loss: 0.00105 | Running loss: 0.04000\n","Epoch: 9 | Iteration: 33171 | Classification loss: 0.02040 | Regression loss: 0.02187 | Objectness loss: 0.00124 | RPN Regression loss: 0.00358 | Running loss: 0.04710\n","Epoch: 9 | Iteration: 33172 | Classification loss: 0.01440 | Regression loss: 0.02244 | Objectness loss: 0.00336 | RPN Regression loss: 0.00187 | Running loss: 0.04208\n","Epoch: 9 | Iteration: 33173 | Classification loss: 0.02141 | Regression loss: 0.02448 | Objectness loss: 0.00009 | RPN Regression loss: 0.00190 | Running loss: 0.04788\n","Epoch: 9 | Iteration: 33174 | Classification loss: 0.03352 | Regression loss: 0.03464 | Objectness loss: 0.00404 | RPN Regression loss: 0.00123 | Running loss: 0.07341\n","Epoch: 9 | Iteration: 33175 | Classification loss: 0.03075 | Regression loss: 0.03338 | Objectness loss: 0.00051 | RPN Regression loss: 0.00125 | Running loss: 0.06589\n","Epoch: 9 | Iteration: 33176 | Classification loss: 0.01425 | Regression loss: 0.01646 | Objectness loss: 0.00007 | RPN Regression loss: 0.00066 | Running loss: 0.03143\n","Epoch: 9 | Iteration: 33177 | Classification loss: 0.00881 | Regression loss: 0.02083 | Objectness loss: 0.00004 | RPN Regression loss: 0.00048 | Running loss: 0.03016\n","Epoch: 9 | Iteration: 33178 | Classification loss: 0.00839 | Regression loss: 0.01538 | Objectness loss: 0.00023 | RPN Regression loss: 0.00055 | Running loss: 0.02455\n","Epoch: 9 | Iteration: 33179 | Classification loss: 0.03529 | Regression loss: 0.06487 | Objectness loss: 0.00012 | RPN Regression loss: 0.00141 | Running loss: 0.10169\n","Epoch: 9 | Iteration: 33180 | Classification loss: 0.01568 | Regression loss: 0.02656 | Objectness loss: 0.00510 | RPN Regression loss: 0.00101 | Running loss: 0.04835\n","Epoch: 9 | Iteration: 33181 | Classification loss: 0.01312 | Regression loss: 0.02277 | Objectness loss: 0.00014 | RPN Regression loss: 0.00079 | Running loss: 0.03682\n","Epoch: 9 | Iteration: 33182 | Classification loss: 0.00696 | Regression loss: 0.01372 | Objectness loss: 0.00026 | RPN Regression loss: 0.00077 | Running loss: 0.02171\n","Epoch: 9 | Iteration: 33183 | Classification loss: 0.04886 | Regression loss: 0.04840 | Objectness loss: 0.00020 | RPN Regression loss: 0.00220 | Running loss: 0.09967\n","Epoch: 9 | Iteration: 33184 | Classification loss: 0.00955 | Regression loss: 0.01855 | Objectness loss: 0.00446 | RPN Regression loss: 0.00041 | Running loss: 0.03297\n","Epoch: 9 | Iteration: 33185 | Classification loss: 0.01485 | Regression loss: 0.01510 | Objectness loss: 0.00239 | RPN Regression loss: 0.00331 | Running loss: 0.03566\n","Epoch: 9 | Iteration: 33186 | Classification loss: 0.01660 | Regression loss: 0.02377 | Objectness loss: 0.00052 | RPN Regression loss: 0.00071 | Running loss: 0.04161\n","Epoch: 9 | Iteration: 33187 | Classification loss: 0.04628 | Regression loss: 0.06168 | Objectness loss: 0.00340 | RPN Regression loss: 0.00917 | Running loss: 0.12053\n","Epoch: 9 | Iteration: 33188 | Classification loss: 0.00626 | Regression loss: 0.01709 | Objectness loss: 0.00020 | RPN Regression loss: 0.00059 | Running loss: 0.02413\n","Epoch: 9 | Iteration: 33189 | Classification loss: 0.01358 | Regression loss: 0.02141 | Objectness loss: 0.00674 | RPN Regression loss: 0.00245 | Running loss: 0.04418\n","Epoch: 9 | Iteration: 33190 | Classification loss: 0.03347 | Regression loss: 0.02660 | Objectness loss: 0.00640 | RPN Regression loss: 0.00023 | Running loss: 0.06670\n","Epoch: 9 | Iteration: 33191 | Classification loss: 0.00916 | Regression loss: 0.02866 | Objectness loss: 0.00116 | RPN Regression loss: 0.00162 | Running loss: 0.04060\n","Epoch: 9 | Iteration: 33192 | Classification loss: 0.01425 | Regression loss: 0.01691 | Objectness loss: 0.00060 | RPN Regression loss: 0.00166 | Running loss: 0.03342\n","Epoch: 9 | Iteration: 33193 | Classification loss: 0.07509 | Regression loss: 0.03409 | Objectness loss: 0.03613 | RPN Regression loss: 0.00106 | Running loss: 0.14637\n","Epoch: 9 | Iteration: 33194 | Classification loss: 0.02371 | Regression loss: 0.03574 | Objectness loss: 0.00019 | RPN Regression loss: 0.00137 | Running loss: 0.06101\n","Epoch: 9 | Iteration: 33195 | Classification loss: 0.01139 | Regression loss: 0.02694 | Objectness loss: 0.00005 | RPN Regression loss: 0.00084 | Running loss: 0.03921\n","Epoch: 9 | Iteration: 33196 | Classification loss: 0.01308 | Regression loss: 0.02051 | Objectness loss: 0.00006 | RPN Regression loss: 0.00118 | Running loss: 0.03483\n","Epoch: 9 | Iteration: 33197 | Classification loss: 0.01274 | Regression loss: 0.02724 | Objectness loss: 0.00033 | RPN Regression loss: 0.00379 | Running loss: 0.04411\n","Epoch: 9 | Iteration: 33198 | Classification loss: 0.01797 | Regression loss: 0.01618 | Objectness loss: 0.00041 | RPN Regression loss: 0.00400 | Running loss: 0.03856\n","Epoch: 9 | Iteration: 33199 | Classification loss: 0.01431 | Regression loss: 0.01605 | Objectness loss: 0.00049 | RPN Regression loss: 0.00303 | Running loss: 0.03388\n","Epoch: 9 | Iteration: 33200 | Classification loss: 0.01140 | Regression loss: 0.01598 | Objectness loss: 0.00008 | RPN Regression loss: 0.00132 | Running loss: 0.02878\n","Epoch: 9 | Iteration: 33201 | Classification loss: 0.01906 | Regression loss: 0.06222 | Objectness loss: 0.00017 | RPN Regression loss: 0.00709 | Running loss: 0.08853\n","Epoch: 9 | Iteration: 33202 | Classification loss: 0.02180 | Regression loss: 0.03139 | Objectness loss: 0.00030 | RPN Regression loss: 0.00110 | Running loss: 0.05459\n","Epoch: 9 | Iteration: 33203 | Classification loss: 0.04971 | Regression loss: 0.02827 | Objectness loss: 0.00568 | RPN Regression loss: 0.00120 | Running loss: 0.08486\n","Epoch: 9 | Iteration: 33204 | Classification loss: 0.00706 | Regression loss: 0.01406 | Objectness loss: 0.00011 | RPN Regression loss: 0.00198 | Running loss: 0.02322\n","Epoch: 9 | Iteration: 33205 | Classification loss: 0.00884 | Regression loss: 0.02302 | Objectness loss: 0.00052 | RPN Regression loss: 0.00179 | Running loss: 0.03416\n","Epoch: 9 | Iteration: 33206 | Classification loss: 0.01884 | Regression loss: 0.02887 | Objectness loss: 0.00043 | RPN Regression loss: 0.00166 | Running loss: 0.04980\n","Epoch: 9 | Iteration: 33207 | Classification loss: 0.00853 | Regression loss: 0.01365 | Objectness loss: 0.00003 | RPN Regression loss: 0.00129 | Running loss: 0.02351\n","Epoch: 9 | Iteration: 33208 | Classification loss: 0.01215 | Regression loss: 0.01910 | Objectness loss: 0.00033 | RPN Regression loss: 0.00187 | Running loss: 0.03346\n","Epoch: 9 | Iteration: 33209 | Classification loss: 0.01463 | Regression loss: 0.02792 | Objectness loss: 0.00245 | RPN Regression loss: 0.00195 | Running loss: 0.04695\n","Epoch: 9 | Iteration: 33210 | Classification loss: 0.02947 | Regression loss: 0.05778 | Objectness loss: 0.00114 | RPN Regression loss: 0.00128 | Running loss: 0.08967\n","Epoch: 9 | Iteration: 33211 | Classification loss: 0.03165 | Regression loss: 0.03010 | Objectness loss: 0.00176 | RPN Regression loss: 0.00101 | Running loss: 0.06453\n","Epoch: 9 | Iteration: 33212 | Classification loss: 0.00453 | Regression loss: 0.01838 | Objectness loss: 0.00106 | RPN Regression loss: 0.00185 | Running loss: 0.02583\n","Epoch: 9 | Iteration: 33213 | Classification loss: 0.02051 | Regression loss: 0.01737 | Objectness loss: 0.00086 | RPN Regression loss: 0.00227 | Running loss: 0.04101\n","Epoch: 9 | Iteration: 33214 | Classification loss: 0.03673 | Regression loss: 0.02650 | Objectness loss: 0.00014 | RPN Regression loss: 0.00124 | Running loss: 0.06460\n","Epoch: 9 | Iteration: 33215 | Classification loss: 0.02088 | Regression loss: 0.02532 | Objectness loss: 0.00050 | RPN Regression loss: 0.00309 | Running loss: 0.04978\n","Epoch: 9 | Iteration: 33216 | Classification loss: 0.01643 | Regression loss: 0.03136 | Objectness loss: 0.00087 | RPN Regression loss: 0.00206 | Running loss: 0.05071\n","Epoch: 9 | Iteration: 33217 | Classification loss: 0.03130 | Regression loss: 0.02012 | Objectness loss: 0.00031 | RPN Regression loss: 0.00660 | Running loss: 0.05834\n","Epoch: 9 | Iteration: 33218 | Classification loss: 0.01291 | Regression loss: 0.02462 | Objectness loss: 0.00098 | RPN Regression loss: 0.00177 | Running loss: 0.04028\n","Epoch: 9 | Iteration: 33219 | Classification loss: 0.01672 | Regression loss: 0.02171 | Objectness loss: 0.00279 | RPN Regression loss: 0.00185 | Running loss: 0.04307\n","Epoch: 9 | Iteration: 33220 | Classification loss: 0.03971 | Regression loss: 0.05252 | Objectness loss: 0.00123 | RPN Regression loss: 0.00244 | Running loss: 0.09591\n","Epoch: 9 | Iteration: 33221 | Classification loss: 0.02646 | Regression loss: 0.02703 | Objectness loss: 0.00341 | RPN Regression loss: 0.00218 | Running loss: 0.05907\n","Epoch: 9 | Iteration: 33222 | Classification loss: 0.01954 | Regression loss: 0.02763 | Objectness loss: 0.00306 | RPN Regression loss: 0.00100 | Running loss: 0.05124\n","Epoch: 9 | Iteration: 33223 | Classification loss: 0.01259 | Regression loss: 0.01489 | Objectness loss: 0.00019 | RPN Regression loss: 0.00655 | Running loss: 0.03421\n","Epoch: 9 | Iteration: 33224 | Classification loss: 0.03325 | Regression loss: 0.03616 | Objectness loss: 0.03088 | RPN Regression loss: 0.00143 | Running loss: 0.10172\n","Epoch: 9 | Iteration: 33225 | Classification loss: 0.01922 | Regression loss: 0.02276 | Objectness loss: 0.00003 | RPN Regression loss: 0.00244 | Running loss: 0.04445\n","Epoch: 9 | Iteration: 33226 | Classification loss: 0.02571 | Regression loss: 0.02181 | Objectness loss: 0.00045 | RPN Regression loss: 0.00380 | Running loss: 0.05177\n","Epoch: 9 | Iteration: 33227 | Classification loss: 0.02111 | Regression loss: 0.01825 | Objectness loss: 0.00011 | RPN Regression loss: 0.00063 | Running loss: 0.04009\n","Epoch: 9 | Iteration: 33228 | Classification loss: 0.01273 | Regression loss: 0.02780 | Objectness loss: 0.00112 | RPN Regression loss: 0.00082 | Running loss: 0.04247\n","Epoch: 9 | Iteration: 33229 | Classification loss: 0.02028 | Regression loss: 0.04419 | Objectness loss: 0.00018 | RPN Regression loss: 0.00262 | Running loss: 0.06728\n","Epoch: 9 | Iteration: 33230 | Classification loss: 0.03109 | Regression loss: 0.02771 | Objectness loss: 0.00018 | RPN Regression loss: 0.00080 | Running loss: 0.05977\n","Epoch: 9 | Iteration: 33231 | Classification loss: 0.02054 | Regression loss: 0.01649 | Objectness loss: 0.00446 | RPN Regression loss: 0.00179 | Running loss: 0.04327\n","Epoch: 9 | Iteration: 33232 | Classification loss: 0.00941 | Regression loss: 0.01475 | Objectness loss: 0.00034 | RPN Regression loss: 0.03124 | Running loss: 0.05574\n","Epoch: 9 | Iteration: 33233 | Classification loss: 0.01140 | Regression loss: 0.01975 | Objectness loss: 0.00093 | RPN Regression loss: 0.00066 | Running loss: 0.03274\n","Epoch: 9 | Iteration: 33234 | Classification loss: 0.01946 | Regression loss: 0.03589 | Objectness loss: 0.00127 | RPN Regression loss: 0.01482 | Running loss: 0.07144\n","Epoch: 9 | Iteration: 33235 | Classification loss: 0.01406 | Regression loss: 0.02382 | Objectness loss: 0.00011 | RPN Regression loss: 0.00089 | Running loss: 0.03888\n","Epoch: 9 | Iteration: 33236 | Classification loss: 0.01328 | Regression loss: 0.01951 | Objectness loss: 0.00027 | RPN Regression loss: 0.00055 | Running loss: 0.03360\n","Epoch: 9 | Iteration: 33237 | Classification loss: 0.02576 | Regression loss: 0.01964 | Objectness loss: 0.00013 | RPN Regression loss: 0.00103 | Running loss: 0.04655\n","Epoch: 9 | Iteration: 33238 | Classification loss: 0.04785 | Regression loss: 0.03987 | Objectness loss: 0.00272 | RPN Regression loss: 0.00364 | Running loss: 0.09408\n","Epoch: 9 | Iteration: 33239 | Classification loss: 0.00740 | Regression loss: 0.02456 | Objectness loss: 0.00006 | RPN Regression loss: 0.00066 | Running loss: 0.03268\n","Epoch: 9 | Iteration: 33240 | Classification loss: 0.00924 | Regression loss: 0.01597 | Objectness loss: 0.00007 | RPN Regression loss: 0.00044 | Running loss: 0.02572\n","Epoch: 9 | Iteration: 33241 | Classification loss: 0.00919 | Regression loss: 0.01377 | Objectness loss: 0.00073 | RPN Regression loss: 0.00119 | Running loss: 0.02489\n","Epoch: 9 | Iteration: 33242 | Classification loss: 0.03554 | Regression loss: 0.03497 | Objectness loss: 0.00456 | RPN Regression loss: 0.00528 | Running loss: 0.08035\n","Epoch: 9 | Iteration: 33243 | Classification loss: 0.01029 | Regression loss: 0.01100 | Objectness loss: 0.00016 | RPN Regression loss: 0.00121 | Running loss: 0.02266\n","Epoch: 9 | Iteration: 33244 | Classification loss: 0.02104 | Regression loss: 0.02011 | Objectness loss: 0.00170 | RPN Regression loss: 0.00204 | Running loss: 0.04487\n","Epoch: 9 | Iteration: 33245 | Classification loss: 0.03701 | Regression loss: 0.02623 | Objectness loss: 0.00508 | RPN Regression loss: 0.00106 | Running loss: 0.06938\n","Epoch: 9 | Iteration: 33246 | Classification loss: 0.00999 | Regression loss: 0.02038 | Objectness loss: 0.00084 | RPN Regression loss: 0.00233 | Running loss: 0.03355\n","Epoch: 9 | Iteration: 33247 | Classification loss: 0.02019 | Regression loss: 0.03689 | Objectness loss: 0.00098 | RPN Regression loss: 0.00173 | Running loss: 0.05978\n","Epoch: 9 | Iteration: 33248 | Classification loss: 0.00958 | Regression loss: 0.02089 | Objectness loss: 0.00031 | RPN Regression loss: 0.00304 | Running loss: 0.03382\n","Epoch: 9 | Iteration: 33249 | Classification loss: 0.05882 | Regression loss: 0.04456 | Objectness loss: 0.01246 | RPN Regression loss: 0.00147 | Running loss: 0.11731\n","Epoch: 9 | Iteration: 33250 | Classification loss: 0.02443 | Regression loss: 0.03086 | Objectness loss: 0.00020 | RPN Regression loss: 0.00122 | Running loss: 0.05671\n","Epoch: 9 | Iteration: 33251 | Classification loss: 0.02583 | Regression loss: 0.03027 | Objectness loss: 0.00149 | RPN Regression loss: 0.00141 | Running loss: 0.05901\n","Epoch: 9 | Iteration: 33252 | Classification loss: 0.00891 | Regression loss: 0.01779 | Objectness loss: 0.00098 | RPN Regression loss: 0.00101 | Running loss: 0.02869\n","Epoch: 9 | Iteration: 33253 | Classification loss: 0.01517 | Regression loss: 0.01718 | Objectness loss: 0.00015 | RPN Regression loss: 0.00132 | Running loss: 0.03382\n","Epoch: 9 | Iteration: 33254 | Classification loss: 0.00553 | Regression loss: 0.01918 | Objectness loss: 0.00038 | RPN Regression loss: 0.00062 | Running loss: 0.02570\n","Epoch: 9 | Iteration: 33255 | Classification loss: 0.02393 | Regression loss: 0.02408 | Objectness loss: 0.00031 | RPN Regression loss: 0.00187 | Running loss: 0.05019\n","Epoch: 9 | Iteration: 33256 | Classification loss: 0.01029 | Regression loss: 0.01847 | Objectness loss: 0.00103 | RPN Regression loss: 0.00034 | Running loss: 0.03014\n","Epoch: 9 | Iteration: 33257 | Classification loss: 0.00660 | Regression loss: 0.02268 | Objectness loss: 0.00043 | RPN Regression loss: 0.00061 | Running loss: 0.03033\n","Epoch: 9 | Iteration: 33258 | Classification loss: 0.04507 | Regression loss: 0.02740 | Objectness loss: 0.00149 | RPN Regression loss: 0.00030 | Running loss: 0.07427\n","Epoch: 9 | Iteration: 33259 | Classification loss: 0.02912 | Regression loss: 0.03373 | Objectness loss: 0.00084 | RPN Regression loss: 0.00162 | Running loss: 0.06531\n","Epoch: 9 | Iteration: 33260 | Classification loss: 0.02276 | Regression loss: 0.02348 | Objectness loss: 0.00051 | RPN Regression loss: 0.00370 | Running loss: 0.05045\n","Epoch: 9 | Iteration: 33261 | Classification loss: 0.00601 | Regression loss: 0.01616 | Objectness loss: 0.00023 | RPN Regression loss: 0.00137 | Running loss: 0.02377\n","Epoch: 9 | Iteration: 33262 | Classification loss: 0.04167 | Regression loss: 0.05281 | Objectness loss: 0.00470 | RPN Regression loss: 0.00259 | Running loss: 0.10177\n","Epoch: 9 | Iteration: 33263 | Classification loss: 0.02427 | Regression loss: 0.03814 | Objectness loss: 0.00189 | RPN Regression loss: 0.00112 | Running loss: 0.06542\n","Epoch: 9 | Iteration: 33264 | Classification loss: 0.02071 | Regression loss: 0.02223 | Objectness loss: 0.00173 | RPN Regression loss: 0.00229 | Running loss: 0.04696\n","Epoch: 9 | Iteration: 33265 | Classification loss: 0.03311 | Regression loss: 0.01796 | Objectness loss: 0.00007 | RPN Regression loss: 0.00122 | Running loss: 0.05237\n","Epoch: 9 | Iteration: 33266 | Classification loss: 0.02134 | Regression loss: 0.02083 | Objectness loss: 0.00394 | RPN Regression loss: 0.01041 | Running loss: 0.05652\n","Epoch: 9 | Iteration: 33267 | Classification loss: 0.00822 | Regression loss: 0.01852 | Objectness loss: 0.00027 | RPN Regression loss: 0.00221 | Running loss: 0.02922\n","Epoch: 9 | Iteration: 33268 | Classification loss: 0.02691 | Regression loss: 0.01886 | Objectness loss: 0.00022 | RPN Regression loss: 0.00104 | Running loss: 0.04702\n","Epoch: 9 | Iteration: 33269 | Classification loss: 0.01492 | Regression loss: 0.02079 | Objectness loss: 0.00069 | RPN Regression loss: 0.00093 | Running loss: 0.03733\n","Epoch: 9 | Iteration: 33270 | Classification loss: 0.02330 | Regression loss: 0.04236 | Objectness loss: 0.02381 | RPN Regression loss: 0.00386 | Running loss: 0.09333\n","Epoch: 9 | Iteration: 33271 | Classification loss: 0.01945 | Regression loss: 0.01690 | Objectness loss: 0.00161 | RPN Regression loss: 0.00096 | Running loss: 0.03892\n","Epoch: 9 | Iteration: 33272 | Classification loss: 0.00991 | Regression loss: 0.01452 | Objectness loss: 0.00007 | RPN Regression loss: 0.00121 | Running loss: 0.02571\n","Epoch: 9 | Iteration: 33273 | Classification loss: 0.02776 | Regression loss: 0.03611 | Objectness loss: 0.00140 | RPN Regression loss: 0.00158 | Running loss: 0.06685\n","Epoch: 9 | Iteration: 33274 | Classification loss: 0.01951 | Regression loss: 0.03214 | Objectness loss: 0.00091 | RPN Regression loss: 0.00724 | Running loss: 0.05980\n","Epoch: 9 | Iteration: 33275 | Classification loss: 0.01207 | Regression loss: 0.01996 | Objectness loss: 0.00119 | RPN Regression loss: 0.00404 | Running loss: 0.03727\n","Epoch: 9 | Iteration: 33276 | Classification loss: 0.01195 | Regression loss: 0.01505 | Objectness loss: 0.00533 | RPN Regression loss: 0.00132 | Running loss: 0.03365\n","Epoch: 9 | Iteration: 33277 | Classification loss: 0.00569 | Regression loss: 0.00955 | Objectness loss: 0.00633 | RPN Regression loss: 0.00120 | Running loss: 0.02277\n","Epoch: 9 | Iteration: 33278 | Classification loss: 0.01748 | Regression loss: 0.03076 | Objectness loss: 0.00008 | RPN Regression loss: 0.00160 | Running loss: 0.04992\n","Epoch: 9 | Iteration: 33279 | Classification loss: 0.02644 | Regression loss: 0.03353 | Objectness loss: 0.00032 | RPN Regression loss: 0.00372 | Running loss: 0.06402\n","Epoch: 9 | Iteration: 33280 | Classification loss: 0.01005 | Regression loss: 0.01977 | Objectness loss: 0.00013 | RPN Regression loss: 0.00176 | Running loss: 0.03171\n","Epoch: 9 | Iteration: 33281 | Classification loss: 0.01373 | Regression loss: 0.04692 | Objectness loss: 0.00034 | RPN Regression loss: 0.00263 | Running loss: 0.06362\n","Epoch: 9 | Iteration: 33282 | Classification loss: 0.00679 | Regression loss: 0.02251 | Objectness loss: 0.00023 | RPN Regression loss: 0.00058 | Running loss: 0.03011\n","Epoch: 9 | Iteration: 33283 | Classification loss: 0.02044 | Regression loss: 0.03494 | Objectness loss: 0.00036 | RPN Regression loss: 0.00359 | Running loss: 0.05932\n","Epoch: 9 | Iteration: 33284 | Classification loss: 0.01431 | Regression loss: 0.03008 | Objectness loss: 0.00066 | RPN Regression loss: 0.00091 | Running loss: 0.04596\n","Epoch: 9 | Iteration: 33285 | Classification loss: 0.02094 | Regression loss: 0.02993 | Objectness loss: 0.00002 | RPN Regression loss: 0.00054 | Running loss: 0.05143\n","Epoch: 9 | Iteration: 33286 | Classification loss: 0.05012 | Regression loss: 0.08158 | Objectness loss: 0.00179 | RPN Regression loss: 0.00185 | Running loss: 0.13533\n","Epoch: 9 | Iteration: 33287 | Classification loss: 0.01411 | Regression loss: 0.04037 | Objectness loss: 0.00190 | RPN Regression loss: 0.00125 | Running loss: 0.05763\n","Epoch: 9 | Iteration: 33288 | Classification loss: 0.02945 | Regression loss: 0.03032 | Objectness loss: 0.00003 | RPN Regression loss: 0.00147 | Running loss: 0.06126\n","Epoch: 9 | Iteration: 33289 | Classification loss: 0.01229 | Regression loss: 0.04471 | Objectness loss: 0.00019 | RPN Regression loss: 0.00204 | Running loss: 0.05924\n","Epoch: 9 | Iteration: 33290 | Classification loss: 0.01259 | Regression loss: 0.03863 | Objectness loss: 0.00066 | RPN Regression loss: 0.00065 | Running loss: 0.05253\n","Epoch: 9 | Iteration: 33291 | Classification loss: 0.02837 | Regression loss: 0.01850 | Objectness loss: 0.00005 | RPN Regression loss: 0.00042 | Running loss: 0.04734\n","Epoch: 9 | Iteration: 33292 | Classification loss: 0.02174 | Regression loss: 0.01811 | Objectness loss: 0.00363 | RPN Regression loss: 0.00150 | Running loss: 0.04497\n","Epoch: 9 | Iteration: 33293 | Classification loss: 0.01434 | Regression loss: 0.02710 | Objectness loss: 0.00267 | RPN Regression loss: 0.00329 | Running loss: 0.04740\n","Epoch: 9 | Iteration: 33294 | Classification loss: 0.03539 | Regression loss: 0.04332 | Objectness loss: 0.00015 | RPN Regression loss: 0.00091 | Running loss: 0.07977\n","Epoch: 9 | Iteration: 33295 | Classification loss: 0.02249 | Regression loss: 0.03042 | Objectness loss: 0.00008 | RPN Regression loss: 0.00056 | Running loss: 0.05355\n","Epoch: 9 | Iteration: 33296 | Classification loss: 0.05715 | Regression loss: 0.04363 | Objectness loss: 0.00890 | RPN Regression loss: 0.00177 | Running loss: 0.11145\n","Epoch: 9 | Iteration: 33297 | Classification loss: 0.02780 | Regression loss: 0.03113 | Objectness loss: 0.00048 | RPN Regression loss: 0.00090 | Running loss: 0.06030\n","Epoch: 9 | Iteration: 33298 | Classification loss: 0.01721 | Regression loss: 0.02454 | Objectness loss: 0.00053 | RPN Regression loss: 0.00257 | Running loss: 0.04485\n","Epoch: 9 | Iteration: 33299 | Classification loss: 0.01486 | Regression loss: 0.04050 | Objectness loss: 0.00401 | RPN Regression loss: 0.00229 | Running loss: 0.06166\n","Epoch: 9 | Iteration: 33300 | Classification loss: 0.01600 | Regression loss: 0.01923 | Objectness loss: 0.00031 | RPN Regression loss: 0.00171 | Running loss: 0.03725\n","Epoch: 9 | Iteration: 33301 | Classification loss: 0.01636 | Regression loss: 0.01841 | Objectness loss: 0.00140 | RPN Regression loss: 0.00078 | Running loss: 0.03695\n","Epoch: 9 | Iteration: 33302 | Classification loss: 0.00918 | Regression loss: 0.01366 | Objectness loss: 0.00022 | RPN Regression loss: 0.00303 | Running loss: 0.02608\n","Epoch: 9 | Iteration: 33303 | Classification loss: 0.02034 | Regression loss: 0.03639 | Objectness loss: 0.00034 | RPN Regression loss: 0.00060 | Running loss: 0.05767\n","Epoch: 9 | Iteration: 33304 | Classification loss: 0.01114 | Regression loss: 0.02729 | Objectness loss: 0.00028 | RPN Regression loss: 0.00308 | Running loss: 0.04179\n","Epoch: 9 | Iteration: 33305 | Classification loss: 0.00853 | Regression loss: 0.02100 | Objectness loss: 0.00030 | RPN Regression loss: 0.00038 | Running loss: 0.03021\n","Epoch: 9 | Iteration: 33306 | Classification loss: 0.02133 | Regression loss: 0.02659 | Objectness loss: 0.00071 | RPN Regression loss: 0.00097 | Running loss: 0.04960\n","Epoch: 9 | Iteration: 33307 | Classification loss: 0.00891 | Regression loss: 0.01549 | Objectness loss: 0.00008 | RPN Regression loss: 0.00042 | Running loss: 0.02490\n","Epoch: 9 | Iteration: 33308 | Classification loss: 0.00890 | Regression loss: 0.01600 | Objectness loss: 0.00023 | RPN Regression loss: 0.00072 | Running loss: 0.02585\n","Epoch: 9 | Iteration: 33309 | Classification loss: 0.01169 | Regression loss: 0.02206 | Objectness loss: 0.00046 | RPN Regression loss: 0.00591 | Running loss: 0.04012\n","Epoch: 9 | Iteration: 33310 | Classification loss: 0.00906 | Regression loss: 0.02427 | Objectness loss: 0.00182 | RPN Regression loss: 0.00159 | Running loss: 0.03673\n","Epoch: 9 | Iteration: 33311 | Classification loss: 0.02125 | Regression loss: 0.01978 | Objectness loss: 0.00064 | RPN Regression loss: 0.04395 | Running loss: 0.08562\n","Epoch: 9 | Iteration: 33312 | Classification loss: 0.03228 | Regression loss: 0.03730 | Objectness loss: 0.00008 | RPN Regression loss: 0.00131 | Running loss: 0.07097\n","Epoch: 9 | Iteration: 33313 | Classification loss: 0.00905 | Regression loss: 0.01963 | Objectness loss: 0.00088 | RPN Regression loss: 0.00104 | Running loss: 0.03060\n","Epoch: 9 | Iteration: 33314 | Classification loss: 0.01061 | Regression loss: 0.02421 | Objectness loss: 0.00013 | RPN Regression loss: 0.00278 | Running loss: 0.03773\n","Epoch: 9 | Iteration: 33315 | Classification loss: 0.01350 | Regression loss: 0.01886 | Objectness loss: 0.00005 | RPN Regression loss: 0.00100 | Running loss: 0.03341\n","Epoch: 9 | Iteration: 33316 | Classification loss: 0.00872 | Regression loss: 0.02731 | Objectness loss: 0.00007 | RPN Regression loss: 0.00365 | Running loss: 0.03975\n","Epoch: 9 | Iteration: 33317 | Classification loss: 0.02106 | Regression loss: 0.02105 | Objectness loss: 0.00018 | RPN Regression loss: 0.00104 | Running loss: 0.04334\n","Epoch: 9 | Iteration: 33318 | Classification loss: 0.02032 | Regression loss: 0.01912 | Objectness loss: 0.00271 | RPN Regression loss: 0.00606 | Running loss: 0.04821\n","Epoch: 9 | Iteration: 33319 | Classification loss: 0.01256 | Regression loss: 0.01962 | Objectness loss: 0.00007 | RPN Regression loss: 0.00067 | Running loss: 0.03292\n","Epoch: 9 | Iteration: 33320 | Classification loss: 0.01193 | Regression loss: 0.02317 | Objectness loss: 0.00002 | RPN Regression loss: 0.00123 | Running loss: 0.03636\n","Epoch: 9 | Iteration: 33321 | Classification loss: 0.00869 | Regression loss: 0.01737 | Objectness loss: 0.00005 | RPN Regression loss: 0.00074 | Running loss: 0.02685\n","Epoch: 9 | Iteration: 33322 | Classification loss: 0.01144 | Regression loss: 0.02778 | Objectness loss: 0.00051 | RPN Regression loss: 0.00084 | Running loss: 0.04056\n","Epoch: 9 | Iteration: 33323 | Classification loss: 0.02134 | Regression loss: 0.01572 | Objectness loss: 0.00231 | RPN Regression loss: 0.00203 | Running loss: 0.04140\n","Epoch: 9 | Iteration: 33324 | Classification loss: 0.01589 | Regression loss: 0.01901 | Objectness loss: 0.00031 | RPN Regression loss: 0.00196 | Running loss: 0.03718\n","Epoch: 9 | Iteration: 33325 | Classification loss: 0.03233 | Regression loss: 0.03688 | Objectness loss: 0.00298 | RPN Regression loss: 0.00229 | Running loss: 0.07448\n","Epoch: 9 | Iteration: 33326 | Classification loss: 0.01262 | Regression loss: 0.02811 | Objectness loss: 0.00006 | RPN Regression loss: 0.00316 | Running loss: 0.04395\n","Epoch: 9 | Iteration: 33327 | Classification loss: 0.02641 | Regression loss: 0.03982 | Objectness loss: 0.00332 | RPN Regression loss: 0.00549 | Running loss: 0.07504\n","Epoch: 9 | Iteration: 33328 | Classification loss: 0.00634 | Regression loss: 0.01628 | Objectness loss: 0.00008 | RPN Regression loss: 0.00224 | Running loss: 0.02494\n","Epoch: 9 | Iteration: 33329 | Classification loss: 0.01686 | Regression loss: 0.04173 | Objectness loss: 0.00128 | RPN Regression loss: 0.00299 | Running loss: 0.06286\n","Epoch: 9 | Iteration: 33330 | Classification loss: 0.01870 | Regression loss: 0.01508 | Objectness loss: 0.00336 | RPN Regression loss: 0.00227 | Running loss: 0.03941\n","Epoch: 9 | Iteration: 33331 | Classification loss: 0.03762 | Regression loss: 0.03568 | Objectness loss: 0.00171 | RPN Regression loss: 0.00249 | Running loss: 0.07750\n","Epoch: 9 | Iteration: 33332 | Classification loss: 0.02977 | Regression loss: 0.02954 | Objectness loss: 0.00034 | RPN Regression loss: 0.00147 | Running loss: 0.06112\n","Epoch: 9 | Iteration: 33333 | Classification loss: 0.02386 | Regression loss: 0.02303 | Objectness loss: 0.00009 | RPN Regression loss: 0.00053 | Running loss: 0.04751\n","Epoch: 9 | Iteration: 33334 | Classification loss: 0.03342 | Regression loss: 0.03956 | Objectness loss: 0.00879 | RPN Regression loss: 0.01603 | Running loss: 0.09779\n","Epoch: 9 | Iteration: 33335 | Classification loss: 0.02878 | Regression loss: 0.02890 | Objectness loss: 0.02777 | RPN Regression loss: 0.04268 | Running loss: 0.12813\n","Epoch: 9 | Iteration: 33336 | Classification loss: 0.01180 | Regression loss: 0.02919 | Objectness loss: 0.00019 | RPN Regression loss: 0.00122 | Running loss: 0.04241\n","Epoch: 9 | Iteration: 33337 | Classification loss: 0.00545 | Regression loss: 0.01453 | Objectness loss: 0.00325 | RPN Regression loss: 0.00218 | Running loss: 0.02540\n","Epoch: 9 | Iteration: 33338 | Classification loss: 0.01948 | Regression loss: 0.02432 | Objectness loss: 0.00024 | RPN Regression loss: 0.00053 | Running loss: 0.04457\n","Epoch: 9 | Iteration: 33339 | Classification loss: 0.00745 | Regression loss: 0.01945 | Objectness loss: 0.00338 | RPN Regression loss: 0.00231 | Running loss: 0.03259\n","Epoch: 9 | Iteration: 33340 | Classification loss: 0.02786 | Regression loss: 0.03443 | Objectness loss: 0.00075 | RPN Regression loss: 0.01028 | Running loss: 0.07332\n","Epoch: 9 | Iteration: 33341 | Classification loss: 0.01998 | Regression loss: 0.05142 | Objectness loss: 0.00008 | RPN Regression loss: 0.00287 | Running loss: 0.07434\n","Epoch: 9 | Iteration: 33342 | Classification loss: 0.01325 | Regression loss: 0.03497 | Objectness loss: 0.00104 | RPN Regression loss: 0.00136 | Running loss: 0.05062\n","Epoch: 9 | Iteration: 33343 | Classification loss: 0.03712 | Regression loss: 0.06472 | Objectness loss: 0.00216 | RPN Regression loss: 0.00116 | Running loss: 0.10516\n","Epoch: 9 | Iteration: 33344 | Classification loss: 0.01401 | Regression loss: 0.01332 | Objectness loss: 0.00033 | RPN Regression loss: 0.00062 | Running loss: 0.02829\n","Epoch: 9 | Iteration: 33345 | Classification loss: 0.01730 | Regression loss: 0.01639 | Objectness loss: 0.00037 | RPN Regression loss: 0.00101 | Running loss: 0.03507\n","Epoch: 9 | Iteration: 33346 | Classification loss: 0.02751 | Regression loss: 0.02889 | Objectness loss: 0.00279 | RPN Regression loss: 0.00320 | Running loss: 0.06239\n","Epoch: 9 | Iteration: 33347 | Classification loss: 0.01093 | Regression loss: 0.01952 | Objectness loss: 0.00395 | RPN Regression loss: 0.00287 | Running loss: 0.03728\n","Epoch: 9 | Iteration: 33348 | Classification loss: 0.02395 | Regression loss: 0.04063 | Objectness loss: 0.00233 | RPN Regression loss: 0.00068 | Running loss: 0.06759\n","Epoch: 9 | Iteration: 33349 | Classification loss: 0.00824 | Regression loss: 0.01178 | Objectness loss: 0.00063 | RPN Regression loss: 0.00778 | Running loss: 0.02844\n","Epoch: 9 | Iteration: 33350 | Classification loss: 0.01440 | Regression loss: 0.02991 | Objectness loss: 0.00046 | RPN Regression loss: 0.00095 | Running loss: 0.04572\n","Epoch: 9 | Iteration: 33351 | Classification loss: 0.01300 | Regression loss: 0.02299 | Objectness loss: 0.00061 | RPN Regression loss: 0.00078 | Running loss: 0.03738\n","Epoch: 9 | Iteration: 33352 | Classification loss: 0.01341 | Regression loss: 0.02379 | Objectness loss: 0.00075 | RPN Regression loss: 0.00083 | Running loss: 0.03878\n","Epoch: 9 | Iteration: 33353 | Classification loss: 0.02251 | Regression loss: 0.01522 | Objectness loss: 0.00143 | RPN Regression loss: 0.00145 | Running loss: 0.04061\n","Epoch: 9 | Iteration: 33354 | Classification loss: 0.02617 | Regression loss: 0.04414 | Objectness loss: 0.00018 | RPN Regression loss: 0.00103 | Running loss: 0.07152\n","Epoch: 9 | Iteration: 33355 | Classification loss: 0.00502 | Regression loss: 0.01548 | Objectness loss: 0.00166 | RPN Regression loss: 0.00080 | Running loss: 0.02296\n","Epoch: 9 | Iteration: 33356 | Classification loss: 0.02089 | Regression loss: 0.04551 | Objectness loss: 0.00294 | RPN Regression loss: 0.00427 | Running loss: 0.07361\n","Epoch: 9 | Iteration: 33357 | Classification loss: 0.01951 | Regression loss: 0.02205 | Objectness loss: 0.00986 | RPN Regression loss: 0.00407 | Running loss: 0.05549\n","Epoch: 9 | Iteration: 33358 | Classification loss: 0.01326 | Regression loss: 0.03038 | Objectness loss: 0.00022 | RPN Regression loss: 0.00193 | Running loss: 0.04580\n","Epoch: 9 | Iteration: 33359 | Classification loss: 0.00990 | Regression loss: 0.01434 | Objectness loss: 0.00044 | RPN Regression loss: 0.00154 | Running loss: 0.02623\n","Epoch: 9 | Iteration: 33360 | Classification loss: 0.01599 | Regression loss: 0.01583 | Objectness loss: 0.00240 | RPN Regression loss: 0.00076 | Running loss: 0.03498\n","Epoch: 9 | Iteration: 33361 | Classification loss: 0.00848 | Regression loss: 0.01268 | Objectness loss: 0.00180 | RPN Regression loss: 0.00134 | Running loss: 0.02431\n","Epoch: 9 | Iteration: 33362 | Classification loss: 0.02184 | Regression loss: 0.02350 | Objectness loss: 0.00059 | RPN Regression loss: 0.00071 | Running loss: 0.04664\n","Epoch: 9 | Iteration: 33363 | Classification loss: 0.01120 | Regression loss: 0.01503 | Objectness loss: 0.00016 | RPN Regression loss: 0.00501 | Running loss: 0.03141\n","Epoch: 9 | Iteration: 33364 | Classification loss: 0.02345 | Regression loss: 0.02169 | Objectness loss: 0.00089 | RPN Regression loss: 0.00113 | Running loss: 0.04716\n","Epoch: 9 | Iteration: 33365 | Classification loss: 0.00760 | Regression loss: 0.01473 | Objectness loss: 0.00045 | RPN Regression loss: 0.00156 | Running loss: 0.02433\n","Epoch: 9 | Iteration: 33366 | Classification loss: 0.04504 | Regression loss: 0.04073 | Objectness loss: 0.00176 | RPN Regression loss: 0.00581 | Running loss: 0.09335\n","Epoch: 9 | Iteration: 33367 | Classification loss: 0.00956 | Regression loss: 0.02005 | Objectness loss: 0.00014 | RPN Regression loss: 0.00122 | Running loss: 0.03097\n","Epoch: 9 | Iteration: 33368 | Classification loss: 0.00655 | Regression loss: 0.02344 | Objectness loss: 0.00007 | RPN Regression loss: 0.00092 | Running loss: 0.03098\n","Epoch: 9 | Iteration: 33369 | Classification loss: 0.00792 | Regression loss: 0.01872 | Objectness loss: 0.00018 | RPN Regression loss: 0.00179 | Running loss: 0.02860\n","Epoch: 9 | Iteration: 33370 | Classification loss: 0.02071 | Regression loss: 0.02621 | Objectness loss: 0.00115 | RPN Regression loss: 0.00098 | Running loss: 0.04906\n","Epoch: 9 | Iteration: 33371 | Classification loss: 0.00874 | Regression loss: 0.02314 | Objectness loss: 0.00116 | RPN Regression loss: 0.00215 | Running loss: 0.03519\n","Epoch: 9 | Iteration: 33372 | Classification loss: 0.01993 | Regression loss: 0.01643 | Objectness loss: 0.00013 | RPN Regression loss: 0.00101 | Running loss: 0.03750\n","Epoch: 9 | Iteration: 33373 | Classification loss: 0.01414 | Regression loss: 0.02619 | Objectness loss: 0.00345 | RPN Regression loss: 0.00153 | Running loss: 0.04531\n","Epoch: 9 | Iteration: 33374 | Classification loss: 0.02474 | Regression loss: 0.02544 | Objectness loss: 0.00329 | RPN Regression loss: 0.00426 | Running loss: 0.05773\n","Epoch: 9 | Iteration: 33375 | Classification loss: 0.00751 | Regression loss: 0.01905 | Objectness loss: 0.00024 | RPN Regression loss: 0.00388 | Running loss: 0.03068\n","Epoch: 9 | Iteration: 33376 | Classification loss: 0.01859 | Regression loss: 0.01786 | Objectness loss: 0.00029 | RPN Regression loss: 0.00085 | Running loss: 0.03758\n","Epoch: 9 | Iteration: 33377 | Classification loss: 0.04206 | Regression loss: 0.05384 | Objectness loss: 0.00050 | RPN Regression loss: 0.00414 | Running loss: 0.10054\n","Epoch: 9 | Iteration: 33378 | Classification loss: 0.00626 | Regression loss: 0.01387 | Objectness loss: 0.00000 | RPN Regression loss: 0.00082 | Running loss: 0.02096\n","Epoch: 9 | Iteration: 33379 | Classification loss: 0.01349 | Regression loss: 0.02791 | Objectness loss: 0.00015 | RPN Regression loss: 0.00071 | Running loss: 0.04226\n","Epoch: 9 | Iteration: 33380 | Classification loss: 0.01397 | Regression loss: 0.03488 | Objectness loss: 0.00033 | RPN Regression loss: 0.00133 | Running loss: 0.05050\n","Epoch: 9 | Iteration: 33381 | Classification loss: 0.02122 | Regression loss: 0.01231 | Objectness loss: 0.00080 | RPN Regression loss: 0.00148 | Running loss: 0.03581\n","Epoch: 9 | Iteration: 33382 | Classification loss: 0.02070 | Regression loss: 0.02832 | Objectness loss: 0.00073 | RPN Regression loss: 0.00211 | Running loss: 0.05186\n","Epoch: 9 | Iteration: 33383 | Classification loss: 0.03061 | Regression loss: 0.03767 | Objectness loss: 0.00008 | RPN Regression loss: 0.00044 | Running loss: 0.06880\n","Epoch: 9 | Iteration: 33384 | Classification loss: 0.01484 | Regression loss: 0.03610 | Objectness loss: 0.00004 | RPN Regression loss: 0.00058 | Running loss: 0.05156\n","Epoch: 9 | Iteration: 33385 | Classification loss: 0.01156 | Regression loss: 0.02249 | Objectness loss: 0.00024 | RPN Regression loss: 0.00158 | Running loss: 0.03587\n","Epoch: 9 | Iteration: 33386 | Classification loss: 0.02454 | Regression loss: 0.03455 | Objectness loss: 0.00128 | RPN Regression loss: 0.00338 | Running loss: 0.06374\n","Epoch: 9 | Iteration: 33387 | Classification loss: 0.01341 | Regression loss: 0.03014 | Objectness loss: 0.00145 | RPN Regression loss: 0.00071 | Running loss: 0.04571\n","Epoch: 9 | Iteration: 33388 | Classification loss: 0.01115 | Regression loss: 0.02633 | Objectness loss: 0.00080 | RPN Regression loss: 0.00123 | Running loss: 0.03950\n","Epoch: 9 | Iteration: 33389 | Classification loss: 0.02064 | Regression loss: 0.03445 | Objectness loss: 0.00060 | RPN Regression loss: 0.00237 | Running loss: 0.05807\n","Epoch: 9 | Iteration: 33390 | Classification loss: 0.00912 | Regression loss: 0.01648 | Objectness loss: 0.00004 | RPN Regression loss: 0.00216 | Running loss: 0.02780\n","Epoch: 9 | Iteration: 33391 | Classification loss: 0.01269 | Regression loss: 0.02605 | Objectness loss: 0.00362 | RPN Regression loss: 0.00104 | Running loss: 0.04339\n","Epoch: 9 | Iteration: 33392 | Classification loss: 0.01687 | Regression loss: 0.02845 | Objectness loss: 0.00005 | RPN Regression loss: 0.00110 | Running loss: 0.04647\n","Epoch: 9 | Iteration: 33393 | Classification loss: 0.00741 | Regression loss: 0.02318 | Objectness loss: 0.00004 | RPN Regression loss: 0.00046 | Running loss: 0.03109\n","Epoch: 9 | Iteration: 33394 | Classification loss: 0.00848 | Regression loss: 0.01472 | Objectness loss: 0.00011 | RPN Regression loss: 0.00185 | Running loss: 0.02516\n","Epoch: 9 | Iteration: 33395 | Classification loss: 0.04085 | Regression loss: 0.05370 | Objectness loss: 0.00379 | RPN Regression loss: 0.00202 | Running loss: 0.10036\n","Epoch: 9 | Iteration: 33396 | Classification loss: 0.04148 | Regression loss: 0.06514 | Objectness loss: 0.00007 | RPN Regression loss: 0.00605 | Running loss: 0.11274\n","Epoch: 9 | Iteration: 33397 | Classification loss: 0.02401 | Regression loss: 0.02206 | Objectness loss: 0.00120 | RPN Regression loss: 0.00091 | Running loss: 0.04818\n","Epoch: 9 | Iteration: 33398 | Classification loss: 0.02452 | Regression loss: 0.02794 | Objectness loss: 0.00171 | RPN Regression loss: 0.00476 | Running loss: 0.05893\n","Epoch: 9 | Iteration: 33399 | Classification loss: 0.01437 | Regression loss: 0.01585 | Objectness loss: 0.00009 | RPN Regression loss: 0.00026 | Running loss: 0.03057\n","Epoch: 9 | Iteration: 33400 | Classification loss: 0.02835 | Regression loss: 0.02270 | Objectness loss: 0.00005 | RPN Regression loss: 0.00096 | Running loss: 0.05206\n","Epoch: 9 | Iteration: 33401 | Classification loss: 0.01166 | Regression loss: 0.01632 | Objectness loss: 0.00098 | RPN Regression loss: 0.00422 | Running loss: 0.03318\n","Epoch: 9 | Iteration: 33402 | Classification loss: 0.01415 | Regression loss: 0.02952 | Objectness loss: 0.00108 | RPN Regression loss: 0.00119 | Running loss: 0.04595\n","Epoch: 9 | Iteration: 33403 | Classification loss: 0.02565 | Regression loss: 0.01499 | Objectness loss: 0.06084 | RPN Regression loss: 0.11842 | Running loss: 0.21990\n","Epoch: 9 | Iteration: 33404 | Classification loss: 0.01255 | Regression loss: 0.02325 | Objectness loss: 0.00139 | RPN Regression loss: 0.00089 | Running loss: 0.03807\n","Epoch: 9 | Iteration: 33405 | Classification loss: 0.02035 | Regression loss: 0.03651 | Objectness loss: 0.00124 | RPN Regression loss: 0.00117 | Running loss: 0.05928\n","Epoch: 9 | Iteration: 33406 | Classification loss: 0.01165 | Regression loss: 0.01179 | Objectness loss: 0.00011 | RPN Regression loss: 0.00344 | Running loss: 0.02699\n","Epoch: 9 | Iteration: 33407 | Classification loss: 0.00740 | Regression loss: 0.02195 | Objectness loss: 0.00151 | RPN Regression loss: 0.00149 | Running loss: 0.03235\n","Epoch: 9 | Iteration: 33408 | Classification loss: 0.00833 | Regression loss: 0.02863 | Objectness loss: 0.00321 | RPN Regression loss: 0.00109 | Running loss: 0.04126\n","Epoch: 9 | Iteration: 33409 | Classification loss: 0.01230 | Regression loss: 0.01907 | Objectness loss: 0.00074 | RPN Regression loss: 0.00111 | Running loss: 0.03321\n","Epoch: 9 | Iteration: 33410 | Classification loss: 0.00787 | Regression loss: 0.01363 | Objectness loss: 0.00613 | RPN Regression loss: 0.00129 | Running loss: 0.02891\n","Epoch: 9 | Iteration: 33411 | Classification loss: 0.01100 | Regression loss: 0.02510 | Objectness loss: 0.00069 | RPN Regression loss: 0.00137 | Running loss: 0.03816\n","Epoch: 9 | Iteration: 33412 | Classification loss: 0.03610 | Regression loss: 0.02978 | Objectness loss: 0.00122 | RPN Regression loss: 0.00050 | Running loss: 0.06760\n","Epoch: 9 | Iteration: 33413 | Classification loss: 0.01505 | Regression loss: 0.01792 | Objectness loss: 0.00462 | RPN Regression loss: 0.00103 | Running loss: 0.03862\n","Epoch: 9 | Iteration: 33414 | Classification loss: 0.01388 | Regression loss: 0.02212 | Objectness loss: 0.00295 | RPN Regression loss: 0.00133 | Running loss: 0.04028\n","Epoch: 9 | Iteration: 33415 | Classification loss: 0.01042 | Regression loss: 0.03206 | Objectness loss: 0.00008 | RPN Regression loss: 0.00067 | Running loss: 0.04323\n","Epoch: 9 | Iteration: 33416 | Classification loss: 0.01009 | Regression loss: 0.02130 | Objectness loss: 0.00236 | RPN Regression loss: 0.00301 | Running loss: 0.03676\n","Epoch: 9 | Iteration: 33417 | Classification loss: 0.01204 | Regression loss: 0.01570 | Objectness loss: 0.00010 | RPN Regression loss: 0.00254 | Running loss: 0.03038\n","Epoch: 9 | Iteration: 33418 | Classification loss: 0.00878 | Regression loss: 0.02169 | Objectness loss: 0.00343 | RPN Regression loss: 0.00460 | Running loss: 0.03849\n","Epoch: 9 | Iteration: 33419 | Classification loss: 0.01484 | Regression loss: 0.02467 | Objectness loss: 0.00010 | RPN Regression loss: 0.00052 | Running loss: 0.04013\n","Epoch: 9 | Iteration: 33420 | Classification loss: 0.01947 | Regression loss: 0.03730 | Objectness loss: 0.00548 | RPN Regression loss: 0.00094 | Running loss: 0.06319\n","Epoch: 9 | Iteration: 33421 | Classification loss: 0.01857 | Regression loss: 0.02757 | Objectness loss: 0.00517 | RPN Regression loss: 0.00076 | Running loss: 0.05206\n","Epoch: 9 | Iteration: 33422 | Classification loss: 0.02615 | Regression loss: 0.02913 | Objectness loss: 0.00077 | RPN Regression loss: 0.00150 | Running loss: 0.05756\n","Epoch: 9 | Iteration: 33423 | Classification loss: 0.00863 | Regression loss: 0.01875 | Objectness loss: 0.00196 | RPN Regression loss: 0.00074 | Running loss: 0.03007\n","Epoch: 9 | Iteration: 33424 | Classification loss: 0.01481 | Regression loss: 0.02500 | Objectness loss: 0.00225 | RPN Regression loss: 0.00118 | Running loss: 0.04325\n","Epoch: 9 | Iteration: 33425 | Classification loss: 0.02463 | Regression loss: 0.01972 | Objectness loss: 0.00539 | RPN Regression loss: 0.00072 | Running loss: 0.05046\n","Epoch: 9 | Iteration: 33426 | Classification loss: 0.00947 | Regression loss: 0.01361 | Objectness loss: 0.00085 | RPN Regression loss: 0.00212 | Running loss: 0.02604\n","Epoch: 9 | Iteration: 33427 | Classification loss: 0.03374 | Regression loss: 0.04677 | Objectness loss: 0.00105 | RPN Regression loss: 0.00160 | Running loss: 0.08316\n","Epoch: 9 | Iteration: 33428 | Classification loss: 0.01894 | Regression loss: 0.02015 | Objectness loss: 0.00222 | RPN Regression loss: 0.00192 | Running loss: 0.04323\n","Epoch: 9 | Iteration: 33429 | Classification loss: 0.02583 | Regression loss: 0.02220 | Objectness loss: 0.00003 | RPN Regression loss: 0.00072 | Running loss: 0.04879\n","Epoch: 9 | Iteration: 33430 | Classification loss: 0.00895 | Regression loss: 0.01746 | Objectness loss: 0.00085 | RPN Regression loss: 0.00343 | Running loss: 0.03069\n","Epoch: 9 | Iteration: 33431 | Classification loss: 0.02175 | Regression loss: 0.03311 | Objectness loss: 0.00019 | RPN Regression loss: 0.00126 | Running loss: 0.05631\n","Epoch: 9 | Iteration: 33432 | Classification loss: 0.01927 | Regression loss: 0.01901 | Objectness loss: 0.00026 | RPN Regression loss: 0.00047 | Running loss: 0.03901\n","Epoch: 9 | Iteration: 33433 | Classification loss: 0.05461 | Regression loss: 0.06109 | Objectness loss: 0.01601 | RPN Regression loss: 0.00686 | Running loss: 0.13857\n","Epoch: 9 | Iteration: 33434 | Classification loss: 0.00873 | Regression loss: 0.02011 | Objectness loss: 0.00016 | RPN Regression loss: 0.00210 | Running loss: 0.03110\n","Epoch: 9 | Iteration: 33435 | Classification loss: 0.00985 | Regression loss: 0.02780 | Objectness loss: 0.00234 | RPN Regression loss: 0.00414 | Running loss: 0.04413\n","Epoch: 9 | Iteration: 33436 | Classification loss: 0.01109 | Regression loss: 0.01414 | Objectness loss: 0.00030 | RPN Regression loss: 0.00340 | Running loss: 0.02893\n","Epoch: 9 | Iteration: 33437 | Classification loss: 0.00686 | Regression loss: 0.02174 | Objectness loss: 0.00007 | RPN Regression loss: 0.00089 | Running loss: 0.02956\n","Epoch: 9 | Iteration: 33438 | Classification loss: 0.04012 | Regression loss: 0.04371 | Objectness loss: 0.00255 | RPN Regression loss: 0.00226 | Running loss: 0.08865\n","Epoch: 9 | Iteration: 33439 | Classification loss: 0.01516 | Regression loss: 0.01956 | Objectness loss: 0.00987 | RPN Regression loss: 0.00099 | Running loss: 0.04557\n","Epoch: 9 | Iteration: 33440 | Classification loss: 0.02030 | Regression loss: 0.01896 | Objectness loss: 0.00674 | RPN Regression loss: 0.00151 | Running loss: 0.04751\n","Epoch: 9 | Iteration: 33441 | Classification loss: 0.05385 | Regression loss: 0.03172 | Objectness loss: 0.02760 | RPN Regression loss: 0.00354 | Running loss: 0.11672\n","Epoch: 9 | Iteration: 33442 | Classification loss: 0.02034 | Regression loss: 0.03104 | Objectness loss: 0.00351 | RPN Regression loss: 0.00350 | Running loss: 0.05840\n","Epoch: 9 | Iteration: 33443 | Classification loss: 0.01673 | Regression loss: 0.02385 | Objectness loss: 0.00112 | RPN Regression loss: 0.00527 | Running loss: 0.04697\n","Epoch: 9 | Iteration: 33444 | Classification loss: 0.01243 | Regression loss: 0.02213 | Objectness loss: 0.00026 | RPN Regression loss: 0.00139 | Running loss: 0.03622\n","Epoch: 9 | Iteration: 33445 | Classification loss: 0.03134 | Regression loss: 0.03002 | Objectness loss: 0.00334 | RPN Regression loss: 0.00166 | Running loss: 0.06635\n","Epoch: 9 | Iteration: 33446 | Classification loss: 0.03368 | Regression loss: 0.04508 | Objectness loss: 0.00214 | RPN Regression loss: 0.00412 | Running loss: 0.08503\n","Epoch: 9 | Iteration: 33447 | Classification loss: 0.01861 | Regression loss: 0.02361 | Objectness loss: 0.00433 | RPN Regression loss: 0.00169 | Running loss: 0.04824\n","Epoch: 9 | Iteration: 33448 | Classification loss: 0.02228 | Regression loss: 0.01955 | Objectness loss: 0.00213 | RPN Regression loss: 0.00110 | Running loss: 0.04506\n","Epoch: 9 | Iteration: 33449 | Classification loss: 0.03692 | Regression loss: 0.04174 | Objectness loss: 0.00646 | RPN Regression loss: 0.00355 | Running loss: 0.08867\n","Epoch: 9 | Iteration: 33450 | Classification loss: 0.01810 | Regression loss: 0.02420 | Objectness loss: 0.00094 | RPN Regression loss: 0.00162 | Running loss: 0.04486\n","Epoch: 9 | Iteration: 33451 | Classification loss: 0.02452 | Regression loss: 0.03058 | Objectness loss: 0.00152 | RPN Regression loss: 0.00392 | Running loss: 0.06053\n","Epoch: 9 | Iteration: 33452 | Classification loss: 0.01770 | Regression loss: 0.02705 | Objectness loss: 0.00012 | RPN Regression loss: 0.00191 | Running loss: 0.04677\n","Epoch: 9 | Iteration: 33453 | Classification loss: 0.01645 | Regression loss: 0.03062 | Objectness loss: 0.00052 | RPN Regression loss: 0.00201 | Running loss: 0.04960\n","Epoch: 9 | Iteration: 33454 | Classification loss: 0.02399 | Regression loss: 0.02140 | Objectness loss: 0.00598 | RPN Regression loss: 0.00330 | Running loss: 0.05467\n","Epoch: 9 | Iteration: 33455 | Classification loss: 0.02019 | Regression loss: 0.02482 | Objectness loss: 0.00184 | RPN Regression loss: 0.00051 | Running loss: 0.04736\n","Epoch: 9 | Iteration: 33456 | Classification loss: 0.01167 | Regression loss: 0.02233 | Objectness loss: 0.00029 | RPN Regression loss: 0.00055 | Running loss: 0.03483\n","Epoch: 9 | Iteration: 33457 | Classification loss: 0.00508 | Regression loss: 0.01742 | Objectness loss: 0.00748 | RPN Regression loss: 0.00086 | Running loss: 0.03085\n","Epoch: 9 | Iteration: 33458 | Classification loss: 0.03389 | Regression loss: 0.03318 | Objectness loss: 0.00005 | RPN Regression loss: 0.00155 | Running loss: 0.06867\n","Epoch: 9 | Iteration: 33459 | Classification loss: 0.00675 | Regression loss: 0.01559 | Objectness loss: 0.00023 | RPN Regression loss: 0.00042 | Running loss: 0.02299\n","Epoch: 9 | Iteration: 33460 | Classification loss: 0.00725 | Regression loss: 0.01464 | Objectness loss: 0.00178 | RPN Regression loss: 0.00155 | Running loss: 0.02522\n","Epoch: 9 | Iteration: 33461 | Classification loss: 0.02040 | Regression loss: 0.02748 | Objectness loss: 0.00066 | RPN Regression loss: 0.00088 | Running loss: 0.04942\n","Epoch: 9 | Iteration: 33462 | Classification loss: 0.03546 | Regression loss: 0.06346 | Objectness loss: 0.00352 | RPN Regression loss: 0.00175 | Running loss: 0.10419\n","Epoch: 9 | Iteration: 33463 | Classification loss: 0.02838 | Regression loss: 0.04499 | Objectness loss: 0.00249 | RPN Regression loss: 0.00041 | Running loss: 0.07627\n","Epoch: 9 | Iteration: 33464 | Classification loss: 0.02647 | Regression loss: 0.02417 | Objectness loss: 0.00041 | RPN Regression loss: 0.00081 | Running loss: 0.05186\n","Epoch: 9 | Iteration: 33465 | Classification loss: 0.01644 | Regression loss: 0.02675 | Objectness loss: 0.00192 | RPN Regression loss: 0.00219 | Running loss: 0.04729\n","Epoch: 9 | Iteration: 33466 | Classification loss: 0.02147 | Regression loss: 0.04107 | Objectness loss: 0.01218 | RPN Regression loss: 0.00422 | Running loss: 0.07894\n","Epoch: 9 | Iteration: 33467 | Classification loss: 0.00498 | Regression loss: 0.01580 | Objectness loss: 0.00142 | RPN Regression loss: 0.00313 | Running loss: 0.02533\n","Epoch: 9 | Iteration: 33468 | Classification loss: 0.01269 | Regression loss: 0.02465 | Objectness loss: 0.00018 | RPN Regression loss: 0.00126 | Running loss: 0.03877\n","Epoch: 9 | Iteration: 33469 | Classification loss: 0.01754 | Regression loss: 0.02830 | Objectness loss: 0.00013 | RPN Regression loss: 0.00367 | Running loss: 0.04964\n","Epoch: 9 | Iteration: 33470 | Classification loss: 0.02443 | Regression loss: 0.02393 | Objectness loss: 0.00056 | RPN Regression loss: 0.00022 | Running loss: 0.04914\n","Epoch: 9 | Iteration: 33471 | Classification loss: 0.01440 | Regression loss: 0.02775 | Objectness loss: 0.00117 | RPN Regression loss: 0.00242 | Running loss: 0.04574\n","Epoch: 9 | Iteration: 33472 | Classification loss: 0.01122 | Regression loss: 0.02472 | Objectness loss: 0.00011 | RPN Regression loss: 0.00109 | Running loss: 0.03714\n","Epoch: 9 | Iteration: 33473 | Classification loss: 0.01107 | Regression loss: 0.02636 | Objectness loss: 0.00051 | RPN Regression loss: 0.00027 | Running loss: 0.03821\n","Epoch: 9 | Iteration: 33474 | Classification loss: 0.01837 | Regression loss: 0.03082 | Objectness loss: 0.00130 | RPN Regression loss: 0.00394 | Running loss: 0.05442\n","Epoch: 9 | Iteration: 33475 | Classification loss: 0.01429 | Regression loss: 0.03671 | Objectness loss: 0.00014 | RPN Regression loss: 0.00137 | Running loss: 0.05251\n","Epoch: 9 | Iteration: 33476 | Classification loss: 0.01983 | Regression loss: 0.02228 | Objectness loss: 0.00068 | RPN Regression loss: 0.00054 | Running loss: 0.04333\n","Epoch: 9 | Iteration: 33477 | Classification loss: 0.03072 | Regression loss: 0.03097 | Objectness loss: 0.00210 | RPN Regression loss: 0.00272 | Running loss: 0.06651\n","Epoch: 9 | Iteration: 33478 | Classification loss: 0.03729 | Regression loss: 0.03657 | Objectness loss: 0.00470 | RPN Regression loss: 0.00172 | Running loss: 0.08028\n","Epoch: 9 | Iteration: 33479 | Classification loss: 0.02219 | Regression loss: 0.02892 | Objectness loss: 0.00122 | RPN Regression loss: 0.00375 | Running loss: 0.05609\n","Epoch: 9 | Iteration: 33480 | Classification loss: 0.02184 | Regression loss: 0.01715 | Objectness loss: 0.00075 | RPN Regression loss: 0.00447 | Running loss: 0.04421\n","Epoch: 9 | Iteration: 33481 | Classification loss: 0.02510 | Regression loss: 0.02405 | Objectness loss: 0.00046 | RPN Regression loss: 0.00036 | Running loss: 0.04997\n","Epoch: 9 | Iteration: 33482 | Classification loss: 0.02212 | Regression loss: 0.01505 | Objectness loss: 0.00069 | RPN Regression loss: 0.00088 | Running loss: 0.03875\n","Epoch: 9 | Iteration: 33483 | Classification loss: 0.01298 | Regression loss: 0.01846 | Objectness loss: 0.00005 | RPN Regression loss: 0.00089 | Running loss: 0.03239\n","Epoch: 9 | Iteration: 33484 | Classification loss: 0.01023 | Regression loss: 0.02702 | Objectness loss: 0.00006 | RPN Regression loss: 0.00063 | Running loss: 0.03793\n","Epoch: 9 | Iteration: 33485 | Classification loss: 0.03740 | Regression loss: 0.04300 | Objectness loss: 0.00015 | RPN Regression loss: 0.00129 | Running loss: 0.08184\n","Epoch: 9 | Iteration: 33486 | Classification loss: 0.01482 | Regression loss: 0.02704 | Objectness loss: 0.00191 | RPN Regression loss: 0.00272 | Running loss: 0.04649\n","Epoch: 9 | Iteration: 33487 | Classification loss: 0.03204 | Regression loss: 0.02913 | Objectness loss: 0.00559 | RPN Regression loss: 0.00136 | Running loss: 0.06812\n","Epoch: 9 | Iteration: 33488 | Classification loss: 0.01871 | Regression loss: 0.03114 | Objectness loss: 0.00009 | RPN Regression loss: 0.00194 | Running loss: 0.05187\n","Epoch: 9 | Iteration: 33489 | Classification loss: 0.01930 | Regression loss: 0.02768 | Objectness loss: 0.00178 | RPN Regression loss: 0.00105 | Running loss: 0.04980\n","Epoch: 9 | Iteration: 33490 | Classification loss: 0.00740 | Regression loss: 0.01274 | Objectness loss: 0.00085 | RPN Regression loss: 0.00066 | Running loss: 0.02165\n","Epoch: 9 | Iteration: 33491 | Classification loss: 0.02472 | Regression loss: 0.01723 | Objectness loss: 0.00015 | RPN Regression loss: 0.00077 | Running loss: 0.04288\n","Epoch: 9 | Iteration: 33492 | Classification loss: 0.02066 | Regression loss: 0.03833 | Objectness loss: 0.00100 | RPN Regression loss: 0.00248 | Running loss: 0.06246\n","Epoch: 9 | Iteration: 33493 | Classification loss: 0.01309 | Regression loss: 0.01898 | Objectness loss: 0.00305 | RPN Regression loss: 0.00253 | Running loss: 0.03765\n","Epoch: 9 | Iteration: 33494 | Classification loss: 0.00618 | Regression loss: 0.01750 | Objectness loss: 0.00007 | RPN Regression loss: 0.00020 | Running loss: 0.02396\n","Epoch: 9 | Iteration: 33495 | Classification loss: 0.00873 | Regression loss: 0.01572 | Objectness loss: 0.00036 | RPN Regression loss: 0.00107 | Running loss: 0.02587\n","Epoch: 9 | Iteration: 33496 | Classification loss: 0.01842 | Regression loss: 0.01117 | Objectness loss: 0.00093 | RPN Regression loss: 0.00064 | Running loss: 0.03116\n","Epoch: 9 | Iteration: 33497 | Classification loss: 0.00997 | Regression loss: 0.01825 | Objectness loss: 0.00138 | RPN Regression loss: 0.00081 | Running loss: 0.03041\n","Epoch: 9 | Iteration: 33498 | Classification loss: 0.01384 | Regression loss: 0.02719 | Objectness loss: 0.00013 | RPN Regression loss: 0.00261 | Running loss: 0.04377\n","Epoch: 9 | Iteration: 33499 | Classification loss: 0.02565 | Regression loss: 0.02853 | Objectness loss: 0.00050 | RPN Regression loss: 0.00576 | Running loss: 0.06044\n","Epoch: 9 | Iteration: 33500 | Classification loss: 0.01163 | Regression loss: 0.02179 | Objectness loss: 0.00014 | RPN Regression loss: 0.00062 | Running loss: 0.03418\n","Epoch: 9 | Iteration: 33501 | Classification loss: 0.00948 | Regression loss: 0.01064 | Objectness loss: 0.00013 | RPN Regression loss: 0.00210 | Running loss: 0.02235\n","Epoch: 9 | Iteration: 33502 | Classification loss: 0.02265 | Regression loss: 0.02916 | Objectness loss: 0.00098 | RPN Regression loss: 0.00049 | Running loss: 0.05327\n","Epoch: 9 | Iteration: 33503 | Classification loss: 0.00940 | Regression loss: 0.03004 | Objectness loss: 0.00202 | RPN Regression loss: 0.00109 | Running loss: 0.04255\n","Epoch: 9 | Iteration: 33504 | Classification loss: 0.01939 | Regression loss: 0.02730 | Objectness loss: 0.00060 | RPN Regression loss: 0.00166 | Running loss: 0.04895\n","Epoch: 9 | Iteration: 33505 | Classification loss: 0.00921 | Regression loss: 0.01634 | Objectness loss: 0.00011 | RPN Regression loss: 0.00067 | Running loss: 0.02633\n","Epoch: 9 | Iteration: 33506 | Classification loss: 0.01295 | Regression loss: 0.02737 | Objectness loss: 0.00017 | RPN Regression loss: 0.00080 | Running loss: 0.04129\n","Epoch: 9 | Iteration: 33507 | Classification loss: 0.03152 | Regression loss: 0.03014 | Objectness loss: 0.00106 | RPN Regression loss: 0.00084 | Running loss: 0.06356\n","Epoch: 9 | Iteration: 33508 | Classification loss: 0.01438 | Regression loss: 0.02320 | Objectness loss: 0.00125 | RPN Regression loss: 0.00039 | Running loss: 0.03922\n","Epoch: 9 | Iteration: 33509 | Classification loss: 0.04272 | Regression loss: 0.04781 | Objectness loss: 0.01128 | RPN Regression loss: 0.00336 | Running loss: 0.10517\n","Epoch: 9 | Iteration: 33510 | Classification loss: 0.01402 | Regression loss: 0.03427 | Objectness loss: 0.00022 | RPN Regression loss: 0.00189 | Running loss: 0.05041\n","Epoch: 9 | Iteration: 33511 | Classification loss: 0.02802 | Regression loss: 0.03877 | Objectness loss: 0.00024 | RPN Regression loss: 0.00197 | Running loss: 0.06901\n","Epoch: 9 | Iteration: 33512 | Classification loss: 0.00813 | Regression loss: 0.01581 | Objectness loss: 0.00147 | RPN Regression loss: 0.00202 | Running loss: 0.02743\n","Epoch: 9 | Iteration: 33513 | Classification loss: 0.03000 | Regression loss: 0.02402 | Objectness loss: 0.00361 | RPN Regression loss: 0.00091 | Running loss: 0.05853\n","Epoch: 9 | Iteration: 33514 | Classification loss: 0.01210 | Regression loss: 0.02778 | Objectness loss: 0.00048 | RPN Regression loss: 0.00078 | Running loss: 0.04115\n","Epoch: 9 | Iteration: 33515 | Classification loss: 0.02472 | Regression loss: 0.02803 | Objectness loss: 0.00008 | RPN Regression loss: 0.00103 | Running loss: 0.05387\n","Epoch: 9 | Iteration: 33516 | Classification loss: 0.00800 | Regression loss: 0.02059 | Objectness loss: 0.00003 | RPN Regression loss: 0.00058 | Running loss: 0.02921\n","Epoch: 9 | Iteration: 33517 | Classification loss: 0.00753 | Regression loss: 0.01997 | Objectness loss: 0.00072 | RPN Regression loss: 0.00074 | Running loss: 0.02895\n","Epoch: 9 | Iteration: 33518 | Classification loss: 0.01665 | Regression loss: 0.01235 | Objectness loss: 0.00749 | RPN Regression loss: 0.00149 | Running loss: 0.03798\n","Epoch: 9 | Iteration: 33519 | Classification loss: 0.03266 | Regression loss: 0.04307 | Objectness loss: 0.00618 | RPN Regression loss: 0.00097 | Running loss: 0.08287\n","Epoch: 9 | Iteration: 33520 | Classification loss: 0.01064 | Regression loss: 0.01298 | Objectness loss: 0.00005 | RPN Regression loss: 0.00250 | Running loss: 0.02617\n","Epoch: 9 | Iteration: 33521 | Classification loss: 0.01437 | Regression loss: 0.01385 | Objectness loss: 0.00003 | RPN Regression loss: 0.00285 | Running loss: 0.03110\n","Epoch: 9 | Iteration: 33522 | Classification loss: 0.01885 | Regression loss: 0.02360 | Objectness loss: 0.00063 | RPN Regression loss: 0.00216 | Running loss: 0.04525\n","Epoch: 9 | Iteration: 33523 | Classification loss: 0.01487 | Regression loss: 0.04441 | Objectness loss: 0.00361 | RPN Regression loss: 0.00262 | Running loss: 0.06551\n","Epoch: 9 | Iteration: 33524 | Classification loss: 0.02753 | Regression loss: 0.03609 | Objectness loss: 0.00343 | RPN Regression loss: 0.00303 | Running loss: 0.07008\n","Epoch: 9 | Iteration: 33525 | Classification loss: 0.02519 | Regression loss: 0.03616 | Objectness loss: 0.00034 | RPN Regression loss: 0.00474 | Running loss: 0.06644\n","Epoch: 9 | Iteration: 33526 | Classification loss: 0.00953 | Regression loss: 0.01729 | Objectness loss: 0.00026 | RPN Regression loss: 0.00122 | Running loss: 0.02830\n","Epoch: 9 | Iteration: 33527 | Classification loss: 0.02589 | Regression loss: 0.01560 | Objectness loss: 0.00062 | RPN Regression loss: 0.00120 | Running loss: 0.04331\n","Epoch: 9 | Iteration: 33528 | Classification loss: 0.02169 | Regression loss: 0.02321 | Objectness loss: 0.00037 | RPN Regression loss: 0.00123 | Running loss: 0.04649\n","Epoch: 9 | Iteration: 33529 | Classification loss: 0.02768 | Regression loss: 0.03539 | Objectness loss: 0.00020 | RPN Regression loss: 0.00287 | Running loss: 0.06614\n","Epoch: 9 | Iteration: 33530 | Classification loss: 0.01294 | Regression loss: 0.04052 | Objectness loss: 0.00026 | RPN Regression loss: 0.00078 | Running loss: 0.05450\n","Epoch: 9 | Iteration: 33531 | Classification loss: 0.01053 | Regression loss: 0.02302 | Objectness loss: 0.00055 | RPN Regression loss: 0.00266 | Running loss: 0.03676\n","Epoch: 9 | Iteration: 33532 | Classification loss: 0.01549 | Regression loss: 0.03472 | Objectness loss: 0.00271 | RPN Regression loss: 0.00449 | Running loss: 0.05742\n","Epoch: 9 | Iteration: 33533 | Classification loss: 0.01092 | Regression loss: 0.01545 | Objectness loss: 0.00063 | RPN Regression loss: 0.00086 | Running loss: 0.02786\n","Epoch: 9 | Iteration: 33534 | Classification loss: 0.03886 | Regression loss: 0.02043 | Objectness loss: 0.00043 | RPN Regression loss: 0.00105 | Running loss: 0.06076\n","Epoch: 9 | Iteration: 33535 | Classification loss: 0.02110 | Regression loss: 0.01803 | Objectness loss: 0.00079 | RPN Regression loss: 0.00061 | Running loss: 0.04053\n","Epoch: 9 | Iteration: 33536 | Classification loss: 0.00913 | Regression loss: 0.01362 | Objectness loss: 0.00454 | RPN Regression loss: 0.00277 | Running loss: 0.03006\n","Epoch: 9 | Iteration: 33537 | Classification loss: 0.02200 | Regression loss: 0.01831 | Objectness loss: 0.00139 | RPN Regression loss: 0.00435 | Running loss: 0.04604\n","Epoch: 9 | Iteration: 33538 | Classification loss: 0.01580 | Regression loss: 0.02308 | Objectness loss: 0.00081 | RPN Regression loss: 0.00414 | Running loss: 0.04383\n","Epoch: 9 | Iteration: 33539 | Classification loss: 0.00781 | Regression loss: 0.01559 | Objectness loss: 0.00004 | RPN Regression loss: 0.00253 | Running loss: 0.02597\n","Epoch: 9 | Iteration: 33540 | Classification loss: 0.02334 | Regression loss: 0.02196 | Objectness loss: 0.00016 | RPN Regression loss: 0.00237 | Running loss: 0.04783\n","Epoch: 9 | Iteration: 33541 | Classification loss: 0.02371 | Regression loss: 0.04624 | Objectness loss: 0.00136 | RPN Regression loss: 0.00069 | Running loss: 0.07199\n","Epoch: 9 | Iteration: 33542 | Classification loss: 0.01311 | Regression loss: 0.01848 | Objectness loss: 0.00004 | RPN Regression loss: 0.00131 | Running loss: 0.03295\n","Epoch: 9 | Iteration: 33543 | Classification loss: 0.00943 | Regression loss: 0.01612 | Objectness loss: 0.00018 | RPN Regression loss: 0.00107 | Running loss: 0.02680\n","Epoch: 9 | Iteration: 33544 | Classification loss: 0.01128 | Regression loss: 0.03260 | Objectness loss: 0.00112 | RPN Regression loss: 0.00132 | Running loss: 0.04632\n","Epoch: 9 | Iteration: 33545 | Classification loss: 0.01077 | Regression loss: 0.02088 | Objectness loss: 0.00015 | RPN Regression loss: 0.00095 | Running loss: 0.03275\n","Epoch: 9 | Iteration: 33546 | Classification loss: 0.02919 | Regression loss: 0.03878 | Objectness loss: 0.00032 | RPN Regression loss: 0.00106 | Running loss: 0.06935\n","Epoch: 9 | Iteration: 33547 | Classification loss: 0.00860 | Regression loss: 0.02108 | Objectness loss: 0.00091 | RPN Regression loss: 0.00137 | Running loss: 0.03196\n","Epoch: 9 | Iteration: 33548 | Classification loss: 0.00821 | Regression loss: 0.03133 | Objectness loss: 0.00020 | RPN Regression loss: 0.00327 | Running loss: 0.04302\n","Epoch: 9 | Iteration: 33549 | Classification loss: 0.00965 | Regression loss: 0.01716 | Objectness loss: 0.00012 | RPN Regression loss: 0.00072 | Running loss: 0.02764\n","Epoch: 9 | Iteration: 33550 | Classification loss: 0.01835 | Regression loss: 0.01304 | Objectness loss: 0.00009 | RPN Regression loss: 0.00071 | Running loss: 0.03218\n","Epoch: 9 | Iteration: 33551 | Classification loss: 0.01948 | Regression loss: 0.01835 | Objectness loss: 0.00406 | RPN Regression loss: 0.00279 | Running loss: 0.04469\n","Epoch: 9 | Iteration: 33552 | Classification loss: 0.01120 | Regression loss: 0.01837 | Objectness loss: 0.00031 | RPN Regression loss: 0.00185 | Running loss: 0.03174\n","Epoch: 9 | Iteration: 33553 | Classification loss: 0.01715 | Regression loss: 0.04745 | Objectness loss: 0.00014 | RPN Regression loss: 0.00089 | Running loss: 0.06563\n","Epoch: 9 | Iteration: 33554 | Classification loss: 0.00975 | Regression loss: 0.01811 | Objectness loss: 0.00145 | RPN Regression loss: 0.00587 | Running loss: 0.03518\n","Epoch: 9 | Iteration: 33555 | Classification loss: 0.00920 | Regression loss: 0.01959 | Objectness loss: 0.00020 | RPN Regression loss: 0.00114 | Running loss: 0.03013\n","Epoch: 9 | Iteration: 33556 | Classification loss: 0.01774 | Regression loss: 0.03005 | Objectness loss: 0.00069 | RPN Regression loss: 0.00130 | Running loss: 0.04978\n","Epoch: 9 | Iteration: 33557 | Classification loss: 0.02522 | Regression loss: 0.03951 | Objectness loss: 0.00014 | RPN Regression loss: 0.00113 | Running loss: 0.06600\n","Epoch: 9 | Iteration: 33558 | Classification loss: 0.01706 | Regression loss: 0.02370 | Objectness loss: 0.00019 | RPN Regression loss: 0.00081 | Running loss: 0.04177\n","Epoch: 9 | Iteration: 33559 | Classification loss: 0.00597 | Regression loss: 0.01682 | Objectness loss: 0.00005 | RPN Regression loss: 0.00203 | Running loss: 0.02488\n","Epoch: 9 | Iteration: 33560 | Classification loss: 0.01288 | Regression loss: 0.02088 | Objectness loss: 0.00072 | RPN Regression loss: 0.00207 | Running loss: 0.03654\n","Epoch: 9 | Iteration: 33561 | Classification loss: 0.00850 | Regression loss: 0.01152 | Objectness loss: 0.00106 | RPN Regression loss: 0.00126 | Running loss: 0.02235\n","Epoch: 9 | Iteration: 33562 | Classification loss: 0.01853 | Regression loss: 0.02053 | Objectness loss: 0.00159 | RPN Regression loss: 0.00040 | Running loss: 0.04105\n","Epoch: 9 | Iteration: 33563 | Classification loss: 0.01860 | Regression loss: 0.04177 | Objectness loss: 0.00008 | RPN Regression loss: 0.00037 | Running loss: 0.06082\n","Epoch: 9 | Iteration: 33564 | Classification loss: 0.01460 | Regression loss: 0.03101 | Objectness loss: 0.00004 | RPN Regression loss: 0.00086 | Running loss: 0.04651\n","Epoch: 9 | Iteration: 33565 | Classification loss: 0.00815 | Regression loss: 0.01288 | Objectness loss: 0.00064 | RPN Regression loss: 0.00073 | Running loss: 0.02239\n","Epoch: 9 | Iteration: 33566 | Classification loss: 0.00634 | Regression loss: 0.01079 | Objectness loss: 0.00001 | RPN Regression loss: 0.00098 | Running loss: 0.01811\n","Epoch: 9 | Iteration: 33567 | Classification loss: 0.00954 | Regression loss: 0.02906 | Objectness loss: 0.00613 | RPN Regression loss: 0.00226 | Running loss: 0.04699\n","Epoch: 9 | Iteration: 33568 | Classification loss: 0.01748 | Regression loss: 0.04396 | Objectness loss: 0.00441 | RPN Regression loss: 0.00511 | Running loss: 0.07095\n","Epoch: 9 | Iteration: 33569 | Classification loss: 0.00887 | Regression loss: 0.01838 | Objectness loss: 0.00010 | RPN Regression loss: 0.00131 | Running loss: 0.02867\n","Epoch: 9 | Iteration: 33570 | Classification loss: 0.01022 | Regression loss: 0.01613 | Objectness loss: 0.00006 | RPN Regression loss: 0.00296 | Running loss: 0.02937\n","Epoch: 9 | Iteration: 33571 | Classification loss: 0.02549 | Regression loss: 0.03010 | Objectness loss: 0.00082 | RPN Regression loss: 0.00163 | Running loss: 0.05803\n","Epoch: 9 | Iteration: 33572 | Classification loss: 0.00676 | Regression loss: 0.01185 | Objectness loss: 0.00006 | RPN Regression loss: 0.00063 | Running loss: 0.01930\n","Epoch: 9 | Iteration: 33573 | Classification loss: 0.02069 | Regression loss: 0.02910 | Objectness loss: 0.00033 | RPN Regression loss: 0.00051 | Running loss: 0.05063\n","Epoch: 9 | Iteration: 33574 | Classification loss: 0.01217 | Regression loss: 0.01869 | Objectness loss: 0.00032 | RPN Regression loss: 0.00429 | Running loss: 0.03546\n","Epoch: 9 | Iteration: 33575 | Classification loss: 0.00781 | Regression loss: 0.02267 | Objectness loss: 0.00029 | RPN Regression loss: 0.00088 | Running loss: 0.03166\n","Epoch: 9 | Iteration: 33576 | Classification loss: 0.01096 | Regression loss: 0.01538 | Objectness loss: 0.00068 | RPN Regression loss: 0.00052 | Running loss: 0.02754\n","Epoch: 9 | Iteration: 33577 | Classification loss: 0.00749 | Regression loss: 0.01124 | Objectness loss: 0.00062 | RPN Regression loss: 0.00199 | Running loss: 0.02134\n","Epoch: 9 | Iteration: 33578 | Classification loss: 0.03128 | Regression loss: 0.06208 | Objectness loss: 0.00055 | RPN Regression loss: 0.00271 | Running loss: 0.09662\n","Epoch: 9 | Iteration: 33579 | Classification loss: 0.00988 | Regression loss: 0.02018 | Objectness loss: 0.00011 | RPN Regression loss: 0.00057 | Running loss: 0.03074\n","Epoch: 9 | Iteration: 33580 | Classification loss: 0.00540 | Regression loss: 0.01430 | Objectness loss: 0.00058 | RPN Regression loss: 0.00098 | Running loss: 0.02125\n","Epoch: 9 | Iteration: 33581 | Classification loss: 0.01131 | Regression loss: 0.02106 | Objectness loss: 0.00019 | RPN Regression loss: 0.00065 | Running loss: 0.03321\n","Epoch: 9 | Iteration: 33582 | Classification loss: 0.02011 | Regression loss: 0.02166 | Objectness loss: 0.00008 | RPN Regression loss: 0.00373 | Running loss: 0.04559\n","Epoch: 9 | Iteration: 33583 | Classification loss: 0.03532 | Regression loss: 0.04321 | Objectness loss: 0.00002 | RPN Regression loss: 0.00199 | Running loss: 0.08055\n","Epoch: 9 | Iteration: 33584 | Classification loss: 0.01032 | Regression loss: 0.01949 | Objectness loss: 0.00018 | RPN Regression loss: 0.00150 | Running loss: 0.03149\n","Epoch: 9 | Iteration: 33585 | Classification loss: 0.03998 | Regression loss: 0.01510 | Objectness loss: 0.00019 | RPN Regression loss: 0.00188 | Running loss: 0.05714\n","Epoch: 9 | Iteration: 33586 | Classification loss: 0.03050 | Regression loss: 0.03462 | Objectness loss: 0.00192 | RPN Regression loss: 0.00216 | Running loss: 0.06920\n","Epoch: 9 | Iteration: 33587 | Classification loss: 0.01632 | Regression loss: 0.03881 | Objectness loss: 0.00004 | RPN Regression loss: 0.00172 | Running loss: 0.05690\n","Epoch: 9 | Iteration: 33588 | Classification loss: 0.02054 | Regression loss: 0.01569 | Objectness loss: 0.00002 | RPN Regression loss: 0.00030 | Running loss: 0.03655\n","Epoch: 9 | Iteration: 33589 | Classification loss: 0.01446 | Regression loss: 0.03950 | Objectness loss: 0.00054 | RPN Regression loss: 0.00155 | Running loss: 0.05605\n","Epoch: 9 | Iteration: 33590 | Classification loss: 0.02140 | Regression loss: 0.01556 | Objectness loss: 0.00049 | RPN Regression loss: 0.00130 | Running loss: 0.03875\n","Epoch: 9 | Iteration: 33591 | Classification loss: 0.01611 | Regression loss: 0.04699 | Objectness loss: 0.00382 | RPN Regression loss: 0.00545 | Running loss: 0.07237\n","Epoch: 9 | Iteration: 33592 | Classification loss: 0.00959 | Regression loss: 0.02272 | Objectness loss: 0.00060 | RPN Regression loss: 0.00166 | Running loss: 0.03456\n","Epoch: 9 | Iteration: 33593 | Classification loss: 0.00714 | Regression loss: 0.01217 | Objectness loss: 0.00004 | RPN Regression loss: 0.00049 | Running loss: 0.01984\n","Epoch: 9 | Iteration: 33594 | Classification loss: 0.01104 | Regression loss: 0.02340 | Objectness loss: 0.00035 | RPN Regression loss: 0.00029 | Running loss: 0.03507\n","Epoch: 9 | Iteration: 33595 | Classification loss: 0.00547 | Regression loss: 0.01660 | Objectness loss: 0.00016 | RPN Regression loss: 0.00401 | Running loss: 0.02624\n","Epoch: 9 | Iteration: 33596 | Classification loss: 0.02155 | Regression loss: 0.02120 | Objectness loss: 0.00084 | RPN Regression loss: 0.00094 | Running loss: 0.04452\n","Epoch: 9 | Iteration: 33597 | Classification loss: 0.01606 | Regression loss: 0.03439 | Objectness loss: 0.00061 | RPN Regression loss: 0.00297 | Running loss: 0.05404\n","Epoch: 9 | Iteration: 33598 | Classification loss: 0.01800 | Regression loss: 0.01977 | Objectness loss: 0.00200 | RPN Regression loss: 0.00133 | Running loss: 0.04111\n","Epoch: 9 | Iteration: 33599 | Classification loss: 0.00740 | Regression loss: 0.01882 | Objectness loss: 0.00051 | RPN Regression loss: 0.00252 | Running loss: 0.02925\n","Epoch: 9 | Iteration: 33600 | Classification loss: 0.01068 | Regression loss: 0.01699 | Objectness loss: 0.00034 | RPN Regression loss: 0.00059 | Running loss: 0.02859\n","Epoch: 9 | Iteration: 33601 | Classification loss: 0.01051 | Regression loss: 0.02943 | Objectness loss: 0.00009 | RPN Regression loss: 0.00044 | Running loss: 0.04047\n","Epoch: 9 | Iteration: 33602 | Classification loss: 0.06859 | Regression loss: 0.05415 | Objectness loss: 0.01684 | RPN Regression loss: 0.01531 | Running loss: 0.15490\n","Epoch: 9 | Iteration: 33603 | Classification loss: 0.01624 | Regression loss: 0.02539 | Objectness loss: 0.01182 | RPN Regression loss: 0.01140 | Running loss: 0.06485\n","Epoch: 9 | Iteration: 33604 | Classification loss: 0.03899 | Regression loss: 0.02704 | Objectness loss: 0.00043 | RPN Regression loss: 0.00192 | Running loss: 0.06839\n","Epoch: 9 | Iteration: 33605 | Classification loss: 0.01231 | Regression loss: 0.01874 | Objectness loss: 0.00093 | RPN Regression loss: 0.00121 | Running loss: 0.03320\n","Epoch: 9 | Iteration: 33606 | Classification loss: 0.02002 | Regression loss: 0.03550 | Objectness loss: 0.00312 | RPN Regression loss: 0.00101 | Running loss: 0.05964\n","Epoch: 9 | Iteration: 33607 | Classification loss: 0.01956 | Regression loss: 0.01632 | Objectness loss: 0.00007 | RPN Regression loss: 0.00036 | Running loss: 0.03631\n","Epoch: 9 | Iteration: 33608 | Classification loss: 0.02133 | Regression loss: 0.04212 | Objectness loss: 0.00035 | RPN Regression loss: 0.00410 | Running loss: 0.06790\n","Epoch: 9 | Iteration: 33609 | Classification loss: 0.01442 | Regression loss: 0.02874 | Objectness loss: 0.00087 | RPN Regression loss: 0.00220 | Running loss: 0.04622\n","Epoch: 9 | Iteration: 33610 | Classification loss: 0.01488 | Regression loss: 0.03183 | Objectness loss: 0.00072 | RPN Regression loss: 0.00165 | Running loss: 0.04908\n","Epoch: 9 | Iteration: 33611 | Classification loss: 0.01266 | Regression loss: 0.01129 | Objectness loss: 0.00018 | RPN Regression loss: 0.00360 | Running loss: 0.02774\n","Epoch: 9 | Iteration: 33612 | Classification loss: 0.02509 | Regression loss: 0.01677 | Objectness loss: 0.00050 | RPN Regression loss: 0.00055 | Running loss: 0.04290\n","Epoch: 9 | Iteration: 33613 | Classification loss: 0.03802 | Regression loss: 0.03908 | Objectness loss: 0.00005 | RPN Regression loss: 0.00446 | Running loss: 0.08161\n","Epoch: 9 | Iteration: 33614 | Classification loss: 0.01013 | Regression loss: 0.01716 | Objectness loss: 0.00068 | RPN Regression loss: 0.00321 | Running loss: 0.03118\n","Epoch: 9 | Iteration: 33615 | Classification loss: 0.00978 | Regression loss: 0.01598 | Objectness loss: 0.00180 | RPN Regression loss: 0.00152 | Running loss: 0.02909\n","Epoch: 9 | Iteration: 33616 | Classification loss: 0.01993 | Regression loss: 0.02297 | Objectness loss: 0.00044 | RPN Regression loss: 0.00078 | Running loss: 0.04411\n","Epoch: 9 | Iteration: 33617 | Classification loss: 0.01188 | Regression loss: 0.04128 | Objectness loss: 0.00106 | RPN Regression loss: 0.00421 | Running loss: 0.05842\n","Epoch: 9 | Iteration: 33618 | Classification loss: 0.03071 | Regression loss: 0.02962 | Objectness loss: 0.00573 | RPN Regression loss: 0.00174 | Running loss: 0.06780\n","Epoch: 9 | Iteration: 33619 | Classification loss: 0.07487 | Regression loss: 0.02081 | Objectness loss: 0.00709 | RPN Regression loss: 0.00466 | Running loss: 0.10742\n","Epoch: 9 | Iteration: 33620 | Classification loss: 0.04446 | Regression loss: 0.02259 | Objectness loss: 0.02868 | RPN Regression loss: 0.00455 | Running loss: 0.10027\n","Epoch: 9 | Iteration: 33621 | Classification loss: 0.01038 | Regression loss: 0.02257 | Objectness loss: 0.00025 | RPN Regression loss: 0.00439 | Running loss: 0.03759\n","Epoch: 9 | Iteration: 33622 | Classification loss: 0.01216 | Regression loss: 0.01925 | Objectness loss: 0.00192 | RPN Regression loss: 0.00032 | Running loss: 0.03365\n","Epoch: 9 | Iteration: 33623 | Classification loss: 0.02353 | Regression loss: 0.02397 | Objectness loss: 0.00224 | RPN Regression loss: 0.00263 | Running loss: 0.05237\n","Epoch: 9 | Iteration: 33624 | Classification loss: 0.04336 | Regression loss: 0.02237 | Objectness loss: 0.00194 | RPN Regression loss: 0.00138 | Running loss: 0.06905\n","Epoch: 9 | Iteration: 33625 | Classification loss: 0.01257 | Regression loss: 0.01446 | Objectness loss: 0.00541 | RPN Regression loss: 0.00230 | Running loss: 0.03474\n","Epoch: 9 | Iteration: 33626 | Classification loss: 0.01458 | Regression loss: 0.01783 | Objectness loss: 0.00537 | RPN Regression loss: 0.00142 | Running loss: 0.03920\n","Epoch: 9 | Iteration: 33627 | Classification loss: 0.01498 | Regression loss: 0.02569 | Objectness loss: 0.00079 | RPN Regression loss: 0.00196 | Running loss: 0.04342\n","Epoch: 9 | Iteration: 33628 | Classification loss: 0.00920 | Regression loss: 0.02632 | Objectness loss: 0.00267 | RPN Regression loss: 0.00100 | Running loss: 0.03918\n","Epoch: 9 | Iteration: 33629 | Classification loss: 0.03261 | Regression loss: 0.03072 | Objectness loss: 0.00291 | RPN Regression loss: 0.00155 | Running loss: 0.06779\n","Epoch: 9 | Iteration: 33630 | Classification loss: 0.00997 | Regression loss: 0.01723 | Objectness loss: 0.00052 | RPN Regression loss: 0.00080 | Running loss: 0.02852\n","Epoch: 9 | Iteration: 33631 | Classification loss: 0.01005 | Regression loss: 0.00995 | Objectness loss: 0.00249 | RPN Regression loss: 0.00077 | Running loss: 0.02327\n","Epoch: 9 | Iteration: 33632 | Classification loss: 0.01451 | Regression loss: 0.02183 | Objectness loss: 0.00818 | RPN Regression loss: 0.00154 | Running loss: 0.04605\n","Epoch: 9 | Iteration: 33633 | Classification loss: 0.02768 | Regression loss: 0.01747 | Objectness loss: 0.00729 | RPN Regression loss: 0.00285 | Running loss: 0.05529\n","Epoch: 9 | Iteration: 33634 | Classification loss: 0.01797 | Regression loss: 0.04322 | Objectness loss: 0.00056 | RPN Regression loss: 0.00355 | Running loss: 0.06530\n","Epoch: 9 | Iteration: 33635 | Classification loss: 0.01200 | Regression loss: 0.03416 | Objectness loss: 0.00039 | RPN Regression loss: 0.00086 | Running loss: 0.04741\n","Epoch: 9 | Iteration: 33636 | Classification loss: 0.01536 | Regression loss: 0.03959 | Objectness loss: 0.00154 | RPN Regression loss: 0.00066 | Running loss: 0.05715\n","Epoch: 9 | Iteration: 33637 | Classification loss: 0.03009 | Regression loss: 0.01671 | Objectness loss: 0.00202 | RPN Regression loss: 0.00395 | Running loss: 0.05277\n","Epoch: 9 | Iteration: 33638 | Classification loss: 0.01403 | Regression loss: 0.03200 | Objectness loss: 0.00052 | RPN Regression loss: 0.00082 | Running loss: 0.04737\n","Epoch: 9 | Iteration: 33639 | Classification loss: 0.02109 | Regression loss: 0.02799 | Objectness loss: 0.00169 | RPN Regression loss: 0.00341 | Running loss: 0.05418\n","Epoch: 9 | Iteration: 33640 | Classification loss: 0.02191 | Regression loss: 0.02557 | Objectness loss: 0.00040 | RPN Regression loss: 0.00365 | Running loss: 0.05153\n","Epoch: 9 | Iteration: 33641 | Classification loss: 0.00696 | Regression loss: 0.01176 | Objectness loss: 0.00341 | RPN Regression loss: 0.00084 | Running loss: 0.02298\n","Epoch: 9 | Iteration: 33642 | Classification loss: 0.01079 | Regression loss: 0.01673 | Objectness loss: 0.00108 | RPN Regression loss: 0.00263 | Running loss: 0.03123\n","Epoch: 9 | Iteration: 33643 | Classification loss: 0.01670 | Regression loss: 0.01777 | Objectness loss: 0.00020 | RPN Regression loss: 0.00234 | Running loss: 0.03701\n","Epoch: 9 | Iteration: 33644 | Classification loss: 0.02955 | Regression loss: 0.02506 | Objectness loss: 0.00014 | RPN Regression loss: 0.00109 | Running loss: 0.05584\n","Epoch: 9 | Iteration: 33645 | Classification loss: 0.01332 | Regression loss: 0.01781 | Objectness loss: 0.00047 | RPN Regression loss: 0.00026 | Running loss: 0.03186\n","Epoch: 9 | Iteration: 33646 | Classification loss: 0.01308 | Regression loss: 0.01139 | Objectness loss: 0.00006 | RPN Regression loss: 0.00099 | Running loss: 0.02552\n","Epoch: 9 | Iteration: 33647 | Classification loss: 0.02822 | Regression loss: 0.04625 | Objectness loss: 0.00038 | RPN Regression loss: 0.00070 | Running loss: 0.07556\n","Epoch: 9 | Iteration: 33648 | Classification loss: 0.01875 | Regression loss: 0.01238 | Objectness loss: 0.00078 | RPN Regression loss: 0.00052 | Running loss: 0.03244\n","Epoch: 9 | Iteration: 33649 | Classification loss: 0.02308 | Regression loss: 0.02162 | Objectness loss: 0.00011 | RPN Regression loss: 0.00092 | Running loss: 0.04574\n","Epoch: 9 | Iteration: 33650 | Classification loss: 0.01694 | Regression loss: 0.02552 | Objectness loss: 0.00018 | RPN Regression loss: 0.00146 | Running loss: 0.04410\n","Epoch: 9 | Iteration: 33651 | Classification loss: 0.01509 | Regression loss: 0.01443 | Objectness loss: 0.00200 | RPN Regression loss: 0.00271 | Running loss: 0.03423\n","Epoch: 9 | Iteration: 33652 | Classification loss: 0.01139 | Regression loss: 0.02351 | Objectness loss: 0.00062 | RPN Regression loss: 0.00072 | Running loss: 0.03624\n","Epoch: 9 | Iteration: 33653 | Classification loss: 0.05105 | Regression loss: 0.03470 | Objectness loss: 0.00577 | RPN Regression loss: 0.00518 | Running loss: 0.09670\n","Epoch: 9 | Iteration: 33654 | Classification loss: 0.01961 | Regression loss: 0.03421 | Objectness loss: 0.00019 | RPN Regression loss: 0.00349 | Running loss: 0.05751\n","Epoch: 9 | Iteration: 33655 | Classification loss: 0.02783 | Regression loss: 0.03650 | Objectness loss: 0.00146 | RPN Regression loss: 0.00367 | Running loss: 0.06946\n","Epoch: 9 | Iteration: 33656 | Classification loss: 0.00786 | Regression loss: 0.02040 | Objectness loss: 0.00012 | RPN Regression loss: 0.00044 | Running loss: 0.02881\n","Epoch: 9 | Iteration: 33657 | Classification loss: 0.01011 | Regression loss: 0.01223 | Objectness loss: 0.00051 | RPN Regression loss: 0.00166 | Running loss: 0.02451\n","Epoch: 9 | Iteration: 33658 | Classification loss: 0.01655 | Regression loss: 0.01554 | Objectness loss: 0.00385 | RPN Regression loss: 0.00304 | Running loss: 0.03898\n","Epoch: 9 | Iteration: 33659 | Classification loss: 0.02572 | Regression loss: 0.02946 | Objectness loss: 0.00701 | RPN Regression loss: 0.00089 | Running loss: 0.06309\n","Epoch: 9 | Iteration: 33660 | Classification loss: 0.00974 | Regression loss: 0.02025 | Objectness loss: 0.00153 | RPN Regression loss: 0.00118 | Running loss: 0.03270\n","Epoch: 9 | Iteration: 33661 | Classification loss: 0.00722 | Regression loss: 0.00678 | Objectness loss: 0.00151 | RPN Regression loss: 0.00689 | Running loss: 0.02241\n","Epoch: 9 | Iteration: 33662 | Classification loss: 0.01127 | Regression loss: 0.02373 | Objectness loss: 0.00029 | RPN Regression loss: 0.00189 | Running loss: 0.03717\n","Epoch: 9 | Iteration: 33663 | Classification loss: 0.01922 | Regression loss: 0.02263 | Objectness loss: 0.00015 | RPN Regression loss: 0.00199 | Running loss: 0.04399\n","Epoch: 9 | Iteration: 33664 | Classification loss: 0.05362 | Regression loss: 0.04024 | Objectness loss: 0.00058 | RPN Regression loss: 0.00124 | Running loss: 0.09569\n","Epoch: 9 | Iteration: 33665 | Classification loss: 0.00991 | Regression loss: 0.02124 | Objectness loss: 0.00037 | RPN Regression loss: 0.00347 | Running loss: 0.03500\n","Epoch: 9 | Iteration: 33666 | Classification loss: 0.02452 | Regression loss: 0.02580 | Objectness loss: 0.00356 | RPN Regression loss: 0.00134 | Running loss: 0.05521\n","Epoch: 9 | Iteration: 33667 | Classification loss: 0.02179 | Regression loss: 0.02171 | Objectness loss: 0.00660 | RPN Regression loss: 0.00042 | Running loss: 0.05052\n","Epoch: 9 | Iteration: 33668 | Classification loss: 0.08417 | Regression loss: 0.04466 | Objectness loss: 0.00291 | RPN Regression loss: 0.00121 | Running loss: 0.13295\n","Epoch: 9 | Iteration: 33669 | Classification loss: 0.01118 | Regression loss: 0.01630 | Objectness loss: 0.00305 | RPN Regression loss: 0.00075 | Running loss: 0.03128\n","Epoch: 9 | Iteration: 33670 | Classification loss: 0.01728 | Regression loss: 0.02226 | Objectness loss: 0.00122 | RPN Regression loss: 0.00065 | Running loss: 0.04141\n","Epoch: 9 | Iteration: 33671 | Classification loss: 0.03546 | Regression loss: 0.04341 | Objectness loss: 0.00090 | RPN Regression loss: 0.00089 | Running loss: 0.08066\n","Epoch: 9 | Iteration: 33672 | Classification loss: 0.01418 | Regression loss: 0.02038 | Objectness loss: 0.00024 | RPN Regression loss: 0.00338 | Running loss: 0.03818\n","Epoch: 9 | Iteration: 33673 | Classification loss: 0.01211 | Regression loss: 0.02209 | Objectness loss: 0.00005 | RPN Regression loss: 0.00128 | Running loss: 0.03554\n","Epoch: 9 | Iteration: 33674 | Classification loss: 0.01436 | Regression loss: 0.01512 | Objectness loss: 0.00013 | RPN Regression loss: 0.00218 | Running loss: 0.03179\n","Epoch: 9 | Iteration: 33675 | Classification loss: 0.02691 | Regression loss: 0.03521 | Objectness loss: 0.00029 | RPN Regression loss: 0.00156 | Running loss: 0.06398\n","Epoch: 9 | Iteration: 33676 | Classification loss: 0.02635 | Regression loss: 0.02911 | Objectness loss: 0.00166 | RPN Regression loss: 0.00781 | Running loss: 0.06493\n","Epoch: 9 | Iteration: 33677 | Classification loss: 0.01430 | Regression loss: 0.01426 | Objectness loss: 0.00602 | RPN Regression loss: 0.00391 | Running loss: 0.03848\n","Epoch: 9 | Iteration: 33678 | Classification loss: 0.01410 | Regression loss: 0.04170 | Objectness loss: 0.00080 | RPN Regression loss: 0.00202 | Running loss: 0.05862\n","Epoch: 9 | Iteration: 33679 | Classification loss: 0.02940 | Regression loss: 0.03641 | Objectness loss: 0.00451 | RPN Regression loss: 0.00840 | Running loss: 0.07872\n","Epoch: 9 | Iteration: 33680 | Classification loss: 0.00805 | Regression loss: 0.01145 | Objectness loss: 0.00019 | RPN Regression loss: 0.00042 | Running loss: 0.02011\n","Epoch: 9 | Iteration: 33681 | Classification loss: 0.01066 | Regression loss: 0.01472 | Objectness loss: 0.00060 | RPN Regression loss: 0.00185 | Running loss: 0.02784\n","Epoch: 9 | Iteration: 33682 | Classification loss: 0.02688 | Regression loss: 0.09151 | Objectness loss: 0.00091 | RPN Regression loss: 0.00361 | Running loss: 0.12292\n","Epoch: 9 | Iteration: 33683 | Classification loss: 0.02109 | Regression loss: 0.03506 | Objectness loss: 0.00046 | RPN Regression loss: 0.00114 | Running loss: 0.05775\n","Epoch: 9 | Iteration: 33684 | Classification loss: 0.01981 | Regression loss: 0.02168 | Objectness loss: 0.00010 | RPN Regression loss: 0.00101 | Running loss: 0.04260\n","Epoch: 9 | Iteration: 33685 | Classification loss: 0.01275 | Regression loss: 0.01862 | Objectness loss: 0.00168 | RPN Regression loss: 0.00117 | Running loss: 0.03422\n","Epoch: 9 | Iteration: 33686 | Classification loss: 0.01421 | Regression loss: 0.01658 | Objectness loss: 0.00076 | RPN Regression loss: 0.00590 | Running loss: 0.03745\n","Epoch: 9 | Iteration: 33687 | Classification loss: 0.01417 | Regression loss: 0.02655 | Objectness loss: 0.00063 | RPN Regression loss: 0.00121 | Running loss: 0.04256\n","Epoch: 9 | Iteration: 33688 | Classification loss: 0.00712 | Regression loss: 0.01846 | Objectness loss: 0.00177 | RPN Regression loss: 0.00279 | Running loss: 0.03014\n","Epoch: 9 | Iteration: 33689 | Classification loss: 0.01221 | Regression loss: 0.01318 | Objectness loss: 0.00044 | RPN Regression loss: 0.00280 | Running loss: 0.02863\n","Epoch: 9 | Iteration: 33690 | Classification loss: 0.02135 | Regression loss: 0.04084 | Objectness loss: 0.00044 | RPN Regression loss: 0.00130 | Running loss: 0.06392\n","Epoch: 9 | Iteration: 33691 | Classification loss: 0.03856 | Regression loss: 0.03204 | Objectness loss: 0.06549 | RPN Regression loss: 0.02038 | Running loss: 0.15646\n","Epoch: 9 | Iteration: 33692 | Classification loss: 0.03774 | Regression loss: 0.01776 | Objectness loss: 0.00622 | RPN Regression loss: 0.00189 | Running loss: 0.06361\n","Epoch: 9 | Iteration: 33693 | Classification loss: 0.02700 | Regression loss: 0.02861 | Objectness loss: 0.00053 | RPN Regression loss: 0.00053 | Running loss: 0.05666\n","Epoch: 9 | Iteration: 33694 | Classification loss: 0.02531 | Regression loss: 0.02721 | Objectness loss: 0.00084 | RPN Regression loss: 0.00148 | Running loss: 0.05484\n","Epoch: 9 | Iteration: 33695 | Classification loss: 0.00530 | Regression loss: 0.02444 | Objectness loss: 0.00005 | RPN Regression loss: 0.00173 | Running loss: 0.03152\n","Epoch: 9 | Iteration: 33696 | Classification loss: 0.01128 | Regression loss: 0.03092 | Objectness loss: 0.00254 | RPN Regression loss: 0.00457 | Running loss: 0.04931\n","Epoch: 9 | Iteration: 33697 | Classification loss: 0.00960 | Regression loss: 0.02355 | Objectness loss: 0.00368 | RPN Regression loss: 0.00076 | Running loss: 0.03759\n","Epoch: 9 | Iteration: 33698 | Classification loss: 0.01622 | Regression loss: 0.01720 | Objectness loss: 0.00057 | RPN Regression loss: 0.00236 | Running loss: 0.03634\n","Epoch: 9 | Iteration: 33699 | Classification loss: 0.01612 | Regression loss: 0.01351 | Objectness loss: 0.00356 | RPN Regression loss: 0.00102 | Running loss: 0.03421\n","Epoch: 9 | Iteration: 33700 | Classification loss: 0.01338 | Regression loss: 0.03246 | Objectness loss: 0.00242 | RPN Regression loss: 0.00160 | Running loss: 0.04986\n","Epoch: 9 | Iteration: 33701 | Classification loss: 0.02399 | Regression loss: 0.02290 | Objectness loss: 0.00229 | RPN Regression loss: 0.00081 | Running loss: 0.04999\n","Epoch: 9 | Iteration: 33702 | Classification loss: 0.03106 | Regression loss: 0.01879 | Objectness loss: 0.02236 | RPN Regression loss: 0.00116 | Running loss: 0.07336\n","Epoch: 9 | Iteration: 33703 | Classification loss: 0.01001 | Regression loss: 0.01056 | Objectness loss: 0.00165 | RPN Regression loss: 0.00199 | Running loss: 0.02421\n","Epoch: 9 | Iteration: 33704 | Classification loss: 0.00865 | Regression loss: 0.01417 | Objectness loss: 0.00650 | RPN Regression loss: 0.00101 | Running loss: 0.03033\n","Epoch: 9 | Iteration: 33705 | Classification loss: 0.02693 | Regression loss: 0.03053 | Objectness loss: 0.01049 | RPN Regression loss: 0.00103 | Running loss: 0.06898\n","Epoch: 9 | Iteration: 33706 | Classification loss: 0.04281 | Regression loss: 0.02861 | Objectness loss: 0.00084 | RPN Regression loss: 0.00075 | Running loss: 0.07302\n","Epoch: 9 | Iteration: 33707 | Classification loss: 0.00948 | Regression loss: 0.01781 | Objectness loss: 0.00146 | RPN Regression loss: 0.00075 | Running loss: 0.02950\n","Epoch: 9 | Iteration: 33708 | Classification loss: 0.01581 | Regression loss: 0.02138 | Objectness loss: 0.00799 | RPN Regression loss: 0.00289 | Running loss: 0.04807\n","Epoch: 9 | Iteration: 33709 | Classification loss: 0.01597 | Regression loss: 0.01900 | Objectness loss: 0.00302 | RPN Regression loss: 0.00831 | Running loss: 0.04631\n","Epoch: 9 | Iteration: 33710 | Classification loss: 0.01831 | Regression loss: 0.02455 | Objectness loss: 0.00019 | RPN Regression loss: 0.00218 | Running loss: 0.04524\n","Epoch: 9 | Iteration: 33711 | Classification loss: 0.02777 | Regression loss: 0.04062 | Objectness loss: 0.00424 | RPN Regression loss: 0.00191 | Running loss: 0.07453\n","Epoch: 9 | Iteration: 33712 | Classification loss: 0.00812 | Regression loss: 0.01607 | Objectness loss: 0.00148 | RPN Regression loss: 0.00073 | Running loss: 0.02640\n","Epoch: 9 | Iteration: 33713 | Classification loss: 0.01332 | Regression loss: 0.01826 | Objectness loss: 0.00041 | RPN Regression loss: 0.00084 | Running loss: 0.03284\n","Epoch: 9 | Iteration: 33714 | Classification loss: 0.00706 | Regression loss: 0.02361 | Objectness loss: 0.00007 | RPN Regression loss: 0.00250 | Running loss: 0.03323\n","Epoch: 9 | Iteration: 33715 | Classification loss: 0.01841 | Regression loss: 0.02956 | Objectness loss: 0.00314 | RPN Regression loss: 0.00089 | Running loss: 0.05199\n","Epoch: 9 | Iteration: 33716 | Classification loss: 0.03984 | Regression loss: 0.04661 | Objectness loss: 0.00110 | RPN Regression loss: 0.00140 | Running loss: 0.08894\n","Epoch: 9 | Iteration: 33717 | Classification loss: 0.00774 | Regression loss: 0.01869 | Objectness loss: 0.00090 | RPN Regression loss: 0.00256 | Running loss: 0.02989\n","Epoch: 9 | Iteration: 33718 | Classification loss: 0.01722 | Regression loss: 0.01688 | Objectness loss: 0.01071 | RPN Regression loss: 0.00319 | Running loss: 0.04800\n","Epoch: 9 | Iteration: 33719 | Classification loss: 0.02313 | Regression loss: 0.02560 | Objectness loss: 0.00121 | RPN Regression loss: 0.00144 | Running loss: 0.05137\n","Epoch: 9 | Iteration: 33720 | Classification loss: 0.04696 | Regression loss: 0.05729 | Objectness loss: 0.00266 | RPN Regression loss: 0.00245 | Running loss: 0.10935\n","Epoch: 9 | Iteration: 33721 | Classification loss: 0.00804 | Regression loss: 0.01913 | Objectness loss: 0.00537 | RPN Regression loss: 0.00156 | Running loss: 0.03411\n","Epoch: 9 | Iteration: 33722 | Classification loss: 0.00914 | Regression loss: 0.01554 | Objectness loss: 0.00371 | RPN Regression loss: 0.00059 | Running loss: 0.02897\n","Epoch: 9 | Iteration: 33723 | Classification loss: 0.00883 | Regression loss: 0.01152 | Objectness loss: 0.00007 | RPN Regression loss: 0.00067 | Running loss: 0.02109\n","Epoch: 9 | Iteration: 33724 | Classification loss: 0.02646 | Regression loss: 0.02183 | Objectness loss: 0.00141 | RPN Regression loss: 0.00041 | Running loss: 0.05010\n","Epoch: 9 | Iteration: 33725 | Classification loss: 0.00911 | Regression loss: 0.01934 | Objectness loss: 0.00013 | RPN Regression loss: 0.00073 | Running loss: 0.02932\n","Epoch: 9 | Iteration: 33726 | Classification loss: 0.00934 | Regression loss: 0.01520 | Objectness loss: 0.00007 | RPN Regression loss: 0.00055 | Running loss: 0.02516\n","Epoch: 9 | Iteration: 33727 | Classification loss: 0.02076 | Regression loss: 0.03005 | Objectness loss: 0.00702 | RPN Regression loss: 0.00505 | Running loss: 0.06288\n","Epoch: 9 | Iteration: 33728 | Classification loss: 0.03814 | Regression loss: 0.02765 | Objectness loss: 0.00224 | RPN Regression loss: 0.00071 | Running loss: 0.06874\n","Epoch: 9 | Iteration: 33729 | Classification loss: 0.00824 | Regression loss: 0.01590 | Objectness loss: 0.00022 | RPN Regression loss: 0.00255 | Running loss: 0.02690\n","Epoch: 9 | Iteration: 33730 | Classification loss: 0.01831 | Regression loss: 0.02069 | Objectness loss: 0.00608 | RPN Regression loss: 0.00459 | Running loss: 0.04967\n","Epoch: 9 | Iteration: 33731 | Classification loss: 0.00931 | Regression loss: 0.01468 | Objectness loss: 0.00005 | RPN Regression loss: 0.00036 | Running loss: 0.02440\n","Epoch: 9 | Iteration: 33732 | Classification loss: 0.02541 | Regression loss: 0.03183 | Objectness loss: 0.00012 | RPN Regression loss: 0.00086 | Running loss: 0.05823\n","Epoch: 9 | Iteration: 33733 | Classification loss: 0.02187 | Regression loss: 0.03910 | Objectness loss: 0.00027 | RPN Regression loss: 0.00068 | Running loss: 0.06191\n","Epoch: 9 | Iteration: 33734 | Classification loss: 0.01587 | Regression loss: 0.03355 | Objectness loss: 0.00041 | RPN Regression loss: 0.00139 | Running loss: 0.05122\n","Epoch: 9 | Iteration: 33735 | Classification loss: 0.01320 | Regression loss: 0.02175 | Objectness loss: 0.00062 | RPN Regression loss: 0.00147 | Running loss: 0.03704\n","Epoch: 9 | Iteration: 33736 | Classification loss: 0.02923 | Regression loss: 0.04540 | Objectness loss: 0.00163 | RPN Regression loss: 0.00128 | Running loss: 0.07754\n","Epoch: 9 | Iteration: 33737 | Classification loss: 0.00791 | Regression loss: 0.01849 | Objectness loss: 0.00485 | RPN Regression loss: 0.00238 | Running loss: 0.03363\n","Epoch: 9 | Iteration: 33738 | Classification loss: 0.01704 | Regression loss: 0.01841 | Objectness loss: 0.00151 | RPN Regression loss: 0.00131 | Running loss: 0.03827\n","Epoch: 9 | Iteration: 33739 | Classification loss: 0.04087 | Regression loss: 0.05444 | Objectness loss: 0.00030 | RPN Regression loss: 0.00141 | Running loss: 0.09703\n","Epoch: 9 | Iteration: 33740 | Classification loss: 0.01358 | Regression loss: 0.03001 | Objectness loss: 0.00434 | RPN Regression loss: 0.02261 | Running loss: 0.07055\n","Epoch: 9 | Iteration: 33741 | Classification loss: 0.00686 | Regression loss: 0.01609 | Objectness loss: 0.00146 | RPN Regression loss: 0.00249 | Running loss: 0.02690\n","Epoch: 9 | Iteration: 33742 | Classification loss: 0.00862 | Regression loss: 0.01838 | Objectness loss: 0.00051 | RPN Regression loss: 0.00108 | Running loss: 0.02858\n","Epoch: 9 | Iteration: 33743 | Classification loss: 0.01588 | Regression loss: 0.03290 | Objectness loss: 0.00117 | RPN Regression loss: 0.00087 | Running loss: 0.05081\n","Epoch: 9 | Iteration: 33744 | Classification loss: 0.01916 | Regression loss: 0.03819 | Objectness loss: 0.00066 | RPN Regression loss: 0.00160 | Running loss: 0.05961\n","Epoch: 9 | Iteration: 33745 | Classification loss: 0.00941 | Regression loss: 0.02529 | Objectness loss: 0.00616 | RPN Regression loss: 0.00202 | Running loss: 0.04288\n","Epoch: 9 | Iteration: 33746 | Classification loss: 0.00705 | Regression loss: 0.01970 | Objectness loss: 0.00012 | RPN Regression loss: 0.00067 | Running loss: 0.02754\n","Epoch: 9 | Iteration: 33747 | Classification loss: 0.01156 | Regression loss: 0.01585 | Objectness loss: 0.00014 | RPN Regression loss: 0.00057 | Running loss: 0.02811\n","Epoch: 9 | Iteration: 33748 | Classification loss: 0.01158 | Regression loss: 0.02515 | Objectness loss: 0.00023 | RPN Regression loss: 0.00134 | Running loss: 0.03830\n","Epoch: 9 | Iteration: 33749 | Classification loss: 0.01697 | Regression loss: 0.01654 | Objectness loss: 0.00047 | RPN Regression loss: 0.00288 | Running loss: 0.03686\n","Epoch: 9 | Iteration: 33750 | Classification loss: 0.02130 | Regression loss: 0.01408 | Objectness loss: 0.00078 | RPN Regression loss: 0.00069 | Running loss: 0.03684\n","Epoch: 9 | Iteration: 33751 | Classification loss: 0.01013 | Regression loss: 0.01157 | Objectness loss: 0.00007 | RPN Regression loss: 0.00100 | Running loss: 0.02277\n","Epoch: 9 | Iteration: 33752 | Classification loss: 0.01780 | Regression loss: 0.01004 | Objectness loss: 0.00031 | RPN Regression loss: 0.00049 | Running loss: 0.02864\n","Epoch: 9 | Iteration: 33753 | Classification loss: 0.02161 | Regression loss: 0.02426 | Objectness loss: 0.00017 | RPN Regression loss: 0.00077 | Running loss: 0.04681\n","Epoch: 9 | Iteration: 33754 | Classification loss: 0.01607 | Regression loss: 0.01532 | Objectness loss: 0.00041 | RPN Regression loss: 0.00217 | Running loss: 0.03397\n","Epoch: 9 | Iteration: 33755 | Classification loss: 0.01939 | Regression loss: 0.01471 | Objectness loss: 0.00032 | RPN Regression loss: 0.00041 | Running loss: 0.03483\n","Epoch: 9 | Iteration: 33756 | Classification loss: 0.02524 | Regression loss: 0.02083 | Objectness loss: 0.00185 | RPN Regression loss: 0.00107 | Running loss: 0.04899\n","Epoch: 9 | Iteration: 33757 | Classification loss: 0.00954 | Regression loss: 0.02353 | Objectness loss: 0.00099 | RPN Regression loss: 0.00101 | Running loss: 0.03506\n","Epoch: 9 | Iteration: 33758 | Classification loss: 0.02783 | Regression loss: 0.02308 | Objectness loss: 0.01437 | RPN Regression loss: 0.00221 | Running loss: 0.06749\n","Epoch: 9 | Iteration: 33759 | Classification loss: 0.01078 | Regression loss: 0.02435 | Objectness loss: 0.00038 | RPN Regression loss: 0.00162 | Running loss: 0.03713\n","Epoch: 9 | Iteration: 33760 | Classification loss: 0.03789 | Regression loss: 0.04740 | Objectness loss: 0.00093 | RPN Regression loss: 0.01502 | Running loss: 0.10124\n","Epoch: 9 | Iteration: 33761 | Classification loss: 0.00984 | Regression loss: 0.01887 | Objectness loss: 0.00004 | RPN Regression loss: 0.00051 | Running loss: 0.02926\n","Epoch: 9 | Iteration: 33762 | Classification loss: 0.01343 | Regression loss: 0.02905 | Objectness loss: 0.00018 | RPN Regression loss: 0.00122 | Running loss: 0.04387\n","Epoch: 9 | Iteration: 33763 | Classification loss: 0.00822 | Regression loss: 0.01992 | Objectness loss: 0.00351 | RPN Regression loss: 0.00078 | Running loss: 0.03242\n","Epoch: 9 | Iteration: 33764 | Classification loss: 0.02382 | Regression loss: 0.02602 | Objectness loss: 0.00006 | RPN Regression loss: 0.00109 | Running loss: 0.05099\n","Epoch: 9 | Iteration: 33765 | Classification loss: 0.01152 | Regression loss: 0.01213 | Objectness loss: 0.00014 | RPN Regression loss: 0.00231 | Running loss: 0.02610\n","Epoch: 9 | Iteration: 33766 | Classification loss: 0.00934 | Regression loss: 0.01430 | Objectness loss: 0.00042 | RPN Regression loss: 0.00328 | Running loss: 0.02734\n","Epoch: 9 | Iteration: 33767 | Classification loss: 0.02030 | Regression loss: 0.01907 | Objectness loss: 0.00122 | RPN Regression loss: 0.00110 | Running loss: 0.04169\n","Epoch: 9 | Iteration: 33768 | Classification loss: 0.01594 | Regression loss: 0.02780 | Objectness loss: 0.00063 | RPN Regression loss: 0.00106 | Running loss: 0.04544\n","Epoch: 9 | Iteration: 33769 | Classification loss: 0.00951 | Regression loss: 0.01979 | Objectness loss: 0.00071 | RPN Regression loss: 0.00078 | Running loss: 0.03079\n","Epoch: 9 | Iteration: 33770 | Classification loss: 0.04062 | Regression loss: 0.02712 | Objectness loss: 0.00881 | RPN Regression loss: 0.00456 | Running loss: 0.08110\n","Epoch: 9 | Iteration: 33771 | Classification loss: 0.02268 | Regression loss: 0.02543 | Objectness loss: 0.00050 | RPN Regression loss: 0.00136 | Running loss: 0.04998\n","Epoch: 9 | Iteration: 33772 | Classification loss: 0.00794 | Regression loss: 0.01997 | Objectness loss: 0.00009 | RPN Regression loss: 0.00108 | Running loss: 0.02909\n","Epoch: 9 | Iteration: 33773 | Classification loss: 0.02082 | Regression loss: 0.01486 | Objectness loss: 0.00026 | RPN Regression loss: 0.00078 | Running loss: 0.03672\n","Epoch: 9 | Iteration: 33774 | Classification loss: 0.02746 | Regression loss: 0.05013 | Objectness loss: 0.00133 | RPN Regression loss: 0.00327 | Running loss: 0.08219\n","Epoch: 9 | Iteration: 33775 | Classification loss: 0.01849 | Regression loss: 0.03486 | Objectness loss: 0.00056 | RPN Regression loss: 0.00093 | Running loss: 0.05484\n","Epoch: 9 | Iteration: 33776 | Classification loss: 0.00874 | Regression loss: 0.01756 | Objectness loss: 0.00130 | RPN Regression loss: 0.00055 | Running loss: 0.02815\n","Epoch: 9 | Iteration: 33777 | Classification loss: 0.04623 | Regression loss: 0.02760 | Objectness loss: 0.00050 | RPN Regression loss: 0.00086 | Running loss: 0.07518\n","Epoch: 9 | Iteration: 33778 | Classification loss: 0.00974 | Regression loss: 0.01946 | Objectness loss: 0.00038 | RPN Regression loss: 0.00190 | Running loss: 0.03148\n","Epoch: 9 | Iteration: 33779 | Classification loss: 0.00802 | Regression loss: 0.01400 | Objectness loss: 0.00016 | RPN Regression loss: 0.00066 | Running loss: 0.02284\n","Epoch: 9 | Iteration: 33780 | Classification loss: 0.01214 | Regression loss: 0.03399 | Objectness loss: 0.00047 | RPN Regression loss: 0.00086 | Running loss: 0.04745\n","Epoch: 9 | Iteration: 33781 | Classification loss: 0.02048 | Regression loss: 0.04064 | Objectness loss: 0.00022 | RPN Regression loss: 0.00219 | Running loss: 0.06352\n","Epoch: 9 | Iteration: 33782 | Classification loss: 0.01008 | Regression loss: 0.02748 | Objectness loss: 0.00006 | RPN Regression loss: 0.00195 | Running loss: 0.03958\n","Epoch: 9 | Iteration: 33783 | Classification loss: 0.01255 | Regression loss: 0.01769 | Objectness loss: 0.00609 | RPN Regression loss: 0.00279 | Running loss: 0.03912\n","Epoch: 9 | Iteration: 33784 | Classification loss: 0.01894 | Regression loss: 0.02252 | Objectness loss: 0.00014 | RPN Regression loss: 0.00103 | Running loss: 0.04262\n","Epoch: 9 | Iteration: 33785 | Classification loss: 0.01056 | Regression loss: 0.01466 | Objectness loss: 0.00272 | RPN Regression loss: 0.00418 | Running loss: 0.03212\n","Epoch: 9 | Iteration: 33786 | Classification loss: 0.02070 | Regression loss: 0.01612 | Objectness loss: 0.00006 | RPN Regression loss: 0.00043 | Running loss: 0.03731\n","Epoch: 9 | Iteration: 33787 | Classification loss: 0.03497 | Regression loss: 0.05593 | Objectness loss: 0.00322 | RPN Regression loss: 0.00483 | Running loss: 0.09896\n","Epoch: 9 | Iteration: 33788 | Classification loss: 0.02717 | Regression loss: 0.03110 | Objectness loss: 0.00727 | RPN Regression loss: 0.00119 | Running loss: 0.06672\n","Epoch: 9 | Iteration: 33789 | Classification loss: 0.00990 | Regression loss: 0.01071 | Objectness loss: 0.00010 | RPN Regression loss: 0.00082 | Running loss: 0.02152\n","Epoch: 9 | Iteration: 33790 | Classification loss: 0.03185 | Regression loss: 0.02784 | Objectness loss: 0.00193 | RPN Regression loss: 0.00077 | Running loss: 0.06238\n","Epoch: 9 | Iteration: 33791 | Classification loss: 0.02081 | Regression loss: 0.02863 | Objectness loss: 0.00167 | RPN Regression loss: 0.00155 | Running loss: 0.05265\n","Epoch: 9 | Iteration: 33792 | Classification loss: 0.02396 | Regression loss: 0.02450 | Objectness loss: 0.00015 | RPN Regression loss: 0.00224 | Running loss: 0.05086\n","Epoch: 9 | Iteration: 33793 | Classification loss: 0.02013 | Regression loss: 0.02902 | Objectness loss: 0.00216 | RPN Regression loss: 0.00177 | Running loss: 0.05307\n","Epoch: 9 | Iteration: 33794 | Classification loss: 0.01594 | Regression loss: 0.01497 | Objectness loss: 0.00009 | RPN Regression loss: 0.00036 | Running loss: 0.03136\n","Epoch: 9 | Iteration: 33795 | Classification loss: 0.00761 | Regression loss: 0.01000 | Objectness loss: 0.00002 | RPN Regression loss: 0.00164 | Running loss: 0.01927\n","Epoch: 9 | Iteration: 33796 | Classification loss: 0.01549 | Regression loss: 0.02420 | Objectness loss: 0.00040 | RPN Regression loss: 0.00196 | Running loss: 0.04204\n","Epoch: 9 | Iteration: 33797 | Classification loss: 0.01758 | Regression loss: 0.01572 | Objectness loss: 0.00024 | RPN Regression loss: 0.00096 | Running loss: 0.03450\n","Epoch: 9 | Iteration: 33798 | Classification loss: 0.02070 | Regression loss: 0.03346 | Objectness loss: 0.00231 | RPN Regression loss: 0.00399 | Running loss: 0.06045\n","Epoch: 9 | Iteration: 33799 | Classification loss: 0.00798 | Regression loss: 0.02233 | Objectness loss: 0.00073 | RPN Regression loss: 0.00256 | Running loss: 0.03360\n","Epoch: 9 | Iteration: 33800 | Classification loss: 0.02013 | Regression loss: 0.04496 | Objectness loss: 0.00026 | RPN Regression loss: 0.00073 | Running loss: 0.06608\n","Epoch: 9 | Iteration: 33801 | Classification loss: 0.01349 | Regression loss: 0.02187 | Objectness loss: 0.00020 | RPN Regression loss: 0.00209 | Running loss: 0.03764\n","Epoch: 9 | Iteration: 33802 | Classification loss: 0.01125 | Regression loss: 0.01824 | Objectness loss: 0.00337 | RPN Regression loss: 0.00224 | Running loss: 0.03509\n","Epoch: 9 | Iteration: 33803 | Classification loss: 0.00991 | Regression loss: 0.01859 | Objectness loss: 0.00355 | RPN Regression loss: 0.00092 | Running loss: 0.03297\n","Epoch: 9 | Iteration: 33804 | Classification loss: 0.01421 | Regression loss: 0.01604 | Objectness loss: 0.00062 | RPN Regression loss: 0.00095 | Running loss: 0.03182\n","Epoch: 9 | Iteration: 33805 | Classification loss: 0.02246 | Regression loss: 0.01336 | Objectness loss: 0.00012 | RPN Regression loss: 0.00033 | Running loss: 0.03627\n","Epoch: 9 | Iteration: 33806 | Classification loss: 0.01029 | Regression loss: 0.02149 | Objectness loss: 0.00046 | RPN Regression loss: 0.00109 | Running loss: 0.03333\n","Epoch: 9 | Iteration: 33807 | Classification loss: 0.01376 | Regression loss: 0.03201 | Objectness loss: 0.00538 | RPN Regression loss: 0.00298 | Running loss: 0.05413\n","Epoch: 9 | Iteration: 33808 | Classification loss: 0.02995 | Regression loss: 0.02807 | Objectness loss: 0.00015 | RPN Regression loss: 0.00057 | Running loss: 0.05873\n","Epoch: 9 | Iteration: 33809 | Classification loss: 0.00836 | Regression loss: 0.02010 | Objectness loss: 0.00010 | RPN Regression loss: 0.00496 | Running loss: 0.03353\n","Epoch: 9 | Iteration: 33810 | Classification loss: 0.00569 | Regression loss: 0.01714 | Objectness loss: 0.00006 | RPN Regression loss: 0.00036 | Running loss: 0.02325\n","Epoch: 9 | Iteration: 33811 | Classification loss: 0.03871 | Regression loss: 0.03155 | Objectness loss: 0.00085 | RPN Regression loss: 0.00131 | Running loss: 0.07241\n","Epoch: 9 | Iteration: 33812 | Classification loss: 0.00985 | Regression loss: 0.02192 | Objectness loss: 0.00009 | RPN Regression loss: 0.00115 | Running loss: 0.03301\n","Epoch: 9 | Iteration: 33813 | Classification loss: 0.03313 | Regression loss: 0.02208 | Objectness loss: 0.00008 | RPN Regression loss: 0.00233 | Running loss: 0.05763\n","Epoch: 9 | Iteration: 33814 | Classification loss: 0.00820 | Regression loss: 0.02196 | Objectness loss: 0.00037 | RPN Regression loss: 0.00516 | Running loss: 0.03569\n","Epoch: 9 | Iteration: 33815 | Classification loss: 0.01516 | Regression loss: 0.01206 | Objectness loss: 0.00139 | RPN Regression loss: 0.00158 | Running loss: 0.03019\n","Epoch: 9 | Iteration: 33816 | Classification loss: 0.02452 | Regression loss: 0.02517 | Objectness loss: 0.00013 | RPN Regression loss: 0.00115 | Running loss: 0.05096\n","Epoch: 9 | Iteration: 33817 | Classification loss: 0.01195 | Regression loss: 0.01649 | Objectness loss: 0.00084 | RPN Regression loss: 0.00024 | Running loss: 0.02952\n","Epoch: 9 | Iteration: 33818 | Classification loss: 0.01324 | Regression loss: 0.01430 | Objectness loss: 0.00003 | RPN Regression loss: 0.00064 | Running loss: 0.02821\n","Epoch: 9 | Iteration: 33819 | Classification loss: 0.01165 | Regression loss: 0.01827 | Objectness loss: 0.00176 | RPN Regression loss: 0.00089 | Running loss: 0.03257\n","Epoch: 9 | Iteration: 33820 | Classification loss: 0.02835 | Regression loss: 0.03995 | Objectness loss: 0.00015 | RPN Regression loss: 0.00236 | Running loss: 0.07081\n","Epoch: 9 | Iteration: 33821 | Classification loss: 0.00660 | Regression loss: 0.01736 | Objectness loss: 0.00012 | RPN Regression loss: 0.00105 | Running loss: 0.02513\n","Epoch: 9 | Iteration: 33822 | Classification loss: 0.02226 | Regression loss: 0.02798 | Objectness loss: 0.00015 | RPN Regression loss: 0.00063 | Running loss: 0.05102\n","Epoch: 9 | Iteration: 33823 | Classification loss: 0.04211 | Regression loss: 0.02265 | Objectness loss: 0.00006 | RPN Regression loss: 0.00045 | Running loss: 0.06526\n","Epoch: 9 | Iteration: 33824 | Classification loss: 0.02012 | Regression loss: 0.03322 | Objectness loss: 0.00016 | RPN Regression loss: 0.00202 | Running loss: 0.05552\n","Epoch: 9 | Iteration: 33825 | Classification loss: 0.01142 | Regression loss: 0.02122 | Objectness loss: 0.00189 | RPN Regression loss: 0.00283 | Running loss: 0.03737\n","Epoch: 9 | Iteration: 33826 | Classification loss: 0.01482 | Regression loss: 0.03227 | Objectness loss: 0.00008 | RPN Regression loss: 0.00133 | Running loss: 0.04849\n","Epoch: 9 | Iteration: 33827 | Classification loss: 0.01447 | Regression loss: 0.01900 | Objectness loss: 0.00044 | RPN Regression loss: 0.00091 | Running loss: 0.03481\n","Epoch: 9 | Iteration: 33828 | Classification loss: 0.01838 | Regression loss: 0.02982 | Objectness loss: 0.00391 | RPN Regression loss: 0.00480 | Running loss: 0.05691\n","Epoch: 9 | Iteration: 33829 | Classification loss: 0.04324 | Regression loss: 0.02849 | Objectness loss: 0.00200 | RPN Regression loss: 0.00536 | Running loss: 0.07910\n","Epoch: 9 | Iteration: 33830 | Classification loss: 0.00892 | Regression loss: 0.01491 | Objectness loss: 0.00067 | RPN Regression loss: 0.00230 | Running loss: 0.02680\n","Epoch: 9 | Iteration: 33831 | Classification loss: 0.01201 | Regression loss: 0.03430 | Objectness loss: 0.00029 | RPN Regression loss: 0.00124 | Running loss: 0.04783\n","Epoch: 9 | Iteration: 33832 | Classification loss: 0.01080 | Regression loss: 0.01294 | Objectness loss: 0.00027 | RPN Regression loss: 0.00090 | Running loss: 0.02491\n","Epoch: 9 | Iteration: 33833 | Classification loss: 0.02820 | Regression loss: 0.02242 | Objectness loss: 0.00006 | RPN Regression loss: 0.00107 | Running loss: 0.05175\n","Epoch: 9 | Iteration: 33834 | Classification loss: 0.00964 | Regression loss: 0.02266 | Objectness loss: 0.00024 | RPN Regression loss: 0.00092 | Running loss: 0.03347\n","Epoch: 9 | Iteration: 33835 | Classification loss: 0.00789 | Regression loss: 0.02183 | Objectness loss: 0.00026 | RPN Regression loss: 0.00198 | Running loss: 0.03196\n","Epoch: 9 | Iteration: 33836 | Classification loss: 0.02627 | Regression loss: 0.03864 | Objectness loss: 0.00303 | RPN Regression loss: 0.00477 | Running loss: 0.07271\n","Epoch: 9 | Iteration: 33837 | Classification loss: 0.04142 | Regression loss: 0.03157 | Objectness loss: 0.00089 | RPN Regression loss: 0.00038 | Running loss: 0.07426\n","Epoch: 9 | Iteration: 33838 | Classification loss: 0.02599 | Regression loss: 0.01642 | Objectness loss: 0.00006 | RPN Regression loss: 0.00115 | Running loss: 0.04363\n","Epoch: 9 | Iteration: 33839 | Classification loss: 0.01069 | Regression loss: 0.01800 | Objectness loss: 0.00002 | RPN Regression loss: 0.00092 | Running loss: 0.02964\n","Epoch: 9 | Iteration: 33840 | Classification loss: 0.02259 | Regression loss: 0.03026 | Objectness loss: 0.00350 | RPN Regression loss: 0.00076 | Running loss: 0.05712\n","Epoch: 9 | Iteration: 33841 | Classification loss: 0.02181 | Regression loss: 0.03555 | Objectness loss: 0.00006 | RPN Regression loss: 0.00076 | Running loss: 0.05817\n","Epoch: 9 | Iteration: 33842 | Classification loss: 0.00991 | Regression loss: 0.02194 | Objectness loss: 0.00006 | RPN Regression loss: 0.00102 | Running loss: 0.03294\n","Epoch: 9 | Iteration: 33843 | Classification loss: 0.01633 | Regression loss: 0.02220 | Objectness loss: 0.00159 | RPN Regression loss: 0.00149 | Running loss: 0.04160\n","Epoch: 9 | Iteration: 33844 | Classification loss: 0.05757 | Regression loss: 0.06342 | Objectness loss: 0.00222 | RPN Regression loss: 0.00108 | Running loss: 0.12428\n","Epoch: 9 | Iteration: 33845 | Classification loss: 0.02559 | Regression loss: 0.02602 | Objectness loss: 0.00723 | RPN Regression loss: 0.00114 | Running loss: 0.05999\n","Epoch: 9 | Iteration: 33846 | Classification loss: 0.01959 | Regression loss: 0.01829 | Objectness loss: 0.00065 | RPN Regression loss: 0.00085 | Running loss: 0.03937\n","Epoch: 9 | Iteration: 33847 | Classification loss: 0.00792 | Regression loss: 0.01628 | Objectness loss: 0.00008 | RPN Regression loss: 0.00177 | Running loss: 0.02605\n","Epoch: 9 | Iteration: 33848 | Classification loss: 0.02226 | Regression loss: 0.04366 | Objectness loss: 0.00091 | RPN Regression loss: 0.00078 | Running loss: 0.06761\n","Epoch: 9 | Iteration: 33849 | Classification loss: 0.00802 | Regression loss: 0.01589 | Objectness loss: 0.00018 | RPN Regression loss: 0.00098 | Running loss: 0.02506\n","Epoch: 9 | Iteration: 33850 | Classification loss: 0.00948 | Regression loss: 0.01313 | Objectness loss: 0.00006 | RPN Regression loss: 0.00118 | Running loss: 0.02384\n","Epoch: 9 | Iteration: 33851 | Classification loss: 0.03630 | Regression loss: 0.01974 | Objectness loss: 0.00401 | RPN Regression loss: 0.00452 | Running loss: 0.06457\n","Epoch: 9 | Iteration: 33852 | Classification loss: 0.08185 | Regression loss: 0.03931 | Objectness loss: 0.00599 | RPN Regression loss: 0.00231 | Running loss: 0.12945\n","Epoch: 9 | Iteration: 33853 | Classification loss: 0.01188 | Regression loss: 0.02264 | Objectness loss: 0.00071 | RPN Regression loss: 0.00136 | Running loss: 0.03659\n","Epoch: 9 | Iteration: 33854 | Classification loss: 0.00863 | Regression loss: 0.02416 | Objectness loss: 0.00058 | RPN Regression loss: 0.00051 | Running loss: 0.03387\n","Epoch: 9 | Iteration: 33855 | Classification loss: 0.00812 | Regression loss: 0.01553 | Objectness loss: 0.00015 | RPN Regression loss: 0.00087 | Running loss: 0.02467\n","Epoch: 9 | Iteration: 33856 | Classification loss: 0.01611 | Regression loss: 0.02697 | Objectness loss: 0.00130 | RPN Regression loss: 0.00577 | Running loss: 0.05015\n","Epoch: 9 | Iteration: 33857 | Classification loss: 0.02932 | Regression loss: 0.02747 | Objectness loss: 0.00591 | RPN Regression loss: 0.00195 | Running loss: 0.06465\n","Epoch: 9 | Iteration: 33858 | Classification loss: 0.01528 | Regression loss: 0.03148 | Objectness loss: 0.00404 | RPN Regression loss: 0.05346 | Running loss: 0.10426\n","Epoch: 9 | Iteration: 33859 | Classification loss: 0.01238 | Regression loss: 0.02299 | Objectness loss: 0.00024 | RPN Regression loss: 0.00158 | Running loss: 0.03718\n","Epoch: 9 | Iteration: 33860 | Classification loss: 0.01827 | Regression loss: 0.01850 | Objectness loss: 0.00053 | RPN Regression loss: 0.00237 | Running loss: 0.03967\n","Epoch: 9 | Iteration: 33861 | Classification loss: 0.01393 | Regression loss: 0.01506 | Objectness loss: 0.00013 | RPN Regression loss: 0.00130 | Running loss: 0.03042\n","Epoch: 9 | Iteration: 33862 | Classification loss: 0.02317 | Regression loss: 0.06416 | Objectness loss: 0.00055 | RPN Regression loss: 0.00189 | Running loss: 0.08977\n","Epoch: 9 | Iteration: 33863 | Classification loss: 0.03160 | Regression loss: 0.02590 | Objectness loss: 0.00052 | RPN Regression loss: 0.00065 | Running loss: 0.05868\n","Epoch: 9 | Iteration: 33864 | Classification loss: 0.02297 | Regression loss: 0.01485 | Objectness loss: 0.00033 | RPN Regression loss: 0.00074 | Running loss: 0.03889\n","Epoch: 9 | Iteration: 33865 | Classification loss: 0.01640 | Regression loss: 0.03845 | Objectness loss: 0.00015 | RPN Regression loss: 0.00125 | Running loss: 0.05625\n","Epoch: 9 | Iteration: 33866 | Classification loss: 0.01169 | Regression loss: 0.02735 | Objectness loss: 0.00019 | RPN Regression loss: 0.00206 | Running loss: 0.04130\n","Epoch: 9 | Iteration: 33867 | Classification loss: 0.00660 | Regression loss: 0.01302 | Objectness loss: 0.00025 | RPN Regression loss: 0.00089 | Running loss: 0.02075\n","Epoch: 9 | Iteration: 33868 | Classification loss: 0.02220 | Regression loss: 0.01592 | Objectness loss: 0.00246 | RPN Regression loss: 0.00103 | Running loss: 0.04161\n","Epoch: 9 | Iteration: 33869 | Classification loss: 0.02124 | Regression loss: 0.02375 | Objectness loss: 0.00073 | RPN Regression loss: 0.00118 | Running loss: 0.04690\n","Epoch: 9 | Iteration: 33870 | Classification loss: 0.02371 | Regression loss: 0.02466 | Objectness loss: 0.00012 | RPN Regression loss: 0.00049 | Running loss: 0.04898\n","Epoch: 9 | Iteration: 33871 | Classification loss: 0.02202 | Regression loss: 0.01777 | Objectness loss: 0.00033 | RPN Regression loss: 0.00148 | Running loss: 0.04160\n","Epoch: 9 | Iteration: 33872 | Classification loss: 0.02393 | Regression loss: 0.02322 | Objectness loss: 0.00150 | RPN Regression loss: 0.00196 | Running loss: 0.05061\n","Epoch: 9 | Iteration: 33873 | Classification loss: 0.02296 | Regression loss: 0.02093 | Objectness loss: 0.00050 | RPN Regression loss: 0.00175 | Running loss: 0.04614\n","Epoch: 9 | Iteration: 33874 | Classification loss: 0.03087 | Regression loss: 0.02229 | Objectness loss: 0.00057 | RPN Regression loss: 0.00089 | Running loss: 0.05462\n","Epoch: 9 | Iteration: 33875 | Classification loss: 0.02816 | Regression loss: 0.01733 | Objectness loss: 0.00564 | RPN Regression loss: 0.00242 | Running loss: 0.05355\n","Epoch: 9 | Iteration: 33876 | Classification loss: 0.00785 | Regression loss: 0.02246 | Objectness loss: 0.00025 | RPN Regression loss: 0.00206 | Running loss: 0.03263\n","Epoch: 9 | Iteration: 33877 | Classification loss: 0.01369 | Regression loss: 0.03268 | Objectness loss: 0.00017 | RPN Regression loss: 0.00192 | Running loss: 0.04847\n","Epoch: 9 | Iteration: 33878 | Classification loss: 0.01575 | Regression loss: 0.01768 | Objectness loss: 0.00049 | RPN Regression loss: 0.00133 | Running loss: 0.03525\n","Epoch: 9 | Iteration: 33879 | Classification loss: 0.00473 | Regression loss: 0.01401 | Objectness loss: 0.00349 | RPN Regression loss: 0.00045 | Running loss: 0.02267\n","Epoch: 9 | Iteration: 33880 | Classification loss: 0.01390 | Regression loss: 0.02189 | Objectness loss: 0.00016 | RPN Regression loss: 0.00177 | Running loss: 0.03771\n","Epoch: 9 | Iteration: 33881 | Classification loss: 0.01090 | Regression loss: 0.01271 | Objectness loss: 0.00091 | RPN Regression loss: 0.00135 | Running loss: 0.02587\n","Epoch: 9 | Iteration: 33882 | Classification loss: 0.01155 | Regression loss: 0.01927 | Objectness loss: 0.00194 | RPN Regression loss: 0.00107 | Running loss: 0.03383\n","Epoch: 9 | Iteration: 33883 | Classification loss: 0.00892 | Regression loss: 0.01179 | Objectness loss: 0.00006 | RPN Regression loss: 0.00306 | Running loss: 0.02383\n","Epoch: 9 | Iteration: 33884 | Classification loss: 0.02023 | Regression loss: 0.02744 | Objectness loss: 0.00027 | RPN Regression loss: 0.00218 | Running loss: 0.05013\n","Epoch: 9 | Iteration: 33885 | Classification loss: 0.00786 | Regression loss: 0.01371 | Objectness loss: 0.00063 | RPN Regression loss: 0.00074 | Running loss: 0.02294\n","Epoch: 9 | Iteration: 33886 | Classification loss: 0.02232 | Regression loss: 0.02522 | Objectness loss: 0.00028 | RPN Regression loss: 0.00363 | Running loss: 0.05145\n","Epoch: 9 | Iteration: 33887 | Classification loss: 0.03530 | Regression loss: 0.02150 | Objectness loss: 0.00014 | RPN Regression loss: 0.00103 | Running loss: 0.05798\n","Epoch: 9 | Iteration: 33888 | Classification loss: 0.03377 | Regression loss: 0.01914 | Objectness loss: 0.00005 | RPN Regression loss: 0.00083 | Running loss: 0.05379\n","Epoch: 9 | Iteration: 33889 | Classification loss: 0.02550 | Regression loss: 0.01915 | Objectness loss: 0.00086 | RPN Regression loss: 0.00396 | Running loss: 0.04947\n","Epoch: 9 | Iteration: 33890 | Classification loss: 0.01069 | Regression loss: 0.03449 | Objectness loss: 0.00098 | RPN Regression loss: 0.00072 | Running loss: 0.04688\n","Epoch: 9 | Iteration: 33891 | Classification loss: 0.02134 | Regression loss: 0.02441 | Objectness loss: 0.00577 | RPN Regression loss: 0.00223 | Running loss: 0.05376\n","Epoch: 9 | Iteration: 33892 | Classification loss: 0.03022 | Regression loss: 0.01325 | Objectness loss: 0.00010 | RPN Regression loss: 0.00149 | Running loss: 0.04506\n","Epoch: 9 | Iteration: 33893 | Classification loss: 0.01922 | Regression loss: 0.02739 | Objectness loss: 0.00050 | RPN Regression loss: 0.00143 | Running loss: 0.04853\n","Epoch: 9 | Iteration: 33894 | Classification loss: 0.02457 | Regression loss: 0.02457 | Objectness loss: 0.00042 | RPN Regression loss: 0.00235 | Running loss: 0.05191\n","Epoch: 9 | Iteration: 33895 | Classification loss: 0.01163 | Regression loss: 0.02400 | Objectness loss: 0.00065 | RPN Regression loss: 0.00099 | Running loss: 0.03726\n","Epoch: 9 | Iteration: 33896 | Classification loss: 0.02468 | Regression loss: 0.01852 | Objectness loss: 0.00414 | RPN Regression loss: 0.00260 | Running loss: 0.04993\n","Epoch: 9 | Iteration: 33897 | Classification loss: 0.02002 | Regression loss: 0.02248 | Objectness loss: 0.00036 | RPN Regression loss: 0.00085 | Running loss: 0.04370\n","Epoch: 9 | Iteration: 33898 | Classification loss: 0.02589 | Regression loss: 0.01830 | Objectness loss: 0.00004 | RPN Regression loss: 0.00110 | Running loss: 0.04533\n","Epoch: 9 | Iteration: 33899 | Classification loss: 0.01920 | Regression loss: 0.02857 | Objectness loss: 0.00074 | RPN Regression loss: 0.00092 | Running loss: 0.04944\n","Epoch: 9 | Iteration: 33900 | Classification loss: 0.00989 | Regression loss: 0.01424 | Objectness loss: 0.00143 | RPN Regression loss: 0.00295 | Running loss: 0.02850\n","Epoch: 9 | Iteration: 33901 | Classification loss: 0.01326 | Regression loss: 0.02027 | Objectness loss: 0.00013 | RPN Regression loss: 0.00089 | Running loss: 0.03455\n","Epoch: 9 | Iteration: 33902 | Classification loss: 0.00862 | Regression loss: 0.02497 | Objectness loss: 0.00102 | RPN Regression loss: 0.00068 | Running loss: 0.03529\n","Epoch: 9 | Iteration: 33903 | Classification loss: 0.01317 | Regression loss: 0.01282 | Objectness loss: 0.00004 | RPN Regression loss: 0.00295 | Running loss: 0.02898\n","Epoch: 9 | Iteration: 33904 | Classification loss: 0.01073 | Regression loss: 0.01504 | Objectness loss: 0.00013 | RPN Regression loss: 0.00576 | Running loss: 0.03165\n","Epoch: 9 | Iteration: 33905 | Classification loss: 0.00934 | Regression loss: 0.01841 | Objectness loss: 0.00029 | RPN Regression loss: 0.00137 | Running loss: 0.02940\n","Epoch: 9 | Iteration: 33906 | Classification loss: 0.04210 | Regression loss: 0.06404 | Objectness loss: 0.00328 | RPN Regression loss: 0.01112 | Running loss: 0.12054\n","Epoch: 9 | Iteration: 33907 | Classification loss: 0.01055 | Regression loss: 0.01721 | Objectness loss: 0.00024 | RPN Regression loss: 0.00129 | Running loss: 0.02930\n","Epoch: 9 | Iteration: 33908 | Classification loss: 0.00588 | Regression loss: 0.01508 | Objectness loss: 0.00036 | RPN Regression loss: 0.00347 | Running loss: 0.02479\n","Epoch: 9 | Iteration: 33909 | Classification loss: 0.02134 | Regression loss: 0.04276 | Objectness loss: 0.00020 | RPN Regression loss: 0.00147 | Running loss: 0.06577\n","Epoch: 9 | Iteration: 33910 | Classification loss: 0.00536 | Regression loss: 0.01375 | Objectness loss: 0.00001 | RPN Regression loss: 0.00076 | Running loss: 0.01987\n","Epoch: 9 | Iteration: 33911 | Classification loss: 0.02680 | Regression loss: 0.04702 | Objectness loss: 0.00009 | RPN Regression loss: 0.00152 | Running loss: 0.07543\n","Epoch: 9 | Iteration: 33912 | Classification loss: 0.01271 | Regression loss: 0.02688 | Objectness loss: 0.00088 | RPN Regression loss: 0.01508 | Running loss: 0.05554\n","Epoch: 9 | Iteration: 33913 | Classification loss: 0.00714 | Regression loss: 0.02614 | Objectness loss: 0.00028 | RPN Regression loss: 0.00157 | Running loss: 0.03514\n","Epoch: 9 | Iteration: 33914 | Classification loss: 0.01819 | Regression loss: 0.04597 | Objectness loss: 0.00038 | RPN Regression loss: 0.00126 | Running loss: 0.06580\n","Epoch: 9 | Iteration: 33915 | Classification loss: 0.00879 | Regression loss: 0.02202 | Objectness loss: 0.00003 | RPN Regression loss: 0.00155 | Running loss: 0.03240\n","Epoch: 9 | Iteration: 33916 | Classification loss: 0.01604 | Regression loss: 0.03159 | Objectness loss: 0.00224 | RPN Regression loss: 0.00466 | Running loss: 0.05453\n","Epoch: 9 | Iteration: 33917 | Classification loss: 0.01339 | Regression loss: 0.03174 | Objectness loss: 0.00106 | RPN Regression loss: 0.00247 | Running loss: 0.04867\n","Epoch: 9 | Iteration: 33918 | Classification loss: 0.01136 | Regression loss: 0.02977 | Objectness loss: 0.00002 | RPN Regression loss: 0.00069 | Running loss: 0.04184\n","Epoch: 9 | Iteration: 33919 | Classification loss: 0.00892 | Regression loss: 0.01885 | Objectness loss: 0.00007 | RPN Regression loss: 0.00166 | Running loss: 0.02950\n","Epoch: 9 | Iteration: 33920 | Classification loss: 0.01628 | Regression loss: 0.02332 | Objectness loss: 0.00024 | RPN Regression loss: 0.00096 | Running loss: 0.04079\n","Epoch: 9 | Iteration: 33921 | Classification loss: 0.00935 | Regression loss: 0.01720 | Objectness loss: 0.00006 | RPN Regression loss: 0.00148 | Running loss: 0.02808\n","Epoch: 9 | Iteration: 33922 | Classification loss: 0.01729 | Regression loss: 0.03342 | Objectness loss: 0.00005 | RPN Regression loss: 0.00128 | Running loss: 0.05205\n","Epoch: 9 | Iteration: 33923 | Classification loss: 0.01329 | Regression loss: 0.02698 | Objectness loss: 0.00015 | RPN Regression loss: 0.00090 | Running loss: 0.04132\n","Epoch: 9 | Iteration: 33924 | Classification loss: 0.04143 | Regression loss: 0.03390 | Objectness loss: 0.01489 | RPN Regression loss: 0.01423 | Running loss: 0.10445\n","Epoch: 9 | Iteration: 33925 | Classification loss: 0.00834 | Regression loss: 0.01581 | Objectness loss: 0.00001 | RPN Regression loss: 0.00104 | Running loss: 0.02522\n","Epoch: 9 | Iteration: 33926 | Classification loss: 0.01171 | Regression loss: 0.02294 | Objectness loss: 0.00067 | RPN Regression loss: 0.00322 | Running loss: 0.03853\n","Epoch: 9 | Iteration: 33927 | Classification loss: 0.01078 | Regression loss: 0.01324 | Objectness loss: 0.00005 | RPN Regression loss: 0.00139 | Running loss: 0.02546\n","Epoch: 9 | Iteration: 33928 | Classification loss: 0.03078 | Regression loss: 0.03202 | Objectness loss: 0.00007 | RPN Regression loss: 0.00101 | Running loss: 0.06388\n","Epoch: 9 | Iteration: 33929 | Classification loss: 0.03173 | Regression loss: 0.03780 | Objectness loss: 0.00055 | RPN Regression loss: 0.00157 | Running loss: 0.07165\n","Epoch: 9 | Iteration: 33930 | Classification loss: 0.01140 | Regression loss: 0.02303 | Objectness loss: 0.00359 | RPN Regression loss: 0.00452 | Running loss: 0.04254\n","Epoch: 9 | Iteration: 33931 | Classification loss: 0.02323 | Regression loss: 0.02519 | Objectness loss: 0.00011 | RPN Regression loss: 0.00152 | Running loss: 0.05005\n","Epoch: 9 | Iteration: 33932 | Classification loss: 0.01453 | Regression loss: 0.02651 | Objectness loss: 0.00462 | RPN Regression loss: 0.00228 | Running loss: 0.04793\n","Epoch: 9 | Iteration: 33933 | Classification loss: 0.01089 | Regression loss: 0.03111 | Objectness loss: 0.00057 | RPN Regression loss: 0.00143 | Running loss: 0.04400\n","Epoch: 9 | Iteration: 33934 | Classification loss: 0.01893 | Regression loss: 0.02461 | Objectness loss: 0.00017 | RPN Regression loss: 0.00127 | Running loss: 0.04498\n","Epoch: 9 | Iteration: 33935 | Classification loss: 0.00577 | Regression loss: 0.01659 | Objectness loss: 0.00001 | RPN Regression loss: 0.00045 | Running loss: 0.02283\n","Epoch: 9 | Iteration: 33936 | Classification loss: 0.00748 | Regression loss: 0.01500 | Objectness loss: 0.00020 | RPN Regression loss: 0.00122 | Running loss: 0.02389\n","Epoch: 9 | Iteration: 33937 | Classification loss: 0.01123 | Regression loss: 0.01205 | Objectness loss: 0.00099 | RPN Regression loss: 0.00089 | Running loss: 0.02517\n","Epoch: 9 | Iteration: 33938 | Classification loss: 0.00982 | Regression loss: 0.01065 | Objectness loss: 0.00027 | RPN Regression loss: 0.00120 | Running loss: 0.02194\n","Epoch: 9 | Iteration: 33939 | Classification loss: 0.01025 | Regression loss: 0.01374 | Objectness loss: 0.00041 | RPN Regression loss: 0.00053 | Running loss: 0.02492\n","Epoch: 9 | Iteration: 33940 | Classification loss: 0.00752 | Regression loss: 0.01174 | Objectness loss: 0.00009 | RPN Regression loss: 0.00089 | Running loss: 0.02024\n","Epoch: 9 | Iteration: 33941 | Classification loss: 0.00791 | Regression loss: 0.01760 | Objectness loss: 0.00179 | RPN Regression loss: 0.00100 | Running loss: 0.02830\n","Epoch: 9 | Iteration: 33942 | Classification loss: 0.01758 | Regression loss: 0.03975 | Objectness loss: 0.00270 | RPN Regression loss: 0.00078 | Running loss: 0.06082\n","Epoch: 9 | Iteration: 33943 | Classification loss: 0.00502 | Regression loss: 0.02044 | Objectness loss: 0.00026 | RPN Regression loss: 0.00173 | Running loss: 0.02744\n","Epoch: 9 | Iteration: 33944 | Classification loss: 0.00348 | Regression loss: 0.01846 | Objectness loss: 0.00014 | RPN Regression loss: 0.00087 | Running loss: 0.02294\n","Epoch: 9 | Iteration: 33945 | Classification loss: 0.00962 | Regression loss: 0.02105 | Objectness loss: 0.00042 | RPN Regression loss: 0.00099 | Running loss: 0.03208\n","Epoch: 9 | Iteration: 33946 | Classification loss: 0.00440 | Regression loss: 0.01034 | Objectness loss: 0.00002 | RPN Regression loss: 0.00064 | Running loss: 0.01539\n","Epoch: 9 | Iteration: 33947 | Classification loss: 0.03594 | Regression loss: 0.01691 | Objectness loss: 0.00119 | RPN Regression loss: 0.00048 | Running loss: 0.05453\n","Epoch: 9 | Iteration: 33948 | Classification loss: 0.01182 | Regression loss: 0.01756 | Objectness loss: 0.00073 | RPN Regression loss: 0.00225 | Running loss: 0.03236\n","Epoch: 9 | Iteration: 33949 | Classification loss: 0.01035 | Regression loss: 0.01656 | Objectness loss: 0.00071 | RPN Regression loss: 0.00730 | Running loss: 0.03491\n","Epoch: 9 | Iteration: 33950 | Classification loss: 0.00856 | Regression loss: 0.01416 | Objectness loss: 0.00041 | RPN Regression loss: 0.00740 | Running loss: 0.03053\n","Epoch: 9 | Iteration: 33951 | Classification loss: 0.01124 | Regression loss: 0.02379 | Objectness loss: 0.00099 | RPN Regression loss: 0.00608 | Running loss: 0.04210\n","Epoch: 9 | Iteration: 33952 | Classification loss: 0.04399 | Regression loss: 0.03810 | Objectness loss: 0.00993 | RPN Regression loss: 0.00170 | Running loss: 0.09371\n","Epoch: 9 | Iteration: 33953 | Classification loss: 0.01385 | Regression loss: 0.03629 | Objectness loss: 0.00235 | RPN Regression loss: 0.00134 | Running loss: 0.05383\n","Epoch: 9 | Iteration: 33954 | Classification loss: 0.01062 | Regression loss: 0.02071 | Objectness loss: 0.00006 | RPN Regression loss: 0.00625 | Running loss: 0.03765\n","Epoch: 9 | Iteration: 33955 | Classification loss: 0.02116 | Regression loss: 0.02021 | Objectness loss: 0.00116 | RPN Regression loss: 0.00106 | Running loss: 0.04359\n","Epoch: 9 | Iteration: 33956 | Classification loss: 0.00893 | Regression loss: 0.01565 | Objectness loss: 0.00005 | RPN Regression loss: 0.00101 | Running loss: 0.02564\n","Epoch: 9 | Iteration: 33957 | Classification loss: 0.00776 | Regression loss: 0.01283 | Objectness loss: 0.00033 | RPN Regression loss: 0.00233 | Running loss: 0.02325\n","Epoch: 9 | Iteration: 33958 | Classification loss: 0.02045 | Regression loss: 0.02054 | Objectness loss: 0.00045 | RPN Regression loss: 0.00151 | Running loss: 0.04295\n","Epoch: 9 | Iteration: 33959 | Classification loss: 0.01052 | Regression loss: 0.02906 | Objectness loss: 0.00091 | RPN Regression loss: 0.00062 | Running loss: 0.04111\n","Epoch: 9 | Iteration: 33960 | Classification loss: 0.03104 | Regression loss: 0.03867 | Objectness loss: 0.00019 | RPN Regression loss: 0.00130 | Running loss: 0.07122\n","Epoch: 9 | Iteration: 33961 | Classification loss: 0.00873 | Regression loss: 0.00950 | Objectness loss: 0.00034 | RPN Regression loss: 0.00090 | Running loss: 0.01948\n","Epoch: 9 | Iteration: 33962 | Classification loss: 0.00816 | Regression loss: 0.02195 | Objectness loss: 0.00011 | RPN Regression loss: 0.00074 | Running loss: 0.03096\n","Epoch: 9 | Iteration: 33963 | Classification loss: 0.01930 | Regression loss: 0.01922 | Objectness loss: 0.00007 | RPN Regression loss: 0.00300 | Running loss: 0.04159\n","Epoch: 9 | Iteration: 33964 | Classification loss: 0.02437 | Regression loss: 0.03665 | Objectness loss: 0.00030 | RPN Regression loss: 0.00143 | Running loss: 0.06276\n","Epoch: 9 | Iteration: 33965 | Classification loss: 0.03102 | Regression loss: 0.02301 | Objectness loss: 0.00037 | RPN Regression loss: 0.01756 | Running loss: 0.07196\n","Epoch: 9 | Iteration: 33966 | Classification loss: 0.01958 | Regression loss: 0.01785 | Objectness loss: 0.00036 | RPN Regression loss: 0.00070 | Running loss: 0.03849\n","Epoch: 9 | Iteration: 33967 | Classification loss: 0.06262 | Regression loss: 0.04494 | Objectness loss: 0.03321 | RPN Regression loss: 0.01381 | Running loss: 0.15459\n","Epoch: 9 | Iteration: 33968 | Classification loss: 0.02116 | Regression loss: 0.01722 | Objectness loss: 0.00017 | RPN Regression loss: 0.00615 | Running loss: 0.04470\n","Epoch: 9 | Iteration: 33969 | Classification loss: 0.02368 | Regression loss: 0.03902 | Objectness loss: 0.00016 | RPN Regression loss: 0.00152 | Running loss: 0.06438\n","Epoch: 9 | Iteration: 33970 | Classification loss: 0.01020 | Regression loss: 0.01352 | Objectness loss: 0.00571 | RPN Regression loss: 0.00062 | Running loss: 0.03005\n","Epoch: 9 | Iteration: 33971 | Classification loss: 0.01053 | Regression loss: 0.01700 | Objectness loss: 0.00074 | RPN Regression loss: 0.00117 | Running loss: 0.02944\n","Epoch: 9 | Iteration: 33972 | Classification loss: 0.03162 | Regression loss: 0.01924 | Objectness loss: 0.00065 | RPN Regression loss: 0.00111 | Running loss: 0.05261\n","Epoch: 9 | Iteration: 33973 | Classification loss: 0.02375 | Regression loss: 0.03825 | Objectness loss: 0.00025 | RPN Regression loss: 0.00168 | Running loss: 0.06393\n","Epoch: 9 | Iteration: 33974 | Classification loss: 0.01606 | Regression loss: 0.03136 | Objectness loss: 0.00009 | RPN Regression loss: 0.00058 | Running loss: 0.04809\n","Epoch: 9 | Iteration: 33975 | Classification loss: 0.01199 | Regression loss: 0.02287 | Objectness loss: 0.00038 | RPN Regression loss: 0.00141 | Running loss: 0.03665\n","Epoch: 9 | Iteration: 33976 | Classification loss: 0.00962 | Regression loss: 0.02726 | Objectness loss: 0.00206 | RPN Regression loss: 0.00287 | Running loss: 0.04181\n","Epoch: 9 | Iteration: 33977 | Classification loss: 0.00724 | Regression loss: 0.01502 | Objectness loss: 0.01718 | RPN Regression loss: 0.00470 | Running loss: 0.04414\n","Epoch: 9 | Iteration: 33978 | Classification loss: 0.01269 | Regression loss: 0.02010 | Objectness loss: 0.00834 | RPN Regression loss: 0.00246 | Running loss: 0.04359\n","Epoch: 9 | Iteration: 33979 | Classification loss: 0.05934 | Regression loss: 0.01370 | Objectness loss: 0.00050 | RPN Regression loss: 0.00080 | Running loss: 0.07433\n","Epoch: 9 | Iteration: 33980 | Classification loss: 0.01943 | Regression loss: 0.02476 | Objectness loss: 0.00735 | RPN Regression loss: 0.00221 | Running loss: 0.05375\n","Epoch: 9 | Iteration: 33981 | Classification loss: 0.02126 | Regression loss: 0.02178 | Objectness loss: 0.00152 | RPN Regression loss: 0.00270 | Running loss: 0.04726\n","Epoch: 9 | Iteration: 33982 | Classification loss: 0.02454 | Regression loss: 0.02186 | Objectness loss: 0.00078 | RPN Regression loss: 0.00155 | Running loss: 0.04873\n","Epoch: 9 | Iteration: 33983 | Classification loss: 0.01043 | Regression loss: 0.02496 | Objectness loss: 0.00033 | RPN Regression loss: 0.00070 | Running loss: 0.03641\n","Epoch: 9 | Iteration: 33984 | Classification loss: 0.01893 | Regression loss: 0.02471 | Objectness loss: 0.01684 | RPN Regression loss: 0.00268 | Running loss: 0.06316\n","Epoch: 9 | Iteration: 33985 | Classification loss: 0.01277 | Regression loss: 0.02062 | Objectness loss: 0.00023 | RPN Regression loss: 0.00051 | Running loss: 0.03414\n","Epoch: 9 | Iteration: 33986 | Classification loss: 0.01940 | Regression loss: 0.03322 | Objectness loss: 0.00067 | RPN Regression loss: 0.00132 | Running loss: 0.05461\n","Epoch: 9 | Iteration: 33987 | Classification loss: 0.00632 | Regression loss: 0.00971 | Objectness loss: 0.00012 | RPN Regression loss: 0.00142 | Running loss: 0.01757\n","Epoch: 9 | Iteration: 33988 | Classification loss: 0.00952 | Regression loss: 0.02638 | Objectness loss: 0.00059 | RPN Regression loss: 0.00167 | Running loss: 0.03815\n","Epoch: 9 | Iteration: 33989 | Classification loss: 0.00838 | Regression loss: 0.01568 | Objectness loss: 0.00056 | RPN Regression loss: 0.00138 | Running loss: 0.02600\n","Epoch: 9 | Iteration: 33990 | Classification loss: 0.01748 | Regression loss: 0.02530 | Objectness loss: 0.00010 | RPN Regression loss: 0.00090 | Running loss: 0.04378\n","Epoch: 9 | Iteration: 33991 | Classification loss: 0.02746 | Regression loss: 0.02064 | Objectness loss: 0.00008 | RPN Regression loss: 0.00072 | Running loss: 0.04890\n","Epoch: 9 | Iteration: 33992 | Classification loss: 0.00667 | Regression loss: 0.01613 | Objectness loss: 0.00026 | RPN Regression loss: 0.00040 | Running loss: 0.02346\n","Epoch: 9 | Iteration: 33993 | Classification loss: 0.02215 | Regression loss: 0.01480 | Objectness loss: 0.00459 | RPN Regression loss: 0.00168 | Running loss: 0.04323\n","Epoch: 9 | Iteration: 33994 | Classification loss: 0.00649 | Regression loss: 0.01439 | Objectness loss: 0.00070 | RPN Regression loss: 0.00173 | Running loss: 0.02331\n","Epoch: 9 | Iteration: 33995 | Classification loss: 0.01172 | Regression loss: 0.02071 | Objectness loss: 0.00016 | RPN Regression loss: 0.00078 | Running loss: 0.03338\n","Epoch: 9 | Iteration: 33996 | Classification loss: 0.00841 | Regression loss: 0.02458 | Objectness loss: 0.00330 | RPN Regression loss: 0.00381 | Running loss: 0.04010\n","Epoch: 9 | Iteration: 33997 | Classification loss: 0.00845 | Regression loss: 0.01902 | Objectness loss: 0.00288 | RPN Regression loss: 0.00122 | Running loss: 0.03158\n","Epoch: 9 | Iteration: 33998 | Classification loss: 0.01731 | Regression loss: 0.04042 | Objectness loss: 0.00210 | RPN Regression loss: 0.00719 | Running loss: 0.06702\n","Epoch: 9 | Iteration: 33999 | Classification loss: 0.02282 | Regression loss: 0.03136 | Objectness loss: 0.00089 | RPN Regression loss: 0.00196 | Running loss: 0.05703\n","Epoch: 9 | Iteration: 34000 | Classification loss: 0.02652 | Regression loss: 0.01832 | Objectness loss: 0.00130 | RPN Regression loss: 0.00096 | Running loss: 0.04710\n","Epoch: 9 | Iteration: 34001 | Classification loss: 0.02588 | Regression loss: 0.03857 | Objectness loss: 0.00396 | RPN Regression loss: 0.00064 | Running loss: 0.06904\n","Epoch: 9 | Iteration: 34002 | Classification loss: 0.01591 | Regression loss: 0.03312 | Objectness loss: 0.00027 | RPN Regression loss: 0.00361 | Running loss: 0.05292\n","Epoch: 9 | Iteration: 34003 | Classification loss: 0.01637 | Regression loss: 0.02475 | Objectness loss: 0.00110 | RPN Regression loss: 0.03830 | Running loss: 0.08051\n","Epoch: 9 | Iteration: 34004 | Classification loss: 0.00933 | Regression loss: 0.01302 | Objectness loss: 0.00084 | RPN Regression loss: 0.00176 | Running loss: 0.02495\n","Epoch: 9 | Iteration: 34005 | Classification loss: 0.00999 | Regression loss: 0.01717 | Objectness loss: 0.00016 | RPN Regression loss: 0.00156 | Running loss: 0.02888\n","Epoch: 9 | Iteration: 34006 | Classification loss: 0.00838 | Regression loss: 0.02900 | Objectness loss: 0.00040 | RPN Regression loss: 0.00102 | Running loss: 0.03880\n","Epoch: 9 | Iteration: 34007 | Classification loss: 0.02392 | Regression loss: 0.02289 | Objectness loss: 0.00029 | RPN Regression loss: 0.00067 | Running loss: 0.04777\n","Epoch: 9 | Iteration: 34008 | Classification loss: 0.02766 | Regression loss: 0.03674 | Objectness loss: 0.00116 | RPN Regression loss: 0.00592 | Running loss: 0.07147\n","Epoch: 9 | Iteration: 34009 | Classification loss: 0.02310 | Regression loss: 0.02477 | Objectness loss: 0.00075 | RPN Regression loss: 0.00101 | Running loss: 0.04964\n","Epoch: 9 | Iteration: 34010 | Classification loss: 0.01595 | Regression loss: 0.01386 | Objectness loss: 0.00011 | RPN Regression loss: 0.00170 | Running loss: 0.03161\n","Epoch: 9 | Iteration: 34011 | Classification loss: 0.04480 | Regression loss: 0.04702 | Objectness loss: 0.00213 | RPN Regression loss: 0.00281 | Running loss: 0.09675\n","Epoch: 9 | Iteration: 34012 | Classification loss: 0.00488 | Regression loss: 0.01181 | Objectness loss: 0.00007 | RPN Regression loss: 0.00056 | Running loss: 0.01732\n","Epoch: 9 | Iteration: 34013 | Classification loss: 0.00613 | Regression loss: 0.01039 | Objectness loss: 0.00004 | RPN Regression loss: 0.00093 | Running loss: 0.01749\n","Epoch: 9 | Iteration: 34014 | Classification loss: 0.01873 | Regression loss: 0.05413 | Objectness loss: 0.00588 | RPN Regression loss: 0.03230 | Running loss: 0.11105\n","Epoch: 9 | Iteration: 34015 | Classification loss: 0.01010 | Regression loss: 0.02929 | Objectness loss: 0.00072 | RPN Regression loss: 0.00127 | Running loss: 0.04138\n","Epoch: 9 | Iteration: 34016 | Classification loss: 0.02243 | Regression loss: 0.03323 | Objectness loss: 0.00025 | RPN Regression loss: 0.00268 | Running loss: 0.05860\n","Epoch: 9 | Iteration: 34017 | Classification loss: 0.00709 | Regression loss: 0.02000 | Objectness loss: 0.00166 | RPN Regression loss: 0.00233 | Running loss: 0.03109\n","Epoch: 9 | Iteration: 34018 | Classification loss: 0.00691 | Regression loss: 0.01586 | Objectness loss: 0.00073 | RPN Regression loss: 0.00107 | Running loss: 0.02456\n","Epoch: 9 | Iteration: 34019 | Classification loss: 0.01249 | Regression loss: 0.02251 | Objectness loss: 0.00059 | RPN Regression loss: 0.00285 | Running loss: 0.03843\n","Epoch: 9 | Iteration: 34020 | Classification loss: 0.00944 | Regression loss: 0.01290 | Objectness loss: 0.00008 | RPN Regression loss: 0.00120 | Running loss: 0.02361\n","Epoch: 9 | Iteration: 34021 | Classification loss: 0.01074 | Regression loss: 0.02283 | Objectness loss: 0.00005 | RPN Regression loss: 0.00193 | Running loss: 0.03555\n","Epoch: 9 | Iteration: 34022 | Classification loss: 0.01267 | Regression loss: 0.02070 | Objectness loss: 0.00410 | RPN Regression loss: 0.00165 | Running loss: 0.03913\n","Epoch: 9 | Iteration: 34023 | Classification loss: 0.01525 | Regression loss: 0.01871 | Objectness loss: 0.00021 | RPN Regression loss: 0.00082 | Running loss: 0.03499\n","Epoch: 9 | Iteration: 34024 | Classification loss: 0.01468 | Regression loss: 0.03094 | Objectness loss: 0.00088 | RPN Regression loss: 0.00133 | Running loss: 0.04782\n","Epoch: 9 | Iteration: 34025 | Classification loss: 0.00935 | Regression loss: 0.01744 | Objectness loss: 0.00002 | RPN Regression loss: 0.00087 | Running loss: 0.02768\n","Epoch: 9 | Iteration: 34026 | Classification loss: 0.02437 | Regression loss: 0.01791 | Objectness loss: 0.00013 | RPN Regression loss: 0.00133 | Running loss: 0.04373\n","Epoch: 9 | Iteration: 34027 | Classification loss: 0.01600 | Regression loss: 0.03940 | Objectness loss: 0.00025 | RPN Regression loss: 0.00196 | Running loss: 0.05760\n","Epoch: 9 | Iteration: 34028 | Classification loss: 0.01942 | Regression loss: 0.01746 | Objectness loss: 0.00079 | RPN Regression loss: 0.00103 | Running loss: 0.03870\n","Epoch: 9 | Iteration: 34029 | Classification loss: 0.02228 | Regression loss: 0.03247 | Objectness loss: 0.00012 | RPN Regression loss: 0.00071 | Running loss: 0.05558\n","Epoch: 9 | Iteration: 34030 | Classification loss: 0.00531 | Regression loss: 0.02228 | Objectness loss: 0.00183 | RPN Regression loss: 0.00313 | Running loss: 0.03254\n","Epoch: 9 | Iteration: 34031 | Classification loss: 0.00748 | Regression loss: 0.00797 | Objectness loss: 0.00143 | RPN Regression loss: 0.00107 | Running loss: 0.01795\n","Epoch: 9 | Iteration: 34032 | Classification loss: 0.01721 | Regression loss: 0.02110 | Objectness loss: 0.00038 | RPN Regression loss: 0.00045 | Running loss: 0.03914\n","Epoch: 9 | Iteration: 34033 | Classification loss: 0.01233 | Regression loss: 0.04350 | Objectness loss: 0.00031 | RPN Regression loss: 0.00328 | Running loss: 0.05943\n","Epoch: 9 | Iteration: 34034 | Classification loss: 0.02319 | Regression loss: 0.03557 | Objectness loss: 0.00721 | RPN Regression loss: 0.00106 | Running loss: 0.06703\n","Epoch: 9 | Iteration: 34035 | Classification loss: 0.01094 | Regression loss: 0.02643 | Objectness loss: 0.00023 | RPN Regression loss: 0.00069 | Running loss: 0.03829\n","Epoch: 9 | Iteration: 34036 | Classification loss: 0.01426 | Regression loss: 0.02463 | Objectness loss: 0.00011 | RPN Regression loss: 0.00278 | Running loss: 0.04178\n","Epoch: 9 | Iteration: 34037 | Classification loss: 0.00689 | Regression loss: 0.01934 | Objectness loss: 0.00005 | RPN Regression loss: 0.00093 | Running loss: 0.02720\n","Epoch: 9 | Iteration: 34038 | Classification loss: 0.03487 | Regression loss: 0.03980 | Objectness loss: 0.00084 | RPN Regression loss: 0.00151 | Running loss: 0.07702\n","Epoch: 9 | Iteration: 34039 | Classification loss: 0.01634 | Regression loss: 0.02094 | Objectness loss: 0.00012 | RPN Regression loss: 0.01049 | Running loss: 0.04788\n","Epoch: 9 | Iteration: 34040 | Classification loss: 0.01502 | Regression loss: 0.01806 | Objectness loss: 0.00010 | RPN Regression loss: 0.00161 | Running loss: 0.03478\n","Epoch: 9 | Iteration: 34041 | Classification loss: 0.04331 | Regression loss: 0.03337 | Objectness loss: 0.00111 | RPN Regression loss: 0.00116 | Running loss: 0.07894\n","Epoch: 9 | Iteration: 34042 | Classification loss: 0.01136 | Regression loss: 0.01689 | Objectness loss: 0.00045 | RPN Regression loss: 0.00039 | Running loss: 0.02909\n","Epoch: 9 | Iteration: 34043 | Classification loss: 0.05552 | Regression loss: 0.05501 | Objectness loss: 0.00424 | RPN Regression loss: 0.00311 | Running loss: 0.11788\n","Epoch: 9 | Iteration: 34044 | Classification loss: 0.01627 | Regression loss: 0.01495 | Objectness loss: 0.00014 | RPN Regression loss: 0.00069 | Running loss: 0.03205\n","Epoch: 9 | Iteration: 34045 | Classification loss: 0.00983 | Regression loss: 0.02557 | Objectness loss: 0.00040 | RPN Regression loss: 0.00085 | Running loss: 0.03665\n","Epoch: 9 | Iteration: 34046 | Classification loss: 0.01561 | Regression loss: 0.03063 | Objectness loss: 0.00544 | RPN Regression loss: 0.00199 | Running loss: 0.05368\n","Epoch: 9 | Iteration: 34047 | Classification loss: 0.00643 | Regression loss: 0.01977 | Objectness loss: 0.00110 | RPN Regression loss: 0.00141 | Running loss: 0.02871\n","Epoch: 9 | Iteration: 34048 | Classification loss: 0.02716 | Regression loss: 0.02318 | Objectness loss: 0.00268 | RPN Regression loss: 0.03699 | Running loss: 0.09001\n","Epoch: 9 | Iteration: 34049 | Classification loss: 0.00657 | Regression loss: 0.01874 | Objectness loss: 0.00109 | RPN Regression loss: 0.00082 | Running loss: 0.02722\n","Epoch: 9 | Iteration: 34050 | Classification loss: 0.01372 | Regression loss: 0.02698 | Objectness loss: 0.00035 | RPN Regression loss: 0.00140 | Running loss: 0.04245\n","Epoch: 9 | Iteration: 34051 | Classification loss: 0.01164 | Regression loss: 0.02174 | Objectness loss: 0.00096 | RPN Regression loss: 0.00144 | Running loss: 0.03579\n","Epoch: 9 | Iteration: 34052 | Classification loss: 0.01139 | Regression loss: 0.02973 | Objectness loss: 0.00009 | RPN Regression loss: 0.00058 | Running loss: 0.04179\n","Epoch: 9 | Iteration: 34053 | Classification loss: 0.02002 | Regression loss: 0.02832 | Objectness loss: 0.00119 | RPN Regression loss: 0.00101 | Running loss: 0.05054\n","Epoch: 9 | Iteration: 34054 | Classification loss: 0.04138 | Regression loss: 0.03595 | Objectness loss: 0.00793 | RPN Regression loss: 0.00146 | Running loss: 0.08673\n","Epoch: 9 | Iteration: 34055 | Classification loss: 0.02259 | Regression loss: 0.02557 | Objectness loss: 0.00369 | RPN Regression loss: 0.00276 | Running loss: 0.05462\n","Epoch: 9 | Iteration: 34056 | Classification loss: 0.01909 | Regression loss: 0.03184 | Objectness loss: 0.00017 | RPN Regression loss: 0.00153 | Running loss: 0.05263\n","Epoch: 9 | Iteration: 34057 | Classification loss: 0.01610 | Regression loss: 0.01967 | Objectness loss: 0.00011 | RPN Regression loss: 0.00152 | Running loss: 0.03740\n","Epoch: 9 | Iteration: 34058 | Classification loss: 0.01178 | Regression loss: 0.02468 | Objectness loss: 0.00130 | RPN Regression loss: 0.00088 | Running loss: 0.03865\n","Epoch: 9 | Iteration: 34059 | Classification loss: 0.02619 | Regression loss: 0.02918 | Objectness loss: 0.00022 | RPN Regression loss: 0.00251 | Running loss: 0.05810\n","Epoch: 9 | Iteration: 34060 | Classification loss: 0.02595 | Regression loss: 0.02631 | Objectness loss: 0.00116 | RPN Regression loss: 0.00226 | Running loss: 0.05568\n","Epoch: 9 | Iteration: 34061 | Classification loss: 0.01030 | Regression loss: 0.03504 | Objectness loss: 0.00224 | RPN Regression loss: 0.00098 | Running loss: 0.04856\n","Epoch: 9 | Iteration: 34062 | Classification loss: 0.01247 | Regression loss: 0.02174 | Objectness loss: 0.00134 | RPN Regression loss: 0.00063 | Running loss: 0.03618\n","Epoch: 9 | Iteration: 34063 | Classification loss: 0.01262 | Regression loss: 0.01202 | Objectness loss: 0.00007 | RPN Regression loss: 0.00088 | Running loss: 0.02559\n","Epoch: 9 | Iteration: 34064 | Classification loss: 0.01872 | Regression loss: 0.01966 | Objectness loss: 0.00140 | RPN Regression loss: 0.00158 | Running loss: 0.04135\n","Epoch: 9 | Iteration: 34065 | Classification loss: 0.01734 | Regression loss: 0.03239 | Objectness loss: 0.00027 | RPN Regression loss: 0.00137 | Running loss: 0.05137\n","Epoch: 9 | Iteration: 34066 | Classification loss: 0.02090 | Regression loss: 0.01949 | Objectness loss: 0.00005 | RPN Regression loss: 0.00173 | Running loss: 0.04217\n","Epoch: 9 | Iteration: 34067 | Classification loss: 0.00540 | Regression loss: 0.01220 | Objectness loss: 0.00182 | RPN Regression loss: 0.00140 | Running loss: 0.02083\n","Epoch: 9 | Iteration: 34068 | Classification loss: 0.03664 | Regression loss: 0.03389 | Objectness loss: 0.00334 | RPN Regression loss: 0.00145 | Running loss: 0.07532\n","Epoch: 9 | Iteration: 34069 | Classification loss: 0.00786 | Regression loss: 0.02466 | Objectness loss: 0.00118 | RPN Regression loss: 0.00189 | Running loss: 0.03559\n","Epoch: 9 | Iteration: 34070 | Classification loss: 0.00776 | Regression loss: 0.01700 | Objectness loss: 0.00006 | RPN Regression loss: 0.00081 | Running loss: 0.02564\n","Epoch: 9 | Iteration: 34071 | Classification loss: 0.03999 | Regression loss: 0.02736 | Objectness loss: 0.00032 | RPN Regression loss: 0.00103 | Running loss: 0.06870\n","Epoch: 9 | Iteration: 34072 | Classification loss: 0.03091 | Regression loss: 0.01571 | Objectness loss: 0.00008 | RPN Regression loss: 0.00094 | Running loss: 0.04764\n","Epoch: 9 | Iteration: 34073 | Classification loss: 0.00936 | Regression loss: 0.01768 | Objectness loss: 0.00050 | RPN Regression loss: 0.00130 | Running loss: 0.02884\n","Epoch: 9 | Iteration: 34074 | Classification loss: 0.00902 | Regression loss: 0.02183 | Objectness loss: 0.00033 | RPN Regression loss: 0.00167 | Running loss: 0.03285\n","Epoch: 9 | Iteration: 34075 | Classification loss: 0.00947 | Regression loss: 0.02120 | Objectness loss: 0.00007 | RPN Regression loss: 0.00074 | Running loss: 0.03147\n","Epoch: 9 | Iteration: 34076 | Classification loss: 0.00989 | Regression loss: 0.02287 | Objectness loss: 0.00001 | RPN Regression loss: 0.00077 | Running loss: 0.03354\n","Epoch: 9 | Iteration: 34077 | Classification loss: 0.00876 | Regression loss: 0.01242 | Objectness loss: 0.00468 | RPN Regression loss: 0.00205 | Running loss: 0.02791\n","Epoch: 9 | Iteration: 34078 | Classification loss: 0.00904 | Regression loss: 0.02766 | Objectness loss: 0.00037 | RPN Regression loss: 0.00100 | Running loss: 0.03806\n","Epoch: 9 | Iteration: 34079 | Classification loss: 0.02873 | Regression loss: 0.02523 | Objectness loss: 0.00675 | RPN Regression loss: 0.00066 | Running loss: 0.06136\n","Epoch: 9 | Iteration: 34080 | Classification loss: 0.02528 | Regression loss: 0.03358 | Objectness loss: 0.00397 | RPN Regression loss: 0.00048 | Running loss: 0.06332\n","Epoch: 9 | Iteration: 34081 | Classification loss: 0.00595 | Regression loss: 0.01358 | Objectness loss: 0.00179 | RPN Regression loss: 0.00294 | Running loss: 0.02426\n","Epoch: 9 | Iteration: 34082 | Classification loss: 0.01360 | Regression loss: 0.02279 | Objectness loss: 0.00006 | RPN Regression loss: 0.00100 | Running loss: 0.03745\n","Epoch: 9 | Iteration: 34083 | Classification loss: 0.01362 | Regression loss: 0.02276 | Objectness loss: 0.00119 | RPN Regression loss: 0.00125 | Running loss: 0.03882\n","Epoch: 9 | Iteration: 34084 | Classification loss: 0.01169 | Regression loss: 0.01493 | Objectness loss: 0.00179 | RPN Regression loss: 0.00143 | Running loss: 0.02984\n","Epoch: 9 | Iteration: 34085 | Classification loss: 0.01794 | Regression loss: 0.03432 | Objectness loss: 0.00018 | RPN Regression loss: 0.00092 | Running loss: 0.05335\n","Epoch: 9 | Iteration: 34086 | Classification loss: 0.01110 | Regression loss: 0.02804 | Objectness loss: 0.00003 | RPN Regression loss: 0.00066 | Running loss: 0.03983\n","Epoch: 9 | Iteration: 34087 | Classification loss: 0.02533 | Regression loss: 0.02308 | Objectness loss: 0.00189 | RPN Regression loss: 0.00255 | Running loss: 0.05286\n","Epoch: 9 | Iteration: 34088 | Classification loss: 0.05299 | Regression loss: 0.02643 | Objectness loss: 0.00593 | RPN Regression loss: 0.00187 | Running loss: 0.08722\n","Epoch: 9 | Iteration: 34089 | Classification loss: 0.02057 | Regression loss: 0.03169 | Objectness loss: 0.00029 | RPN Regression loss: 0.00064 | Running loss: 0.05319\n","Epoch: 9 | Iteration: 34090 | Classification loss: 0.02184 | Regression loss: 0.03684 | Objectness loss: 0.00009 | RPN Regression loss: 0.00219 | Running loss: 0.06096\n","Epoch: 9 | Iteration: 34091 | Classification loss: 0.01301 | Regression loss: 0.03323 | Objectness loss: 0.00030 | RPN Regression loss: 0.00062 | Running loss: 0.04715\n","Epoch: 9 | Iteration: 34092 | Classification loss: 0.01369 | Regression loss: 0.02339 | Objectness loss: 0.00047 | RPN Regression loss: 0.00432 | Running loss: 0.04187\n","Epoch: 9 | Iteration: 34093 | Classification loss: 0.01508 | Regression loss: 0.02719 | Objectness loss: 0.00032 | RPN Regression loss: 0.00151 | Running loss: 0.04410\n","Epoch: 9 | Iteration: 34094 | Classification loss: 0.03043 | Regression loss: 0.03200 | Objectness loss: 0.00049 | RPN Regression loss: 0.00083 | Running loss: 0.06375\n","Epoch: 9 | Iteration: 34095 | Classification loss: 0.02238 | Regression loss: 0.02305 | Objectness loss: 0.00018 | RPN Regression loss: 0.00052 | Running loss: 0.04613\n","Epoch: 9 | Iteration: 34096 | Classification loss: 0.01243 | Regression loss: 0.02586 | Objectness loss: 0.00150 | RPN Regression loss: 0.00116 | Running loss: 0.04095\n","Epoch: 9 | Iteration: 34097 | Classification loss: 0.01525 | Regression loss: 0.02879 | Objectness loss: 0.00014 | RPN Regression loss: 0.00134 | Running loss: 0.04553\n","Epoch: 9 | Iteration: 34098 | Classification loss: 0.01158 | Regression loss: 0.01753 | Objectness loss: 0.00036 | RPN Regression loss: 0.00089 | Running loss: 0.03036\n","Epoch: 9 | Iteration: 34099 | Classification loss: 0.00647 | Regression loss: 0.02199 | Objectness loss: 0.00161 | RPN Regression loss: 0.00160 | Running loss: 0.03168\n","Epoch: 9 | Iteration: 34100 | Classification loss: 0.02702 | Regression loss: 0.03778 | Objectness loss: 0.00181 | RPN Regression loss: 0.00208 | Running loss: 0.06868\n","Epoch: 9 | Iteration: 34101 | Classification loss: 0.00979 | Regression loss: 0.01895 | Objectness loss: 0.00041 | RPN Regression loss: 0.00090 | Running loss: 0.03005\n","Epoch: 9 | Iteration: 34102 | Classification loss: 0.01452 | Regression loss: 0.01244 | Objectness loss: 0.00010 | RPN Regression loss: 0.00062 | Running loss: 0.02768\n","Epoch: 9 | Iteration: 34103 | Classification loss: 0.01094 | Regression loss: 0.02306 | Objectness loss: 0.00053 | RPN Regression loss: 0.00129 | Running loss: 0.03582\n","Epoch: 9 | Iteration: 34104 | Classification loss: 0.02692 | Regression loss: 0.02538 | Objectness loss: 0.00017 | RPN Regression loss: 0.00055 | Running loss: 0.05301\n","Epoch: 9 | Iteration: 34105 | Classification loss: 0.00998 | Regression loss: 0.01444 | Objectness loss: 0.00160 | RPN Regression loss: 0.00120 | Running loss: 0.02722\n","Epoch: 9 | Iteration: 34106 | Classification loss: 0.00816 | Regression loss: 0.02279 | Objectness loss: 0.00011 | RPN Regression loss: 0.00043 | Running loss: 0.03148\n","Epoch: 9 | Iteration: 34107 | Classification loss: 0.01565 | Regression loss: 0.03375 | Objectness loss: 0.00134 | RPN Regression loss: 0.00068 | Running loss: 0.05143\n","Epoch: 9 | Iteration: 34108 | Classification loss: 0.02556 | Regression loss: 0.01862 | Objectness loss: 0.00015 | RPN Regression loss: 0.00152 | Running loss: 0.04585\n","Epoch: 9 | Iteration: 34109 | Classification loss: 0.02355 | Regression loss: 0.03791 | Objectness loss: 0.00323 | RPN Regression loss: 0.00143 | Running loss: 0.06613\n","Epoch: 9 | Iteration: 34110 | Classification loss: 0.01740 | Regression loss: 0.01398 | Objectness loss: 0.00020 | RPN Regression loss: 0.00151 | Running loss: 0.03309\n","Epoch: 9 | Iteration: 34111 | Classification loss: 0.00545 | Regression loss: 0.01502 | Objectness loss: 0.00025 | RPN Regression loss: 0.00097 | Running loss: 0.02169\n","Epoch: 9 | Iteration: 34112 | Classification loss: 0.01563 | Regression loss: 0.02305 | Objectness loss: 0.00189 | RPN Regression loss: 0.00236 | Running loss: 0.04293\n","Epoch: 9 | Iteration: 34113 | Classification loss: 0.02869 | Regression loss: 0.02579 | Objectness loss: 0.00070 | RPN Regression loss: 0.00270 | Running loss: 0.05787\n","Epoch: 9 | Iteration: 34114 | Classification loss: 0.02141 | Regression loss: 0.02518 | Objectness loss: 0.00028 | RPN Regression loss: 0.00092 | Running loss: 0.04778\n","Epoch: 9 | Iteration: 34115 | Classification loss: 0.00570 | Regression loss: 0.02043 | Objectness loss: 0.00018 | RPN Regression loss: 0.00078 | Running loss: 0.02709\n","Epoch: 9 | Iteration: 34116 | Classification loss: 0.01350 | Regression loss: 0.01638 | Objectness loss: 0.00539 | RPN Regression loss: 0.00034 | Running loss: 0.03561\n","Epoch: 9 | Iteration: 34117 | Classification loss: 0.00697 | Regression loss: 0.01651 | Objectness loss: 0.00011 | RPN Regression loss: 0.00051 | Running loss: 0.02410\n","Epoch: 9 | Iteration: 34118 | Classification loss: 0.01335 | Regression loss: 0.02456 | Objectness loss: 0.00007 | RPN Regression loss: 0.00092 | Running loss: 0.03889\n","Epoch: 9 | Iteration: 34119 | Classification loss: 0.01044 | Regression loss: 0.02248 | Objectness loss: 0.00012 | RPN Regression loss: 0.00106 | Running loss: 0.03411\n","Epoch: 9 | Iteration: 34120 | Classification loss: 0.01474 | Regression loss: 0.01913 | Objectness loss: 0.00026 | RPN Regression loss: 0.00081 | Running loss: 0.03495\n","Epoch: 9 | Iteration: 34121 | Classification loss: 0.01647 | Regression loss: 0.02274 | Objectness loss: 0.00002 | RPN Regression loss: 0.00056 | Running loss: 0.03979\n","Epoch: 9 | Iteration: 34122 | Classification loss: 0.02472 | Regression loss: 0.02202 | Objectness loss: 0.01140 | RPN Regression loss: 0.00066 | Running loss: 0.05881\n","Epoch: 9 | Iteration: 34123 | Classification loss: 0.01137 | Regression loss: 0.03240 | Objectness loss: 0.00003 | RPN Regression loss: 0.00110 | Running loss: 0.04491\n","Epoch: 9 | Iteration: 34124 | Classification loss: 0.01297 | Regression loss: 0.02390 | Objectness loss: 0.00007 | RPN Regression loss: 0.00077 | Running loss: 0.03771\n","Epoch: 9 | Iteration: 34125 | Classification loss: 0.04000 | Regression loss: 0.03997 | Objectness loss: 0.00022 | RPN Regression loss: 0.00346 | Running loss: 0.08365\n","Epoch: 9 | Iteration: 34126 | Classification loss: 0.01347 | Regression loss: 0.01369 | Objectness loss: 0.00014 | RPN Regression loss: 0.00123 | Running loss: 0.02853\n","Epoch: 9 | Iteration: 34127 | Classification loss: 0.01462 | Regression loss: 0.02704 | Objectness loss: 0.00039 | RPN Regression loss: 0.00192 | Running loss: 0.04397\n","Epoch: 9 | Iteration: 34128 | Classification loss: 0.01728 | Regression loss: 0.02480 | Objectness loss: 0.00013 | RPN Regression loss: 0.00121 | Running loss: 0.04342\n","Epoch: 9 | Iteration: 34129 | Classification loss: 0.03707 | Regression loss: 0.04842 | Objectness loss: 0.00329 | RPN Regression loss: 0.00274 | Running loss: 0.09152\n","Epoch: 9 | Iteration: 34130 | Classification loss: 0.02904 | Regression loss: 0.04457 | Objectness loss: 0.00032 | RPN Regression loss: 0.00164 | Running loss: 0.07558\n","Epoch: 9 | Iteration: 34131 | Classification loss: 0.02555 | Regression loss: 0.03289 | Objectness loss: 0.00047 | RPN Regression loss: 0.00179 | Running loss: 0.06070\n","Epoch: 9 | Iteration: 34132 | Classification loss: 0.03087 | Regression loss: 0.06415 | Objectness loss: 0.00137 | RPN Regression loss: 0.00147 | Running loss: 0.09786\n","Epoch: 9 | Iteration: 34133 | Classification loss: 0.01240 | Regression loss: 0.03262 | Objectness loss: 0.00041 | RPN Regression loss: 0.00147 | Running loss: 0.04690\n","Epoch: 9 | Iteration: 34134 | Classification loss: 0.02041 | Regression loss: 0.02389 | Objectness loss: 0.00109 | RPN Regression loss: 0.00179 | Running loss: 0.04717\n","Epoch: 9 | Iteration: 34135 | Classification loss: 0.00374 | Regression loss: 0.01285 | Objectness loss: 0.00020 | RPN Regression loss: 0.00100 | Running loss: 0.01779\n","Epoch: 9 | Iteration: 34136 | Classification loss: 0.01489 | Regression loss: 0.02619 | Objectness loss: 0.00053 | RPN Regression loss: 0.00145 | Running loss: 0.04306\n","Epoch: 9 | Iteration: 34137 | Classification loss: 0.01343 | Regression loss: 0.03041 | Objectness loss: 0.00005 | RPN Regression loss: 0.00128 | Running loss: 0.04518\n","Epoch: 9 | Iteration: 34138 | Classification loss: 0.05291 | Regression loss: 0.05921 | Objectness loss: 0.01617 | RPN Regression loss: 0.00208 | Running loss: 0.13037\n","Epoch: 9 | Iteration: 34139 | Classification loss: 0.02951 | Regression loss: 0.02698 | Objectness loss: 0.00066 | RPN Regression loss: 0.00085 | Running loss: 0.05798\n","Epoch: 9 | Iteration: 34140 | Classification loss: 0.03217 | Regression loss: 0.04600 | Objectness loss: 0.00019 | RPN Regression loss: 0.00137 | Running loss: 0.07973\n","Epoch: 9 | Iteration: 34141 | Classification loss: 0.02647 | Regression loss: 0.05689 | Objectness loss: 0.00099 | RPN Regression loss: 0.00193 | Running loss: 0.08629\n","Epoch: 9 | Iteration: 34142 | Classification loss: 0.01186 | Regression loss: 0.02909 | Objectness loss: 0.00005 | RPN Regression loss: 0.00062 | Running loss: 0.04161\n","Epoch: 9 | Iteration: 34143 | Classification loss: 0.01149 | Regression loss: 0.01978 | Objectness loss: 0.00022 | RPN Regression loss: 0.00055 | Running loss: 0.03204\n","Epoch: 9 | Iteration: 34144 | Classification loss: 0.03257 | Regression loss: 0.04572 | Objectness loss: 0.02008 | RPN Regression loss: 0.00267 | Running loss: 0.10104\n","Epoch: 9 | Iteration: 34145 | Classification loss: 0.02177 | Regression loss: 0.02489 | Objectness loss: 0.00017 | RPN Regression loss: 0.00160 | Running loss: 0.04843\n","Epoch: 9 | Iteration: 34146 | Classification loss: 0.02241 | Regression loss: 0.03629 | Objectness loss: 0.00009 | RPN Regression loss: 0.00250 | Running loss: 0.06129\n","Epoch: 9 | Iteration: 34147 | Classification loss: 0.01770 | Regression loss: 0.01766 | Objectness loss: 0.00234 | RPN Regression loss: 0.00190 | Running loss: 0.03961\n","Epoch: 9 | Iteration: 34148 | Classification loss: 0.02601 | Regression loss: 0.02350 | Objectness loss: 0.00055 | RPN Regression loss: 0.00108 | Running loss: 0.05114\n","Epoch: 9 | Iteration: 34149 | Classification loss: 0.00797 | Regression loss: 0.01258 | Objectness loss: 0.00074 | RPN Regression loss: 0.00129 | Running loss: 0.02258\n","Epoch: 9 | Iteration: 34150 | Classification loss: 0.04959 | Regression loss: 0.08724 | Objectness loss: 0.00294 | RPN Regression loss: 0.00361 | Running loss: 0.14339\n","Epoch: 9 | Iteration: 34151 | Classification loss: 0.01110 | Regression loss: 0.02417 | Objectness loss: 0.00006 | RPN Regression loss: 0.00199 | Running loss: 0.03732\n","Epoch: 9 | Iteration: 34152 | Classification loss: 0.00395 | Regression loss: 0.01561 | Objectness loss: 0.00011 | RPN Regression loss: 0.00043 | Running loss: 0.02010\n","Epoch: 9 | Iteration: 34153 | Classification loss: 0.00857 | Regression loss: 0.01837 | Objectness loss: 0.00101 | RPN Regression loss: 0.00103 | Running loss: 0.02898\n","Epoch: 9 | Iteration: 34154 | Classification loss: 0.01426 | Regression loss: 0.02542 | Objectness loss: 0.00172 | RPN Regression loss: 0.00509 | Running loss: 0.04650\n","Epoch: 9 | Iteration: 34155 | Classification loss: 0.01059 | Regression loss: 0.01812 | Objectness loss: 0.00077 | RPN Regression loss: 0.00315 | Running loss: 0.03262\n","Epoch: 9 | Iteration: 34156 | Classification loss: 0.02495 | Regression loss: 0.02919 | Objectness loss: 0.00116 | RPN Regression loss: 0.00081 | Running loss: 0.05611\n","Epoch: 9 | Iteration: 34157 | Classification loss: 0.01902 | Regression loss: 0.02891 | Objectness loss: 0.00222 | RPN Regression loss: 0.00145 | Running loss: 0.05160\n","Epoch: 9 | Iteration: 34158 | Classification loss: 0.01313 | Regression loss: 0.04292 | Objectness loss: 0.00011 | RPN Regression loss: 0.00130 | Running loss: 0.05747\n","Epoch: 9 | Iteration: 34159 | Classification loss: 0.01114 | Regression loss: 0.01582 | Objectness loss: 0.00011 | RPN Regression loss: 0.00188 | Running loss: 0.02894\n","Epoch: 9 | Iteration: 34160 | Classification loss: 0.01192 | Regression loss: 0.02925 | Objectness loss: 0.00155 | RPN Regression loss: 0.00329 | Running loss: 0.04601\n","Epoch: 9 | Iteration: 34161 | Classification loss: 0.00918 | Regression loss: 0.01865 | Objectness loss: 0.00048 | RPN Regression loss: 0.00603 | Running loss: 0.03435\n","Epoch: 9 | Iteration: 34162 | Classification loss: 0.02026 | Regression loss: 0.01805 | Objectness loss: 0.00056 | RPN Regression loss: 0.00084 | Running loss: 0.03971\n","Epoch: 9 | Iteration: 34163 | Classification loss: 0.03392 | Regression loss: 0.03427 | Objectness loss: 0.00586 | RPN Regression loss: 0.00328 | Running loss: 0.07733\n","Epoch: 9 | Iteration: 34164 | Classification loss: 0.03697 | Regression loss: 0.01862 | Objectness loss: 0.01012 | RPN Regression loss: 0.00180 | Running loss: 0.06752\n","Epoch: 9 | Iteration: 34165 | Classification loss: 0.01119 | Regression loss: 0.01746 | Objectness loss: 0.00002 | RPN Regression loss: 0.00100 | Running loss: 0.02967\n","Epoch: 9 | Iteration: 34166 | Classification loss: 0.01257 | Regression loss: 0.01760 | Objectness loss: 0.00013 | RPN Regression loss: 0.00212 | Running loss: 0.03242\n","Epoch: 9 | Iteration: 34167 | Classification loss: 0.01288 | Regression loss: 0.01850 | Objectness loss: 0.00003 | RPN Regression loss: 0.00072 | Running loss: 0.03212\n","Epoch: 9 | Iteration: 34168 | Classification loss: 0.01021 | Regression loss: 0.01657 | Objectness loss: 0.00005 | RPN Regression loss: 0.00092 | Running loss: 0.02775\n","Epoch: 9 | Iteration: 34169 | Classification loss: 0.01488 | Regression loss: 0.01829 | Objectness loss: 0.00003 | RPN Regression loss: 0.00049 | Running loss: 0.03368\n","Epoch: 9 | Iteration: 34170 | Classification loss: 0.00835 | Regression loss: 0.02649 | Objectness loss: 0.00002 | RPN Regression loss: 0.00057 | Running loss: 0.03544\n","Epoch: 9 | Iteration: 34171 | Classification loss: 0.01030 | Regression loss: 0.02101 | Objectness loss: 0.00029 | RPN Regression loss: 0.00659 | Running loss: 0.03819\n","Epoch: 9 | Iteration: 34172 | Classification loss: 0.01654 | Regression loss: 0.03179 | Objectness loss: 0.00018 | RPN Regression loss: 0.00100 | Running loss: 0.04951\n","Epoch: 9 | Iteration: 34173 | Classification loss: 0.01000 | Regression loss: 0.01329 | Objectness loss: 0.00018 | RPN Regression loss: 0.00120 | Running loss: 0.02467\n","Epoch: 9 | Iteration: 34174 | Classification loss: 0.01638 | Regression loss: 0.03949 | Objectness loss: 0.00023 | RPN Regression loss: 0.00210 | Running loss: 0.05819\n","Epoch: 9 | Iteration: 34175 | Classification loss: 0.01769 | Regression loss: 0.02076 | Objectness loss: 0.00005 | RPN Regression loss: 0.00125 | Running loss: 0.03975\n","Epoch: 9 | Iteration: 34176 | Classification loss: 0.01015 | Regression loss: 0.01800 | Objectness loss: 0.00076 | RPN Regression loss: 0.00161 | Running loss: 0.03051\n","Epoch: 9 | Iteration: 34177 | Classification loss: 0.02859 | Regression loss: 0.02193 | Objectness loss: 0.04651 | RPN Regression loss: 0.00419 | Running loss: 0.10122\n","Epoch: 9 | Iteration: 34178 | Classification loss: 0.02916 | Regression loss: 0.02849 | Objectness loss: 0.00242 | RPN Regression loss: 0.00120 | Running loss: 0.06128\n","Epoch: 9 | Iteration: 34179 | Classification loss: 0.00600 | Regression loss: 0.01472 | Objectness loss: 0.00002 | RPN Regression loss: 0.00072 | Running loss: 0.02147\n","Epoch: 9 | Iteration: 34180 | Classification loss: 0.01925 | Regression loss: 0.01626 | Objectness loss: 0.00009 | RPN Regression loss: 0.00225 | Running loss: 0.03786\n","Epoch: 9 | Iteration: 34181 | Classification loss: 0.00962 | Regression loss: 0.01763 | Objectness loss: 0.00010 | RPN Regression loss: 0.00028 | Running loss: 0.02762\n","Epoch: 9 | Iteration: 34182 | Classification loss: 0.01022 | Regression loss: 0.01218 | Objectness loss: 0.00270 | RPN Regression loss: 0.01554 | Running loss: 0.04065\n","Epoch: 9 | Iteration: 34183 | Classification loss: 0.01110 | Regression loss: 0.01792 | Objectness loss: 0.00045 | RPN Regression loss: 0.00116 | Running loss: 0.03062\n","Epoch: 9 | Iteration: 34184 | Classification loss: 0.01945 | Regression loss: 0.04324 | Objectness loss: 0.00052 | RPN Regression loss: 0.00249 | Running loss: 0.06570\n","Epoch: 9 | Iteration: 34185 | Classification loss: 0.00927 | Regression loss: 0.01292 | Objectness loss: 0.00063 | RPN Regression loss: 0.00219 | Running loss: 0.02501\n","Epoch: 9 | Iteration: 34186 | Classification loss: 0.02248 | Regression loss: 0.03712 | Objectness loss: 0.00081 | RPN Regression loss: 0.00216 | Running loss: 0.06256\n","Epoch: 9 | Iteration: 34187 | Classification loss: 0.02053 | Regression loss: 0.02237 | Objectness loss: 0.00694 | RPN Regression loss: 0.00356 | Running loss: 0.05340\n","Epoch: 9 | Iteration: 34188 | Classification loss: 0.01474 | Regression loss: 0.01076 | Objectness loss: 0.00044 | RPN Regression loss: 0.00093 | Running loss: 0.02688\n","Epoch: 9 | Iteration: 34189 | Classification loss: 0.02207 | Regression loss: 0.01775 | Objectness loss: 0.00126 | RPN Regression loss: 0.00129 | Running loss: 0.04237\n","Epoch: 9 | Iteration: 34190 | Classification loss: 0.01405 | Regression loss: 0.02835 | Objectness loss: 0.00274 | RPN Regression loss: 0.00504 | Running loss: 0.05018\n","Epoch: 9 | Iteration: 34191 | Classification loss: 0.03144 | Regression loss: 0.03670 | Objectness loss: 0.00017 | RPN Regression loss: 0.00066 | Running loss: 0.06896\n","Epoch: 9 | Iteration: 34192 | Classification loss: 0.00605 | Regression loss: 0.01309 | Objectness loss: 0.00019 | RPN Regression loss: 0.00193 | Running loss: 0.02126\n","Epoch: 9 | Iteration: 34193 | Classification loss: 0.00910 | Regression loss: 0.02350 | Objectness loss: 0.00073 | RPN Regression loss: 0.00077 | Running loss: 0.03410\n","Epoch: 9 | Iteration: 34194 | Classification loss: 0.00624 | Regression loss: 0.01179 | Objectness loss: 0.00003 | RPN Regression loss: 0.00087 | Running loss: 0.01893\n","Epoch: 9 | Iteration: 34195 | Classification loss: 0.02090 | Regression loss: 0.01830 | Objectness loss: 0.00014 | RPN Regression loss: 0.00083 | Running loss: 0.04017\n","Epoch: 9 | Iteration: 34196 | Classification loss: 0.01072 | Regression loss: 0.02118 | Objectness loss: 0.00010 | RPN Regression loss: 0.00227 | Running loss: 0.03427\n","Epoch: 9 | Iteration: 34197 | Classification loss: 0.00592 | Regression loss: 0.01634 | Objectness loss: 0.00111 | RPN Regression loss: 0.00191 | Running loss: 0.02529\n","Epoch: 9 | Iteration: 34198 | Classification loss: 0.02894 | Regression loss: 0.02658 | Objectness loss: 0.00015 | RPN Regression loss: 0.00123 | Running loss: 0.05690\n","Epoch: 9 | Iteration: 34199 | Classification loss: 0.02089 | Regression loss: 0.03038 | Objectness loss: 0.00010 | RPN Regression loss: 0.00388 | Running loss: 0.05524\n","Epoch: 9 | Iteration: 34200 | Classification loss: 0.01183 | Regression loss: 0.01078 | Objectness loss: 0.00046 | RPN Regression loss: 0.00199 | Running loss: 0.02506\n","Epoch: 9 | Iteration: 34201 | Classification loss: 0.08529 | Regression loss: 0.04196 | Objectness loss: 0.00771 | RPN Regression loss: 0.00134 | Running loss: 0.13630\n","Epoch: 9 | Iteration: 34202 | Classification loss: 0.01342 | Regression loss: 0.03049 | Objectness loss: 0.00014 | RPN Regression loss: 0.00142 | Running loss: 0.04547\n","Epoch: 9 | Iteration: 34203 | Classification loss: 0.01239 | Regression loss: 0.00998 | Objectness loss: 0.00048 | RPN Regression loss: 0.00095 | Running loss: 0.02380\n","Epoch: 9 | Iteration: 34204 | Classification loss: 0.01546 | Regression loss: 0.02428 | Objectness loss: 0.00374 | RPN Regression loss: 0.00154 | Running loss: 0.04502\n","Epoch: 9 | Iteration: 34205 | Classification loss: 0.02091 | Regression loss: 0.01886 | Objectness loss: 0.00034 | RPN Regression loss: 0.00268 | Running loss: 0.04280\n","Epoch: 9 | Iteration: 34206 | Classification loss: 0.01996 | Regression loss: 0.03841 | Objectness loss: 0.00153 | RPN Regression loss: 0.00211 | Running loss: 0.06202\n","Epoch: 9 | Iteration: 34207 | Classification loss: 0.03448 | Regression loss: 0.03491 | Objectness loss: 0.00189 | RPN Regression loss: 0.00110 | Running loss: 0.07238\n","Epoch: 9 | Iteration: 34208 | Classification loss: 0.02443 | Regression loss: 0.01582 | Objectness loss: 0.00013 | RPN Regression loss: 0.00119 | Running loss: 0.04157\n","Epoch: 9 | Iteration: 34209 | Classification loss: 0.00870 | Regression loss: 0.01111 | Objectness loss: 0.00025 | RPN Regression loss: 0.00080 | Running loss: 0.02086\n","Epoch: 9 | Iteration: 34210 | Classification loss: 0.01377 | Regression loss: 0.02615 | Objectness loss: 0.00101 | RPN Regression loss: 0.00080 | Running loss: 0.04174\n","Epoch: 9 | Iteration: 34211 | Classification loss: 0.02600 | Regression loss: 0.02389 | Objectness loss: 0.00034 | RPN Regression loss: 0.00149 | Running loss: 0.05172\n","Epoch: 9 | Iteration: 34212 | Classification loss: 0.00812 | Regression loss: 0.01592 | Objectness loss: 0.00027 | RPN Regression loss: 0.00102 | Running loss: 0.02533\n","Epoch: 9 | Iteration: 34213 | Classification loss: 0.01036 | Regression loss: 0.02209 | Objectness loss: 0.00303 | RPN Regression loss: 0.00089 | Running loss: 0.03638\n","Epoch: 9 | Iteration: 34214 | Classification loss: 0.02065 | Regression loss: 0.02383 | Objectness loss: 0.00065 | RPN Regression loss: 0.00049 | Running loss: 0.04562\n","Epoch: 9 | Iteration: 34215 | Classification loss: 0.01808 | Regression loss: 0.02863 | Objectness loss: 0.00028 | RPN Regression loss: 0.00071 | Running loss: 0.04770\n","Epoch: 9 | Iteration: 34216 | Classification loss: 0.04948 | Regression loss: 0.02185 | Objectness loss: 0.00527 | RPN Regression loss: 0.00348 | Running loss: 0.08009\n","Epoch: 9 | Iteration: 34217 | Classification loss: 0.01369 | Regression loss: 0.01828 | Objectness loss: 0.00028 | RPN Regression loss: 0.00071 | Running loss: 0.03296\n","Epoch: 9 | Iteration: 34218 | Classification loss: 0.01211 | Regression loss: 0.01879 | Objectness loss: 0.00037 | RPN Regression loss: 0.00043 | Running loss: 0.03170\n","Epoch: 9 | Iteration: 34219 | Classification loss: 0.02948 | Regression loss: 0.03822 | Objectness loss: 0.00056 | RPN Regression loss: 0.00166 | Running loss: 0.06992\n","Epoch: 9 | Iteration: 34220 | Classification loss: 0.01267 | Regression loss: 0.01709 | Objectness loss: 0.00191 | RPN Regression loss: 0.00091 | Running loss: 0.03259\n","Epoch: 9 | Iteration: 34221 | Classification loss: 0.01982 | Regression loss: 0.02755 | Objectness loss: 0.00018 | RPN Regression loss: 0.00128 | Running loss: 0.04883\n","Epoch: 9 | Iteration: 34222 | Classification loss: 0.01946 | Regression loss: 0.03487 | Objectness loss: 0.00009 | RPN Regression loss: 0.00073 | Running loss: 0.05514\n","Epoch: 9 | Iteration: 34223 | Classification loss: 0.01810 | Regression loss: 0.01578 | Objectness loss: 0.00117 | RPN Regression loss: 0.00044 | Running loss: 0.03550\n","Epoch: 9 | Iteration: 34224 | Classification loss: 0.01366 | Regression loss: 0.02973 | Objectness loss: 0.00020 | RPN Regression loss: 0.00052 | Running loss: 0.04411\n","Epoch: 9 | Iteration: 34225 | Classification loss: 0.01265 | Regression loss: 0.02199 | Objectness loss: 0.00329 | RPN Regression loss: 0.00187 | Running loss: 0.03980\n","Epoch: 9 | Iteration: 34226 | Classification loss: 0.00720 | Regression loss: 0.01313 | Objectness loss: 0.00104 | RPN Regression loss: 0.00220 | Running loss: 0.02358\n","Epoch: 9 | Iteration: 34227 | Classification loss: 0.01909 | Regression loss: 0.02759 | Objectness loss: 0.00069 | RPN Regression loss: 0.00173 | Running loss: 0.04910\n","Epoch: 9 | Iteration: 34228 | Classification loss: 0.01090 | Regression loss: 0.01245 | Objectness loss: 0.00042 | RPN Regression loss: 0.00394 | Running loss: 0.02770\n","Epoch: 9 | Iteration: 34229 | Classification loss: 0.00600 | Regression loss: 0.01394 | Objectness loss: 0.00050 | RPN Regression loss: 0.00172 | Running loss: 0.02215\n","Epoch: 9 | Iteration: 34230 | Classification loss: 0.01891 | Regression loss: 0.03118 | Objectness loss: 0.00041 | RPN Regression loss: 0.00099 | Running loss: 0.05148\n","Epoch: 9 | Iteration: 34231 | Classification loss: 0.02291 | Regression loss: 0.02818 | Objectness loss: 0.00153 | RPN Regression loss: 0.00655 | Running loss: 0.05917\n","Epoch: 9 | Iteration: 34232 | Classification loss: 0.02377 | Regression loss: 0.02835 | Objectness loss: 0.00136 | RPN Regression loss: 0.00064 | Running loss: 0.05412\n","Epoch: 9 | Iteration: 34233 | Classification loss: 0.02188 | Regression loss: 0.03689 | Objectness loss: 0.00244 | RPN Regression loss: 0.00151 | Running loss: 0.06273\n","Epoch: 9 | Iteration: 34234 | Classification loss: 0.01394 | Regression loss: 0.03623 | Objectness loss: 0.00079 | RPN Regression loss: 0.00208 | Running loss: 0.05303\n","Epoch: 9 | Iteration: 34235 | Classification loss: 0.02340 | Regression loss: 0.02448 | Objectness loss: 0.00022 | RPN Regression loss: 0.00647 | Running loss: 0.05457\n","Epoch: 9 | Iteration: 34236 | Classification loss: 0.00656 | Regression loss: 0.02180 | Objectness loss: 0.00032 | RPN Regression loss: 0.00111 | Running loss: 0.02979\n","Epoch: 9 | Iteration: 34237 | Classification loss: 0.00912 | Regression loss: 0.01360 | Objectness loss: 0.00011 | RPN Regression loss: 0.00104 | Running loss: 0.02388\n","Epoch: 9 | Iteration: 34238 | Classification loss: 0.02966 | Regression loss: 0.02643 | Objectness loss: 0.00018 | RPN Regression loss: 0.00146 | Running loss: 0.05773\n","Epoch: 9 | Iteration: 34239 | Classification loss: 0.00639 | Regression loss: 0.01205 | Objectness loss: 0.00029 | RPN Regression loss: 0.00281 | Running loss: 0.02154\n","Epoch: 9 | Iteration: 34240 | Classification loss: 0.03131 | Regression loss: 0.02141 | Objectness loss: 0.00008 | RPN Regression loss: 0.00159 | Running loss: 0.05439\n","Epoch: 9 | Iteration: 34241 | Classification loss: 0.02666 | Regression loss: 0.02750 | Objectness loss: 0.00226 | RPN Regression loss: 0.00090 | Running loss: 0.05732\n","Epoch: 9 | Iteration: 34242 | Classification loss: 0.00758 | Regression loss: 0.01923 | Objectness loss: 0.00008 | RPN Regression loss: 0.00152 | Running loss: 0.02842\n","Epoch: 9 | Iteration: 34243 | Classification loss: 0.00987 | Regression loss: 0.02021 | Objectness loss: 0.00083 | RPN Regression loss: 0.00171 | Running loss: 0.03262\n","Epoch: 9 | Iteration: 34244 | Classification loss: 0.00725 | Regression loss: 0.01782 | Objectness loss: 0.00037 | RPN Regression loss: 0.00211 | Running loss: 0.02755\n","Epoch: 9 | Iteration: 34245 | Classification loss: 0.01225 | Regression loss: 0.02707 | Objectness loss: 0.00062 | RPN Regression loss: 0.00111 | Running loss: 0.04105\n","Epoch: 9 | Iteration: 34246 | Classification loss: 0.00711 | Regression loss: 0.01927 | Objectness loss: 0.00371 | RPN Regression loss: 0.00127 | Running loss: 0.03135\n","Epoch: 9 | Iteration: 34247 | Classification loss: 0.00465 | Regression loss: 0.01515 | Objectness loss: 0.00006 | RPN Regression loss: 0.00150 | Running loss: 0.02135\n","Epoch: 9 | Iteration: 34248 | Classification loss: 0.00987 | Regression loss: 0.01854 | Objectness loss: 0.00003 | RPN Regression loss: 0.00031 | Running loss: 0.02875\n","Epoch: 9 | Iteration: 34249 | Classification loss: 0.00944 | Regression loss: 0.01131 | Objectness loss: 0.00062 | RPN Regression loss: 0.00330 | Running loss: 0.02468\n","Epoch: 9 | Iteration: 34250 | Classification loss: 0.00700 | Regression loss: 0.01633 | Objectness loss: 0.00006 | RPN Regression loss: 0.00094 | Running loss: 0.02432\n","Epoch: 9 | Iteration: 34251 | Classification loss: 0.02345 | Regression loss: 0.03028 | Objectness loss: 0.00004 | RPN Regression loss: 0.00030 | Running loss: 0.05407\n","Epoch: 9 | Iteration: 34252 | Classification loss: 0.00842 | Regression loss: 0.01575 | Objectness loss: 0.00000 | RPN Regression loss: 0.00020 | Running loss: 0.02438\n","Epoch: 9 | Iteration: 34253 | Classification loss: 0.00608 | Regression loss: 0.01111 | Objectness loss: 0.00049 | RPN Regression loss: 0.00061 | Running loss: 0.01829\n","Epoch: 9 | Iteration: 34254 | Classification loss: 0.01911 | Regression loss: 0.02657 | Objectness loss: 0.00058 | RPN Regression loss: 0.00440 | Running loss: 0.05066\n","Epoch: 9 | Iteration: 34255 | Classification loss: 0.02149 | Regression loss: 0.01864 | Objectness loss: 0.00220 | RPN Regression loss: 0.00145 | Running loss: 0.04378\n","Epoch: 9 | Iteration: 34256 | Classification loss: 0.00637 | Regression loss: 0.01809 | Objectness loss: 0.00047 | RPN Regression loss: 0.00082 | Running loss: 0.02574\n","Epoch: 9 | Iteration: 34257 | Classification loss: 0.01255 | Regression loss: 0.01969 | Objectness loss: 0.00007 | RPN Regression loss: 0.00099 | Running loss: 0.03331\n","Epoch: 9 | Iteration: 34258 | Classification loss: 0.01207 | Regression loss: 0.01660 | Objectness loss: 0.00038 | RPN Regression loss: 0.00203 | Running loss: 0.03108\n","Epoch: 9 | Iteration: 34259 | Classification loss: 0.00944 | Regression loss: 0.02743 | Objectness loss: 0.00005 | RPN Regression loss: 0.00075 | Running loss: 0.03766\n","Epoch: 9 | Iteration: 34260 | Classification loss: 0.01405 | Regression loss: 0.01649 | Objectness loss: 0.00009 | RPN Regression loss: 0.00108 | Running loss: 0.03171\n","Epoch: 9 | Iteration: 34261 | Classification loss: 0.00850 | Regression loss: 0.01489 | Objectness loss: 0.00111 | RPN Regression loss: 0.00152 | Running loss: 0.02602\n","Epoch: 9 | Iteration: 34262 | Classification loss: 0.01314 | Regression loss: 0.02825 | Objectness loss: 0.00035 | RPN Regression loss: 0.00302 | Running loss: 0.04477\n","Epoch: 9 | Iteration: 34263 | Classification loss: 0.00603 | Regression loss: 0.02551 | Objectness loss: 0.00020 | RPN Regression loss: 0.00136 | Running loss: 0.03310\n","Epoch: 9 | Iteration: 34264 | Classification loss: 0.00839 | Regression loss: 0.02129 | Objectness loss: 0.00002 | RPN Regression loss: 0.00058 | Running loss: 0.03028\n","Epoch: 9 | Iteration: 34265 | Classification loss: 0.01989 | Regression loss: 0.01062 | Objectness loss: 0.00075 | RPN Regression loss: 0.00105 | Running loss: 0.03231\n","Epoch: 9 | Iteration: 34266 | Classification loss: 0.01440 | Regression loss: 0.03038 | Objectness loss: 0.00014 | RPN Regression loss: 0.00271 | Running loss: 0.04763\n","Epoch: 9 | Iteration: 34267 | Classification loss: 0.00858 | Regression loss: 0.01254 | Objectness loss: 0.00004 | RPN Regression loss: 0.00059 | Running loss: 0.02176\n","Epoch: 9 | Iteration: 34268 | Classification loss: 0.02534 | Regression loss: 0.03648 | Objectness loss: 0.00136 | RPN Regression loss: 0.00271 | Running loss: 0.06589\n","Epoch: 9 | Iteration: 34269 | Classification loss: 0.03285 | Regression loss: 0.04873 | Objectness loss: 0.00003 | RPN Regression loss: 0.00090 | Running loss: 0.08251\n","Epoch: 9 | Iteration: 34270 | Classification loss: 0.01639 | Regression loss: 0.03451 | Objectness loss: 0.00002 | RPN Regression loss: 0.00181 | Running loss: 0.05272\n","Epoch: 9 | Iteration: 34271 | Classification loss: 0.02589 | Regression loss: 0.02978 | Objectness loss: 0.00017 | RPN Regression loss: 0.00125 | Running loss: 0.05710\n","Epoch: 9 | Iteration: 34272 | Classification loss: 0.01267 | Regression loss: 0.03724 | Objectness loss: 0.00017 | RPN Regression loss: 0.00117 | Running loss: 0.05126\n","Epoch: 9 | Iteration: 34273 | Classification loss: 0.02263 | Regression loss: 0.02073 | Objectness loss: 0.00002 | RPN Regression loss: 0.00222 | Running loss: 0.04560\n","Epoch: 9 | Iteration: 34274 | Classification loss: 0.03698 | Regression loss: 0.05829 | Objectness loss: 0.00009 | RPN Regression loss: 0.00202 | Running loss: 0.09737\n","Epoch: 9 | Iteration: 34275 | Classification loss: 0.00807 | Regression loss: 0.01364 | Objectness loss: 0.00022 | RPN Regression loss: 0.00150 | Running loss: 0.02343\n","Epoch: 9 | Iteration: 34276 | Classification loss: 0.01237 | Regression loss: 0.01662 | Objectness loss: 0.00117 | RPN Regression loss: 0.00204 | Running loss: 0.03219\n","Epoch: 9 | Iteration: 34277 | Classification loss: 0.02058 | Regression loss: 0.01473 | Objectness loss: 0.00500 | RPN Regression loss: 0.00170 | Running loss: 0.04201\n","Epoch: 9 | Iteration: 34278 | Classification loss: 0.01865 | Regression loss: 0.02128 | Objectness loss: 0.00030 | RPN Regression loss: 0.00077 | Running loss: 0.04100\n","Epoch: 9 | Iteration: 34279 | Classification loss: 0.00806 | Regression loss: 0.02186 | Objectness loss: 0.00035 | RPN Regression loss: 0.00738 | Running loss: 0.03765\n","Epoch: 9 | Iteration: 34280 | Classification loss: 0.01002 | Regression loss: 0.01681 | Objectness loss: 0.00011 | RPN Regression loss: 0.00086 | Running loss: 0.02780\n","Epoch: 9 | Iteration: 34281 | Classification loss: 0.01582 | Regression loss: 0.02189 | Objectness loss: 0.00175 | RPN Regression loss: 0.00186 | Running loss: 0.04131\n","Epoch: 9 | Iteration: 34282 | Classification loss: 0.02198 | Regression loss: 0.02821 | Objectness loss: 0.00008 | RPN Regression loss: 0.00227 | Running loss: 0.05254\n","Epoch: 9 | Iteration: 34283 | Classification loss: 0.00867 | Regression loss: 0.01353 | Objectness loss: 0.00085 | RPN Regression loss: 0.00470 | Running loss: 0.02774\n","Epoch: 9 | Iteration: 34284 | Classification loss: 0.03135 | Regression loss: 0.02743 | Objectness loss: 0.00038 | RPN Regression loss: 0.00247 | Running loss: 0.06163\n","Epoch: 9 | Iteration: 34285 | Classification loss: 0.00811 | Regression loss: 0.02043 | Objectness loss: 0.00000 | RPN Regression loss: 0.00082 | Running loss: 0.02937\n","Epoch: 9 | Iteration: 34286 | Classification loss: 0.02760 | Regression loss: 0.03343 | Objectness loss: 0.00001 | RPN Regression loss: 0.00140 | Running loss: 0.06244\n","Epoch: 9 | Iteration: 34287 | Classification loss: 0.00597 | Regression loss: 0.01342 | Objectness loss: 0.00006 | RPN Regression loss: 0.00162 | Running loss: 0.02107\n","Epoch: 9 | Iteration: 34288 | Classification loss: 0.01955 | Regression loss: 0.02389 | Objectness loss: 0.00002 | RPN Regression loss: 0.00051 | Running loss: 0.04397\n","Epoch: 9 | Iteration: 34289 | Classification loss: 0.01298 | Regression loss: 0.01860 | Objectness loss: 0.00011 | RPN Regression loss: 0.00029 | Running loss: 0.03197\n","Epoch: 9 | Iteration: 34290 | Classification loss: 0.00686 | Regression loss: 0.01349 | Objectness loss: 0.00023 | RPN Regression loss: 0.00133 | Running loss: 0.02192\n","Epoch: 9 | Iteration: 34291 | Classification loss: 0.00694 | Regression loss: 0.01627 | Objectness loss: 0.00001 | RPN Regression loss: 0.00068 | Running loss: 0.02390\n","Epoch: 9 | Iteration: 34292 | Classification loss: 0.00766 | Regression loss: 0.01388 | Objectness loss: 0.00007 | RPN Regression loss: 0.00170 | Running loss: 0.02331\n","Epoch: 9 | Iteration: 34293 | Classification loss: 0.02087 | Regression loss: 0.01636 | Objectness loss: 0.00511 | RPN Regression loss: 0.00183 | Running loss: 0.04416\n","Epoch: 9 | Iteration: 34294 | Classification loss: 0.01087 | Regression loss: 0.01812 | Objectness loss: 0.00101 | RPN Regression loss: 0.00081 | Running loss: 0.03082\n","Epoch: 9 | Iteration: 34295 | Classification loss: 0.02271 | Regression loss: 0.01242 | Objectness loss: 0.00187 | RPN Regression loss: 0.00058 | Running loss: 0.03758\n","Epoch: 9 | Iteration: 34296 | Classification loss: 0.01174 | Regression loss: 0.01643 | Objectness loss: 0.00067 | RPN Regression loss: 0.00099 | Running loss: 0.02984\n","Epoch: 9 | Iteration: 34297 | Classification loss: 0.00562 | Regression loss: 0.01175 | Objectness loss: 0.00010 | RPN Regression loss: 0.00062 | Running loss: 0.01809\n","Epoch: 9 | Iteration: 34298 | Classification loss: 0.00896 | Regression loss: 0.01362 | Objectness loss: 0.00006 | RPN Regression loss: 0.00184 | Running loss: 0.02448\n","Epoch: 9 | Iteration: 34299 | Classification loss: 0.01542 | Regression loss: 0.03590 | Objectness loss: 0.00114 | RPN Regression loss: 0.00381 | Running loss: 0.05627\n","Epoch: 9 | Iteration: 34300 | Classification loss: 0.02105 | Regression loss: 0.03067 | Objectness loss: 0.00021 | RPN Regression loss: 0.00079 | Running loss: 0.05272\n","Epoch: 9 | Iteration: 34301 | Classification loss: 0.00861 | Regression loss: 0.01839 | Objectness loss: 0.00019 | RPN Regression loss: 0.00114 | Running loss: 0.02833\n","Epoch: 9 | Iteration: 34302 | Classification loss: 0.01336 | Regression loss: 0.02204 | Objectness loss: 0.00046 | RPN Regression loss: 0.00262 | Running loss: 0.03848\n","Epoch: 9 | Iteration: 34303 | Classification loss: 0.02496 | Regression loss: 0.02112 | Objectness loss: 0.00009 | RPN Regression loss: 0.00160 | Running loss: 0.04776\n","Epoch: 9 | Iteration: 34304 | Classification loss: 0.01225 | Regression loss: 0.02296 | Objectness loss: 0.00009 | RPN Regression loss: 0.00094 | Running loss: 0.03623\n","Epoch: 9 | Iteration: 34305 | Classification loss: 0.00861 | Regression loss: 0.02143 | Objectness loss: 0.00001 | RPN Regression loss: 0.00102 | Running loss: 0.03106\n","Epoch: 9 | Iteration: 34306 | Classification loss: 0.01704 | Regression loss: 0.02277 | Objectness loss: 0.00532 | RPN Regression loss: 0.00512 | Running loss: 0.05026\n","Epoch: 9 | Iteration: 34307 | Classification loss: 0.00869 | Regression loss: 0.02166 | Objectness loss: 0.00013 | RPN Regression loss: 0.00040 | Running loss: 0.03088\n","Epoch: 9 | Iteration: 34308 | Classification loss: 0.01318 | Regression loss: 0.01527 | Objectness loss: 0.00010 | RPN Regression loss: 0.00162 | Running loss: 0.03018\n","Epoch: 9 | Iteration: 34309 | Classification loss: 0.00825 | Regression loss: 0.00984 | Objectness loss: 0.00001 | RPN Regression loss: 0.00060 | Running loss: 0.01870\n","Epoch: 9 | Iteration: 34310 | Classification loss: 0.01216 | Regression loss: 0.01438 | Objectness loss: 0.00007 | RPN Regression loss: 0.00107 | Running loss: 0.02769\n","Epoch: 9 | Iteration: 34311 | Classification loss: 0.02071 | Regression loss: 0.02438 | Objectness loss: 0.00004 | RPN Regression loss: 0.00049 | Running loss: 0.04562\n","Epoch: 9 | Iteration: 34312 | Classification loss: 0.03623 | Regression loss: 0.03799 | Objectness loss: 0.00075 | RPN Regression loss: 0.00116 | Running loss: 0.07613\n","Epoch: 9 | Iteration: 34313 | Classification loss: 0.01210 | Regression loss: 0.01969 | Objectness loss: 0.00002 | RPN Regression loss: 0.00042 | Running loss: 0.03222\n","Epoch: 9 | Iteration: 34314 | Classification loss: 0.01130 | Regression loss: 0.01377 | Objectness loss: 0.00022 | RPN Regression loss: 0.00396 | Running loss: 0.02924\n","Epoch: 9 | Iteration: 34315 | Classification loss: 0.01589 | Regression loss: 0.02431 | Objectness loss: 0.00089 | RPN Regression loss: 0.00182 | Running loss: 0.04292\n","Epoch: 9 | Iteration: 34316 | Classification loss: 0.01141 | Regression loss: 0.01252 | Objectness loss: 0.00014 | RPN Regression loss: 0.00127 | Running loss: 0.02533\n","Epoch: 9 | Iteration: 34317 | Classification loss: 0.00934 | Regression loss: 0.02858 | Objectness loss: 0.00003 | RPN Regression loss: 0.00039 | Running loss: 0.03834\n","Epoch: 9 | Iteration: 34318 | Classification loss: 0.01348 | Regression loss: 0.01534 | Objectness loss: 0.00074 | RPN Regression loss: 0.00188 | Running loss: 0.03144\n","Epoch: 9 | Iteration: 34319 | Classification loss: 0.02402 | Regression loss: 0.02189 | Objectness loss: 0.00021 | RPN Regression loss: 0.00225 | Running loss: 0.04837\n","Epoch: 9 | Iteration: 34320 | Classification loss: 0.00808 | Regression loss: 0.01803 | Objectness loss: 0.00147 | RPN Regression loss: 0.00106 | Running loss: 0.02864\n","Epoch: 9 | Iteration: 34321 | Classification loss: 0.01231 | Regression loss: 0.03737 | Objectness loss: 0.00016 | RPN Regression loss: 0.00277 | Running loss: 0.05260\n","Epoch: 9 | Iteration: 34322 | Classification loss: 0.01789 | Regression loss: 0.02962 | Objectness loss: 0.00015 | RPN Regression loss: 0.00387 | Running loss: 0.05152\n","Epoch: 9 | Iteration: 34323 | Classification loss: 0.00773 | Regression loss: 0.01537 | Objectness loss: 0.00018 | RPN Regression loss: 0.00074 | Running loss: 0.02402\n","Epoch: 9 | Iteration: 34324 | Classification loss: 0.01922 | Regression loss: 0.03195 | Objectness loss: 0.00110 | RPN Regression loss: 0.00154 | Running loss: 0.05381\n","Epoch: 9 | Iteration: 34325 | Classification loss: 0.00935 | Regression loss: 0.02613 | Objectness loss: 0.00007 | RPN Regression loss: 0.00128 | Running loss: 0.03682\n","Epoch: 9 | Iteration: 34326 | Classification loss: 0.03094 | Regression loss: 0.03501 | Objectness loss: 0.00008 | RPN Regression loss: 0.00076 | Running loss: 0.06680\n","Epoch: 9 | Iteration: 34327 | Classification loss: 0.04027 | Regression loss: 0.05592 | Objectness loss: 0.00012 | RPN Regression loss: 0.00091 | Running loss: 0.09721\n","Epoch: 9 | Iteration: 34328 | Classification loss: 0.01513 | Regression loss: 0.02257 | Objectness loss: 0.00767 | RPN Regression loss: 0.00788 | Running loss: 0.05325\n","Epoch: 9 | Iteration: 34329 | Classification loss: 0.01332 | Regression loss: 0.02515 | Objectness loss: 0.00002 | RPN Regression loss: 0.00098 | Running loss: 0.03947\n","Epoch: 9 | Iteration: 34330 | Classification loss: 0.00742 | Regression loss: 0.01730 | Objectness loss: 0.00001 | RPN Regression loss: 0.00126 | Running loss: 0.02600\n","Epoch: 9 | Iteration: 34331 | Classification loss: 0.01147 | Regression loss: 0.02716 | Objectness loss: 0.00020 | RPN Regression loss: 0.00179 | Running loss: 0.04062\n","Epoch: 9 | Iteration: 34332 | Classification loss: 0.00707 | Regression loss: 0.01363 | Objectness loss: 0.00009 | RPN Regression loss: 0.00336 | Running loss: 0.02415\n","Epoch: 9 | Iteration: 34333 | Classification loss: 0.02882 | Regression loss: 0.01791 | Objectness loss: 0.00002 | RPN Regression loss: 0.00067 | Running loss: 0.04742\n","Epoch: 9 | Iteration: 34334 | Classification loss: 0.00980 | Regression loss: 0.01642 | Objectness loss: 0.00025 | RPN Regression loss: 0.00061 | Running loss: 0.02708\n","Epoch: 9 | Iteration: 34335 | Classification loss: 0.00732 | Regression loss: 0.01326 | Objectness loss: 0.00069 | RPN Regression loss: 0.00093 | Running loss: 0.02220\n","Epoch: 9 | Iteration: 34336 | Classification loss: 0.02581 | Regression loss: 0.01861 | Objectness loss: 0.00006 | RPN Regression loss: 0.00053 | Running loss: 0.04501\n","Epoch: 9 | Iteration: 34337 | Classification loss: 0.00722 | Regression loss: 0.02110 | Objectness loss: 0.00014 | RPN Regression loss: 0.00240 | Running loss: 0.03086\n","Epoch: 9 | Iteration: 34338 | Classification loss: 0.00715 | Regression loss: 0.02023 | Objectness loss: 0.00007 | RPN Regression loss: 0.00084 | Running loss: 0.02829\n","Epoch: 9 | Iteration: 34339 | Classification loss: 0.01348 | Regression loss: 0.02554 | Objectness loss: 0.00005 | RPN Regression loss: 0.00038 | Running loss: 0.03945\n","Epoch: 9 | Iteration: 34340 | Classification loss: 0.01378 | Regression loss: 0.03316 | Objectness loss: 0.00014 | RPN Regression loss: 0.00109 | Running loss: 0.04816\n","Epoch: 9 | Iteration: 34341 | Classification loss: 0.01917 | Regression loss: 0.03766 | Objectness loss: 0.00014 | RPN Regression loss: 0.00100 | Running loss: 0.05797\n","Epoch: 9 | Iteration: 34342 | Classification loss: 0.00737 | Regression loss: 0.03826 | Objectness loss: 0.00020 | RPN Regression loss: 0.00052 | Running loss: 0.04634\n","Epoch: 9 | Iteration: 34343 | Classification loss: 0.00893 | Regression loss: 0.02037 | Objectness loss: 0.00004 | RPN Regression loss: 0.00132 | Running loss: 0.03066\n","Epoch: 9 | Iteration: 34344 | Classification loss: 0.06985 | Regression loss: 0.04259 | Objectness loss: 0.01289 | RPN Regression loss: 0.00049 | Running loss: 0.12582\n","Epoch: 9 | Iteration: 34345 | Classification loss: 0.01344 | Regression loss: 0.01425 | Objectness loss: 0.00008 | RPN Regression loss: 0.00069 | Running loss: 0.02846\n","Epoch: 9 | Iteration: 34346 | Classification loss: 0.01107 | Regression loss: 0.02844 | Objectness loss: 0.00021 | RPN Regression loss: 0.00146 | Running loss: 0.04118\n","Epoch: 9 | Iteration: 34347 | Classification loss: 0.01869 | Regression loss: 0.01746 | Objectness loss: 0.00436 | RPN Regression loss: 0.00156 | Running loss: 0.04207\n","Epoch: 9 | Iteration: 34348 | Classification loss: 0.01281 | Regression loss: 0.03198 | Objectness loss: 0.00030 | RPN Regression loss: 0.00101 | Running loss: 0.04610\n","Epoch: 9 | Iteration: 34349 | Classification loss: 0.04708 | Regression loss: 0.02415 | Objectness loss: 0.01817 | RPN Regression loss: 0.00287 | Running loss: 0.09228\n","Epoch: 9 | Iteration: 34350 | Classification loss: 0.02864 | Regression loss: 0.02101 | Objectness loss: 0.00053 | RPN Regression loss: 0.00122 | Running loss: 0.05140\n","Epoch: 9 | Iteration: 34351 | Classification loss: 0.02338 | Regression loss: 0.03615 | Objectness loss: 0.00001 | RPN Regression loss: 0.00040 | Running loss: 0.05994\n","Epoch: 9 | Iteration: 34352 | Classification loss: 0.01412 | Regression loss: 0.01264 | Objectness loss: 0.00024 | RPN Regression loss: 0.00134 | Running loss: 0.02833\n","Epoch: 9 | Iteration: 34353 | Classification loss: 0.00881 | Regression loss: 0.02504 | Objectness loss: 0.00001 | RPN Regression loss: 0.00103 | Running loss: 0.03489\n","Epoch: 9 | Iteration: 34354 | Classification loss: 0.02552 | Regression loss: 0.02439 | Objectness loss: 0.00019 | RPN Regression loss: 0.00366 | Running loss: 0.05377\n","Epoch: 9 | Iteration: 34355 | Classification loss: 0.05933 | Regression loss: 0.05963 | Objectness loss: 0.00098 | RPN Regression loss: 0.00178 | Running loss: 0.12172\n","Epoch: 9 | Iteration: 34356 | Classification loss: 0.03324 | Regression loss: 0.03776 | Objectness loss: 0.00638 | RPN Regression loss: 0.00088 | Running loss: 0.07827\n","Epoch: 9 | Iteration: 34357 | Classification loss: 0.03253 | Regression loss: 0.03016 | Objectness loss: 0.00072 | RPN Regression loss: 0.00069 | Running loss: 0.06409\n","Epoch: 9 | Iteration: 34358 | Classification loss: 0.00905 | Regression loss: 0.01972 | Objectness loss: 0.00066 | RPN Regression loss: 0.00118 | Running loss: 0.03061\n","Epoch: 9 | Iteration: 34359 | Classification loss: 0.00810 | Regression loss: 0.01755 | Objectness loss: 0.00017 | RPN Regression loss: 0.00215 | Running loss: 0.02797\n","Epoch: 9 | Iteration: 34360 | Classification loss: 0.01701 | Regression loss: 0.02910 | Objectness loss: 0.00026 | RPN Regression loss: 0.00052 | Running loss: 0.04690\n","Epoch: 9 | Iteration: 34361 | Classification loss: 0.01272 | Regression loss: 0.02063 | Objectness loss: 0.00002 | RPN Regression loss: 0.00068 | Running loss: 0.03406\n","Epoch: 9 | Iteration: 34362 | Classification loss: 0.00950 | Regression loss: 0.00906 | Objectness loss: 0.00001 | RPN Regression loss: 0.00062 | Running loss: 0.01920\n","Epoch: 9 | Iteration: 34363 | Classification loss: 0.00657 | Regression loss: 0.02066 | Objectness loss: 0.00028 | RPN Regression loss: 0.00248 | Running loss: 0.02999\n","Epoch: 9 | Iteration: 34364 | Classification loss: 0.03059 | Regression loss: 0.03550 | Objectness loss: 0.08134 | RPN Regression loss: 0.02573 | Running loss: 0.17317\n","Epoch: 9 | Iteration: 34365 | Classification loss: 0.01378 | Regression loss: 0.02592 | Objectness loss: 0.00290 | RPN Regression loss: 0.00095 | Running loss: 0.04356\n","Epoch: 9 | Iteration: 34366 | Classification loss: 0.01890 | Regression loss: 0.03642 | Objectness loss: 0.00183 | RPN Regression loss: 0.00205 | Running loss: 0.05919\n","Epoch: 9 | Iteration: 34367 | Classification loss: 0.01996 | Regression loss: 0.01531 | Objectness loss: 0.00684 | RPN Regression loss: 0.00148 | Running loss: 0.04360\n","Epoch: 9 | Iteration: 34368 | Classification loss: 0.02043 | Regression loss: 0.01882 | Objectness loss: 0.00388 | RPN Regression loss: 0.00101 | Running loss: 0.04414\n","Epoch: 9 | Iteration: 34369 | Classification loss: 0.02390 | Regression loss: 0.01472 | Objectness loss: 0.00032 | RPN Regression loss: 0.00252 | Running loss: 0.04145\n","Epoch: 9 | Iteration: 34370 | Classification loss: 0.01082 | Regression loss: 0.01787 | Objectness loss: 0.00088 | RPN Regression loss: 0.00076 | Running loss: 0.03033\n","Epoch: 9 | Iteration: 34371 | Classification loss: 0.01335 | Regression loss: 0.02185 | Objectness loss: 0.00080 | RPN Regression loss: 0.00019 | Running loss: 0.03619\n","Epoch: 9 | Iteration: 34372 | Classification loss: 0.01794 | Regression loss: 0.02305 | Objectness loss: 0.00411 | RPN Regression loss: 0.00127 | Running loss: 0.04637\n","Epoch: 9 | Iteration: 34373 | Classification loss: 0.00925 | Regression loss: 0.01688 | Objectness loss: 0.00160 | RPN Regression loss: 0.00064 | Running loss: 0.02836\n","Epoch: 9 | Iteration: 34374 | Classification loss: 0.01392 | Regression loss: 0.02336 | Objectness loss: 0.00088 | RPN Regression loss: 0.00282 | Running loss: 0.04098\n","Epoch: 9 | Iteration: 34375 | Classification loss: 0.02088 | Regression loss: 0.02779 | Objectness loss: 0.00024 | RPN Regression loss: 0.00020 | Running loss: 0.04911\n","Epoch: 9 | Iteration: 34376 | Classification loss: 0.01480 | Regression loss: 0.01068 | Objectness loss: 0.00143 | RPN Regression loss: 0.00990 | Running loss: 0.03681\n","Epoch: 9 | Iteration: 34377 | Classification loss: 0.01238 | Regression loss: 0.01621 | Objectness loss: 0.00083 | RPN Regression loss: 0.00491 | Running loss: 0.03433\n","Epoch: 9 | Iteration: 34378 | Classification loss: 0.01251 | Regression loss: 0.02323 | Objectness loss: 0.00704 | RPN Regression loss: 0.00107 | Running loss: 0.04385\n","Epoch: 9 | Iteration: 34379 | Classification loss: 0.00922 | Regression loss: 0.01354 | Objectness loss: 0.00444 | RPN Regression loss: 0.00434 | Running loss: 0.03153\n","Epoch: 9 | Iteration: 34380 | Classification loss: 0.01645 | Regression loss: 0.02933 | Objectness loss: 0.00250 | RPN Regression loss: 0.00653 | Running loss: 0.05480\n","Epoch: 9 | Iteration: 34381 | Classification loss: 0.00529 | Regression loss: 0.01781 | Objectness loss: 0.00105 | RPN Regression loss: 0.00057 | Running loss: 0.02472\n","Epoch: 9 | Iteration: 34382 | Classification loss: 0.00639 | Regression loss: 0.01559 | Objectness loss: 0.00164 | RPN Regression loss: 0.00052 | Running loss: 0.02414\n","Epoch: 9 | Iteration: 34383 | Classification loss: 0.02061 | Regression loss: 0.02935 | Objectness loss: 0.00355 | RPN Regression loss: 0.00115 | Running loss: 0.05466\n","Epoch: 9 | Iteration: 34384 | Classification loss: 0.00617 | Regression loss: 0.01851 | Objectness loss: 0.00229 | RPN Regression loss: 0.00328 | Running loss: 0.03025\n","Epoch: 9 | Iteration: 34385 | Classification loss: 0.02168 | Regression loss: 0.03014 | Objectness loss: 0.00359 | RPN Regression loss: 0.00113 | Running loss: 0.05654\n","Epoch: 9 | Iteration: 34386 | Classification loss: 0.01963 | Regression loss: 0.03569 | Objectness loss: 0.00071 | RPN Regression loss: 0.00146 | Running loss: 0.05749\n","Epoch: 9 | Iteration: 34387 | Classification loss: 0.07761 | Regression loss: 0.03071 | Objectness loss: 0.00074 | RPN Regression loss: 0.00151 | Running loss: 0.11057\n","Epoch: 9 | Iteration: 34388 | Classification loss: 0.01358 | Regression loss: 0.02185 | Objectness loss: 0.00023 | RPN Regression loss: 0.00058 | Running loss: 0.03624\n","Epoch: 9 | Iteration: 34389 | Classification loss: 0.00670 | Regression loss: 0.01402 | Objectness loss: 0.00068 | RPN Regression loss: 0.00280 | Running loss: 0.02419\n","Epoch: 9 | Iteration: 34390 | Classification loss: 0.00990 | Regression loss: 0.03346 | Objectness loss: 0.00039 | RPN Regression loss: 0.00176 | Running loss: 0.04551\n","Epoch: 9 | Iteration: 34391 | Classification loss: 0.00908 | Regression loss: 0.01453 | Objectness loss: 0.00023 | RPN Regression loss: 0.00060 | Running loss: 0.02445\n","Epoch: 9 | Iteration: 34392 | Classification loss: 0.00700 | Regression loss: 0.00777 | Objectness loss: 0.00011 | RPN Regression loss: 0.00173 | Running loss: 0.01661\n","Epoch: 9 | Iteration: 34393 | Classification loss: 0.02887 | Regression loss: 0.03051 | Objectness loss: 0.00156 | RPN Regression loss: 0.00117 | Running loss: 0.06211\n","Epoch: 9 | Iteration: 34394 | Classification loss: 0.03952 | Regression loss: 0.04969 | Objectness loss: 0.00658 | RPN Regression loss: 0.00273 | Running loss: 0.09852\n","Epoch: 9 | Iteration: 34395 | Classification loss: 0.05903 | Regression loss: 0.03540 | Objectness loss: 0.03001 | RPN Regression loss: 0.00334 | Running loss: 0.12779\n","Epoch: 9 | Iteration: 34396 | Classification loss: 0.01713 | Regression loss: 0.02264 | Objectness loss: 0.00095 | RPN Regression loss: 0.00147 | Running loss: 0.04219\n","Epoch: 9 | Iteration: 34397 | Classification loss: 0.01090 | Regression loss: 0.01607 | Objectness loss: 0.00164 | RPN Regression loss: 0.00293 | Running loss: 0.03153\n","Epoch: 9 | Iteration: 34398 | Classification loss: 0.00947 | Regression loss: 0.01568 | Objectness loss: 0.00019 | RPN Regression loss: 0.00046 | Running loss: 0.02581\n","Epoch: 9 | Iteration: 34399 | Classification loss: 0.01779 | Regression loss: 0.02030 | Objectness loss: 0.00204 | RPN Regression loss: 0.00116 | Running loss: 0.04129\n","Epoch: 9 | Iteration: 34400 | Classification loss: 0.02476 | Regression loss: 0.03140 | Objectness loss: 0.00020 | RPN Regression loss: 0.00144 | Running loss: 0.05780\n","Epoch: 9 | Iteration: 34401 | Classification loss: 0.01697 | Regression loss: 0.04715 | Objectness loss: 0.00078 | RPN Regression loss: 0.00170 | Running loss: 0.06660\n","Epoch: 9 | Iteration: 34402 | Classification loss: 0.01955 | Regression loss: 0.01661 | Objectness loss: 0.00573 | RPN Regression loss: 0.00240 | Running loss: 0.04429\n","Epoch: 9 | Iteration: 34403 | Classification loss: 0.00620 | Regression loss: 0.01456 | Objectness loss: 0.00067 | RPN Regression loss: 0.00476 | Running loss: 0.02619\n","Epoch: 9 | Iteration: 34404 | Classification loss: 0.02292 | Regression loss: 0.02536 | Objectness loss: 0.00169 | RPN Regression loss: 0.00205 | Running loss: 0.05202\n","Epoch: 9 | Iteration: 34405 | Classification loss: 0.00776 | Regression loss: 0.01579 | Objectness loss: 0.00054 | RPN Regression loss: 0.00093 | Running loss: 0.02501\n","Epoch: 9 | Iteration: 34406 | Classification loss: 0.02199 | Regression loss: 0.01640 | Objectness loss: 0.00056 | RPN Regression loss: 0.00116 | Running loss: 0.04011\n","Epoch: 9 | Iteration: 34407 | Classification loss: 0.01743 | Regression loss: 0.03280 | Objectness loss: 0.00073 | RPN Regression loss: 0.00131 | Running loss: 0.05227\n","Epoch: 9 | Iteration: 34408 | Classification loss: 0.00956 | Regression loss: 0.03078 | Objectness loss: 0.00036 | RPN Regression loss: 0.00262 | Running loss: 0.04332\n","Epoch: 9 | Iteration: 34409 | Classification loss: 0.01275 | Regression loss: 0.02244 | Objectness loss: 0.00047 | RPN Regression loss: 0.00184 | Running loss: 0.03750\n","Epoch: 9 | Iteration: 34410 | Classification loss: 0.02149 | Regression loss: 0.01983 | Objectness loss: 0.00055 | RPN Regression loss: 0.00082 | Running loss: 0.04269\n","Epoch: 9 | Iteration: 34411 | Classification loss: 0.00688 | Regression loss: 0.01379 | Objectness loss: 0.00081 | RPN Regression loss: 0.00104 | Running loss: 0.02251\n","Epoch: 9 | Iteration: 34412 | Classification loss: 0.01727 | Regression loss: 0.01920 | Objectness loss: 0.00165 | RPN Regression loss: 0.00782 | Running loss: 0.04594\n","Epoch: 9 | Iteration: 34413 | Classification loss: 0.01250 | Regression loss: 0.02797 | Objectness loss: 0.00041 | RPN Regression loss: 0.00140 | Running loss: 0.04229\n","Epoch: 9 | Iteration: 34414 | Classification loss: 0.01886 | Regression loss: 0.03217 | Objectness loss: 0.00030 | RPN Regression loss: 0.00132 | Running loss: 0.05265\n","Epoch: 9 | Iteration: 34415 | Classification loss: 0.01180 | Regression loss: 0.02302 | Objectness loss: 0.00229 | RPN Regression loss: 0.00126 | Running loss: 0.03837\n","Epoch: 9 | Iteration: 34416 | Classification loss: 0.00802 | Regression loss: 0.01577 | Objectness loss: 0.00029 | RPN Regression loss: 0.00244 | Running loss: 0.02651\n","Epoch: 9 | Iteration: 34417 | Classification loss: 0.01001 | Regression loss: 0.02534 | Objectness loss: 0.00321 | RPN Regression loss: 0.00071 | Running loss: 0.03927\n","Epoch: 9 | Iteration: 34418 | Classification loss: 0.00854 | Regression loss: 0.01367 | Objectness loss: 0.00008 | RPN Regression loss: 0.00281 | Running loss: 0.02510\n","Epoch: 9 | Iteration: 34419 | Classification loss: 0.01353 | Regression loss: 0.02224 | Objectness loss: 0.00037 | RPN Regression loss: 0.00309 | Running loss: 0.03923\n","Epoch: 9 | Iteration: 34420 | Classification loss: 0.01618 | Regression loss: 0.02101 | Objectness loss: 0.00209 | RPN Regression loss: 0.00159 | Running loss: 0.04087\n","Epoch: 9 | Iteration: 34421 | Classification loss: 0.02739 | Regression loss: 0.03562 | Objectness loss: 0.00722 | RPN Regression loss: 0.00435 | Running loss: 0.07458\n","Epoch: 9 | Iteration: 34422 | Classification loss: 0.00813 | Regression loss: 0.02215 | Objectness loss: 0.00191 | RPN Regression loss: 0.00081 | Running loss: 0.03300\n","Epoch: 9 | Iteration: 34423 | Classification loss: 0.01550 | Regression loss: 0.04323 | Objectness loss: 0.00814 | RPN Regression loss: 0.00895 | Running loss: 0.07581\n","Epoch: 9 | Iteration: 34424 | Classification loss: 0.01215 | Regression loss: 0.01759 | Objectness loss: 0.00007 | RPN Regression loss: 0.00125 | Running loss: 0.03106\n","Epoch: 9 | Iteration: 34425 | Classification loss: 0.02145 | Regression loss: 0.01555 | Objectness loss: 0.00015 | RPN Regression loss: 0.00045 | Running loss: 0.03760\n","Epoch: 9 | Iteration: 34426 | Classification loss: 0.00960 | Regression loss: 0.01671 | Objectness loss: 0.00113 | RPN Regression loss: 0.00434 | Running loss: 0.03178\n","Epoch: 9 | Iteration: 34427 | Classification loss: 0.00809 | Regression loss: 0.01852 | Objectness loss: 0.00052 | RPN Regression loss: 0.00054 | Running loss: 0.02766\n","Epoch: 9 | Iteration: 34428 | Classification loss: 0.01438 | Regression loss: 0.02274 | Objectness loss: 0.00049 | RPN Regression loss: 0.00091 | Running loss: 0.03853\n","Epoch: 9 | Iteration: 34429 | Classification loss: 0.01775 | Regression loss: 0.02987 | Objectness loss: 0.00030 | RPN Regression loss: 0.00439 | Running loss: 0.05231\n","Epoch: 9 | Iteration: 34430 | Classification loss: 0.01515 | Regression loss: 0.02995 | Objectness loss: 0.00083 | RPN Regression loss: 0.00262 | Running loss: 0.04855\n","Epoch: 9 | Iteration: 34431 | Classification loss: 0.01130 | Regression loss: 0.01573 | Objectness loss: 0.00050 | RPN Regression loss: 0.00491 | Running loss: 0.03243\n","Epoch: 9 | Iteration: 34432 | Classification loss: 0.02670 | Regression loss: 0.04363 | Objectness loss: 0.00030 | RPN Regression loss: 0.00378 | Running loss: 0.07441\n","Epoch: 9 | Iteration: 34433 | Classification loss: 0.00700 | Regression loss: 0.01338 | Objectness loss: 0.00012 | RPN Regression loss: 0.00138 | Running loss: 0.02188\n","Epoch: 9 | Iteration: 34434 | Classification loss: 0.01796 | Regression loss: 0.01640 | Objectness loss: 0.00004 | RPN Regression loss: 0.00028 | Running loss: 0.03468\n","Epoch: 9 | Iteration: 34435 | Classification loss: 0.01003 | Regression loss: 0.02295 | Objectness loss: 0.00075 | RPN Regression loss: 0.00265 | Running loss: 0.03637\n","Epoch: 9 | Iteration: 34436 | Classification loss: 0.00849 | Regression loss: 0.01402 | Objectness loss: 0.00005 | RPN Regression loss: 0.00085 | Running loss: 0.02340\n","Epoch: 9 | Iteration: 34437 | Classification loss: 0.01599 | Regression loss: 0.03023 | Objectness loss: 0.00201 | RPN Regression loss: 0.00277 | Running loss: 0.05100\n","Epoch: 9 | Iteration: 34438 | Classification loss: 0.01057 | Regression loss: 0.02446 | Objectness loss: 0.00029 | RPN Regression loss: 0.00076 | Running loss: 0.03608\n","Epoch: 9 | Iteration: 34439 | Classification loss: 0.04979 | Regression loss: 0.04240 | Objectness loss: 0.00398 | RPN Regression loss: 0.00173 | Running loss: 0.09790\n","Epoch: 9 | Iteration: 34440 | Classification loss: 0.01329 | Regression loss: 0.01898 | Objectness loss: 0.00033 | RPN Regression loss: 0.00088 | Running loss: 0.03349\n","Epoch: 9 | Iteration: 34441 | Classification loss: 0.00498 | Regression loss: 0.02301 | Objectness loss: 0.00056 | RPN Regression loss: 0.00128 | Running loss: 0.02983\n","Epoch: 9 | Iteration: 34442 | Classification loss: 0.01667 | Regression loss: 0.02949 | Objectness loss: 0.00119 | RPN Regression loss: 0.00133 | Running loss: 0.04868\n","Epoch: 9 | Iteration: 34443 | Classification loss: 0.03006 | Regression loss: 0.01765 | Objectness loss: 0.00129 | RPN Regression loss: 0.00097 | Running loss: 0.04997\n","Epoch: 9 | Iteration: 34444 | Classification loss: 0.02647 | Regression loss: 0.04184 | Objectness loss: 0.00106 | RPN Regression loss: 0.00454 | Running loss: 0.07390\n","Epoch: 9 | Iteration: 34445 | Classification loss: 0.01370 | Regression loss: 0.01018 | Objectness loss: 0.00004 | RPN Regression loss: 0.00068 | Running loss: 0.02460\n","Epoch: 9 | Iteration: 34446 | Classification loss: 0.00886 | Regression loss: 0.02931 | Objectness loss: 0.00022 | RPN Regression loss: 0.00067 | Running loss: 0.03905\n","Epoch: 9 | Iteration: 34447 | Classification loss: 0.02209 | Regression loss: 0.01536 | Objectness loss: 0.00054 | RPN Regression loss: 0.00131 | Running loss: 0.03930\n","Epoch: 9 | Iteration: 34448 | Classification loss: 0.01502 | Regression loss: 0.02381 | Objectness loss: 0.00292 | RPN Regression loss: 0.00148 | Running loss: 0.04322\n","Epoch: 9 | Iteration: 34449 | Classification loss: 0.02276 | Regression loss: 0.01173 | Objectness loss: 0.00005 | RPN Regression loss: 0.00031 | Running loss: 0.03484\n","Epoch: 9 | Iteration: 34450 | Classification loss: 0.00823 | Regression loss: 0.01476 | Objectness loss: 0.00037 | RPN Regression loss: 0.00098 | Running loss: 0.02435\n","Epoch: 9 | Iteration: 34451 | Classification loss: 0.01833 | Regression loss: 0.02823 | Objectness loss: 0.00158 | RPN Regression loss: 0.00352 | Running loss: 0.05167\n","Epoch: 9 | Iteration: 34452 | Classification loss: 0.00882 | Regression loss: 0.02539 | Objectness loss: 0.00080 | RPN Regression loss: 0.00152 | Running loss: 0.03653\n","Epoch: 9 | Iteration: 34453 | Classification loss: 0.01587 | Regression loss: 0.03029 | Objectness loss: 0.00031 | RPN Regression loss: 0.00179 | Running loss: 0.04825\n","Epoch: 9 | Iteration: 34454 | Classification loss: 0.01123 | Regression loss: 0.01785 | Objectness loss: 0.00010 | RPN Regression loss: 0.00123 | Running loss: 0.03042\n","Epoch: 9 | Iteration: 34455 | Classification loss: 0.00931 | Regression loss: 0.02654 | Objectness loss: 0.00008 | RPN Regression loss: 0.00141 | Running loss: 0.03733\n","Epoch: 9 | Iteration: 34456 | Classification loss: 0.01135 | Regression loss: 0.01824 | Objectness loss: 0.00200 | RPN Regression loss: 0.00089 | Running loss: 0.03248\n","Epoch: 9 | Iteration: 34457 | Classification loss: 0.01724 | Regression loss: 0.02251 | Objectness loss: 0.00170 | RPN Regression loss: 0.00437 | Running loss: 0.04582\n","Epoch: 9 | Iteration: 34458 | Classification loss: 0.02002 | Regression loss: 0.02569 | Objectness loss: 0.00019 | RPN Regression loss: 0.00206 | Running loss: 0.04797\n","Epoch: 9 | Iteration: 34459 | Classification loss: 0.00823 | Regression loss: 0.01991 | Objectness loss: 0.00006 | RPN Regression loss: 0.00047 | Running loss: 0.02867\n","Epoch: 9 | Iteration: 34460 | Classification loss: 0.05173 | Regression loss: 0.02614 | Objectness loss: 0.00309 | RPN Regression loss: 0.00384 | Running loss: 0.08480\n","Epoch: 9 | Iteration: 34461 | Classification loss: 0.08040 | Regression loss: 0.04576 | Objectness loss: 0.00405 | RPN Regression loss: 0.00227 | Running loss: 0.13248\n","Epoch: 9 | Iteration: 34462 | Classification loss: 0.01904 | Regression loss: 0.01533 | Objectness loss: 0.00050 | RPN Regression loss: 0.00075 | Running loss: 0.03562\n","Epoch: 9 | Iteration: 34463 | Classification loss: 0.00701 | Regression loss: 0.01870 | Objectness loss: 0.00034 | RPN Regression loss: 0.00073 | Running loss: 0.02679\n","Epoch: 9 | Iteration: 34464 | Classification loss: 0.01021 | Regression loss: 0.01840 | Objectness loss: 0.00076 | RPN Regression loss: 0.00123 | Running loss: 0.03060\n","Epoch: 9 | Iteration: 34465 | Classification loss: 0.02888 | Regression loss: 0.03448 | Objectness loss: 0.00005 | RPN Regression loss: 0.00130 | Running loss: 0.06471\n","Epoch: 9 | Iteration: 34466 | Classification loss: 0.01107 | Regression loss: 0.01969 | Objectness loss: 0.00005 | RPN Regression loss: 0.00080 | Running loss: 0.03161\n","Epoch: 9 | Iteration: 34467 | Classification loss: 0.01617 | Regression loss: 0.02416 | Objectness loss: 0.00012 | RPN Regression loss: 0.00100 | Running loss: 0.04145\n","Epoch: 9 | Iteration: 34468 | Classification loss: 0.01287 | Regression loss: 0.02358 | Objectness loss: 0.00005 | RPN Regression loss: 0.00060 | Running loss: 0.03710\n","Epoch: 9 | Iteration: 34469 | Classification loss: 0.02758 | Regression loss: 0.01355 | Objectness loss: 0.00058 | RPN Regression loss: 0.00257 | Running loss: 0.04428\n","Epoch: 9 | Iteration: 34470 | Classification loss: 0.02530 | Regression loss: 0.03186 | Objectness loss: 0.00280 | RPN Regression loss: 0.00080 | Running loss: 0.06077\n","Epoch: 9 | Iteration: 34471 | Classification loss: 0.02859 | Regression loss: 0.01777 | Objectness loss: 0.00024 | RPN Regression loss: 0.00318 | Running loss: 0.04978\n","Epoch: 9 | Iteration: 34472 | Classification loss: 0.01186 | Regression loss: 0.02860 | Objectness loss: 0.00014 | RPN Regression loss: 0.00100 | Running loss: 0.04159\n","Epoch: 9 | Iteration: 34473 | Classification loss: 0.01816 | Regression loss: 0.01971 | Objectness loss: 0.00043 | RPN Regression loss: 0.01164 | Running loss: 0.04994\n","Epoch: 9 | Iteration: 34474 | Classification loss: 0.00942 | Regression loss: 0.02317 | Objectness loss: 0.00041 | RPN Regression loss: 0.00130 | Running loss: 0.03429\n","Epoch: 9 | Iteration: 34475 | Classification loss: 0.02590 | Regression loss: 0.04864 | Objectness loss: 0.00015 | RPN Regression loss: 0.00350 | Running loss: 0.07819\n","Epoch: 9 | Iteration: 34476 | Classification loss: 0.00792 | Regression loss: 0.01716 | Objectness loss: 0.00008 | RPN Regression loss: 0.00082 | Running loss: 0.02598\n","Epoch: 9 | Iteration: 34477 | Classification loss: 0.00806 | Regression loss: 0.01871 | Objectness loss: 0.00005 | RPN Regression loss: 0.00060 | Running loss: 0.02743\n","Epoch: 9 | Iteration: 34478 | Classification loss: 0.01353 | Regression loss: 0.02753 | Objectness loss: 0.00005 | RPN Regression loss: 0.00146 | Running loss: 0.04258\n","Epoch: 9 | Iteration: 34479 | Classification loss: 0.01677 | Regression loss: 0.01570 | Objectness loss: 0.00052 | RPN Regression loss: 0.00456 | Running loss: 0.03754\n","Epoch: 9 | Iteration: 34480 | Classification loss: 0.01102 | Regression loss: 0.01973 | Objectness loss: 0.00137 | RPN Regression loss: 0.00096 | Running loss: 0.03307\n","Epoch: 9 | Iteration: 34481 | Classification loss: 0.01222 | Regression loss: 0.03028 | Objectness loss: 0.00435 | RPN Regression loss: 0.00106 | Running loss: 0.04790\n","Epoch: 9 | Iteration: 34482 | Classification loss: 0.00907 | Regression loss: 0.01710 | Objectness loss: 0.00030 | RPN Regression loss: 0.00233 | Running loss: 0.02880\n","Epoch: 9 | Iteration: 34483 | Classification loss: 0.01880 | Regression loss: 0.02026 | Objectness loss: 0.00007 | RPN Regression loss: 0.00124 | Running loss: 0.04037\n","Epoch: 9 | Iteration: 34484 | Classification loss: 0.02619 | Regression loss: 0.03936 | Objectness loss: 0.00023 | RPN Regression loss: 0.00081 | Running loss: 0.06658\n","Epoch: 9 | Iteration: 34485 | Classification loss: 0.02017 | Regression loss: 0.01621 | Objectness loss: 0.00002 | RPN Regression loss: 0.00098 | Running loss: 0.03738\n","Epoch: 9 | Iteration: 34486 | Classification loss: 0.04207 | Regression loss: 0.01871 | Objectness loss: 0.00058 | RPN Regression loss: 0.00104 | Running loss: 0.06240\n","Epoch: 9 | Iteration: 34487 | Classification loss: 0.00823 | Regression loss: 0.01387 | Objectness loss: 0.00003 | RPN Regression loss: 0.00097 | Running loss: 0.02309\n","Epoch: 9 | Iteration: 34488 | Classification loss: 0.00931 | Regression loss: 0.01453 | Objectness loss: 0.00040 | RPN Regression loss: 0.00100 | Running loss: 0.02525\n","Epoch: 9 | Iteration: 34489 | Classification loss: 0.03743 | Regression loss: 0.03013 | Objectness loss: 0.00294 | RPN Regression loss: 0.00177 | Running loss: 0.07226\n","Epoch: 9 | Iteration: 34490 | Classification loss: 0.01739 | Regression loss: 0.01389 | Objectness loss: 0.00345 | RPN Regression loss: 0.00055 | Running loss: 0.03527\n","Epoch: 9 | Iteration: 34491 | Classification loss: 0.01348 | Regression loss: 0.01965 | Objectness loss: 0.00090 | RPN Regression loss: 0.00132 | Running loss: 0.03535\n","Epoch: 9 | Iteration: 34492 | Classification loss: 0.01238 | Regression loss: 0.02262 | Objectness loss: 0.00011 | RPN Regression loss: 0.00162 | Running loss: 0.03673\n","Epoch: 9 | Iteration: 34493 | Classification loss: 0.01903 | Regression loss: 0.01698 | Objectness loss: 0.00042 | RPN Regression loss: 0.00142 | Running loss: 0.03786\n","Epoch: 9 | Iteration: 34494 | Classification loss: 0.00797 | Regression loss: 0.01691 | Objectness loss: 0.00038 | RPN Regression loss: 0.00177 | Running loss: 0.02703\n","Epoch: 9 | Iteration: 34495 | Classification loss: 0.00759 | Regression loss: 0.01786 | Objectness loss: 0.00021 | RPN Regression loss: 0.00069 | Running loss: 0.02635\n","Epoch: 9 | Iteration: 34496 | Classification loss: 0.00609 | Regression loss: 0.01081 | Objectness loss: 0.00701 | RPN Regression loss: 0.00216 | Running loss: 0.02607\n","Epoch: 9 | Iteration: 34497 | Classification loss: 0.02114 | Regression loss: 0.01562 | Objectness loss: 0.00047 | RPN Regression loss: 0.00136 | Running loss: 0.03859\n","Epoch: 9 | Iteration: 34498 | Classification loss: 0.00872 | Regression loss: 0.02414 | Objectness loss: 0.00002 | RPN Regression loss: 0.00230 | Running loss: 0.03519\n","Epoch: 9 | Iteration: 34499 | Classification loss: 0.00637 | Regression loss: 0.01154 | Objectness loss: 0.00005 | RPN Regression loss: 0.00229 | Running loss: 0.02024\n","Epoch: 9 | Iteration: 34500 | Classification loss: 0.01970 | Regression loss: 0.01802 | Objectness loss: 0.00025 | RPN Regression loss: 0.00207 | Running loss: 0.04003\n","Epoch: 9 | Iteration: 34501 | Classification loss: 0.00557 | Regression loss: 0.01588 | Objectness loss: 0.00001 | RPN Regression loss: 0.00046 | Running loss: 0.02192\n","Epoch: 9 | Iteration: 34502 | Classification loss: 0.01003 | Regression loss: 0.01696 | Objectness loss: 0.00457 | RPN Regression loss: 0.00140 | Running loss: 0.03297\n","Epoch: 9 | Iteration: 34503 | Classification loss: 0.00660 | Regression loss: 0.01134 | Objectness loss: 0.00016 | RPN Regression loss: 0.00132 | Running loss: 0.01943\n","Epoch: 9 | Iteration: 34504 | Classification loss: 0.01170 | Regression loss: 0.01361 | Objectness loss: 0.00005 | RPN Regression loss: 0.00075 | Running loss: 0.02611\n","Epoch: 9 | Iteration: 34505 | Classification loss: 0.02109 | Regression loss: 0.03022 | Objectness loss: 0.00016 | RPN Regression loss: 0.00221 | Running loss: 0.05368\n","Epoch: 9 | Iteration: 34506 | Classification loss: 0.01782 | Regression loss: 0.01874 | Objectness loss: 0.00208 | RPN Regression loss: 0.00094 | Running loss: 0.03958\n","Epoch: 9 | Iteration: 34507 | Classification loss: 0.02581 | Regression loss: 0.03186 | Objectness loss: 0.00095 | RPN Regression loss: 0.00114 | Running loss: 0.05976\n","Epoch: 9 | Iteration: 34508 | Classification loss: 0.01122 | Regression loss: 0.02199 | Objectness loss: 0.00011 | RPN Regression loss: 0.00250 | Running loss: 0.03581\n","Epoch: 9 | Iteration: 34509 | Classification loss: 0.02698 | Regression loss: 0.02841 | Objectness loss: 0.00108 | RPN Regression loss: 0.00060 | Running loss: 0.05707\n","Epoch: 9 | Iteration: 34510 | Classification loss: 0.00427 | Regression loss: 0.01231 | Objectness loss: 0.00009 | RPN Regression loss: 0.00058 | Running loss: 0.01725\n","Epoch: 9 | Iteration: 34511 | Classification loss: 0.01612 | Regression loss: 0.01732 | Objectness loss: 0.00002 | RPN Regression loss: 0.00103 | Running loss: 0.03449\n","Epoch: 9 | Iteration: 34512 | Classification loss: 0.01063 | Regression loss: 0.02223 | Objectness loss: 0.00096 | RPN Regression loss: 0.00217 | Running loss: 0.03600\n","Epoch: 9 | Iteration: 34513 | Classification loss: 0.01321 | Regression loss: 0.03106 | Objectness loss: 0.00071 | RPN Regression loss: 0.00126 | Running loss: 0.04624\n","Epoch: 9 | Iteration: 34514 | Classification loss: 0.01921 | Regression loss: 0.03005 | Objectness loss: 0.00030 | RPN Regression loss: 0.00268 | Running loss: 0.05223\n","Epoch: 9 | Iteration: 34515 | Classification loss: 0.01310 | Regression loss: 0.02551 | Objectness loss: 0.00002 | RPN Regression loss: 0.00079 | Running loss: 0.03942\n","Epoch: 9 | Iteration: 34516 | Classification loss: 0.01482 | Regression loss: 0.02028 | Objectness loss: 0.00656 | RPN Regression loss: 0.00071 | Running loss: 0.04237\n","Epoch: 9 | Iteration: 34517 | Classification loss: 0.01249 | Regression loss: 0.02569 | Objectness loss: 0.00004 | RPN Regression loss: 0.00044 | Running loss: 0.03867\n","Epoch: 9 | Iteration: 34518 | Classification loss: 0.01285 | Regression loss: 0.02167 | Objectness loss: 0.00438 | RPN Regression loss: 0.00395 | Running loss: 0.04286\n","Epoch: 9 | Iteration: 34519 | Classification loss: 0.01794 | Regression loss: 0.01384 | Objectness loss: 0.00012 | RPN Regression loss: 0.00181 | Running loss: 0.03371\n","Epoch: 9 | Iteration: 34520 | Classification loss: 0.01276 | Regression loss: 0.01406 | Objectness loss: 0.00014 | RPN Regression loss: 0.00063 | Running loss: 0.02759\n","Epoch: 9 | Iteration: 34521 | Classification loss: 0.01070 | Regression loss: 0.03693 | Objectness loss: 0.00017 | RPN Regression loss: 0.00133 | Running loss: 0.04912\n","Epoch: 9 | Iteration: 34522 | Classification loss: 0.02653 | Regression loss: 0.01369 | Objectness loss: 0.00040 | RPN Regression loss: 0.00023 | Running loss: 0.04085\n","Epoch: 9 | Iteration: 34523 | Classification loss: 0.04756 | Regression loss: 0.03166 | Objectness loss: 0.00204 | RPN Regression loss: 0.00071 | Running loss: 0.08197\n","Epoch: 9 | Iteration: 34524 | Classification loss: 0.04047 | Regression loss: 0.04414 | Objectness loss: 0.00008 | RPN Regression loss: 0.00330 | Running loss: 0.08799\n","Epoch: 9 | Iteration: 34525 | Classification loss: 0.00830 | Regression loss: 0.03363 | Objectness loss: 0.00050 | RPN Regression loss: 0.00046 | Running loss: 0.04290\n","Epoch: 9 | Iteration: 34526 | Classification loss: 0.01493 | Regression loss: 0.02437 | Objectness loss: 0.00021 | RPN Regression loss: 0.00098 | Running loss: 0.04049\n","Epoch: 9 | Iteration: 34527 | Classification loss: 0.02961 | Regression loss: 0.02834 | Objectness loss: 0.00077 | RPN Regression loss: 0.00236 | Running loss: 0.06108\n","Epoch: 9 | Iteration: 34528 | Classification loss: 0.01657 | Regression loss: 0.02169 | Objectness loss: 0.00013 | RPN Regression loss: 0.00119 | Running loss: 0.03959\n","Epoch: 9 | Iteration: 34529 | Classification loss: 0.00798 | Regression loss: 0.01724 | Objectness loss: 0.00004 | RPN Regression loss: 0.00030 | Running loss: 0.02557\n","Epoch: 9 | Iteration: 34530 | Classification loss: 0.01608 | Regression loss: 0.03204 | Objectness loss: 0.00019 | RPN Regression loss: 0.00101 | Running loss: 0.04932\n","Epoch: 9 | Iteration: 34531 | Classification loss: 0.02645 | Regression loss: 0.02374 | Objectness loss: 0.00033 | RPN Regression loss: 0.00331 | Running loss: 0.05383\n","Epoch: 9 | Iteration: 34532 | Classification loss: 0.01435 | Regression loss: 0.03771 | Objectness loss: 0.00003 | RPN Regression loss: 0.00128 | Running loss: 0.05338\n","Epoch: 9 | Iteration: 34533 | Classification loss: 0.01697 | Regression loss: 0.01636 | Objectness loss: 0.00003 | RPN Regression loss: 0.00043 | Running loss: 0.03379\n","Epoch: 9 | Iteration: 34534 | Classification loss: 0.01645 | Regression loss: 0.01332 | Objectness loss: 0.00043 | RPN Regression loss: 0.00086 | Running loss: 0.03107\n","Epoch: 9 | Iteration: 34535 | Classification loss: 0.01093 | Regression loss: 0.01764 | Objectness loss: 0.00008 | RPN Regression loss: 0.00122 | Running loss: 0.02987\n","Epoch: 9 | Iteration: 34536 | Classification loss: 0.00833 | Regression loss: 0.02306 | Objectness loss: 0.00150 | RPN Regression loss: 0.00174 | Running loss: 0.03463\n","Epoch: 9 | Iteration: 34537 | Classification loss: 0.01761 | Regression loss: 0.02656 | Objectness loss: 0.00199 | RPN Regression loss: 0.00047 | Running loss: 0.04664\n","Epoch: 9 | Iteration: 34538 | Classification loss: 0.01848 | Regression loss: 0.02088 | Objectness loss: 0.00012 | RPN Regression loss: 0.00195 | Running loss: 0.04142\n","Epoch: 9 | Iteration: 34539 | Classification loss: 0.02155 | Regression loss: 0.01617 | Objectness loss: 0.00731 | RPN Regression loss: 0.00036 | Running loss: 0.04539\n","Epoch: 9 | Iteration: 34540 | Classification loss: 0.03603 | Regression loss: 0.04602 | Objectness loss: 0.00486 | RPN Regression loss: 0.00276 | Running loss: 0.08967\n","Epoch: 9 | Iteration: 34541 | Classification loss: 0.01094 | Regression loss: 0.01457 | Objectness loss: 0.00027 | RPN Regression loss: 0.00211 | Running loss: 0.02790\n","Epoch: 9 | Iteration: 34542 | Classification loss: 0.02385 | Regression loss: 0.03895 | Objectness loss: 0.00044 | RPN Regression loss: 0.00170 | Running loss: 0.06494\n","Epoch: 9 | Iteration: 34543 | Classification loss: 0.01403 | Regression loss: 0.02945 | Objectness loss: 0.00167 | RPN Regression loss: 0.00171 | Running loss: 0.04686\n","Epoch: 9 | Iteration: 34544 | Classification loss: 0.01323 | Regression loss: 0.02334 | Objectness loss: 0.00217 | RPN Regression loss: 0.00332 | Running loss: 0.04206\n","Epoch: 9 | Iteration: 34545 | Classification loss: 0.02163 | Regression loss: 0.04126 | Objectness loss: 0.00004 | RPN Regression loss: 0.00153 | Running loss: 0.06446\n","Epoch: 9 | Iteration: 34546 | Classification loss: 0.01374 | Regression loss: 0.04486 | Objectness loss: 0.00008 | RPN Regression loss: 0.00093 | Running loss: 0.05961\n","Epoch: 9 | Iteration: 34547 | Classification loss: 0.01300 | Regression loss: 0.02335 | Objectness loss: 0.00041 | RPN Regression loss: 0.00080 | Running loss: 0.03756\n","Epoch: 9 | Iteration: 34548 | Classification loss: 0.01537 | Regression loss: 0.01806 | Objectness loss: 0.00269 | RPN Regression loss: 0.00182 | Running loss: 0.03794\n","Epoch: 9 | Iteration: 34549 | Classification loss: 0.03066 | Regression loss: 0.03434 | Objectness loss: 0.00003 | RPN Regression loss: 0.00113 | Running loss: 0.06616\n","Epoch: 9 | Iteration: 34550 | Classification loss: 0.02294 | Regression loss: 0.01702 | Objectness loss: 0.00152 | RPN Regression loss: 0.00076 | Running loss: 0.04224\n","Epoch: 9 | Iteration: 34551 | Classification loss: 0.05183 | Regression loss: 0.02666 | Objectness loss: 0.01318 | RPN Regression loss: 0.00245 | Running loss: 0.09412\n","Epoch: 9 | Iteration: 34552 | Classification loss: 0.01372 | Regression loss: 0.03448 | Objectness loss: 0.00213 | RPN Regression loss: 0.00094 | Running loss: 0.05127\n","Epoch: 9 | Iteration: 34553 | Classification loss: 0.00802 | Regression loss: 0.02026 | Objectness loss: 0.00003 | RPN Regression loss: 0.00064 | Running loss: 0.02896\n","Epoch: 9 | Iteration: 34554 | Classification loss: 0.02095 | Regression loss: 0.03470 | Objectness loss: 0.00132 | RPN Regression loss: 0.00088 | Running loss: 0.05784\n","Epoch: 9 | Iteration: 34555 | Classification loss: 0.02576 | Regression loss: 0.03594 | Objectness loss: 0.00014 | RPN Regression loss: 0.00668 | Running loss: 0.06851\n","Epoch: 9 | Iteration: 34556 | Classification loss: 0.00817 | Regression loss: 0.01485 | Objectness loss: 0.00027 | RPN Regression loss: 0.00153 | Running loss: 0.02482\n","Epoch: 9 | Iteration: 34557 | Classification loss: 0.01810 | Regression loss: 0.02595 | Objectness loss: 0.00017 | RPN Regression loss: 0.00139 | Running loss: 0.04561\n","Epoch: 9 | Iteration: 34558 | Classification loss: 0.00932 | Regression loss: 0.02359 | Objectness loss: 0.00088 | RPN Regression loss: 0.01899 | Running loss: 0.05277\n","Epoch: 9 | Iteration: 34559 | Classification loss: 0.01608 | Regression loss: 0.01885 | Objectness loss: 0.00038 | RPN Regression loss: 0.00092 | Running loss: 0.03623\n","Epoch: 9 | Iteration: 34560 | Classification loss: 0.00928 | Regression loss: 0.01380 | Objectness loss: 0.00429 | RPN Regression loss: 0.00058 | Running loss: 0.02795\n","Epoch: 9 | Iteration: 34561 | Classification loss: 0.00749 | Regression loss: 0.01816 | Objectness loss: 0.00101 | RPN Regression loss: 0.00100 | Running loss: 0.02766\n","Epoch: 9 | Iteration: 34562 | Classification loss: 0.00905 | Regression loss: 0.02717 | Objectness loss: 0.00189 | RPN Regression loss: 0.00763 | Running loss: 0.04576\n","Epoch: 9 | Iteration: 34563 | Classification loss: 0.02339 | Regression loss: 0.02008 | Objectness loss: 0.00311 | RPN Regression loss: 0.00215 | Running loss: 0.04872\n","Epoch: 9 | Iteration: 34564 | Classification loss: 0.00993 | Regression loss: 0.02005 | Objectness loss: 0.00050 | RPN Regression loss: 0.00128 | Running loss: 0.03177\n","Epoch: 9 | Iteration: 34565 | Classification loss: 0.03388 | Regression loss: 0.03804 | Objectness loss: 0.00114 | RPN Regression loss: 0.00148 | Running loss: 0.07453\n","Epoch: 9 | Iteration: 34566 | Classification loss: 0.01709 | Regression loss: 0.01956 | Objectness loss: 0.00138 | RPN Regression loss: 0.00097 | Running loss: 0.03901\n","Epoch: 9 | Iteration: 34567 | Classification loss: 0.01768 | Regression loss: 0.01923 | Objectness loss: 0.00162 | RPN Regression loss: 0.00052 | Running loss: 0.03905\n","Epoch: 9 | Iteration: 34568 | Classification loss: 0.02677 | Regression loss: 0.03523 | Objectness loss: 0.00078 | RPN Regression loss: 0.00161 | Running loss: 0.06438\n","Epoch: 9 | Iteration: 34569 | Classification loss: 0.01962 | Regression loss: 0.03942 | Objectness loss: 0.00057 | RPN Regression loss: 0.00142 | Running loss: 0.06104\n","Epoch: 9 | Iteration: 34570 | Classification loss: 0.02561 | Regression loss: 0.01846 | Objectness loss: 0.00003 | RPN Regression loss: 0.00073 | Running loss: 0.04483\n","Epoch: 9 | Iteration: 34571 | Classification loss: 0.02542 | Regression loss: 0.02715 | Objectness loss: 0.00011 | RPN Regression loss: 0.00208 | Running loss: 0.05476\n","Epoch: 9 | Iteration: 34572 | Classification loss: 0.01263 | Regression loss: 0.03659 | Objectness loss: 0.00153 | RPN Regression loss: 0.00131 | Running loss: 0.05206\n","Epoch: 9 | Iteration: 34573 | Classification loss: 0.01170 | Regression loss: 0.02217 | Objectness loss: 0.00023 | RPN Regression loss: 0.00068 | Running loss: 0.03479\n","Epoch: 9 | Iteration: 34574 | Classification loss: 0.01184 | Regression loss: 0.01914 | Objectness loss: 0.00252 | RPN Regression loss: 0.00095 | Running loss: 0.03444\n","Epoch: 9 | Iteration: 34575 | Classification loss: 0.02364 | Regression loss: 0.02492 | Objectness loss: 0.00024 | RPN Regression loss: 0.00377 | Running loss: 0.05258\n","Epoch: 9 | Iteration: 34576 | Classification loss: 0.01895 | Regression loss: 0.02950 | Objectness loss: 0.00004 | RPN Regression loss: 0.00137 | Running loss: 0.04986\n","Epoch: 9 | Iteration: 34577 | Classification loss: 0.01124 | Regression loss: 0.02035 | Objectness loss: 0.00003 | RPN Regression loss: 0.00128 | Running loss: 0.03291\n","Epoch: 9 | Iteration: 34578 | Classification loss: 0.01924 | Regression loss: 0.03266 | Objectness loss: 0.00035 | RPN Regression loss: 0.00100 | Running loss: 0.05324\n","Epoch: 9 | Iteration: 34579 | Classification loss: 0.01787 | Regression loss: 0.01713 | Objectness loss: 0.00001 | RPN Regression loss: 0.00069 | Running loss: 0.03570\n","Epoch: 9 | Iteration: 34580 | Classification loss: 0.01054 | Regression loss: 0.02194 | Objectness loss: 0.00061 | RPN Regression loss: 0.00095 | Running loss: 0.03404\n","Epoch: 9 | Iteration: 34581 | Classification loss: 0.03404 | Regression loss: 0.05013 | Objectness loss: 0.00170 | RPN Regression loss: 0.00066 | Running loss: 0.08652\n","Epoch: 9 | Iteration: 34582 | Classification loss: 0.01225 | Regression loss: 0.02144 | Objectness loss: 0.00013 | RPN Regression loss: 0.00071 | Running loss: 0.03454\n","Epoch: 9 | Iteration: 34583 | Classification loss: 0.01493 | Regression loss: 0.02068 | Objectness loss: 0.00002 | RPN Regression loss: 0.00184 | Running loss: 0.03747\n","Epoch: 9 | Iteration: 34584 | Classification loss: 0.01779 | Regression loss: 0.02546 | Objectness loss: 0.00021 | RPN Regression loss: 0.00180 | Running loss: 0.04526\n","Epoch: 9 | Iteration: 34585 | Classification loss: 0.02333 | Regression loss: 0.04604 | Objectness loss: 0.00403 | RPN Regression loss: 0.00191 | Running loss: 0.07530\n","Epoch: 9 | Iteration: 34586 | Classification loss: 0.02202 | Regression loss: 0.02666 | Objectness loss: 0.00003 | RPN Regression loss: 0.00072 | Running loss: 0.04943\n","Epoch: 9 | Iteration: 34587 | Classification loss: 0.02026 | Regression loss: 0.01842 | Objectness loss: 0.00041 | RPN Regression loss: 0.00130 | Running loss: 0.04040\n","Epoch: 9 | Iteration: 34588 | Classification loss: 0.01312 | Regression loss: 0.03929 | Objectness loss: 0.00035 | RPN Regression loss: 0.00147 | Running loss: 0.05424\n","Epoch: 9 | Iteration: 34589 | Classification loss: 0.02531 | Regression loss: 0.03735 | Objectness loss: 0.00087 | RPN Regression loss: 0.00125 | Running loss: 0.06477\n","Epoch: 9 | Iteration: 34590 | Classification loss: 0.01373 | Regression loss: 0.01324 | Objectness loss: 0.00041 | RPN Regression loss: 0.00106 | Running loss: 0.02844\n","Epoch: 9 | Iteration: 34591 | Classification loss: 0.03134 | Regression loss: 0.02899 | Objectness loss: 0.00022 | RPN Regression loss: 0.00168 | Running loss: 0.06224\n","Epoch: 9 | Iteration: 34592 | Classification loss: 0.00555 | Regression loss: 0.01968 | Objectness loss: 0.00003 | RPN Regression loss: 0.00128 | Running loss: 0.02654\n","Epoch: 9 | Iteration: 34593 | Classification loss: 0.02270 | Regression loss: 0.01726 | Objectness loss: 0.00018 | RPN Regression loss: 0.00084 | Running loss: 0.04099\n","Epoch: 9 | Iteration: 34594 | Classification loss: 0.00760 | Regression loss: 0.02001 | Objectness loss: 0.00032 | RPN Regression loss: 0.00092 | Running loss: 0.02886\n","Epoch: 9 | Iteration: 34595 | Classification loss: 0.02739 | Regression loss: 0.03819 | Objectness loss: 0.00156 | RPN Regression loss: 0.00171 | Running loss: 0.06885\n","Epoch: 9 | Iteration: 34596 | Classification loss: 0.02361 | Regression loss: 0.02589 | Objectness loss: 0.00438 | RPN Regression loss: 0.00044 | Running loss: 0.05432\n","Epoch: 9 | Iteration: 34597 | Classification loss: 0.00950 | Regression loss: 0.01906 | Objectness loss: 0.00016 | RPN Regression loss: 0.00178 | Running loss: 0.03051\n","Epoch: 9 | Iteration: 34598 | Classification loss: 0.00769 | Regression loss: 0.01835 | Objectness loss: 0.00143 | RPN Regression loss: 0.01064 | Running loss: 0.03812\n","Epoch: 9 | Iteration: 34599 | Classification loss: 0.01891 | Regression loss: 0.03205 | Objectness loss: 0.00365 | RPN Regression loss: 0.02194 | Running loss: 0.07656\n","Epoch: 9 | Iteration: 34600 | Classification loss: 0.01946 | Regression loss: 0.02433 | Objectness loss: 0.00365 | RPN Regression loss: 0.00159 | Running loss: 0.04903\n","Epoch: 9 | Iteration: 34601 | Classification loss: 0.01386 | Regression loss: 0.02256 | Objectness loss: 0.00410 | RPN Regression loss: 0.00178 | Running loss: 0.04229\n","Epoch: 9 | Iteration: 34602 | Classification loss: 0.00926 | Regression loss: 0.01697 | Objectness loss: 0.00005 | RPN Regression loss: 0.00104 | Running loss: 0.02733\n","Epoch: 9 | Iteration: 34603 | Classification loss: 0.00888 | Regression loss: 0.02478 | Objectness loss: 0.00030 | RPN Regression loss: 0.00188 | Running loss: 0.03584\n","Epoch: 9 | Iteration: 34604 | Classification loss: 0.02905 | Regression loss: 0.03546 | Objectness loss: 0.00055 | RPN Regression loss: 0.00053 | Running loss: 0.06559\n","Epoch: 9 | Iteration: 34605 | Classification loss: 0.01294 | Regression loss: 0.01831 | Objectness loss: 0.00008 | RPN Regression loss: 0.00076 | Running loss: 0.03209\n","Epoch: 9 | Iteration: 34606 | Classification loss: 0.01385 | Regression loss: 0.03438 | Objectness loss: 0.00050 | RPN Regression loss: 0.00134 | Running loss: 0.05006\n","Epoch: 9 | Iteration: 34607 | Classification loss: 0.01051 | Regression loss: 0.01637 | Objectness loss: 0.00001 | RPN Regression loss: 0.00101 | Running loss: 0.02790\n","Epoch: 9 | Iteration: 34608 | Classification loss: 0.00989 | Regression loss: 0.03243 | Objectness loss: 0.00006 | RPN Regression loss: 0.00072 | Running loss: 0.04310\n","Epoch: 9 | Iteration: 34609 | Classification loss: 0.01863 | Regression loss: 0.01802 | Objectness loss: 0.00015 | RPN Regression loss: 0.00134 | Running loss: 0.03814\n","Epoch: 9 | Iteration: 34610 | Classification loss: 0.02556 | Regression loss: 0.02319 | Objectness loss: 0.00292 | RPN Regression loss: 0.00108 | Running loss: 0.05274\n","Epoch: 9 | Iteration: 34611 | Classification loss: 0.02365 | Regression loss: 0.01483 | Objectness loss: 0.00677 | RPN Regression loss: 0.00051 | Running loss: 0.04576\n","Epoch: 9 | Iteration: 34612 | Classification loss: 0.01381 | Regression loss: 0.03538 | Objectness loss: 0.00002 | RPN Regression loss: 0.00186 | Running loss: 0.05107\n","Epoch: 9 | Iteration: 34613 | Classification loss: 0.02386 | Regression loss: 0.02924 | Objectness loss: 0.00224 | RPN Regression loss: 0.00130 | Running loss: 0.05664\n","Epoch: 9 | Iteration: 34614 | Classification loss: 0.00484 | Regression loss: 0.01105 | Objectness loss: 0.00001 | RPN Regression loss: 0.00154 | Running loss: 0.01744\n","Epoch: 9 | Iteration: 34615 | Classification loss: 0.01901 | Regression loss: 0.02427 | Objectness loss: 0.00012 | RPN Regression loss: 0.00280 | Running loss: 0.04620\n","Epoch: 9 | Iteration: 34616 | Classification loss: 0.00597 | Regression loss: 0.02938 | Objectness loss: 0.00023 | RPN Regression loss: 0.00151 | Running loss: 0.03709\n","Epoch: 9 | Iteration: 34617 | Classification loss: 0.00721 | Regression loss: 0.01115 | Objectness loss: 0.00001 | RPN Regression loss: 0.00098 | Running loss: 0.01935\n","Epoch: 9 | Iteration: 34618 | Classification loss: 0.00607 | Regression loss: 0.02731 | Objectness loss: 0.00016 | RPN Regression loss: 0.00099 | Running loss: 0.03453\n","Epoch: 9 | Iteration: 34619 | Classification loss: 0.02910 | Regression loss: 0.01742 | Objectness loss: 0.00009 | RPN Regression loss: 0.00256 | Running loss: 0.04916\n","Epoch: 9 | Iteration: 34620 | Classification loss: 0.00836 | Regression loss: 0.01369 | Objectness loss: 0.00023 | RPN Regression loss: 0.00159 | Running loss: 0.02386\n","Epoch: 9 | Iteration: 34621 | Classification loss: 0.01597 | Regression loss: 0.03812 | Objectness loss: 0.00011 | RPN Regression loss: 0.00149 | Running loss: 0.05568\n","Epoch: 9 | Iteration: 34622 | Classification loss: 0.01014 | Regression loss: 0.02939 | Objectness loss: 0.00080 | RPN Regression loss: 0.00064 | Running loss: 0.04096\n","Epoch: 9 | Iteration: 34623 | Classification loss: 0.00422 | Regression loss: 0.00993 | Objectness loss: 0.00004 | RPN Regression loss: 0.00050 | Running loss: 0.01469\n","Epoch: 9 | Iteration: 34624 | Classification loss: 0.01306 | Regression loss: 0.02681 | Objectness loss: 0.00052 | RPN Regression loss: 0.00545 | Running loss: 0.04584\n","Epoch: 9 | Iteration: 34625 | Classification loss: 0.01352 | Regression loss: 0.03020 | Objectness loss: 0.00008 | RPN Regression loss: 0.00117 | Running loss: 0.04497\n","Epoch: 9 | Iteration: 34626 | Classification loss: 0.01004 | Regression loss: 0.02036 | Objectness loss: 0.00003 | RPN Regression loss: 0.00101 | Running loss: 0.03144\n","Epoch: 9 | Iteration: 34627 | Classification loss: 0.03889 | Regression loss: 0.03588 | Objectness loss: 0.00747 | RPN Regression loss: 0.00293 | Running loss: 0.08517\n","Epoch: 9 | Iteration: 34628 | Classification loss: 0.01792 | Regression loss: 0.02371 | Objectness loss: 0.00096 | RPN Regression loss: 0.00183 | Running loss: 0.04442\n","Epoch: 9 | Iteration: 34629 | Classification loss: 0.02485 | Regression loss: 0.02037 | Objectness loss: 0.00001 | RPN Regression loss: 0.00038 | Running loss: 0.04561\n","Epoch: 9 | Iteration: 34630 | Classification loss: 0.01182 | Regression loss: 0.02213 | Objectness loss: 0.00017 | RPN Regression loss: 0.00330 | Running loss: 0.03743\n","Epoch: 9 | Iteration: 34631 | Classification loss: 0.02494 | Regression loss: 0.02269 | Objectness loss: 0.00003 | RPN Regression loss: 0.00227 | Running loss: 0.04993\n","Epoch: 9 | Iteration: 34632 | Classification loss: 0.03870 | Regression loss: 0.02726 | Objectness loss: 0.00043 | RPN Regression loss: 0.00194 | Running loss: 0.06833\n","Epoch: 9 | Iteration: 34633 | Classification loss: 0.02127 | Regression loss: 0.02276 | Objectness loss: 0.00026 | RPN Regression loss: 0.00078 | Running loss: 0.04507\n","Epoch: 9 | Iteration: 34634 | Classification loss: 0.02262 | Regression loss: 0.03383 | Objectness loss: 0.00316 | RPN Regression loss: 0.00138 | Running loss: 0.06099\n","Epoch: 9 | Iteration: 34635 | Classification loss: 0.02194 | Regression loss: 0.01987 | Objectness loss: 0.00138 | RPN Regression loss: 0.00109 | Running loss: 0.04428\n","Epoch: 9 | Iteration: 34636 | Classification loss: 0.02238 | Regression loss: 0.02943 | Objectness loss: 0.00003 | RPN Regression loss: 0.00087 | Running loss: 0.05271\n","Epoch: 9 | Iteration: 34637 | Classification loss: 0.02043 | Regression loss: 0.01770 | Objectness loss: 0.00009 | RPN Regression loss: 0.00054 | Running loss: 0.03875\n","Epoch: 9 | Iteration: 34638 | Classification loss: 0.02573 | Regression loss: 0.02173 | Objectness loss: 0.00006 | RPN Regression loss: 0.00090 | Running loss: 0.04841\n","Epoch: 9 | Iteration: 34639 | Classification loss: 0.01094 | Regression loss: 0.00896 | Objectness loss: 0.00012 | RPN Regression loss: 0.00213 | Running loss: 0.02215\n","Epoch: 9 | Iteration: 34640 | Classification loss: 0.00900 | Regression loss: 0.01923 | Objectness loss: 0.00016 | RPN Regression loss: 0.00298 | Running loss: 0.03137\n","Epoch: 9 | Iteration: 34641 | Classification loss: 0.02613 | Regression loss: 0.02971 | Objectness loss: 0.00067 | RPN Regression loss: 0.08601 | Running loss: 0.14251\n","Epoch: 9 | Iteration: 34642 | Classification loss: 0.01852 | Regression loss: 0.01921 | Objectness loss: 0.00248 | RPN Regression loss: 0.00215 | Running loss: 0.04237\n","Epoch: 9 | Iteration: 34643 | Classification loss: 0.01046 | Regression loss: 0.01808 | Objectness loss: 0.00003 | RPN Regression loss: 0.00121 | Running loss: 0.02979\n","Epoch: 9 | Iteration: 34644 | Classification loss: 0.02398 | Regression loss: 0.02009 | Objectness loss: 0.00007 | RPN Regression loss: 0.00086 | Running loss: 0.04501\n","Epoch: 9 | Iteration: 34645 | Classification loss: 0.01395 | Regression loss: 0.01775 | Objectness loss: 0.00261 | RPN Regression loss: 0.00077 | Running loss: 0.03507\n","Epoch: 9 | Iteration: 34646 | Classification loss: 0.01237 | Regression loss: 0.01150 | Objectness loss: 0.00003 | RPN Regression loss: 0.00074 | Running loss: 0.02464\n","Epoch: 9 | Iteration: 34647 | Classification loss: 0.02002 | Regression loss: 0.02086 | Objectness loss: 0.00065 | RPN Regression loss: 0.00052 | Running loss: 0.04205\n","Epoch: 9 | Iteration: 34648 | Classification loss: 0.01797 | Regression loss: 0.02445 | Objectness loss: 0.00100 | RPN Regression loss: 0.00472 | Running loss: 0.04814\n","Epoch: 9 | Iteration: 34649 | Classification loss: 0.00789 | Regression loss: 0.01936 | Objectness loss: 0.00029 | RPN Regression loss: 0.00171 | Running loss: 0.02926\n","Epoch: 9 | Iteration: 34650 | Classification loss: 0.01044 | Regression loss: 0.00939 | Objectness loss: 0.00002 | RPN Regression loss: 0.00063 | Running loss: 0.02047\n","Epoch: 9 | Iteration: 34651 | Classification loss: 0.01677 | Regression loss: 0.03031 | Objectness loss: 0.00031 | RPN Regression loss: 0.00154 | Running loss: 0.04893\n","Epoch: 9 | Iteration: 34652 | Classification loss: 0.01687 | Regression loss: 0.01489 | Objectness loss: 0.00037 | RPN Regression loss: 0.00548 | Running loss: 0.03760\n","Epoch: 9 | Iteration: 34653 | Classification loss: 0.01537 | Regression loss: 0.04436 | Objectness loss: 0.00016 | RPN Regression loss: 0.00102 | Running loss: 0.06091\n","Epoch: 9 | Iteration: 34654 | Classification loss: 0.01645 | Regression loss: 0.01229 | Objectness loss: 0.00013 | RPN Regression loss: 0.00046 | Running loss: 0.02933\n","Epoch: 9 | Iteration: 34655 | Classification loss: 0.00791 | Regression loss: 0.01450 | Objectness loss: 0.00015 | RPN Regression loss: 0.00055 | Running loss: 0.02310\n","Epoch: 9 | Iteration: 34656 | Classification loss: 0.00727 | Regression loss: 0.02138 | Objectness loss: 0.00006 | RPN Regression loss: 0.00045 | Running loss: 0.02916\n","Epoch: 9 | Iteration: 34657 | Classification loss: 0.01086 | Regression loss: 0.03932 | Objectness loss: 0.00021 | RPN Regression loss: 0.00055 | Running loss: 0.05094\n","Epoch: 9 | Iteration: 34658 | Classification loss: 0.00470 | Regression loss: 0.01355 | Objectness loss: 0.00007 | RPN Regression loss: 0.00086 | Running loss: 0.01916\n","Epoch: 9 | Iteration: 34659 | Classification loss: 0.00944 | Regression loss: 0.01019 | Objectness loss: 0.00029 | RPN Regression loss: 0.00223 | Running loss: 0.02214\n","Epoch: 9 | Iteration: 34660 | Classification loss: 0.02447 | Regression loss: 0.02575 | Objectness loss: 0.00005 | RPN Regression loss: 0.00070 | Running loss: 0.05097\n","Epoch: 9 | Iteration: 34661 | Classification loss: 0.00529 | Regression loss: 0.00939 | Objectness loss: 0.00001 | RPN Regression loss: 0.00102 | Running loss: 0.01571\n","Epoch: 9 | Iteration: 34662 | Classification loss: 0.01773 | Regression loss: 0.02409 | Objectness loss: 0.00011 | RPN Regression loss: 0.00042 | Running loss: 0.04235\n","Epoch: 9 | Iteration: 34663 | Classification loss: 0.00658 | Regression loss: 0.01693 | Objectness loss: 0.00048 | RPN Regression loss: 0.00129 | Running loss: 0.02528\n","Epoch: 9 | Iteration: 34664 | Classification loss: 0.03096 | Regression loss: 0.04535 | Objectness loss: 0.00146 | RPN Regression loss: 0.00267 | Running loss: 0.08044\n","Epoch: 9 | Iteration: 34665 | Classification loss: 0.00573 | Regression loss: 0.01773 | Objectness loss: 0.00020 | RPN Regression loss: 0.00097 | Running loss: 0.02463\n","Epoch: 9 | Iteration: 34666 | Classification loss: 0.01083 | Regression loss: 0.01859 | Objectness loss: 0.00340 | RPN Regression loss: 0.00167 | Running loss: 0.03449\n","Epoch: 9 | Iteration: 34667 | Classification loss: 0.03012 | Regression loss: 0.01201 | Objectness loss: 0.00023 | RPN Regression loss: 0.00070 | Running loss: 0.04306\n","Epoch: 9 | Iteration: 34668 | Classification loss: 0.00909 | Regression loss: 0.01896 | Objectness loss: 0.00007 | RPN Regression loss: 0.00446 | Running loss: 0.03259\n","Epoch: 9 | Iteration: 34669 | Classification loss: 0.00637 | Regression loss: 0.01535 | Objectness loss: 0.00042 | RPN Regression loss: 0.00098 | Running loss: 0.02312\n","Epoch: 9 | Iteration: 34670 | Classification loss: 0.03141 | Regression loss: 0.03590 | Objectness loss: 0.00211 | RPN Regression loss: 0.00136 | Running loss: 0.07077\n","Epoch: 9 | Iteration: 34671 | Classification loss: 0.01258 | Regression loss: 0.01521 | Objectness loss: 0.00324 | RPN Regression loss: 0.00219 | Running loss: 0.03321\n","Epoch: 9 | Iteration: 34672 | Classification loss: 0.01762 | Regression loss: 0.02383 | Objectness loss: 0.00070 | RPN Regression loss: 0.00088 | Running loss: 0.04303\n","Epoch: 9 | Iteration: 34673 | Classification loss: 0.01062 | Regression loss: 0.03038 | Objectness loss: 0.00057 | RPN Regression loss: 0.00130 | Running loss: 0.04288\n","Epoch: 9 | Iteration: 34674 | Classification loss: 0.01082 | Regression loss: 0.02511 | Objectness loss: 0.00571 | RPN Regression loss: 0.00131 | Running loss: 0.04295\n","Epoch: 9 | Iteration: 34675 | Classification loss: 0.00951 | Regression loss: 0.03057 | Objectness loss: 0.00005 | RPN Regression loss: 0.00037 | Running loss: 0.04049\n","Epoch: 9 | Iteration: 34676 | Classification loss: 0.00641 | Regression loss: 0.03317 | Objectness loss: 0.00015 | RPN Regression loss: 0.00378 | Running loss: 0.04351\n","Epoch: 9 | Iteration: 34677 | Classification loss: 0.01679 | Regression loss: 0.01991 | Objectness loss: 0.00001 | RPN Regression loss: 0.00082 | Running loss: 0.03754\n","Epoch: 9 | Iteration: 34678 | Classification loss: 0.01749 | Regression loss: 0.01437 | Objectness loss: 0.00098 | RPN Regression loss: 0.00091 | Running loss: 0.03375\n","Epoch: 9 | Iteration: 34679 | Classification loss: 0.01461 | Regression loss: 0.01473 | Objectness loss: 0.00001 | RPN Regression loss: 0.00058 | Running loss: 0.02993\n","Epoch: 9 | Iteration: 34680 | Classification loss: 0.01917 | Regression loss: 0.03141 | Objectness loss: 0.00246 | RPN Regression loss: 0.00051 | Running loss: 0.05355\n","Epoch: 9 | Iteration: 34681 | Classification loss: 0.03830 | Regression loss: 0.04728 | Objectness loss: 0.00577 | RPN Regression loss: 0.00290 | Running loss: 0.09424\n","Epoch: 9 | Iteration: 34682 | Classification loss: 0.00954 | Regression loss: 0.02139 | Objectness loss: 0.00067 | RPN Regression loss: 0.00096 | Running loss: 0.03255\n","Epoch: 9 | Iteration: 34683 | Classification loss: 0.11639 | Regression loss: 0.03192 | Objectness loss: 0.00499 | RPN Regression loss: 0.00137 | Running loss: 0.15468\n","Epoch: 9 | Iteration: 34684 | Classification loss: 0.01990 | Regression loss: 0.02794 | Objectness loss: 0.00075 | RPN Regression loss: 0.00282 | Running loss: 0.05141\n","Epoch: 9 | Iteration: 34685 | Classification loss: 0.00850 | Regression loss: 0.02368 | Objectness loss: 0.00086 | RPN Regression loss: 0.00125 | Running loss: 0.03430\n","Epoch: 9 | Iteration: 34686 | Classification loss: 0.01672 | Regression loss: 0.02480 | Objectness loss: 0.00004 | RPN Regression loss: 0.00099 | Running loss: 0.04255\n","Epoch: 9 | Iteration: 34687 | Classification loss: 0.01195 | Regression loss: 0.01903 | Objectness loss: 0.00114 | RPN Regression loss: 0.00326 | Running loss: 0.03538\n","Epoch: 9 | Iteration: 34688 | Classification loss: 0.01282 | Regression loss: 0.02084 | Objectness loss: 0.00034 | RPN Regression loss: 0.00153 | Running loss: 0.03552\n","Epoch: 9 | Iteration: 34689 | Classification loss: 0.01332 | Regression loss: 0.01914 | Objectness loss: 0.00441 | RPN Regression loss: 0.00144 | Running loss: 0.03830\n","Epoch: 9 | Iteration: 34690 | Classification loss: 0.00633 | Regression loss: 0.01372 | Objectness loss: 0.00040 | RPN Regression loss: 0.00108 | Running loss: 0.02154\n","Epoch: 9 | Iteration: 34691 | Classification loss: 0.00781 | Regression loss: 0.01340 | Objectness loss: 0.00016 | RPN Regression loss: 0.00052 | Running loss: 0.02190\n","Epoch: 9 | Iteration: 34692 | Classification loss: 0.01799 | Regression loss: 0.01847 | Objectness loss: 0.00337 | RPN Regression loss: 0.00323 | Running loss: 0.04306\n","Epoch: 9 | Iteration: 34693 | Classification loss: 0.00927 | Regression loss: 0.01235 | Objectness loss: 0.00003 | RPN Regression loss: 0.00065 | Running loss: 0.02230\n","Epoch: 9 | Iteration: 34694 | Classification loss: 0.01372 | Regression loss: 0.02347 | Objectness loss: 0.00253 | RPN Regression loss: 0.00076 | Running loss: 0.04047\n","Epoch: 9 | Iteration: 34695 | Classification loss: 0.01674 | Regression loss: 0.02823 | Objectness loss: 0.00091 | RPN Regression loss: 0.00129 | Running loss: 0.04717\n","Epoch: 9 | Iteration: 34696 | Classification loss: 0.01574 | Regression loss: 0.02142 | Objectness loss: 0.00102 | RPN Regression loss: 0.00168 | Running loss: 0.03986\n","Epoch: 9 | Iteration: 34697 | Classification loss: 0.00719 | Regression loss: 0.01144 | Objectness loss: 0.00001 | RPN Regression loss: 0.00040 | Running loss: 0.01903\n","Epoch: 9 | Iteration: 34698 | Classification loss: 0.04025 | Regression loss: 0.05126 | Objectness loss: 0.00127 | RPN Regression loss: 0.00153 | Running loss: 0.09432\n","Epoch: 9 | Iteration: 34699 | Classification loss: 0.02981 | Regression loss: 0.02863 | Objectness loss: 0.00004 | RPN Regression loss: 0.00106 | Running loss: 0.05954\n","Epoch: 9 | Iteration: 34700 | Classification loss: 0.02183 | Regression loss: 0.01918 | Objectness loss: 0.00039 | RPN Regression loss: 0.00909 | Running loss: 0.05049\n","Epoch: 9 | Iteration: 34701 | Classification loss: 0.02457 | Regression loss: 0.01305 | Objectness loss: 0.00408 | RPN Regression loss: 0.00022 | Running loss: 0.04192\n","Epoch: 9 | Iteration: 34702 | Classification loss: 0.01683 | Regression loss: 0.02056 | Objectness loss: 0.00040 | RPN Regression loss: 0.00128 | Running loss: 0.03906\n","Epoch: 9 | Iteration: 34703 | Classification loss: 0.02279 | Regression loss: 0.01636 | Objectness loss: 0.00014 | RPN Regression loss: 0.00073 | Running loss: 0.04001\n","Epoch: 9 | Iteration: 34704 | Classification loss: 0.00829 | Regression loss: 0.01255 | Objectness loss: 0.00009 | RPN Regression loss: 0.00184 | Running loss: 0.02276\n","Epoch: 9 | Iteration: 34705 | Classification loss: 0.03017 | Regression loss: 0.02496 | Objectness loss: 0.00331 | RPN Regression loss: 0.00088 | Running loss: 0.05932\n","Epoch: 9 | Iteration: 34706 | Classification loss: 0.00737 | Regression loss: 0.01352 | Objectness loss: 0.00009 | RPN Regression loss: 0.00171 | Running loss: 0.02269\n","Epoch: 9 | Iteration: 34707 | Classification loss: 0.02211 | Regression loss: 0.01706 | Objectness loss: 0.00019 | RPN Regression loss: 0.00034 | Running loss: 0.03969\n","Epoch: 9 | Iteration: 34708 | Classification loss: 0.01951 | Regression loss: 0.02695 | Objectness loss: 0.00114 | RPN Regression loss: 0.00060 | Running loss: 0.04820\n","Epoch: 9 | Iteration: 34709 | Classification loss: 0.01963 | Regression loss: 0.02825 | Objectness loss: 0.00023 | RPN Regression loss: 0.00126 | Running loss: 0.04936\n","Epoch: 9 | Iteration: 34710 | Classification loss: 0.01186 | Regression loss: 0.01882 | Objectness loss: 0.00044 | RPN Regression loss: 0.00089 | Running loss: 0.03200\n","Epoch: 9 | Iteration: 34711 | Classification loss: 0.03077 | Regression loss: 0.01856 | Objectness loss: 0.00040 | RPN Regression loss: 0.00324 | Running loss: 0.05297\n","Epoch: 9 | Iteration: 34712 | Classification loss: 0.02469 | Regression loss: 0.03259 | Objectness loss: 0.00014 | RPN Regression loss: 0.00318 | Running loss: 0.06059\n","Epoch: 9 | Iteration: 34713 | Classification loss: 0.04588 | Regression loss: 0.05403 | Objectness loss: 0.00754 | RPN Regression loss: 0.00149 | Running loss: 0.10894\n","Epoch: 9 | Iteration: 34714 | Classification loss: 0.02383 | Regression loss: 0.02287 | Objectness loss: 0.00032 | RPN Regression loss: 0.00264 | Running loss: 0.04966\n","Epoch: 9 | Iteration: 34715 | Classification loss: 0.04737 | Regression loss: 0.03673 | Objectness loss: 0.00859 | RPN Regression loss: 0.00091 | Running loss: 0.09359\n","Epoch: 9 | Iteration: 34716 | Classification loss: 0.00840 | Regression loss: 0.02866 | Objectness loss: 0.00131 | RPN Regression loss: 0.00122 | Running loss: 0.03959\n","Epoch: 9 | Iteration: 34717 | Classification loss: 0.01023 | Regression loss: 0.01731 | Objectness loss: 0.00103 | RPN Regression loss: 0.00078 | Running loss: 0.02935\n","Epoch: 9 | Iteration: 34718 | Classification loss: 0.01157 | Regression loss: 0.01381 | Objectness loss: 0.00003 | RPN Regression loss: 0.00041 | Running loss: 0.02581\n","Epoch: 9 | Iteration: 34719 | Classification loss: 0.01849 | Regression loss: 0.01932 | Objectness loss: 0.00089 | RPN Regression loss: 0.00066 | Running loss: 0.03936\n","Epoch: 9 | Iteration: 34720 | Classification loss: 0.03275 | Regression loss: 0.03064 | Objectness loss: 0.00043 | RPN Regression loss: 0.00062 | Running loss: 0.06444\n","Epoch: 9 | Iteration: 34721 | Classification loss: 0.03455 | Regression loss: 0.03511 | Objectness loss: 0.00560 | RPN Regression loss: 0.00151 | Running loss: 0.07677\n","Epoch: 9 | Iteration: 34722 | Classification loss: 0.03037 | Regression loss: 0.02268 | Objectness loss: 0.00005 | RPN Regression loss: 0.00073 | Running loss: 0.05384\n","Epoch: 9 | Iteration: 34723 | Classification loss: 0.01013 | Regression loss: 0.02564 | Objectness loss: 0.00123 | RPN Regression loss: 0.00142 | Running loss: 0.03842\n","Epoch: 9 | Iteration: 34724 | Classification loss: 0.02226 | Regression loss: 0.03636 | Objectness loss: 0.00018 | RPN Regression loss: 0.00279 | Running loss: 0.06159\n","Epoch: 9 | Iteration: 34725 | Classification loss: 0.02547 | Regression loss: 0.02185 | Objectness loss: 0.00011 | RPN Regression loss: 0.00104 | Running loss: 0.04847\n","Epoch: 9 | Iteration: 34726 | Classification loss: 0.02226 | Regression loss: 0.05045 | Objectness loss: 0.00018 | RPN Regression loss: 0.00480 | Running loss: 0.07769\n","Epoch: 9 | Iteration: 34727 | Classification loss: 0.01694 | Regression loss: 0.01284 | Objectness loss: 0.00020 | RPN Regression loss: 0.00114 | Running loss: 0.03112\n","Epoch: 9 | Iteration: 34728 | Classification loss: 0.02990 | Regression loss: 0.03559 | Objectness loss: 0.00217 | RPN Regression loss: 0.00136 | Running loss: 0.06903\n","Epoch: 9 | Iteration: 34729 | Classification loss: 0.01339 | Regression loss: 0.02443 | Objectness loss: 0.00025 | RPN Regression loss: 0.00212 | Running loss: 0.04019\n","Epoch: 9 | Iteration: 34730 | Classification loss: 0.01664 | Regression loss: 0.03281 | Objectness loss: 0.00001 | RPN Regression loss: 0.00099 | Running loss: 0.05046\n","Epoch: 9 | Iteration: 34731 | Classification loss: 0.01330 | Regression loss: 0.01281 | Objectness loss: 0.00009 | RPN Regression loss: 0.00291 | Running loss: 0.02910\n","Epoch: 9 | Iteration: 34732 | Classification loss: 0.01060 | Regression loss: 0.02461 | Objectness loss: 0.00004 | RPN Regression loss: 0.00093 | Running loss: 0.03618\n","Epoch: 9 | Iteration: 34733 | Classification loss: 0.02163 | Regression loss: 0.02536 | Objectness loss: 0.00104 | RPN Regression loss: 0.00358 | Running loss: 0.05161\n","Epoch: 9 | Iteration: 34734 | Classification loss: 0.02723 | Regression loss: 0.03055 | Objectness loss: 0.00024 | RPN Regression loss: 0.00100 | Running loss: 0.05901\n","Epoch: 9 | Iteration: 34735 | Classification loss: 0.02896 | Regression loss: 0.02775 | Objectness loss: 0.00029 | RPN Regression loss: 0.00265 | Running loss: 0.05965\n","Epoch: 9 | Iteration: 34736 | Classification loss: 0.02822 | Regression loss: 0.04369 | Objectness loss: 0.00558 | RPN Regression loss: 0.00060 | Running loss: 0.07809\n","Epoch: 9 | Iteration: 34737 | Classification loss: 0.01071 | Regression loss: 0.01835 | Objectness loss: 0.00060 | RPN Regression loss: 0.00181 | Running loss: 0.03146\n","Epoch: 9 | Iteration: 34738 | Classification loss: 0.00697 | Regression loss: 0.01263 | Objectness loss: 0.00118 | RPN Regression loss: 0.00160 | Running loss: 0.02238\n","Epoch: 9 | Iteration: 34739 | Classification loss: 0.00918 | Regression loss: 0.01117 | Objectness loss: 0.00007 | RPN Regression loss: 0.00079 | Running loss: 0.02121\n","Epoch: 9 | Iteration: 34740 | Classification loss: 0.02171 | Regression loss: 0.01442 | Objectness loss: 0.00051 | RPN Regression loss: 0.00079 | Running loss: 0.03743\n","Epoch: 9 | Iteration: 34741 | Classification loss: 0.03357 | Regression loss: 0.04927 | Objectness loss: 0.00289 | RPN Regression loss: 0.00170 | Running loss: 0.08744\n","Epoch: 9 | Iteration: 34742 | Classification loss: 0.01320 | Regression loss: 0.02782 | Objectness loss: 0.00007 | RPN Regression loss: 0.00119 | Running loss: 0.04227\n","Epoch: 9 | Iteration: 34743 | Classification loss: 0.00769 | Regression loss: 0.01268 | Objectness loss: 0.00074 | RPN Regression loss: 0.00059 | Running loss: 0.02171\n","Epoch: 9 | Iteration: 34744 | Classification loss: 0.01987 | Regression loss: 0.03673 | Objectness loss: 0.00211 | RPN Regression loss: 0.00316 | Running loss: 0.06187\n","Epoch: 9 | Iteration: 34745 | Classification loss: 0.00673 | Regression loss: 0.01209 | Objectness loss: 0.00001 | RPN Regression loss: 0.00097 | Running loss: 0.01979\n","Epoch: 9 | Iteration: 34746 | Classification loss: 0.01164 | Regression loss: 0.02632 | Objectness loss: 0.00014 | RPN Regression loss: 0.00111 | Running loss: 0.03922\n","Epoch: 9 | Iteration: 34747 | Classification loss: 0.01040 | Regression loss: 0.02260 | Objectness loss: 0.07247 | RPN Regression loss: 0.02724 | Running loss: 0.13271\n","Epoch: 9 | Iteration: 34748 | Classification loss: 0.00871 | Regression loss: 0.01293 | Objectness loss: 0.00075 | RPN Regression loss: 0.00501 | Running loss: 0.02740\n","Epoch: 9 | Iteration: 34749 | Classification loss: 0.03377 | Regression loss: 0.03005 | Objectness loss: 0.00120 | RPN Regression loss: 0.00117 | Running loss: 0.06620\n","Epoch: 9 | Iteration: 34750 | Classification loss: 0.01059 | Regression loss: 0.02691 | Objectness loss: 0.00011 | RPN Regression loss: 0.00052 | Running loss: 0.03814\n","Epoch: 9 | Iteration: 34751 | Classification loss: 0.03458 | Regression loss: 0.03099 | Objectness loss: 0.00124 | RPN Regression loss: 0.00073 | Running loss: 0.06753\n","Epoch: 9 | Iteration: 34752 | Classification loss: 0.00962 | Regression loss: 0.01143 | Objectness loss: 0.00019 | RPN Regression loss: 0.00119 | Running loss: 0.02242\n","Epoch: 9 | Iteration: 34753 | Classification loss: 0.00972 | Regression loss: 0.01964 | Objectness loss: 0.00042 | RPN Regression loss: 0.00414 | Running loss: 0.03393\n","Epoch: 9 | Iteration: 34754 | Classification loss: 0.01818 | Regression loss: 0.02545 | Objectness loss: 0.00067 | RPN Regression loss: 0.00287 | Running loss: 0.04716\n","Epoch: 9 | Iteration: 34755 | Classification loss: 0.04416 | Regression loss: 0.04852 | Objectness loss: 0.00021 | RPN Regression loss: 0.00075 | Running loss: 0.09364\n","Epoch: 9 | Iteration: 34756 | Classification loss: 0.01135 | Regression loss: 0.02641 | Objectness loss: 0.00061 | RPN Regression loss: 0.00114 | Running loss: 0.03951\n","Epoch: 9 | Iteration: 34757 | Classification loss: 0.01312 | Regression loss: 0.03023 | Objectness loss: 0.00068 | RPN Regression loss: 0.00106 | Running loss: 0.04510\n","Epoch: 9 | Iteration: 34758 | Classification loss: 0.01331 | Regression loss: 0.01781 | Objectness loss: 0.00027 | RPN Regression loss: 0.00081 | Running loss: 0.03220\n","Epoch: 9 | Iteration: 34759 | Classification loss: 0.01534 | Regression loss: 0.01565 | Objectness loss: 0.00016 | RPN Regression loss: 0.00074 | Running loss: 0.03189\n","Epoch: 9 | Iteration: 34760 | Classification loss: 0.00868 | Regression loss: 0.02571 | Objectness loss: 0.00023 | RPN Regression loss: 0.00057 | Running loss: 0.03519\n","Epoch: 9 | Iteration: 34761 | Classification loss: 0.02032 | Regression loss: 0.01650 | Objectness loss: 0.00002 | RPN Regression loss: 0.00132 | Running loss: 0.03815\n","Epoch: 9 | Iteration: 34762 | Classification loss: 0.01950 | Regression loss: 0.04166 | Objectness loss: 0.00004 | RPN Regression loss: 0.00070 | Running loss: 0.06191\n","Epoch: 9 | Iteration: 34763 | Classification loss: 0.04515 | Regression loss: 0.03454 | Objectness loss: 0.00587 | RPN Regression loss: 0.00144 | Running loss: 0.08700\n","Epoch: 9 | Iteration: 34764 | Classification loss: 0.01474 | Regression loss: 0.02344 | Objectness loss: 0.00024 | RPN Regression loss: 0.00170 | Running loss: 0.04013\n","Epoch: 9 | Iteration: 34765 | Classification loss: 0.01403 | Regression loss: 0.02052 | Objectness loss: 0.00031 | RPN Regression loss: 0.00053 | Running loss: 0.03539\n","Epoch: 9 | Iteration: 34766 | Classification loss: 0.01991 | Regression loss: 0.04347 | Objectness loss: 0.00069 | RPN Regression loss: 0.00117 | Running loss: 0.06524\n","Epoch: 9 | Iteration: 34767 | Classification loss: 0.01151 | Regression loss: 0.03081 | Objectness loss: 0.00044 | RPN Regression loss: 0.00074 | Running loss: 0.04350\n","Epoch: 9 | Iteration: 34768 | Classification loss: 0.02350 | Regression loss: 0.02259 | Objectness loss: 0.00280 | RPN Regression loss: 0.01624 | Running loss: 0.06512\n","Epoch: 9 | Iteration: 34769 | Classification loss: 0.06001 | Regression loss: 0.04542 | Objectness loss: 0.00243 | RPN Regression loss: 0.00075 | Running loss: 0.10860\n","Epoch: 9 | Iteration: 34770 | Classification loss: 0.00999 | Regression loss: 0.00984 | Objectness loss: 0.00091 | RPN Regression loss: 0.00129 | Running loss: 0.02203\n","Epoch: 9 | Iteration: 34771 | Classification loss: 0.03079 | Regression loss: 0.04442 | Objectness loss: 0.00038 | RPN Regression loss: 0.00067 | Running loss: 0.07626\n","Epoch: 9 | Iteration: 34772 | Classification loss: 0.00914 | Regression loss: 0.01372 | Objectness loss: 0.00326 | RPN Regression loss: 0.00060 | Running loss: 0.02672\n","Epoch: 9 | Iteration: 34773 | Classification loss: 0.01636 | Regression loss: 0.01493 | Objectness loss: 0.00178 | RPN Regression loss: 0.00110 | Running loss: 0.03417\n","Epoch: 9 | Iteration: 34774 | Classification loss: 0.00882 | Regression loss: 0.01490 | Objectness loss: 0.00089 | RPN Regression loss: 0.00234 | Running loss: 0.02695\n","Epoch: 9 | Iteration: 34775 | Classification loss: 0.02232 | Regression loss: 0.01829 | Objectness loss: 0.00009 | RPN Regression loss: 0.00224 | Running loss: 0.04294\n","Epoch: 9 | Iteration: 34776 | Classification loss: 0.01419 | Regression loss: 0.03082 | Objectness loss: 0.00039 | RPN Regression loss: 0.00077 | Running loss: 0.04618\n","Epoch: 9 | Iteration: 34777 | Classification loss: 0.01086 | Regression loss: 0.01462 | Objectness loss: 0.00023 | RPN Regression loss: 0.00177 | Running loss: 0.02748\n","Epoch: 9 | Iteration: 34778 | Classification loss: 0.01838 | Regression loss: 0.01992 | Objectness loss: 0.00459 | RPN Regression loss: 0.01262 | Running loss: 0.05551\n","Epoch: 9 | Iteration: 34779 | Classification loss: 0.02393 | Regression loss: 0.01901 | Objectness loss: 0.00085 | RPN Regression loss: 0.00187 | Running loss: 0.04566\n","Epoch: 9 | Iteration: 34780 | Classification loss: 0.01251 | Regression loss: 0.01959 | Objectness loss: 0.00028 | RPN Regression loss: 0.00125 | Running loss: 0.03362\n","Epoch: 9 | Iteration: 34781 | Classification loss: 0.01758 | Regression loss: 0.03468 | Objectness loss: 0.00082 | RPN Regression loss: 0.00232 | Running loss: 0.05540\n","Epoch: 9 | Iteration: 34782 | Classification loss: 0.01789 | Regression loss: 0.02667 | Objectness loss: 0.00111 | RPN Regression loss: 0.00123 | Running loss: 0.04690\n","Epoch: 9 | Iteration: 34783 | Classification loss: 0.02919 | Regression loss: 0.02764 | Objectness loss: 0.00028 | RPN Regression loss: 0.00364 | Running loss: 0.06075\n","Epoch: 9 | Iteration: 34784 | Classification loss: 0.01483 | Regression loss: 0.02241 | Objectness loss: 0.00096 | RPN Regression loss: 0.00100 | Running loss: 0.03920\n","Epoch: 9 | Iteration: 34785 | Classification loss: 0.02315 | Regression loss: 0.03582 | Objectness loss: 0.00192 | RPN Regression loss: 0.00200 | Running loss: 0.06289\n","Epoch: 9 | Iteration: 34786 | Classification loss: 0.02088 | Regression loss: 0.02129 | Objectness loss: 0.00921 | RPN Regression loss: 0.00190 | Running loss: 0.05327\n","Epoch: 9 | Iteration: 34787 | Classification loss: 0.00916 | Regression loss: 0.02101 | Objectness loss: 0.00001 | RPN Regression loss: 0.00078 | Running loss: 0.03095\n","Epoch: 9 | Iteration: 34788 | Classification loss: 0.01223 | Regression loss: 0.02564 | Objectness loss: 0.00748 | RPN Regression loss: 0.00279 | Running loss: 0.04814\n","Epoch: 9 | Iteration: 34789 | Classification loss: 0.01043 | Regression loss: 0.01651 | Objectness loss: 0.00007 | RPN Regression loss: 0.00071 | Running loss: 0.02772\n","Epoch: 9 | Iteration: 34790 | Classification loss: 0.01717 | Regression loss: 0.01836 | Objectness loss: 0.00008 | RPN Regression loss: 0.00052 | Running loss: 0.03613\n","Epoch: 9 | Iteration: 34791 | Classification loss: 0.00744 | Regression loss: 0.02885 | Objectness loss: 0.00018 | RPN Regression loss: 0.00104 | Running loss: 0.03751\n","Epoch: 9 | Iteration: 34792 | Classification loss: 0.01056 | Regression loss: 0.03121 | Objectness loss: 0.00004 | RPN Regression loss: 0.00188 | Running loss: 0.04368\n","Epoch: 9 | Iteration: 34793 | Classification loss: 0.02852 | Regression loss: 0.03831 | Objectness loss: 0.00014 | RPN Regression loss: 0.00140 | Running loss: 0.06836\n","Epoch: 9 | Iteration: 34794 | Classification loss: 0.01132 | Regression loss: 0.02467 | Objectness loss: 0.00008 | RPN Regression loss: 0.00151 | Running loss: 0.03757\n","Epoch: 9 | Iteration: 34795 | Classification loss: 0.02080 | Regression loss: 0.03111 | Objectness loss: 0.00070 | RPN Regression loss: 0.00254 | Running loss: 0.05515\n","Epoch: 9 | Iteration: 34796 | Classification loss: 0.01764 | Regression loss: 0.02366 | Objectness loss: 0.00089 | RPN Regression loss: 0.00049 | Running loss: 0.04267\n","Epoch: 9 | Iteration: 34797 | Classification loss: 0.01746 | Regression loss: 0.01678 | Objectness loss: 0.00536 | RPN Regression loss: 0.00318 | Running loss: 0.04279\n","Epoch: 9 | Iteration: 34798 | Classification loss: 0.00815 | Regression loss: 0.01015 | Objectness loss: 0.00007 | RPN Regression loss: 0.00151 | Running loss: 0.01987\n","Epoch: 9 | Iteration: 34799 | Classification loss: 0.02835 | Regression loss: 0.03081 | Objectness loss: 0.00011 | RPN Regression loss: 0.00192 | Running loss: 0.06118\n","Epoch: 9 | Iteration: 34800 | Classification loss: 0.01091 | Regression loss: 0.01472 | Objectness loss: 0.00016 | RPN Regression loss: 0.00055 | Running loss: 0.02635\n","Epoch: 9 | Iteration: 34801 | Classification loss: 0.02143 | Regression loss: 0.04253 | Objectness loss: 0.00014 | RPN Regression loss: 0.00289 | Running loss: 0.06700\n","Epoch: 9 | Iteration: 34802 | Classification loss: 0.01074 | Regression loss: 0.02975 | Objectness loss: 0.00003 | RPN Regression loss: 0.00045 | Running loss: 0.04097\n","Epoch: 9 | Iteration: 34803 | Classification loss: 0.02709 | Regression loss: 0.02104 | Objectness loss: 0.00009 | RPN Regression loss: 0.00113 | Running loss: 0.04937\n","Epoch: 9 | Iteration: 34804 | Classification loss: 0.00886 | Regression loss: 0.01674 | Objectness loss: 0.00028 | RPN Regression loss: 0.00124 | Running loss: 0.02713\n","Epoch: 9 | Iteration: 34805 | Classification loss: 0.01663 | Regression loss: 0.01813 | Objectness loss: 0.00015 | RPN Regression loss: 0.00099 | Running loss: 0.03590\n","Epoch: 9 | Iteration: 34806 | Classification loss: 0.02141 | Regression loss: 0.01925 | Objectness loss: 0.00015 | RPN Regression loss: 0.00145 | Running loss: 0.04226\n","Epoch: 9 | Iteration: 34807 | Classification loss: 0.00863 | Regression loss: 0.01854 | Objectness loss: 0.00014 | RPN Regression loss: 0.00109 | Running loss: 0.02840\n","Epoch: 9 | Iteration: 34808 | Classification loss: 0.01346 | Regression loss: 0.02691 | Objectness loss: 0.00125 | RPN Regression loss: 0.00182 | Running loss: 0.04344\n","Epoch: 9 | Iteration: 34809 | Classification loss: 0.01450 | Regression loss: 0.02232 | Objectness loss: 0.00041 | RPN Regression loss: 0.00083 | Running loss: 0.03806\n","Epoch: 9 | Iteration: 34810 | Classification loss: 0.02347 | Regression loss: 0.02556 | Objectness loss: 0.01096 | RPN Regression loss: 0.00105 | Running loss: 0.06103\n","Epoch: 9 | Iteration: 34811 | Classification loss: 0.01415 | Regression loss: 0.01565 | Objectness loss: 0.00007 | RPN Regression loss: 0.00028 | Running loss: 0.03014\n","Epoch: 9 | Iteration: 34812 | Classification loss: 0.03108 | Regression loss: 0.02962 | Objectness loss: 0.00100 | RPN Regression loss: 0.00169 | Running loss: 0.06339\n","Epoch: 9 | Iteration: 34813 | Classification loss: 0.01087 | Regression loss: 0.01716 | Objectness loss: 0.00002 | RPN Regression loss: 0.00051 | Running loss: 0.02857\n","Epoch: 9 | Iteration: 34814 | Classification loss: 0.01243 | Regression loss: 0.01355 | Objectness loss: 0.00302 | RPN Regression loss: 0.00132 | Running loss: 0.03032\n","Epoch: 9 | Iteration: 34815 | Classification loss: 0.01194 | Regression loss: 0.02638 | Objectness loss: 0.00002 | RPN Regression loss: 0.00103 | Running loss: 0.03937\n","Epoch: 9 | Iteration: 34816 | Classification loss: 0.01704 | Regression loss: 0.02147 | Objectness loss: 0.00017 | RPN Regression loss: 0.00080 | Running loss: 0.03948\n","Epoch: 9 | Iteration: 34817 | Classification loss: 0.01246 | Regression loss: 0.02463 | Objectness loss: 0.00018 | RPN Regression loss: 0.00067 | Running loss: 0.03795\n","Epoch: 9 | Iteration: 34818 | Classification loss: 0.01673 | Regression loss: 0.03451 | Objectness loss: 0.00025 | RPN Regression loss: 0.00175 | Running loss: 0.05324\n","Epoch: 9 | Iteration: 34819 | Classification loss: 0.01398 | Regression loss: 0.03141 | Objectness loss: 0.00007 | RPN Regression loss: 0.00137 | Running loss: 0.04684\n","Epoch: 9 | Iteration: 34820 | Classification loss: 0.02502 | Regression loss: 0.02766 | Objectness loss: 0.00042 | RPN Regression loss: 0.00240 | Running loss: 0.05550\n","Epoch: 9 | Iteration: 34821 | Classification loss: 0.03333 | Regression loss: 0.02542 | Objectness loss: 0.00006 | RPN Regression loss: 0.00061 | Running loss: 0.05941\n","Epoch: 9 | Iteration: 34822 | Classification loss: 0.00757 | Regression loss: 0.01457 | Objectness loss: 0.00002 | RPN Regression loss: 0.00088 | Running loss: 0.02305\n","Epoch: 9 | Iteration: 34823 | Classification loss: 0.02786 | Regression loss: 0.01284 | Objectness loss: 0.00042 | RPN Regression loss: 0.00038 | Running loss: 0.04150\n","Epoch: 9 | Iteration: 34824 | Classification loss: 0.00999 | Regression loss: 0.03140 | Objectness loss: 0.00051 | RPN Regression loss: 0.00109 | Running loss: 0.04300\n","Epoch: 9 | Iteration: 34825 | Classification loss: 0.02798 | Regression loss: 0.02440 | Objectness loss: 0.00032 | RPN Regression loss: 0.00218 | Running loss: 0.05487\n","Epoch: 9 | Iteration: 34826 | Classification loss: 0.00993 | Regression loss: 0.02542 | Objectness loss: 0.00027 | RPN Regression loss: 0.00089 | Running loss: 0.03651\n","Epoch: 9 | Iteration: 34827 | Classification loss: 0.00893 | Regression loss: 0.01763 | Objectness loss: 0.00092 | RPN Regression loss: 0.00172 | Running loss: 0.02920\n","Epoch: 9 | Iteration: 34828 | Classification loss: 0.03438 | Regression loss: 0.02063 | Objectness loss: 0.00432 | RPN Regression loss: 0.00045 | Running loss: 0.05978\n","Epoch: 9 | Iteration: 34829 | Classification loss: 0.03341 | Regression loss: 0.02565 | Objectness loss: 0.00015 | RPN Regression loss: 0.00109 | Running loss: 0.06030\n","Epoch: 9 | Iteration: 34830 | Classification loss: 0.02409 | Regression loss: 0.03589 | Objectness loss: 0.00045 | RPN Regression loss: 0.00111 | Running loss: 0.06155\n","Epoch: 9 | Iteration: 34831 | Classification loss: 0.01179 | Regression loss: 0.01767 | Objectness loss: 0.00001 | RPN Regression loss: 0.00079 | Running loss: 0.03026\n","Epoch: 9 | Iteration: 34832 | Classification loss: 0.02908 | Regression loss: 0.01752 | Objectness loss: 0.00002 | RPN Regression loss: 0.00058 | Running loss: 0.04720\n","Epoch: 9 | Iteration: 34833 | Classification loss: 0.03518 | Regression loss: 0.03532 | Objectness loss: 0.00062 | RPN Regression loss: 0.00174 | Running loss: 0.07287\n","Epoch: 9 | Iteration: 34834 | Classification loss: 0.02761 | Regression loss: 0.02366 | Objectness loss: 0.00004 | RPN Regression loss: 0.00166 | Running loss: 0.05297\n","Epoch: 9 | Iteration: 34835 | Classification loss: 0.02900 | Regression loss: 0.02445 | Objectness loss: 0.00001 | RPN Regression loss: 0.00057 | Running loss: 0.05403\n","Epoch: 9 | Iteration: 34836 | Classification loss: 0.00991 | Regression loss: 0.01599 | Objectness loss: 0.00164 | RPN Regression loss: 0.00111 | Running loss: 0.02864\n","Epoch: 9 | Iteration: 34837 | Classification loss: 0.01303 | Regression loss: 0.01272 | Objectness loss: 0.00009 | RPN Regression loss: 0.00049 | Running loss: 0.02633\n","Epoch: 9 | Iteration: 34838 | Classification loss: 0.03055 | Regression loss: 0.03797 | Objectness loss: 0.00016 | RPN Regression loss: 0.00168 | Running loss: 0.07037\n","Epoch: 9 | Iteration: 34839 | Classification loss: 0.00906 | Regression loss: 0.02025 | Objectness loss: 0.00013 | RPN Regression loss: 0.00185 | Running loss: 0.03129\n","Epoch: 9 | Iteration: 34840 | Classification loss: 0.00649 | Regression loss: 0.01285 | Objectness loss: 0.00016 | RPN Regression loss: 0.00105 | Running loss: 0.02055\n","Epoch: 9 | Iteration: 34841 | Classification loss: 0.02927 | Regression loss: 0.03546 | Objectness loss: 0.00048 | RPN Regression loss: 0.00071 | Running loss: 0.06592\n","Epoch: 9 | Iteration: 34842 | Classification loss: 0.02460 | Regression loss: 0.01965 | Objectness loss: 0.00044 | RPN Regression loss: 0.00113 | Running loss: 0.04581\n","Epoch: 9 | Iteration: 34843 | Classification loss: 0.02753 | Regression loss: 0.01747 | Objectness loss: 0.00227 | RPN Regression loss: 0.00184 | Running loss: 0.04912\n","Epoch: 9 | Iteration: 34844 | Classification loss: 0.01093 | Regression loss: 0.01940 | Objectness loss: 0.00254 | RPN Regression loss: 0.00480 | Running loss: 0.03766\n","Epoch: 9 | Iteration: 34845 | Classification loss: 0.00990 | Regression loss: 0.01862 | Objectness loss: 0.00024 | RPN Regression loss: 0.00128 | Running loss: 0.03005\n","Epoch: 9 | Iteration: 34846 | Classification loss: 0.01355 | Regression loss: 0.03263 | Objectness loss: 0.00182 | RPN Regression loss: 0.00138 | Running loss: 0.04939\n","Epoch: 9 | Iteration: 34847 | Classification loss: 0.02803 | Regression loss: 0.02739 | Objectness loss: 0.00695 | RPN Regression loss: 0.00062 | Running loss: 0.06298\n","Epoch: 9 | Iteration: 34848 | Classification loss: 0.00607 | Regression loss: 0.02011 | Objectness loss: 0.00001 | RPN Regression loss: 0.00119 | Running loss: 0.02739\n","Epoch: 9 | Iteration: 34849 | Classification loss: 0.01211 | Regression loss: 0.01835 | Objectness loss: 0.00017 | RPN Regression loss: 0.00262 | Running loss: 0.03326\n","Epoch: 9 | Iteration: 34850 | Classification loss: 0.01354 | Regression loss: 0.01648 | Objectness loss: 0.00018 | RPN Regression loss: 0.00066 | Running loss: 0.03086\n","\n"," Total Time - 22391\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"VUOJWWhg9IZ3"},"source":["torch.save({\n","        'epoch':epoch,\n","        'model_state_dict': model.state_dict(),\n","        'optimizer_state_dict': optimizer.state_dict(),\n","        'loss': losses}, '/content/drive/MyDrive/TrainingData/model'+str(epoch)+'epoch34334.pth')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ahmiMjBaGrqe"},"source":["<h1>RetinaNet implementation</h1>"]},{"cell_type":"code","metadata":{"id":"RUNecQbGAN6p","colab":{"base_uri":"https://localhost:8080/","height":103,"referenced_widgets":["88ab991bba294849bee8c2764c9c05b2","b42daf46d18b46e5a7053d7bcbc38123","f5c0e581df0144be91cb39fe90444855","bb24860efedd458084209ab41a4e54b1","7d46e646244e470c92155bf13404544d","5aefa198a63242709161abfff969d803","44ca71af31074d4bba4f6a97c7303073","d40a7d40d2e648c49886580a29dfd46a"]},"executionInfo":{"status":"ok","timestamp":1621499121747,"user_tz":-180,"elapsed":2439,"user":{"displayName":"Ilja Pavlovs","photoUrl":"","userId":"13249870573819033434"}},"outputId":"a5cf3d43-4205-42e6-f508-b2b58f4c8cc4"},"source":["#model = torchvision.models.detection.retinanet_resnet50_fpn(pretrained=True, num_classes = num_classes).to(device)\n","backbone = torchvision.models.detection.retinanet_resnet50_fpn(pretrained=True)\n","model = torchvision.models.detection.RetinaNet(backbone.backbone, num_classes=num_classes).to(device)\n","optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n","lr_scheduler = None\n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Downloading: \"https://download.pytorch.org/models/retinanet_resnet50_fpn_coco-eeacb38b.pth\" to /root/.cache/torch/hub/checkpoints/retinanet_resnet50_fpn_coco-eeacb38b.pth\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"88ab991bba294849bee8c2764c9c05b2","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=136595076.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-289_f00Eq3P"},"source":["#Load checkpoint\n","checkpoint = torch.load('/content/drive/MyDrive/TrainingData/model0epoch.pth')\n","\n","model.load_state_dict(checkpoint['model_state_dict'])\n","optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n","start_epoch = checkpoint['epoch']\n","loss = checkpoint['loss']"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MaZ8vVWmWRav"},"source":["<h2>RetinaNet training</h2>"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Py4Ekf6jGcjp","outputId":"d8e3d825-c4fd-4966-d1ab-53083f944d42"},"source":["start_epoch = -1\n","itr = (start_epoch+1)*len(data_loader_train)\n","\n","for epoch in range(start_epoch+1, num_of_epochs):\n","\n","    print(\"Epoch - {} Started\".format(epoch))\n","    st = time.time()\n","    epoch_loss = []\n","\n","    for data in data_loader_train:\n","        itr+=1\n","        images, targets = data_prep(data, type='train')\n","\n","        \n","        model.double().to(device)\n","\n","        # Forward\n","        classification_loss, regression_loss = model(images, targets).values()\n","\n","        # Calculating Loss\n","        classification_loss = classification_loss.mean()\n","        regression_loss = regression_loss.mean()\n","        loss = classification_loss + regression_loss\n","\n","        if bool(loss == 0):\n","            continue\n","\n","        # Calculating Gradients\n","        loss.backward()\n","\n","        # Gradient Clipping\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n","                \n","        # Updating Weights\n","        optimizer.step()\n","\n","        #Epoch Loss\n","        epoch_loss.append(float(loss))\n","\n","        print(\n","            'Epoch: {} | Iteration: {}/{} | Classification loss: {:1.5f} | Regression loss: {:1.5f} | Running loss: {:1.5f}'.format(\n","                epoch, itr, len(data_loader_train),float(classification_loss.item()), float(regression_loss.item()), np.mean(epoch_loss)))\n","        \n","        with open('/content/drive/MyDrive/TrainingData/retina_loss_notbalanced.txt', 'a') as f:\n","            f.write('Epoch: {} | Iteration: {} | Classification loss: {:1.5f} | Regression loss: {:1.5f} | Running loss: {:1.5f}\\n'.format(\n","                epoch, itr, float(classification_loss.item()), float(regression_loss.item()), np.mean(epoch_loss)))\n","\n","        del classification_loss\n","        del regression_loss\n","        \n","    et = time.time()\n","    print(\"\\n Total Time - {}\\n\".format(int(et - st)))\n","    with open('/content/drive/MyDrive/TrainingData/retina_loss_notbalanced.txt', 'a') as f:\n","        f.write(\"Total Time - {}\\n\".format(int(et - st)))\n","    # update the learning rate\n","    if lr_scheduler is not None:\n","        lr_scheduler.step()\n","\n","    #checkpoint\n","    torch.save({\n","        'epoch':epoch,\n","        'model_state_dict': model.state_dict(),\n","        'optimizer_state_dict': optimizer.state_dict(),\n","        'loss': loss}, '/content/drive/MyDrive/TrainingData/retina'+str(epoch)+'epoch_notbalanced.pth')\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch - 0 Started\n","Epoch: 0 | Iteration: 1/2403 | Classification loss: 1.13975 | Regression loss: 0.70913 | Running loss: 1.84887\n","Epoch: 0 | Iteration: 2/2403 | Classification loss: 1.14067 | Regression loss: 0.64121 | Running loss: 1.81538\n","Epoch: 0 | Iteration: 3/2403 | Classification loss: 1.12919 | Regression loss: 0.71046 | Running loss: 1.82347\n","Epoch: 0 | Iteration: 4/2403 | Classification loss: 1.11151 | Regression loss: 0.64043 | Running loss: 1.80559\n","Epoch: 0 | Iteration: 5/2403 | Classification loss: 1.01135 | Regression loss: 0.82804 | Running loss: 1.81235\n","Epoch: 0 | Iteration: 6/2403 | Classification loss: 0.99092 | Regression loss: 0.76104 | Running loss: 1.80228\n","Epoch: 0 | Iteration: 7/2403 | Classification loss: 0.85820 | Regression loss: 0.69957 | Running loss: 1.76735\n","Epoch: 0 | Iteration: 8/2403 | Classification loss: 0.75296 | Regression loss: 0.63806 | Running loss: 1.72031\n","Epoch: 0 | Iteration: 9/2403 | Classification loss: 1.50601 | Regression loss: 0.70852 | Running loss: 1.77522\n","Epoch: 0 | Iteration: 10/2403 | Classification loss: 1.32846 | Regression loss: 0.71039 | Running loss: 1.80159\n","Epoch: 0 | Iteration: 11/2403 | Classification loss: 0.92775 | Regression loss: 0.61954 | Running loss: 1.77847\n","Epoch: 0 | Iteration: 12/2403 | Classification loss: 0.81232 | Regression loss: 0.56222 | Running loss: 1.74481\n","Epoch: 0 | Iteration: 13/2403 | Classification loss: 0.78376 | Regression loss: 0.62148 | Running loss: 1.71869\n","Epoch: 0 | Iteration: 14/2403 | Classification loss: 2.19816 | Regression loss: 0.63424 | Running loss: 1.79824\n","Epoch: 0 | Iteration: 15/2403 | Classification loss: 1.25518 | Regression loss: 0.74098 | Running loss: 1.81143\n","Epoch: 0 | Iteration: 16/2403 | Classification loss: 0.62172 | Regression loss: 0.63551 | Running loss: 1.77680\n","Epoch: 0 | Iteration: 17/2403 | Classification loss: 0.71971 | Regression loss: 0.65372 | Running loss: 1.75307\n","Epoch: 0 | Iteration: 18/2403 | Classification loss: 0.79756 | Regression loss: 0.65609 | Running loss: 1.73643\n","Epoch: 0 | Iteration: 19/2403 | Classification loss: 0.62371 | Regression loss: 0.66039 | Running loss: 1.71263\n","Epoch: 0 | Iteration: 20/2403 | Classification loss: 0.70400 | Regression loss: 0.65989 | Running loss: 1.69519\n","Epoch: 0 | Iteration: 21/2403 | Classification loss: 0.60323 | Regression loss: 0.54589 | Running loss: 1.66919\n","Epoch: 0 | Iteration: 22/2403 | Classification loss: 0.72622 | Regression loss: 0.78524 | Running loss: 1.66202\n","Epoch: 0 | Iteration: 23/2403 | Classification loss: 0.59051 | Regression loss: 0.66395 | Running loss: 1.64430\n","Epoch: 0 | Iteration: 24/2403 | Classification loss: 0.82228 | Regression loss: 0.64736 | Running loss: 1.63702\n","Epoch: 0 | Iteration: 25/2403 | Classification loss: 0.48084 | Regression loss: 0.67142 | Running loss: 1.61763\n","Epoch: 0 | Iteration: 26/2403 | Classification loss: 0.51515 | Regression loss: 0.61902 | Running loss: 1.59903\n","Epoch: 0 | Iteration: 27/2403 | Classification loss: 0.58919 | Regression loss: 0.58515 | Running loss: 1.58330\n","Epoch: 0 | Iteration: 28/2403 | Classification loss: 0.68577 | Regression loss: 0.59514 | Running loss: 1.57251\n","Epoch: 0 | Iteration: 29/2403 | Classification loss: 0.67095 | Regression loss: 0.77449 | Running loss: 1.56812\n","Epoch: 0 | Iteration: 30/2403 | Classification loss: 0.52078 | Regression loss: 0.54998 | Running loss: 1.55155\n","Epoch: 0 | Iteration: 31/2403 | Classification loss: 0.49298 | Regression loss: 0.63886 | Running loss: 1.53801\n","Epoch: 0 | Iteration: 32/2403 | Classification loss: 0.64935 | Regression loss: 0.59735 | Running loss: 1.52890\n","Epoch: 0 | Iteration: 33/2403 | Classification loss: 0.56520 | Regression loss: 0.59701 | Running loss: 1.51779\n","Epoch: 0 | Iteration: 34/2403 | Classification loss: 0.41035 | Regression loss: 0.50733 | Running loss: 1.50014\n","Epoch: 0 | Iteration: 35/2403 | Classification loss: 0.38863 | Regression loss: 0.59108 | Running loss: 1.48527\n","Epoch: 0 | Iteration: 36/2403 | Classification loss: 0.46956 | Regression loss: 0.57640 | Running loss: 1.47307\n","Epoch: 0 | Iteration: 37/2403 | Classification loss: 0.78944 | Regression loss: 0.59628 | Running loss: 1.47071\n","Epoch: 0 | Iteration: 38/2403 | Classification loss: 1.00062 | Regression loss: 0.55491 | Running loss: 1.47294\n","Epoch: 0 | Iteration: 39/2403 | Classification loss: 0.54540 | Regression loss: 0.55291 | Running loss: 1.46333\n","Epoch: 0 | Iteration: 40/2403 | Classification loss: 0.78646 | Regression loss: 0.82922 | Running loss: 1.46714\n","Epoch: 0 | Iteration: 41/2403 | Classification loss: 0.80289 | Regression loss: 0.55623 | Running loss: 1.46451\n","Epoch: 0 | Iteration: 42/2403 | Classification loss: 0.53030 | Regression loss: 0.57522 | Running loss: 1.45596\n","Epoch: 0 | Iteration: 43/2403 | Classification loss: 0.43801 | Regression loss: 0.55407 | Running loss: 1.44517\n","Epoch: 0 | Iteration: 44/2403 | Classification loss: 1.25058 | Regression loss: 0.60339 | Running loss: 1.45446\n","Epoch: 0 | Iteration: 45/2403 | Classification loss: 2.51046 | Regression loss: 0.63625 | Running loss: 1.49207\n","Epoch: 0 | Iteration: 46/2403 | Classification loss: 1.99928 | Regression loss: 0.78193 | Running loss: 1.52009\n","Epoch: 0 | Iteration: 47/2403 | Classification loss: 0.56207 | Regression loss: 0.59541 | Running loss: 1.51238\n","Epoch: 0 | Iteration: 48/2403 | Classification loss: 0.54278 | Regression loss: 0.63030 | Running loss: 1.50531\n","Epoch: 0 | Iteration: 49/2403 | Classification loss: 0.85958 | Regression loss: 1.01836 | Running loss: 1.51291\n","Epoch: 0 | Iteration: 50/2403 | Classification loss: 0.60594 | Regression loss: 0.50467 | Running loss: 1.50487\n","Epoch: 0 | Iteration: 51/2403 | Classification loss: 0.60825 | Regression loss: 0.61013 | Running loss: 1.49925\n","Epoch: 0 | Iteration: 52/2403 | Classification loss: 0.35628 | Regression loss: 0.50813 | Running loss: 1.48704\n","Epoch: 0 | Iteration: 53/2403 | Classification loss: 0.41047 | Regression loss: 0.63868 | Running loss: 1.47878\n","Epoch: 0 | Iteration: 54/2403 | Classification loss: 0.94612 | Regression loss: 0.57801 | Running loss: 1.47962\n","Epoch: 0 | Iteration: 55/2403 | Classification loss: 1.22752 | Regression loss: 0.50285 | Running loss: 1.48418\n","Epoch: 0 | Iteration: 56/2403 | Classification loss: 0.60917 | Regression loss: 0.45997 | Running loss: 1.47677\n","Epoch: 0 | Iteration: 57/2403 | Classification loss: 0.47921 | Regression loss: 0.53724 | Running loss: 1.46869\n","Epoch: 0 | Iteration: 58/2403 | Classification loss: 0.51887 | Regression loss: 0.67465 | Running loss: 1.46395\n","Epoch: 0 | Iteration: 59/2403 | Classification loss: 0.38341 | Regression loss: 0.44844 | Running loss: 1.45323\n","Epoch: 0 | Iteration: 60/2403 | Classification loss: 0.43698 | Regression loss: 0.52155 | Running loss: 1.44499\n","Epoch: 0 | Iteration: 61/2403 | Classification loss: 0.52649 | Regression loss: 0.56381 | Running loss: 1.43917\n","Epoch: 0 | Iteration: 62/2403 | Classification loss: 0.51300 | Regression loss: 0.62535 | Running loss: 1.43432\n","Epoch: 0 | Iteration: 63/2403 | Classification loss: 0.47848 | Regression loss: 0.50993 | Running loss: 1.42724\n","Epoch: 0 | Iteration: 64/2403 | Classification loss: 0.60150 | Regression loss: 0.62801 | Running loss: 1.42416\n","Epoch: 0 | Iteration: 65/2403 | Classification loss: 0.64800 | Regression loss: 0.62119 | Running loss: 1.42177\n","Epoch: 0 | Iteration: 66/2403 | Classification loss: 0.63708 | Regression loss: 0.78083 | Running loss: 1.42171\n","Epoch: 0 | Iteration: 67/2403 | Classification loss: 0.47443 | Regression loss: 0.54440 | Running loss: 1.41570\n","Epoch: 0 | Iteration: 68/2403 | Classification loss: 0.76587 | Regression loss: 0.61162 | Running loss: 1.41514\n","Epoch: 0 | Iteration: 69/2403 | Classification loss: 0.60171 | Regression loss: 0.77815 | Running loss: 1.41463\n","Epoch: 0 | Iteration: 70/2403 | Classification loss: 0.64173 | Regression loss: 0.61656 | Running loss: 1.41239\n","Epoch: 0 | Iteration: 71/2403 | Classification loss: 0.61206 | Regression loss: 0.48344 | Running loss: 1.40793\n","Epoch: 0 | Iteration: 72/2403 | Classification loss: 0.54830 | Regression loss: 0.59617 | Running loss: 1.40427\n","Epoch: 0 | Iteration: 73/2403 | Classification loss: 0.56148 | Regression loss: 0.51749 | Running loss: 1.39981\n","Epoch: 0 | Iteration: 74/2403 | Classification loss: 0.40112 | Regression loss: 0.50472 | Running loss: 1.39314\n","Epoch: 0 | Iteration: 75/2403 | Classification loss: 0.57669 | Regression loss: 0.62704 | Running loss: 1.39061\n","Epoch: 0 | Iteration: 76/2403 | Classification loss: 0.36246 | Regression loss: 0.50338 | Running loss: 1.38371\n","Epoch: 0 | Iteration: 77/2403 | Classification loss: 0.45217 | Regression loss: 0.50392 | Running loss: 1.37815\n","Epoch: 0 | Iteration: 78/2403 | Classification loss: 0.41169 | Regression loss: 0.64734 | Running loss: 1.37406\n","Epoch: 0 | Iteration: 79/2403 | Classification loss: 0.52874 | Regression loss: 0.46133 | Running loss: 1.36920\n","Epoch: 0 | Iteration: 80/2403 | Classification loss: 0.31648 | Regression loss: 0.49876 | Running loss: 1.36228\n","Epoch: 0 | Iteration: 81/2403 | Classification loss: 0.79676 | Regression loss: 0.50979 | Running loss: 1.36159\n","Epoch: 0 | Iteration: 82/2403 | Classification loss: 0.55845 | Regression loss: 0.55497 | Running loss: 1.35856\n","Epoch: 0 | Iteration: 83/2403 | Classification loss: 0.54656 | Regression loss: 0.51473 | Running loss: 1.35498\n","Epoch: 0 | Iteration: 84/2403 | Classification loss: 0.48225 | Regression loss: 0.49748 | Running loss: 1.35051\n","Epoch: 0 | Iteration: 85/2403 | Classification loss: 0.75840 | Regression loss: 0.62493 | Running loss: 1.35090\n","Epoch: 0 | Iteration: 86/2403 | Classification loss: 0.92736 | Regression loss: 0.68841 | Running loss: 1.35398\n","Epoch: 0 | Iteration: 87/2403 | Classification loss: 0.58707 | Regression loss: 0.62400 | Running loss: 1.35234\n","Epoch: 0 | Iteration: 88/2403 | Classification loss: 0.31609 | Regression loss: 0.48442 | Running loss: 1.34607\n","Epoch: 0 | Iteration: 89/2403 | Classification loss: 0.34287 | Regression loss: 0.50767 | Running loss: 1.34050\n","Epoch: 0 | Iteration: 90/2403 | Classification loss: 0.35482 | Regression loss: 0.44707 | Running loss: 1.33452\n","Epoch: 0 | Iteration: 91/2403 | Classification loss: 0.84295 | Regression loss: 0.70629 | Running loss: 1.33687\n","Epoch: 0 | Iteration: 92/2403 | Classification loss: 0.33890 | Regression loss: 0.52422 | Running loss: 1.33173\n","Epoch: 0 | Iteration: 93/2403 | Classification loss: 0.58117 | Regression loss: 0.58026 | Running loss: 1.32989\n","Epoch: 0 | Iteration: 94/2403 | Classification loss: 0.52103 | Regression loss: 0.47888 | Running loss: 1.32638\n","Epoch: 0 | Iteration: 95/2403 | Classification loss: 0.42782 | Regression loss: 0.71089 | Running loss: 1.32441\n","Epoch: 0 | Iteration: 96/2403 | Classification loss: 0.40862 | Regression loss: 0.53284 | Running loss: 1.32042\n","Epoch: 0 | Iteration: 97/2403 | Classification loss: 0.46341 | Regression loss: 0.51604 | Running loss: 1.31690\n","Epoch: 0 | Iteration: 98/2403 | Classification loss: 0.72579 | Regression loss: 0.48994 | Running loss: 1.31587\n","Epoch: 0 | Iteration: 99/2403 | Classification loss: 0.36716 | Regression loss: 0.48187 | Running loss: 1.31116\n","Epoch: 0 | Iteration: 100/2403 | Classification loss: 0.45050 | Regression loss: 0.51120 | Running loss: 1.30766\n","Epoch: 0 | Iteration: 101/2403 | Classification loss: 0.37522 | Regression loss: 0.62462 | Running loss: 1.30461\n","Epoch: 0 | Iteration: 102/2403 | Classification loss: 0.51229 | Regression loss: 0.46321 | Running loss: 1.30139\n","Epoch: 0 | Iteration: 103/2403 | Classification loss: 0.49116 | Regression loss: 0.60734 | Running loss: 1.29942\n","Epoch: 0 | Iteration: 104/2403 | Classification loss: 0.41600 | Regression loss: 0.43374 | Running loss: 1.29509\n","Epoch: 0 | Iteration: 105/2403 | Classification loss: 0.61681 | Regression loss: 0.47081 | Running loss: 1.29312\n","Epoch: 0 | Iteration: 106/2403 | Classification loss: 0.46001 | Regression loss: 0.49632 | Running loss: 1.28994\n","Epoch: 0 | Iteration: 107/2403 | Classification loss: 0.53510 | Regression loss: 0.51368 | Running loss: 1.28769\n","Epoch: 0 | Iteration: 108/2403 | Classification loss: 0.48346 | Regression loss: 0.45345 | Running loss: 1.28444\n","Epoch: 0 | Iteration: 109/2403 | Classification loss: 0.60650 | Regression loss: 0.53644 | Running loss: 1.28314\n","Epoch: 0 | Iteration: 110/2403 | Classification loss: 0.39593 | Regression loss: 0.45993 | Running loss: 1.27926\n","Epoch: 0 | Iteration: 111/2403 | Classification loss: 0.49053 | Regression loss: 0.55780 | Running loss: 1.27718\n","Epoch: 0 | Iteration: 112/2403 | Classification loss: 0.62633 | Regression loss: 0.51504 | Running loss: 1.27596\n","Epoch: 0 | Iteration: 113/2403 | Classification loss: 0.52948 | Regression loss: 0.49015 | Running loss: 1.27369\n","Epoch: 0 | Iteration: 114/2403 | Classification loss: 0.79951 | Regression loss: 0.41298 | Running loss: 1.27316\n","Epoch: 0 | Iteration: 115/2403 | Classification loss: 0.36701 | Regression loss: 0.47490 | Running loss: 1.26941\n","Epoch: 0 | Iteration: 116/2403 | Classification loss: 0.39083 | Regression loss: 0.48917 | Running loss: 1.26605\n","Epoch: 0 | Iteration: 117/2403 | Classification loss: 0.56407 | Regression loss: 0.66744 | Running loss: 1.26576\n","Epoch: 0 | Iteration: 118/2403 | Classification loss: 0.34564 | Regression loss: 0.46365 | Running loss: 1.26189\n","Epoch: 0 | Iteration: 119/2403 | Classification loss: 0.33213 | Regression loss: 0.54390 | Running loss: 1.25864\n","Epoch: 0 | Iteration: 120/2403 | Classification loss: 0.56299 | Regression loss: 0.51897 | Running loss: 1.25717\n","Epoch: 0 | Iteration: 121/2403 | Classification loss: 0.77343 | Regression loss: 0.55858 | Running loss: 1.25779\n","Epoch: 0 | Iteration: 122/2403 | Classification loss: 0.37690 | Regression loss: 0.42138 | Running loss: 1.25402\n","Epoch: 0 | Iteration: 123/2403 | Classification loss: 0.55041 | Regression loss: 0.50304 | Running loss: 1.25239\n","Epoch: 0 | Iteration: 124/2403 | Classification loss: 0.52866 | Regression loss: 0.44478 | Running loss: 1.25014\n","Epoch: 0 | Iteration: 125/2403 | Classification loss: 0.46206 | Regression loss: 0.41023 | Running loss: 1.24712\n","Epoch: 0 | Iteration: 126/2403 | Classification loss: 0.35256 | Regression loss: 0.44950 | Running loss: 1.24359\n","Epoch: 0 | Iteration: 127/2403 | Classification loss: 0.45715 | Regression loss: 0.54976 | Running loss: 1.24173\n","Epoch: 0 | Iteration: 128/2403 | Classification loss: 0.61026 | Regression loss: 0.42061 | Running loss: 1.24008\n","Epoch: 0 | Iteration: 129/2403 | Classification loss: 0.70770 | Regression loss: 0.49144 | Running loss: 1.23976\n","Epoch: 0 | Iteration: 130/2403 | Classification loss: 0.62210 | Regression loss: 0.51367 | Running loss: 1.23896\n","Epoch: 0 | Iteration: 131/2403 | Classification loss: 0.35654 | Regression loss: 0.47132 | Running loss: 1.23582\n","Epoch: 0 | Iteration: 132/2403 | Classification loss: 0.38913 | Regression loss: 0.46050 | Running loss: 1.23290\n","Epoch: 0 | Iteration: 133/2403 | Classification loss: 0.69900 | Regression loss: 0.65647 | Running loss: 1.23382\n","Epoch: 0 | Iteration: 134/2403 | Classification loss: 0.28084 | Regression loss: 0.43907 | Running loss: 1.22998\n","Epoch: 0 | Iteration: 135/2403 | Classification loss: 0.34772 | Regression loss: 0.48324 | Running loss: 1.22703\n","Epoch: 0 | Iteration: 136/2403 | Classification loss: 0.38398 | Regression loss: 0.48292 | Running loss: 1.22438\n","Epoch: 0 | Iteration: 137/2403 | Classification loss: 0.56429 | Regression loss: 0.47954 | Running loss: 1.22306\n","Epoch: 0 | Iteration: 138/2403 | Classification loss: 0.25674 | Regression loss: 0.40137 | Running loss: 1.21897\n","Epoch: 0 | Iteration: 139/2403 | Classification loss: 0.26243 | Regression loss: 0.31814 | Running loss: 1.21437\n","Epoch: 0 | Iteration: 140/2403 | Classification loss: 0.60798 | Regression loss: 0.58463 | Running loss: 1.21422\n","Epoch: 0 | Iteration: 141/2403 | Classification loss: 0.73070 | Regression loss: 0.53402 | Running loss: 1.21458\n","Epoch: 0 | Iteration: 142/2403 | Classification loss: 0.29164 | Regression loss: 0.56807 | Running loss: 1.21208\n","Epoch: 0 | Iteration: 143/2403 | Classification loss: 0.49037 | Regression loss: 0.60791 | Running loss: 1.21128\n","Epoch: 0 | Iteration: 144/2403 | Classification loss: 0.43265 | Regression loss: 0.39118 | Running loss: 1.20859\n","Epoch: 0 | Iteration: 145/2403 | Classification loss: 0.29236 | Regression loss: 0.43079 | Running loss: 1.20524\n","Epoch: 0 | Iteration: 146/2403 | Classification loss: 0.63678 | Regression loss: 0.46117 | Running loss: 1.20451\n","Epoch: 0 | Iteration: 147/2403 | Classification loss: 0.43549 | Regression loss: 0.55057 | Running loss: 1.20302\n","Epoch: 0 | Iteration: 148/2403 | Classification loss: 0.75275 | Regression loss: 0.47920 | Running loss: 1.20322\n","Epoch: 0 | Iteration: 149/2403 | Classification loss: 0.37609 | Regression loss: 0.47000 | Running loss: 1.20082\n","Epoch: 0 | Iteration: 150/2403 | Classification loss: 0.33546 | Regression loss: 0.39509 | Running loss: 1.19769\n","Epoch: 0 | Iteration: 151/2403 | Classification loss: 0.31956 | Regression loss: 0.38440 | Running loss: 1.19442\n","Epoch: 0 | Iteration: 152/2403 | Classification loss: 0.55471 | Regression loss: 0.47696 | Running loss: 1.19335\n","Epoch: 0 | Iteration: 153/2403 | Classification loss: 0.36492 | Regression loss: 0.39113 | Running loss: 1.19049\n","Epoch: 0 | Iteration: 154/2403 | Classification loss: 0.38273 | Regression loss: 0.43572 | Running loss: 1.18807\n","Epoch: 0 | Iteration: 155/2403 | Classification loss: 0.64301 | Regression loss: 0.38926 | Running loss: 1.18707\n","Epoch: 0 | Iteration: 156/2403 | Classification loss: 0.34321 | Regression loss: 0.36656 | Running loss: 1.18401\n","Epoch: 0 | Iteration: 157/2403 | Classification loss: 0.66633 | Regression loss: 0.57487 | Running loss: 1.18437\n","Epoch: 0 | Iteration: 158/2403 | Classification loss: 0.46039 | Regression loss: 0.61887 | Running loss: 1.18371\n","Epoch: 0 | Iteration: 159/2403 | Classification loss: 0.52785 | Regression loss: 0.46349 | Running loss: 1.18250\n","Epoch: 0 | Iteration: 160/2403 | Classification loss: 0.29503 | Regression loss: 0.38913 | Running loss: 1.17938\n","Epoch: 0 | Iteration: 161/2403 | Classification loss: 0.35821 | Regression loss: 0.47702 | Running loss: 1.17724\n","Epoch: 0 | Iteration: 162/2403 | Classification loss: 0.73290 | Regression loss: 0.43803 | Running loss: 1.17721\n","Epoch: 0 | Iteration: 163/2403 | Classification loss: 0.78463 | Regression loss: 0.47551 | Running loss: 1.17771\n","Epoch: 0 | Iteration: 164/2403 | Classification loss: 0.52176 | Regression loss: 0.44918 | Running loss: 1.17645\n","Epoch: 0 | Iteration: 165/2403 | Classification loss: 0.81986 | Regression loss: 0.48873 | Running loss: 1.17725\n","Epoch: 0 | Iteration: 166/2403 | Classification loss: 0.69969 | Regression loss: 0.47715 | Running loss: 1.17725\n","Epoch: 0 | Iteration: 167/2403 | Classification loss: 0.77988 | Regression loss: 0.52641 | Running loss: 1.17802\n","Epoch: 0 | Iteration: 168/2403 | Classification loss: 0.83754 | Regression loss: 0.54986 | Running loss: 1.17927\n","Epoch: 0 | Iteration: 169/2403 | Classification loss: 0.79019 | Regression loss: 0.60052 | Running loss: 1.18052\n","Epoch: 0 | Iteration: 170/2403 | Classification loss: 0.57080 | Regression loss: 0.38324 | Running loss: 1.17919\n","Epoch: 0 | Iteration: 171/2403 | Classification loss: 0.55693 | Regression loss: 0.47846 | Running loss: 1.17835\n","Epoch: 0 | Iteration: 172/2403 | Classification loss: 0.49535 | Regression loss: 0.43149 | Running loss: 1.17689\n","Epoch: 0 | Iteration: 173/2403 | Classification loss: 0.67861 | Regression loss: 0.37932 | Running loss: 1.17620\n","Epoch: 0 | Iteration: 174/2403 | Classification loss: 0.55026 | Regression loss: 0.39084 | Running loss: 1.17485\n","Epoch: 0 | Iteration: 175/2403 | Classification loss: 0.32904 | Regression loss: 0.37999 | Running loss: 1.17219\n","Epoch: 0 | Iteration: 176/2403 | Classification loss: 0.39580 | Regression loss: 0.42561 | Running loss: 1.17019\n","Epoch: 0 | Iteration: 177/2403 | Classification loss: 0.44063 | Regression loss: 0.41950 | Running loss: 1.16844\n","Epoch: 0 | Iteration: 178/2403 | Classification loss: 0.25751 | Regression loss: 0.30693 | Running loss: 1.16505\n","Epoch: 0 | Iteration: 179/2403 | Classification loss: 0.66697 | Regression loss: 0.53345 | Running loss: 1.16525\n","Epoch: 0 | Iteration: 180/2403 | Classification loss: 0.42726 | Regression loss: 0.40991 | Running loss: 1.16342\n","Epoch: 0 | Iteration: 181/2403 | Classification loss: 0.85748 | Regression loss: 0.58391 | Running loss: 1.16496\n","Epoch: 0 | Iteration: 182/2403 | Classification loss: 0.32539 | Regression loss: 0.43034 | Running loss: 1.16271\n","Epoch: 0 | Iteration: 183/2403 | Classification loss: 0.53772 | Regression loss: 0.43806 | Running loss: 1.16169\n","Epoch: 0 | Iteration: 184/2403 | Classification loss: 0.44988 | Regression loss: 0.43868 | Running loss: 1.16020\n","Epoch: 0 | Iteration: 185/2403 | Classification loss: 0.69036 | Regression loss: 0.49443 | Running loss: 1.16034\n","Epoch: 0 | Iteration: 186/2403 | Classification loss: 0.56225 | Regression loss: 0.43497 | Running loss: 1.15946\n","Epoch: 0 | Iteration: 187/2403 | Classification loss: 0.64069 | Regression loss: 0.50596 | Running loss: 1.15939\n","Epoch: 0 | Iteration: 188/2403 | Classification loss: 0.36157 | Regression loss: 0.63801 | Running loss: 1.15854\n","Epoch: 0 | Iteration: 189/2403 | Classification loss: 0.34856 | Regression loss: 0.41159 | Running loss: 1.15643\n","Epoch: 0 | Iteration: 190/2403 | Classification loss: 0.45997 | Regression loss: 0.47268 | Running loss: 1.15526\n","Epoch: 0 | Iteration: 191/2403 | Classification loss: 0.22684 | Regression loss: 0.29910 | Running loss: 1.15196\n","Epoch: 0 | Iteration: 192/2403 | Classification loss: 0.40389 | Regression loss: 0.48538 | Running loss: 1.15059\n","Epoch: 0 | Iteration: 193/2403 | Classification loss: 0.57860 | Regression loss: 0.43688 | Running loss: 1.14989\n","Epoch: 0 | Iteration: 194/2403 | Classification loss: 0.27462 | Regression loss: 0.36523 | Running loss: 1.14726\n","Epoch: 0 | Iteration: 195/2403 | Classification loss: 0.30358 | Regression loss: 0.42047 | Running loss: 1.14509\n","Epoch: 0 | Iteration: 196/2403 | Classification loss: 0.42340 | Regression loss: 0.51500 | Running loss: 1.14404\n","Epoch: 0 | Iteration: 197/2403 | Classification loss: 0.41587 | Regression loss: 0.66695 | Running loss: 1.14373\n","Epoch: 0 | Iteration: 198/2403 | Classification loss: 0.58995 | Regression loss: 0.44000 | Running loss: 1.14315\n","Epoch: 0 | Iteration: 199/2403 | Classification loss: 0.27332 | Regression loss: 0.45186 | Running loss: 1.14105\n","Epoch: 0 | Iteration: 200/2403 | Classification loss: 0.40694 | Regression loss: 0.40921 | Running loss: 1.13943\n","Epoch: 0 | Iteration: 201/2403 | Classification loss: 0.41130 | Regression loss: 0.41797 | Running loss: 1.13789\n","Epoch: 0 | Iteration: 202/2403 | Classification loss: 0.42612 | Regression loss: 0.44236 | Running loss: 1.13655\n","Epoch: 0 | Iteration: 203/2403 | Classification loss: 0.52588 | Regression loss: 0.43214 | Running loss: 1.13567\n","Epoch: 0 | Iteration: 204/2403 | Classification loss: 0.41300 | Regression loss: 0.39283 | Running loss: 1.13406\n","Epoch: 0 | Iteration: 205/2403 | Classification loss: 0.73832 | Regression loss: 0.41103 | Running loss: 1.13413\n","Epoch: 0 | Iteration: 206/2403 | Classification loss: 0.37886 | Regression loss: 0.34009 | Running loss: 1.13211\n","Epoch: 0 | Iteration: 207/2403 | Classification loss: 0.49064 | Regression loss: 0.45994 | Running loss: 1.13124\n","Epoch: 0 | Iteration: 208/2403 | Classification loss: 0.30164 | Regression loss: 0.34943 | Running loss: 1.12893\n","Epoch: 0 | Iteration: 209/2403 | Classification loss: 0.17779 | Regression loss: 0.29062 | Running loss: 1.12577\n","Epoch: 0 | Iteration: 210/2403 | Classification loss: 0.34111 | Regression loss: 0.41304 | Running loss: 1.12400\n","Epoch: 0 | Iteration: 211/2403 | Classification loss: 0.39559 | Regression loss: 0.45704 | Running loss: 1.12271\n","Epoch: 0 | Iteration: 212/2403 | Classification loss: 0.41681 | Regression loss: 0.47927 | Running loss: 1.12164\n","Epoch: 0 | Iteration: 213/2403 | Classification loss: 0.32595 | Regression loss: 0.38110 | Running loss: 1.11970\n","Epoch: 0 | Iteration: 214/2403 | Classification loss: 0.66244 | Regression loss: 0.46586 | Running loss: 1.11974\n","Epoch: 0 | Iteration: 215/2403 | Classification loss: 0.44719 | Regression loss: 0.49489 | Running loss: 1.11891\n","Epoch: 0 | Iteration: 216/2403 | Classification loss: 0.32203 | Regression loss: 0.44935 | Running loss: 1.11730\n","Epoch: 0 | Iteration: 217/2403 | Classification loss: 0.51309 | Regression loss: 0.45207 | Running loss: 1.11660\n","Epoch: 0 | Iteration: 218/2403 | Classification loss: 0.35092 | Regression loss: 0.56130 | Running loss: 1.11566\n","Epoch: 0 | Iteration: 219/2403 | Classification loss: 0.35641 | Regression loss: 0.42158 | Running loss: 1.11412\n","Epoch: 0 | Iteration: 220/2403 | Classification loss: 0.38512 | Regression loss: 0.42165 | Running loss: 1.11272\n","Epoch: 0 | Iteration: 221/2403 | Classification loss: 0.40540 | Regression loss: 0.39381 | Running loss: 1.11131\n","Epoch: 0 | Iteration: 222/2403 | Classification loss: 0.40356 | Regression loss: 0.54455 | Running loss: 1.11057\n","Epoch: 0 | Iteration: 223/2403 | Classification loss: 0.40038 | Regression loss: 0.49686 | Running loss: 1.10961\n","Epoch: 0 | Iteration: 224/2403 | Classification loss: 0.34763 | Regression loss: 0.39491 | Running loss: 1.10798\n","Epoch: 0 | Iteration: 225/2403 | Classification loss: 0.91427 | Regression loss: 0.43429 | Running loss: 1.10905\n","Epoch: 0 | Iteration: 226/2403 | Classification loss: 0.78391 | Regression loss: 0.69306 | Running loss: 1.11067\n","Epoch: 0 | Iteration: 227/2403 | Classification loss: 0.56340 | Regression loss: 0.47017 | Running loss: 1.11033\n","Epoch: 0 | Iteration: 228/2403 | Classification loss: 0.51334 | Regression loss: 0.40273 | Running loss: 1.10948\n","Epoch: 0 | Iteration: 229/2403 | Classification loss: 0.49030 | Regression loss: 0.42420 | Running loss: 1.10863\n","Epoch: 0 | Iteration: 230/2403 | Classification loss: 0.43594 | Regression loss: 0.46307 | Running loss: 1.10772\n","Epoch: 0 | Iteration: 231/2403 | Classification loss: 0.48455 | Regression loss: 0.48604 | Running loss: 1.10712\n","Epoch: 0 | Iteration: 232/2403 | Classification loss: 0.27412 | Regression loss: 0.37282 | Running loss: 1.10514\n","Epoch: 0 | Iteration: 233/2403 | Classification loss: 0.42345 | Regression loss: 0.40512 | Running loss: 1.10395\n","Epoch: 0 | Iteration: 234/2403 | Classification loss: 0.47909 | Regression loss: 0.42015 | Running loss: 1.10308\n","Epoch: 0 | Iteration: 235/2403 | Classification loss: 0.48140 | Regression loss: 0.45004 | Running loss: 1.10235\n","Epoch: 0 | Iteration: 236/2403 | Classification loss: 0.40261 | Regression loss: 0.40335 | Running loss: 1.10109\n","Epoch: 0 | Iteration: 237/2403 | Classification loss: 0.19570 | Regression loss: 0.30942 | Running loss: 1.09858\n","Epoch: 0 | Iteration: 238/2403 | Classification loss: 0.32696 | Regression loss: 0.41145 | Running loss: 1.09707\n","Epoch: 0 | Iteration: 239/2403 | Classification loss: 0.37227 | Regression loss: 0.35921 | Running loss: 1.09554\n","Epoch: 0 | Iteration: 240/2403 | Classification loss: 0.48274 | Regression loss: 0.38702 | Running loss: 1.09459\n","Epoch: 0 | Iteration: 241/2403 | Classification loss: 0.34257 | Regression loss: 0.44230 | Running loss: 1.09331\n","Epoch: 0 | Iteration: 242/2403 | Classification loss: 0.36507 | Regression loss: 0.42188 | Running loss: 1.09204\n","Epoch: 0 | Iteration: 243/2403 | Classification loss: 0.34214 | Regression loss: 0.30322 | Running loss: 1.09021\n","Epoch: 0 | Iteration: 244/2403 | Classification loss: 0.42559 | Regression loss: 0.41388 | Running loss: 1.08918\n","Epoch: 0 | Iteration: 245/2403 | Classification loss: 0.30350 | Regression loss: 0.30437 | Running loss: 1.08721\n","Epoch: 0 | Iteration: 246/2403 | Classification loss: 0.54914 | Regression loss: 0.42681 | Running loss: 1.08676\n","Epoch: 0 | Iteration: 247/2403 | Classification loss: 0.36796 | Regression loss: 0.33121 | Running loss: 1.08519\n","Epoch: 0 | Iteration: 248/2403 | Classification loss: 0.61738 | Regression loss: 0.65006 | Running loss: 1.08593\n","Epoch: 0 | Iteration: 249/2403 | Classification loss: 0.49988 | Regression loss: 0.53198 | Running loss: 1.08571\n","Epoch: 0 | Iteration: 250/2403 | Classification loss: 0.45285 | Regression loss: 0.49959 | Running loss: 1.08518\n","Epoch: 0 | Iteration: 251/2403 | Classification loss: 0.51767 | Regression loss: 0.41109 | Running loss: 1.08455\n","Epoch: 0 | Iteration: 252/2403 | Classification loss: 0.65448 | Regression loss: 0.32329 | Running loss: 1.08413\n","Epoch: 0 | Iteration: 253/2403 | Classification loss: 0.77457 | Regression loss: 0.37855 | Running loss: 1.08440\n","Epoch: 0 | Iteration: 254/2403 | Classification loss: 0.32439 | Regression loss: 0.47542 | Running loss: 1.08328\n","Epoch: 0 | Iteration: 255/2403 | Classification loss: 0.33260 | Regression loss: 0.33697 | Running loss: 1.08166\n","Epoch: 0 | Iteration: 256/2403 | Classification loss: 0.52544 | Regression loss: 0.47588 | Running loss: 1.08135\n","Epoch: 0 | Iteration: 257/2403 | Classification loss: 0.53610 | Regression loss: 0.36546 | Running loss: 1.08065\n","Epoch: 0 | Iteration: 258/2403 | Classification loss: 0.30029 | Regression loss: 0.27938 | Running loss: 1.07870\n","Epoch: 0 | Iteration: 259/2403 | Classification loss: 0.45203 | Regression loss: 0.43434 | Running loss: 1.07796\n","Epoch: 0 | Iteration: 260/2403 | Classification loss: 0.38911 | Regression loss: 0.43299 | Running loss: 1.07698\n","Epoch: 0 | Iteration: 261/2403 | Classification loss: 0.48322 | Regression loss: 0.41075 | Running loss: 1.07628\n","Epoch: 0 | Iteration: 262/2403 | Classification loss: 0.30157 | Regression loss: 0.30901 | Running loss: 1.07450\n","Epoch: 0 | Iteration: 263/2403 | Classification loss: 0.28371 | Regression loss: 0.31603 | Running loss: 1.07269\n","Epoch: 0 | Iteration: 264/2403 | Classification loss: 0.43009 | Regression loss: 0.37797 | Running loss: 1.07169\n","Epoch: 0 | Iteration: 265/2403 | Classification loss: 0.43873 | Regression loss: 0.43136 | Running loss: 1.07093\n","Epoch: 0 | Iteration: 266/2403 | Classification loss: 0.54756 | Regression loss: 0.48378 | Running loss: 1.07078\n","Epoch: 0 | Iteration: 267/2403 | Classification loss: 0.54067 | Regression loss: 0.42272 | Running loss: 1.07038\n","Epoch: 0 | Iteration: 268/2403 | Classification loss: 0.23270 | Regression loss: 0.37371 | Running loss: 1.06865\n","Epoch: 0 | Iteration: 269/2403 | Classification loss: 0.43218 | Regression loss: 0.40604 | Running loss: 1.06779\n","Epoch: 0 | Iteration: 270/2403 | Classification loss: 0.30841 | Regression loss: 0.36243 | Running loss: 1.06632\n","Epoch: 0 | Iteration: 271/2403 | Classification loss: 0.46880 | Regression loss: 0.36162 | Running loss: 1.06545\n","Epoch: 0 | Iteration: 272/2403 | Classification loss: 0.46527 | Regression loss: 0.57481 | Running loss: 1.06536\n","Epoch: 0 | Iteration: 273/2403 | Classification loss: 0.28983 | Regression loss: 0.36384 | Running loss: 1.06385\n","Epoch: 0 | Iteration: 274/2403 | Classification loss: 0.36928 | Regression loss: 0.34599 | Running loss: 1.06258\n","Epoch: 0 | Iteration: 275/2403 | Classification loss: 0.48045 | Regression loss: 0.45135 | Running loss: 1.06210\n","Epoch: 0 | Iteration: 276/2403 | Classification loss: 0.27359 | Regression loss: 0.45368 | Running loss: 1.06089\n","Epoch: 0 | Iteration: 277/2403 | Classification loss: 0.36811 | Regression loss: 0.39339 | Running loss: 1.05981\n","Epoch: 0 | Iteration: 278/2403 | Classification loss: 0.43342 | Regression loss: 0.35738 | Running loss: 1.05884\n","Epoch: 0 | Iteration: 279/2403 | Classification loss: 0.42284 | Regression loss: 0.30421 | Running loss: 1.05765\n","Epoch: 0 | Iteration: 280/2403 | Classification loss: 0.52531 | Regression loss: 0.28643 | Running loss: 1.05677\n","Epoch: 0 | Iteration: 281/2403 | Classification loss: 0.56032 | Regression loss: 0.39588 | Running loss: 1.05641\n","Epoch: 0 | Iteration: 282/2403 | Classification loss: 0.24410 | Regression loss: 0.30190 | Running loss: 1.05460\n","Epoch: 0 | Iteration: 283/2403 | Classification loss: 0.31811 | Regression loss: 0.36746 | Running loss: 1.05330\n","Epoch: 0 | Iteration: 284/2403 | Classification loss: 0.49586 | Regression loss: 0.51704 | Running loss: 1.05316\n","Epoch: 0 | Iteration: 285/2403 | Classification loss: 0.36145 | Regression loss: 0.37981 | Running loss: 1.05206\n","Epoch: 0 | Iteration: 286/2403 | Classification loss: 0.24831 | Regression loss: 0.33290 | Running loss: 1.05042\n","Epoch: 0 | Iteration: 287/2403 | Classification loss: 0.38321 | Regression loss: 0.35345 | Running loss: 1.04932\n","Epoch: 0 | Iteration: 288/2403 | Classification loss: 0.35295 | Regression loss: 0.39754 | Running loss: 1.04829\n","Epoch: 0 | Iteration: 289/2403 | Classification loss: 0.32205 | Regression loss: 0.37233 | Running loss: 1.04706\n","Epoch: 0 | Iteration: 290/2403 | Classification loss: 0.24811 | Regression loss: 0.28879 | Running loss: 1.04530\n","Epoch: 0 | Iteration: 291/2403 | Classification loss: 0.36789 | Regression loss: 0.42469 | Running loss: 1.04443\n","Epoch: 0 | Iteration: 292/2403 | Classification loss: 0.38998 | Regression loss: 0.42940 | Running loss: 1.04366\n","Epoch: 0 | Iteration: 293/2403 | Classification loss: 0.42318 | Regression loss: 0.33383 | Running loss: 1.04269\n","Epoch: 0 | Iteration: 294/2403 | Classification loss: 0.36150 | Regression loss: 0.28892 | Running loss: 1.04135\n","Epoch: 0 | Iteration: 295/2403 | Classification loss: 0.33626 | Regression loss: 0.32246 | Running loss: 1.04005\n","Epoch: 0 | Iteration: 296/2403 | Classification loss: 0.24660 | Regression loss: 0.39612 | Running loss: 1.03871\n","Epoch: 0 | Iteration: 297/2403 | Classification loss: 0.38160 | Regression loss: 0.32969 | Running loss: 1.03761\n","Epoch: 0 | Iteration: 298/2403 | Classification loss: 0.30135 | Regression loss: 0.31545 | Running loss: 1.03620\n","Epoch: 0 | Iteration: 299/2403 | Classification loss: 0.37973 | Regression loss: 0.36171 | Running loss: 1.03521\n","Epoch: 0 | Iteration: 300/2403 | Classification loss: 0.29804 | Regression loss: 0.34309 | Running loss: 1.03390\n","Epoch: 0 | Iteration: 301/2403 | Classification loss: 0.18183 | Regression loss: 0.25746 | Running loss: 1.03192\n","Epoch: 0 | Iteration: 302/2403 | Classification loss: 0.40688 | Regression loss: 0.24730 | Running loss: 1.03067\n","Epoch: 0 | Iteration: 303/2403 | Classification loss: 0.37459 | Regression loss: 0.35498 | Running loss: 1.02968\n","Epoch: 0 | Iteration: 304/2403 | Classification loss: 0.56842 | Regression loss: 0.49102 | Running loss: 1.02978\n","Epoch: 0 | Iteration: 305/2403 | Classification loss: 0.24949 | Regression loss: 0.25451 | Running loss: 1.02805\n","Epoch: 0 | Iteration: 306/2403 | Classification loss: 0.45681 | Regression loss: 0.34185 | Running loss: 1.02730\n","Epoch: 0 | Iteration: 307/2403 | Classification loss: 0.64385 | Regression loss: 0.40116 | Running loss: 1.02736\n","Epoch: 0 | Iteration: 308/2403 | Classification loss: 0.43097 | Regression loss: 0.40174 | Running loss: 1.02673\n","Epoch: 0 | Iteration: 309/2403 | Classification loss: 0.24276 | Regression loss: 0.35833 | Running loss: 1.02535\n","Epoch: 0 | Iteration: 310/2403 | Classification loss: 0.71639 | Regression loss: 0.38317 | Running loss: 1.02559\n","Epoch: 0 | Iteration: 311/2403 | Classification loss: 2.58613 | Regression loss: 0.70543 | Running loss: 1.03288\n","Epoch: 0 | Iteration: 312/2403 | Classification loss: 0.27156 | Regression loss: 0.37191 | Running loss: 1.03163\n","Epoch: 0 | Iteration: 313/2403 | Classification loss: 0.38083 | Regression loss: 0.36049 | Running loss: 1.03070\n","Epoch: 0 | Iteration: 314/2403 | Classification loss: 0.46215 | Regression loss: 0.31222 | Running loss: 1.02988\n","Epoch: 0 | Iteration: 315/2403 | Classification loss: 0.53533 | Regression loss: 0.76574 | Running loss: 1.03075\n","Epoch: 0 | Iteration: 316/2403 | Classification loss: 0.33719 | Regression loss: 0.36706 | Running loss: 1.02971\n","Epoch: 0 | Iteration: 317/2403 | Classification loss: 0.31196 | Regression loss: 0.34652 | Running loss: 1.02854\n","Epoch: 0 | Iteration: 318/2403 | Classification loss: 0.35156 | Regression loss: 0.35509 | Running loss: 1.02753\n","Epoch: 0 | Iteration: 319/2403 | Classification loss: 0.48338 | Regression loss: 0.37826 | Running loss: 1.02701\n","Epoch: 0 | Iteration: 320/2403 | Classification loss: 0.49842 | Regression loss: 0.37350 | Running loss: 1.02652\n","Epoch: 0 | Iteration: 321/2403 | Classification loss: 0.37301 | Regression loss: 0.29972 | Running loss: 1.02542\n","Epoch: 0 | Iteration: 322/2403 | Classification loss: 0.52732 | Regression loss: 0.45285 | Running loss: 1.02528\n","Epoch: 0 | Iteration: 323/2403 | Classification loss: 0.28673 | Regression loss: 0.25589 | Running loss: 1.02379\n","Epoch: 0 | Iteration: 324/2403 | Classification loss: 0.77526 | Regression loss: 0.50178 | Running loss: 1.02457\n","Epoch: 0 | Iteration: 325/2403 | Classification loss: 0.53809 | Regression loss: 0.39380 | Running loss: 1.02428\n","Epoch: 0 | Iteration: 326/2403 | Classification loss: 0.47130 | Regression loss: 0.46539 | Running loss: 1.02401\n","Epoch: 0 | Iteration: 327/2403 | Classification loss: 0.36087 | Regression loss: 0.32080 | Running loss: 1.02297\n","Epoch: 0 | Iteration: 328/2403 | Classification loss: 0.37650 | Regression loss: 0.39218 | Running loss: 1.02219\n","Epoch: 0 | Iteration: 329/2403 | Classification loss: 0.36028 | Regression loss: 0.40606 | Running loss: 1.02141\n","Epoch: 0 | Iteration: 330/2403 | Classification loss: 0.39333 | Regression loss: 0.89838 | Running loss: 1.02223\n","Epoch: 0 | Iteration: 331/2403 | Classification loss: 0.33386 | Regression loss: 0.36566 | Running loss: 1.02126\n","Epoch: 0 | Iteration: 332/2403 | Classification loss: 0.52643 | Regression loss: 0.41137 | Running loss: 1.02101\n","Epoch: 0 | Iteration: 333/2403 | Classification loss: 0.46938 | Regression loss: 0.36508 | Running loss: 1.02045\n","Epoch: 0 | Iteration: 334/2403 | Classification loss: 0.32587 | Regression loss: 0.37781 | Running loss: 1.01950\n","Epoch: 0 | Iteration: 335/2403 | Classification loss: 0.31042 | Regression loss: 0.32218 | Running loss: 1.01834\n","Epoch: 0 | Iteration: 336/2403 | Classification loss: 0.39931 | Regression loss: 0.43323 | Running loss: 1.01779\n","Epoch: 0 | Iteration: 337/2403 | Classification loss: 0.46354 | Regression loss: 0.45160 | Running loss: 1.01749\n","Epoch: 0 | Iteration: 338/2403 | Classification loss: 0.30963 | Regression loss: 0.41913 | Running loss: 1.01663\n","Epoch: 0 | Iteration: 339/2403 | Classification loss: 0.37260 | Regression loss: 0.41719 | Running loss: 1.01596\n","Epoch: 0 | Iteration: 340/2403 | Classification loss: 0.43592 | Regression loss: 0.37486 | Running loss: 1.01536\n","Epoch: 0 | Iteration: 341/2403 | Classification loss: 0.50903 | Regression loss: 0.37645 | Running loss: 1.01498\n","Epoch: 0 | Iteration: 342/2403 | Classification loss: 0.34996 | Regression loss: 0.32876 | Running loss: 1.01400\n","Epoch: 0 | Iteration: 343/2403 | Classification loss: 0.39196 | Regression loss: 0.34309 | Running loss: 1.01318\n","Epoch: 0 | Iteration: 344/2403 | Classification loss: 0.34629 | Regression loss: 0.37851 | Running loss: 1.01234\n","Epoch: 0 | Iteration: 345/2403 | Classification loss: 0.30602 | Regression loss: 0.36314 | Running loss: 1.01135\n","Epoch: 0 | Iteration: 346/2403 | Classification loss: 0.32295 | Regression loss: 0.34878 | Running loss: 1.01037\n","Epoch: 0 | Iteration: 347/2403 | Classification loss: 0.38317 | Regression loss: 0.29937 | Running loss: 1.00942\n","Epoch: 0 | Iteration: 348/2403 | Classification loss: 0.58946 | Regression loss: 0.42688 | Running loss: 1.00944\n","Epoch: 0 | Iteration: 349/2403 | Classification loss: 0.43690 | Regression loss: 0.48339 | Running loss: 1.00919\n","Epoch: 0 | Iteration: 350/2403 | Classification loss: 0.37460 | Regression loss: 0.36514 | Running loss: 1.00842\n","Epoch: 0 | Iteration: 351/2403 | Classification loss: 0.30862 | Regression loss: 0.52953 | Running loss: 1.00793\n","Epoch: 0 | Iteration: 352/2403 | Classification loss: 0.23259 | Regression loss: 0.29249 | Running loss: 1.00656\n","Epoch: 0 | Iteration: 353/2403 | Classification loss: 0.42760 | Regression loss: 0.39830 | Running loss: 1.00605\n","Epoch: 0 | Iteration: 354/2403 | Classification loss: 0.36624 | Regression loss: 0.39460 | Running loss: 1.00536\n","Epoch: 0 | Iteration: 355/2403 | Classification loss: 0.45291 | Regression loss: 0.42595 | Running loss: 1.00500\n","Epoch: 0 | Iteration: 356/2403 | Classification loss: 0.51595 | Regression loss: 0.38795 | Running loss: 1.00472\n","Epoch: 0 | Iteration: 357/2403 | Classification loss: 0.34431 | Regression loss: 0.28075 | Running loss: 1.00365\n","Epoch: 0 | Iteration: 358/2403 | Classification loss: 0.60029 | Regression loss: 0.40995 | Running loss: 1.00367\n","Epoch: 0 | Iteration: 359/2403 | Classification loss: 0.28824 | Regression loss: 0.26672 | Running loss: 1.00242\n","Epoch: 0 | Iteration: 360/2403 | Classification loss: 0.64828 | Regression loss: 0.41416 | Running loss: 1.00259\n","Epoch: 0 | Iteration: 361/2403 | Classification loss: 0.32615 | Regression loss: 0.34315 | Running loss: 1.00166\n","Epoch: 0 | Iteration: 362/2403 | Classification loss: 0.51613 | Regression loss: 0.33666 | Running loss: 1.00125\n","Epoch: 0 | Iteration: 363/2403 | Classification loss: 0.49385 | Regression loss: 0.52457 | Running loss: 1.00130\n","Epoch: 0 | Iteration: 364/2403 | Classification loss: 0.25725 | Regression loss: 0.23316 | Running loss: 0.99990\n","Epoch: 0 | Iteration: 365/2403 | Classification loss: 0.42855 | Regression loss: 0.41850 | Running loss: 0.99948\n","Epoch: 0 | Iteration: 366/2403 | Classification loss: 0.30133 | Regression loss: 0.23474 | Running loss: 0.99821\n","Epoch: 0 | Iteration: 367/2403 | Classification loss: 0.24351 | Regression loss: 0.30838 | Running loss: 0.99700\n","Epoch: 0 | Iteration: 368/2403 | Classification loss: 0.45046 | Regression loss: 0.37014 | Running loss: 0.99652\n","Epoch: 0 | Iteration: 369/2403 | Classification loss: 0.19779 | Regression loss: 0.27553 | Running loss: 0.99510\n","Epoch: 0 | Iteration: 370/2403 | Classification loss: 0.30698 | Regression loss: 0.34240 | Running loss: 0.99416\n","Epoch: 0 | Iteration: 371/2403 | Classification loss: 0.39789 | Regression loss: 0.44107 | Running loss: 0.99375\n","Epoch: 0 | Iteration: 372/2403 | Classification loss: 0.39356 | Regression loss: 0.32641 | Running loss: 0.99301\n","Epoch: 0 | Iteration: 373/2403 | Classification loss: 0.32109 | Regression loss: 0.35895 | Running loss: 0.99217\n","Epoch: 0 | Iteration: 374/2403 | Classification loss: 0.46960 | Regression loss: 0.46086 | Running loss: 0.99201\n","Epoch: 0 | Iteration: 375/2403 | Classification loss: 0.52359 | Regression loss: 0.39498 | Running loss: 0.99181\n","Epoch: 0 | Iteration: 376/2403 | Classification loss: 0.42552 | Regression loss: 0.42965 | Running loss: 0.99145\n","Epoch: 0 | Iteration: 377/2403 | Classification loss: 0.24219 | Regression loss: 0.36202 | Running loss: 0.99042\n","Epoch: 0 | Iteration: 378/2403 | Classification loss: 0.50428 | Regression loss: 0.43213 | Running loss: 0.99028\n","Epoch: 0 | Iteration: 379/2403 | Classification loss: 0.57327 | Regression loss: 0.48058 | Running loss: 0.99044\n","Epoch: 0 | Iteration: 380/2403 | Classification loss: 0.29109 | Regression loss: 0.35638 | Running loss: 0.98954\n","Epoch: 0 | Iteration: 381/2403 | Classification loss: 0.41614 | Regression loss: 0.32643 | Running loss: 0.98889\n","Epoch: 0 | Iteration: 382/2403 | Classification loss: 0.51958 | Regression loss: 0.39372 | Running loss: 0.98870\n","Epoch: 0 | Iteration: 383/2403 | Classification loss: 0.37353 | Regression loss: 0.36168 | Running loss: 0.98803\n","Epoch: 0 | Iteration: 384/2403 | Classification loss: 0.41687 | Regression loss: 0.50483 | Running loss: 0.98786\n","Epoch: 0 | Iteration: 385/2403 | Classification loss: 0.29652 | Regression loss: 0.28111 | Running loss: 0.98680\n","Epoch: 0 | Iteration: 386/2403 | Classification loss: 0.38920 | Regression loss: 0.42282 | Running loss: 0.98634\n","Epoch: 0 | Iteration: 387/2403 | Classification loss: 0.36262 | Regression loss: 0.37709 | Running loss: 0.98571\n","Epoch: 0 | Iteration: 388/2403 | Classification loss: 0.35747 | Regression loss: 0.26316 | Running loss: 0.98476\n","Epoch: 0 | Iteration: 389/2403 | Classification loss: 0.57595 | Regression loss: 0.62268 | Running loss: 0.98531\n","Epoch: 0 | Iteration: 390/2403 | Classification loss: 0.71218 | Regression loss: 0.61669 | Running loss: 0.98620\n","Epoch: 0 | Iteration: 391/2403 | Classification loss: 0.48311 | Regression loss: 0.31263 | Running loss: 0.98571\n","Epoch: 0 | Iteration: 392/2403 | Classification loss: 0.25361 | Regression loss: 0.31647 | Running loss: 0.98465\n","Epoch: 0 | Iteration: 393/2403 | Classification loss: 0.45886 | Regression loss: 0.41296 | Running loss: 0.98436\n","Epoch: 0 | Iteration: 394/2403 | Classification loss: 0.32902 | Regression loss: 0.33832 | Running loss: 0.98356\n","Epoch: 0 | Iteration: 395/2403 | Classification loss: 0.27103 | Regression loss: 0.33599 | Running loss: 0.98260\n","Epoch: 0 | Iteration: 396/2403 | Classification loss: 0.29225 | Regression loss: 0.35462 | Running loss: 0.98176\n","Epoch: 0 | Iteration: 397/2403 | Classification loss: 0.34037 | Regression loss: 0.31166 | Running loss: 0.98092\n","Epoch: 0 | Iteration: 398/2403 | Classification loss: 1.22064 | Regression loss: 0.43378 | Running loss: 0.98262\n","Epoch: 0 | Iteration: 399/2403 | Classification loss: 0.56412 | Regression loss: 0.34195 | Running loss: 0.98243\n","Epoch: 0 | Iteration: 400/2403 | Classification loss: 0.42788 | Regression loss: 0.45843 | Running loss: 0.98218\n","Epoch: 0 | Iteration: 401/2403 | Classification loss: 0.42557 | Regression loss: 0.33544 | Running loss: 0.98163\n","Epoch: 0 | Iteration: 402/2403 | Classification loss: 0.40648 | Regression loss: 0.45262 | Running loss: 0.98133\n","Epoch: 0 | Iteration: 403/2403 | Classification loss: 0.48551 | Regression loss: 0.39864 | Running loss: 0.98109\n","Epoch: 0 | Iteration: 404/2403 | Classification loss: 0.72820 | Regression loss: 0.46730 | Running loss: 0.98162\n","Epoch: 0 | Iteration: 405/2403 | Classification loss: 0.58957 | Regression loss: 0.40747 | Running loss: 0.98166\n","Epoch: 0 | Iteration: 406/2403 | Classification loss: 0.49552 | Regression loss: 0.39436 | Running loss: 0.98143\n","Epoch: 0 | Iteration: 407/2403 | Classification loss: 0.67073 | Regression loss: 0.49537 | Running loss: 0.98188\n","Epoch: 0 | Iteration: 408/2403 | Classification loss: 0.34635 | Regression loss: 0.34254 | Running loss: 0.98117\n","Epoch: 0 | Iteration: 409/2403 | Classification loss: 0.21607 | Regression loss: 0.25180 | Running loss: 0.97991\n","Epoch: 0 | Iteration: 410/2403 | Classification loss: 0.63004 | Regression loss: 0.40219 | Running loss: 0.98004\n","Epoch: 0 | Iteration: 411/2403 | Classification loss: 0.33390 | Regression loss: 0.26032 | Running loss: 0.97910\n","Epoch: 0 | Iteration: 412/2403 | Classification loss: 0.26529 | Regression loss: 0.25925 | Running loss: 0.97800\n","Epoch: 0 | Iteration: 413/2403 | Classification loss: 0.47149 | Regression loss: 0.36133 | Running loss: 0.97764\n","Epoch: 0 | Iteration: 414/2403 | Classification loss: 0.35311 | Regression loss: 0.36694 | Running loss: 0.97702\n","Epoch: 0 | Iteration: 415/2403 | Classification loss: 0.47622 | Regression loss: 0.34581 | Running loss: 0.97665\n","Epoch: 0 | Iteration: 416/2403 | Classification loss: 0.38749 | Regression loss: 0.61191 | Running loss: 0.97670\n","Epoch: 0 | Iteration: 417/2403 | Classification loss: 0.48941 | Regression loss: 0.36306 | Running loss: 0.97641\n","Epoch: 0 | Iteration: 418/2403 | Classification loss: 0.26167 | Regression loss: 0.36823 | Running loss: 0.97558\n","Epoch: 0 | Iteration: 419/2403 | Classification loss: 0.28815 | Regression loss: 0.29030 | Running loss: 0.97463\n","Epoch: 0 | Iteration: 420/2403 | Classification loss: 0.30923 | Regression loss: 0.33453 | Running loss: 0.97384\n","Epoch: 0 | Iteration: 421/2403 | Classification loss: 0.40463 | Regression loss: 0.36622 | Running loss: 0.97336\n","Epoch: 0 | Iteration: 422/2403 | Classification loss: 0.48600 | Regression loss: 0.37785 | Running loss: 0.97310\n","Epoch: 0 | Iteration: 423/2403 | Classification loss: 0.42709 | Regression loss: 0.42096 | Running loss: 0.97280\n","Epoch: 0 | Iteration: 424/2403 | Classification loss: 0.35922 | Regression loss: 0.34509 | Running loss: 0.97217\n","Epoch: 0 | Iteration: 425/2403 | Classification loss: 0.24685 | Regression loss: 0.26741 | Running loss: 0.97109\n","Epoch: 0 | Iteration: 426/2403 | Classification loss: 0.42829 | Regression loss: 0.40282 | Running loss: 0.97076\n","Epoch: 0 | Iteration: 427/2403 | Classification loss: 0.45119 | Regression loss: 0.42059 | Running loss: 0.97053\n","Epoch: 0 | Iteration: 428/2403 | Classification loss: 0.21261 | Regression loss: 0.25930 | Running loss: 0.96937\n","Epoch: 0 | Iteration: 429/2403 | Classification loss: 0.32983 | Regression loss: 0.58949 | Running loss: 0.96925\n","Epoch: 0 | Iteration: 430/2403 | Classification loss: 0.20142 | Regression loss: 0.26155 | Running loss: 0.96807\n","Epoch: 0 | Iteration: 431/2403 | Classification loss: 0.31087 | Regression loss: 0.58226 | Running loss: 0.96790\n","Epoch: 0 | Iteration: 432/2403 | Classification loss: 0.43212 | Regression loss: 0.36036 | Running loss: 0.96749\n","Epoch: 0 | Iteration: 433/2403 | Classification loss: 1.63698 | Regression loss: 0.58288 | Running loss: 0.97039\n","Epoch: 0 | Iteration: 434/2403 | Classification loss: 0.36580 | Regression loss: 0.31230 | Running loss: 0.96971\n","Epoch: 0 | Iteration: 435/2403 | Classification loss: 0.53996 | Regression loss: 0.62722 | Running loss: 0.97017\n","Epoch: 0 | Iteration: 436/2403 | Classification loss: 0.14644 | Regression loss: 0.20439 | Running loss: 0.96875\n","Epoch: 0 | Iteration: 437/2403 | Classification loss: 0.47354 | Regression loss: 0.34189 | Running loss: 0.96840\n","Epoch: 0 | Iteration: 438/2403 | Classification loss: 0.33359 | Regression loss: 0.60809 | Running loss: 0.96833\n","Epoch: 0 | Iteration: 439/2403 | Classification loss: 0.24602 | Regression loss: 0.26382 | Running loss: 0.96729\n","Epoch: 0 | Iteration: 440/2403 | Classification loss: 0.26046 | Regression loss: 0.34338 | Running loss: 0.96646\n","Epoch: 0 | Iteration: 441/2403 | Classification loss: 0.30318 | Regression loss: 0.31198 | Running loss: 0.96567\n","Epoch: 0 | Iteration: 442/2403 | Classification loss: 0.21259 | Regression loss: 0.24355 | Running loss: 0.96451\n","Epoch: 0 | Iteration: 443/2403 | Classification loss: 0.29825 | Regression loss: 0.32561 | Running loss: 0.96375\n","Epoch: 0 | Iteration: 444/2403 | Classification loss: 0.24098 | Regression loss: 0.25453 | Running loss: 0.96269\n","Epoch: 0 | Iteration: 445/2403 | Classification loss: 0.56540 | Regression loss: 0.37898 | Running loss: 0.96265\n","Epoch: 0 | Iteration: 446/2403 | Classification loss: 0.54272 | Regression loss: 0.40820 | Running loss: 0.96262\n","Epoch: 0 | Iteration: 447/2403 | Classification loss: 0.28744 | Regression loss: 0.34533 | Running loss: 0.96189\n","Epoch: 0 | Iteration: 448/2403 | Classification loss: 0.37677 | Regression loss: 0.40445 | Running loss: 0.96148\n","Epoch: 0 | Iteration: 449/2403 | Classification loss: 0.30636 | Regression loss: 0.42216 | Running loss: 0.96096\n","Epoch: 0 | Iteration: 450/2403 | Classification loss: 0.73035 | Regression loss: 0.53385 | Running loss: 0.96164\n","Epoch: 0 | Iteration: 451/2403 | Classification loss: 0.28276 | Regression loss: 0.29374 | Running loss: 0.96078\n","Epoch: 0 | Iteration: 452/2403 | Classification loss: 0.67898 | Regression loss: 0.45178 | Running loss: 0.96116\n","Epoch: 0 | Iteration: 453/2403 | Classification loss: 0.42368 | Regression loss: 0.25324 | Running loss: 0.96053\n","Epoch: 0 | Iteration: 454/2403 | Classification loss: 0.43011 | Regression loss: 0.33887 | Running loss: 0.96011\n","Epoch: 0 | Iteration: 455/2403 | Classification loss: 0.38982 | Regression loss: 0.30064 | Running loss: 0.95952\n","Epoch: 0 | Iteration: 456/2403 | Classification loss: 0.33823 | Regression loss: 0.39098 | Running loss: 0.95901\n","Epoch: 0 | Iteration: 457/2403 | Classification loss: 0.51502 | Regression loss: 0.32531 | Running loss: 0.95875\n","Epoch: 0 | Iteration: 458/2403 | Classification loss: 0.39573 | Regression loss: 0.36643 | Running loss: 0.95832\n","Epoch: 0 | Iteration: 459/2403 | Classification loss: 0.41082 | Regression loss: 0.39132 | Running loss: 0.95798\n","Epoch: 0 | Iteration: 460/2403 | Classification loss: 0.44519 | Regression loss: 0.37012 | Running loss: 0.95767\n","Epoch: 0 | Iteration: 461/2403 | Classification loss: 0.28039 | Regression loss: 0.28212 | Running loss: 0.95682\n","Epoch: 0 | Iteration: 462/2403 | Classification loss: 0.42731 | Regression loss: 0.33425 | Running loss: 0.95639\n","Epoch: 0 | Iteration: 463/2403 | Classification loss: 0.24444 | Regression loss: 0.31662 | Running loss: 0.95554\n","Epoch: 0 | Iteration: 464/2403 | Classification loss: 0.30898 | Regression loss: 0.32865 | Running loss: 0.95485\n","Epoch: 0 | Iteration: 465/2403 | Classification loss: 0.29098 | Regression loss: 0.33528 | Running loss: 0.95415\n","Epoch: 0 | Iteration: 466/2403 | Classification loss: 0.34404 | Regression loss: 0.46198 | Running loss: 0.95383\n","Epoch: 0 | Iteration: 467/2403 | Classification loss: 0.27304 | Regression loss: 0.38213 | Running loss: 0.95319\n","Epoch: 0 | Iteration: 468/2403 | Classification loss: 0.29150 | Regression loss: 0.31440 | Running loss: 0.95245\n","Epoch: 0 | Iteration: 469/2403 | Classification loss: 0.59726 | Regression loss: 0.39430 | Running loss: 0.95253\n","Epoch: 0 | Iteration: 470/2403 | Classification loss: 0.36727 | Regression loss: 0.49605 | Running loss: 0.95234\n","Epoch: 0 | Iteration: 471/2403 | Classification loss: 0.29796 | Regression loss: 0.39917 | Running loss: 0.95180\n","Epoch: 0 | Iteration: 472/2403 | Classification loss: 0.33024 | Regression loss: 0.26859 | Running loss: 0.95105\n","Epoch: 0 | Iteration: 473/2403 | Classification loss: 0.29114 | Regression loss: 0.33882 | Running loss: 0.95037\n","Epoch: 0 | Iteration: 474/2403 | Classification loss: 0.41214 | Regression loss: 0.34428 | Running loss: 0.94996\n","Epoch: 0 | Iteration: 475/2403 | Classification loss: 0.25397 | Regression loss: 0.22755 | Running loss: 0.94898\n","Epoch: 0 | Iteration: 476/2403 | Classification loss: 0.29509 | Regression loss: 0.30273 | Running loss: 0.94824\n","Epoch: 0 | Iteration: 477/2403 | Classification loss: 0.46774 | Regression loss: 0.36291 | Running loss: 0.94799\n","Epoch: 0 | Iteration: 478/2403 | Classification loss: 0.30401 | Regression loss: 0.36184 | Running loss: 0.94740\n","Epoch: 0 | Iteration: 479/2403 | Classification loss: 0.39914 | Regression loss: 0.41070 | Running loss: 0.94712\n","Epoch: 0 | Iteration: 480/2403 | Classification loss: 0.24299 | Regression loss: 0.30137 | Running loss: 0.94628\n","Epoch: 0 | Iteration: 481/2403 | Classification loss: 0.35989 | Regression loss: 0.29114 | Running loss: 0.94566\n","Epoch: 0 | Iteration: 482/2403 | Classification loss: 0.39505 | Regression loss: 0.41647 | Running loss: 0.94538\n","Epoch: 0 | Iteration: 483/2403 | Classification loss: 0.38025 | Regression loss: 0.38620 | Running loss: 0.94501\n","Epoch: 0 | Iteration: 484/2403 | Classification loss: 0.28178 | Regression loss: 0.34502 | Running loss: 0.94436\n","Epoch: 0 | Iteration: 485/2403 | Classification loss: 0.26908 | Regression loss: 0.25370 | Running loss: 0.94349\n","Epoch: 0 | Iteration: 486/2403 | Classification loss: 0.55070 | Regression loss: 0.34450 | Running loss: 0.94339\n","Epoch: 0 | Iteration: 487/2403 | Classification loss: 0.60851 | Regression loss: 0.48466 | Running loss: 0.94370\n","Epoch: 0 | Iteration: 488/2403 | Classification loss: 0.29085 | Regression loss: 0.26727 | Running loss: 0.94291\n","Epoch: 0 | Iteration: 489/2403 | Classification loss: 0.52749 | Regression loss: 0.36615 | Running loss: 0.94280\n","Epoch: 0 | Iteration: 490/2403 | Classification loss: 0.30926 | Regression loss: 0.26924 | Running loss: 0.94206\n","Epoch: 0 | Iteration: 491/2403 | Classification loss: 0.53092 | Regression loss: 0.47085 | Running loss: 0.94218\n","Epoch: 0 | Iteration: 492/2403 | Classification loss: 0.36461 | Regression loss: 0.32161 | Running loss: 0.94166\n","Epoch: 0 | Iteration: 493/2403 | Classification loss: 0.25277 | Regression loss: 0.23080 | Running loss: 0.94073\n","Epoch: 0 | Iteration: 494/2403 | Classification loss: 0.41211 | Regression loss: 0.41879 | Running loss: 0.94051\n","Epoch: 0 | Iteration: 495/2403 | Classification loss: 0.22867 | Regression loss: 0.24818 | Running loss: 0.93957\n","Epoch: 0 | Iteration: 496/2403 | Classification loss: 0.41179 | Regression loss: 0.37974 | Running loss: 0.93928\n","Epoch: 0 | Iteration: 497/2403 | Classification loss: 0.36272 | Regression loss: 0.28342 | Running loss: 0.93869\n","Epoch: 0 | Iteration: 498/2403 | Classification loss: 0.26673 | Regression loss: 0.26043 | Running loss: 0.93786\n","Epoch: 0 | Iteration: 499/2403 | Classification loss: 0.39360 | Regression loss: 0.31749 | Running loss: 0.93741\n","Epoch: 0 | Iteration: 500/2403 | Classification loss: 0.42724 | Regression loss: 0.29216 | Running loss: 0.93697\n","Epoch: 0 | Iteration: 501/2403 | Classification loss: 1.10092 | Regression loss: 0.67257 | Running loss: 0.93864\n","Epoch: 0 | Iteration: 502/2403 | Classification loss: 0.40789 | Regression loss: 0.41568 | Running loss: 0.93841\n","Epoch: 0 | Iteration: 503/2403 | Classification loss: 0.27805 | Regression loss: 0.31661 | Running loss: 0.93773\n","Epoch: 0 | Iteration: 504/2403 | Classification loss: 0.29103 | Regression loss: 0.35268 | Running loss: 0.93714\n","Epoch: 0 | Iteration: 505/2403 | Classification loss: 0.29169 | Regression loss: 0.28671 | Running loss: 0.93643\n","Epoch: 0 | Iteration: 506/2403 | Classification loss: 0.35376 | Regression loss: 0.35949 | Running loss: 0.93599\n","Epoch: 0 | Iteration: 507/2403 | Classification loss: 0.47146 | Regression loss: 0.65183 | Running loss: 0.93636\n","Epoch: 0 | Iteration: 508/2403 | Classification loss: 0.27739 | Regression loss: 0.35621 | Running loss: 0.93577\n","Epoch: 0 | Iteration: 509/2403 | Classification loss: 0.34301 | Regression loss: 0.31902 | Running loss: 0.93523\n","Epoch: 0 | Iteration: 510/2403 | Classification loss: 0.24518 | Regression loss: 0.32190 | Running loss: 0.93451\n","Epoch: 0 | Iteration: 511/2403 | Classification loss: 0.42710 | Regression loss: 0.38990 | Running loss: 0.93428\n","Epoch: 0 | Iteration: 512/2403 | Classification loss: 0.60115 | Regression loss: 0.43812 | Running loss: 0.93448\n","Epoch: 0 | Iteration: 513/2403 | Classification loss: 0.34140 | Regression loss: 0.29175 | Running loss: 0.93389\n","Epoch: 0 | Iteration: 514/2403 | Classification loss: 0.37965 | Regression loss: 0.40280 | Running loss: 0.93360\n","Epoch: 0 | Iteration: 515/2403 | Classification loss: 0.26666 | Regression loss: 0.32849 | Running loss: 0.93294\n","Epoch: 0 | Iteration: 516/2403 | Classification loss: 0.21264 | Regression loss: 0.25942 | Running loss: 0.93205\n","Epoch: 0 | Iteration: 517/2403 | Classification loss: 0.32106 | Regression loss: 0.35763 | Running loss: 0.93156\n","Epoch: 0 | Iteration: 518/2403 | Classification loss: 0.23097 | Regression loss: 0.31190 | Running loss: 0.93081\n","Epoch: 0 | Iteration: 519/2403 | Classification loss: 0.44722 | Regression loss: 0.30603 | Running loss: 0.93047\n","Epoch: 0 | Iteration: 520/2403 | Classification loss: 0.18100 | Regression loss: 0.30605 | Running loss: 0.92961\n","Epoch: 0 | Iteration: 521/2403 | Classification loss: 0.54847 | Regression loss: 0.42140 | Running loss: 0.92969\n","Epoch: 0 | Iteration: 522/2403 | Classification loss: 0.25425 | Regression loss: 0.33150 | Running loss: 0.92903\n","Epoch: 0 | Iteration: 523/2403 | Classification loss: 0.39922 | Regression loss: 0.44650 | Running loss: 0.92887\n","Epoch: 0 | Iteration: 524/2403 | Classification loss: 0.69696 | Regression loss: 0.52992 | Running loss: 0.92944\n","Epoch: 0 | Iteration: 525/2403 | Classification loss: 0.27419 | Regression loss: 0.32666 | Running loss: 0.92881\n","Epoch: 0 | Iteration: 526/2403 | Classification loss: 0.21505 | Regression loss: 0.28695 | Running loss: 0.92800\n","Epoch: 0 | Iteration: 527/2403 | Classification loss: 0.38934 | Regression loss: 0.28221 | Running loss: 0.92752\n","Epoch: 0 | Iteration: 528/2403 | Classification loss: 0.20931 | Regression loss: 0.30649 | Running loss: 0.92674\n","Epoch: 0 | Iteration: 529/2403 | Classification loss: 0.40726 | Regression loss: 0.39279 | Running loss: 0.92650\n","Epoch: 0 | Iteration: 530/2403 | Classification loss: 0.36313 | Regression loss: 0.32145 | Running loss: 0.92604\n","Epoch: 0 | Iteration: 531/2403 | Classification loss: 0.35588 | Regression loss: 0.36153 | Running loss: 0.92565\n","Epoch: 0 | Iteration: 532/2403 | Classification loss: 0.41383 | Regression loss: 0.35052 | Running loss: 0.92535\n","Epoch: 0 | Iteration: 533/2403 | Classification loss: 0.26256 | Regression loss: 0.29591 | Running loss: 0.92466\n","Epoch: 0 | Iteration: 534/2403 | Classification loss: 0.21300 | Regression loss: 0.34697 | Running loss: 0.92397\n","Epoch: 0 | Iteration: 535/2403 | Classification loss: 0.29834 | Regression loss: 0.30712 | Running loss: 0.92338\n","Epoch: 0 | Iteration: 536/2403 | Classification loss: 0.27600 | Regression loss: 0.33224 | Running loss: 0.92279\n","Epoch: 0 | Iteration: 537/2403 | Classification loss: 0.29083 | Regression loss: 0.43087 | Running loss: 0.92242\n","Epoch: 0 | Iteration: 538/2403 | Classification loss: 0.31107 | Regression loss: 0.40477 | Running loss: 0.92203\n","Epoch: 0 | Iteration: 539/2403 | Classification loss: 0.24531 | Regression loss: 0.35772 | Running loss: 0.92144\n","Epoch: 0 | Iteration: 540/2403 | Classification loss: 0.24088 | Regression loss: 0.28372 | Running loss: 0.92071\n","Epoch: 0 | Iteration: 541/2403 | Classification loss: 0.39373 | Regression loss: 0.31386 | Running loss: 0.92031\n","Epoch: 0 | Iteration: 542/2403 | Classification loss: 0.15940 | Regression loss: 0.21756 | Running loss: 0.91931\n","Epoch: 0 | Iteration: 543/2403 | Classification loss: 0.34277 | Regression loss: 0.37317 | Running loss: 0.91893\n","Epoch: 0 | Iteration: 544/2403 | Classification loss: 0.21235 | Regression loss: 0.32473 | Running loss: 0.91823\n","Epoch: 0 | Iteration: 545/2403 | Classification loss: 0.54170 | Regression loss: 0.50724 | Running loss: 0.91847\n","Epoch: 0 | Iteration: 546/2403 | Classification loss: 0.45120 | Regression loss: 0.42039 | Running loss: 0.91839\n","Epoch: 0 | Iteration: 547/2403 | Classification loss: 0.40624 | Regression loss: 0.37216 | Running loss: 0.91813\n","Epoch: 0 | Iteration: 548/2403 | Classification loss: 0.21192 | Regression loss: 0.30646 | Running loss: 0.91740\n","Epoch: 0 | Iteration: 549/2403 | Classification loss: 0.62676 | Regression loss: 0.42079 | Running loss: 0.91764\n","Epoch: 0 | Iteration: 550/2403 | Classification loss: 0.28924 | Regression loss: 0.23818 | Running loss: 0.91693\n","Epoch: 0 | Iteration: 551/2403 | Classification loss: 0.27707 | Regression loss: 0.27819 | Running loss: 0.91627\n","Epoch: 0 | Iteration: 552/2403 | Classification loss: 0.41444 | Regression loss: 0.35028 | Running loss: 0.91600\n","Epoch: 0 | Iteration: 553/2403 | Classification loss: 0.44224 | Regression loss: 0.60991 | Running loss: 0.91624\n","Epoch: 0 | Iteration: 554/2403 | Classification loss: 0.25161 | Regression loss: 0.31028 | Running loss: 0.91560\n","Epoch: 0 | Iteration: 555/2403 | Classification loss: 0.26581 | Regression loss: 0.32663 | Running loss: 0.91502\n","Epoch: 0 | Iteration: 556/2403 | Classification loss: 0.32434 | Regression loss: 0.32650 | Running loss: 0.91455\n","Epoch: 0 | Iteration: 557/2403 | Classification loss: 0.31571 | Regression loss: 0.27159 | Running loss: 0.91396\n","Epoch: 0 | Iteration: 558/2403 | Classification loss: 0.39003 | Regression loss: 0.31957 | Running loss: 0.91359\n","Epoch: 0 | Iteration: 559/2403 | Classification loss: 0.78653 | Regression loss: 0.51202 | Running loss: 0.91428\n","Epoch: 0 | Iteration: 560/2403 | Classification loss: 0.31888 | Regression loss: 0.28016 | Running loss: 0.91372\n","Epoch: 0 | Iteration: 561/2403 | Classification loss: 1.00517 | Regression loss: 0.47945 | Running loss: 0.91474\n","Epoch: 0 | Iteration: 562/2403 | Classification loss: 0.57064 | Regression loss: 0.43650 | Running loss: 0.91490\n","Epoch: 0 | Iteration: 563/2403 | Classification loss: 0.67083 | Regression loss: 0.44991 | Running loss: 0.91527\n","Epoch: 0 | Iteration: 564/2403 | Classification loss: 0.31240 | Regression loss: 0.36099 | Running loss: 0.91484\n","Epoch: 0 | Iteration: 565/2403 | Classification loss: 0.56685 | Regression loss: 0.54985 | Running loss: 0.91519\n","Epoch: 0 | Iteration: 566/2403 | Classification loss: 0.33127 | Regression loss: 0.35049 | Running loss: 0.91478\n","Epoch: 0 | Iteration: 567/2403 | Classification loss: 0.22734 | Regression loss: 0.40814 | Running loss: 0.91429\n","Epoch: 0 | Iteration: 568/2403 | Classification loss: 0.45952 | Regression loss: 0.40272 | Running loss: 0.91420\n","Epoch: 0 | Iteration: 569/2403 | Classification loss: 0.26132 | Regression loss: 0.38127 | Running loss: 0.91372\n","Epoch: 0 | Iteration: 570/2403 | Classification loss: 0.35118 | Regression loss: 0.32799 | Running loss: 0.91331\n","Epoch: 0 | Iteration: 571/2403 | Classification loss: 0.51443 | Regression loss: 0.37164 | Running loss: 0.91326\n","Epoch: 0 | Iteration: 572/2403 | Classification loss: 0.43377 | Regression loss: 0.35729 | Running loss: 0.91305\n","Epoch: 0 | Iteration: 573/2403 | Classification loss: 0.44297 | Regression loss: 0.39909 | Running loss: 0.91292\n","Epoch: 0 | Iteration: 574/2403 | Classification loss: 0.39671 | Regression loss: 0.42943 | Running loss: 0.91277\n","Epoch: 0 | Iteration: 575/2403 | Classification loss: 0.22522 | Regression loss: 0.25389 | Running loss: 0.91202\n","Epoch: 0 | Iteration: 576/2403 | Classification loss: 0.42266 | Regression loss: 0.42977 | Running loss: 0.91192\n","Epoch: 0 | Iteration: 577/2403 | Classification loss: 0.46664 | Regression loss: 0.52103 | Running loss: 0.91205\n","Epoch: 0 | Iteration: 578/2403 | Classification loss: 0.23512 | Regression loss: 0.35555 | Running loss: 0.91149\n","Epoch: 0 | Iteration: 579/2403 | Classification loss: 0.42346 | Regression loss: 0.33219 | Running loss: 0.91122\n","Epoch: 0 | Iteration: 580/2403 | Classification loss: 0.32876 | Regression loss: 0.30227 | Running loss: 0.91074\n","Epoch: 0 | Iteration: 581/2403 | Classification loss: 0.25823 | Regression loss: 0.25244 | Running loss: 0.91005\n","Epoch: 0 | Iteration: 582/2403 | Classification loss: 0.46530 | Regression loss: 0.39287 | Running loss: 0.90996\n","Epoch: 0 | Iteration: 583/2403 | Classification loss: 0.25927 | Regression loss: 0.34126 | Running loss: 0.90943\n","Epoch: 0 | Iteration: 584/2403 | Classification loss: 0.43125 | Regression loss: 0.34672 | Running loss: 0.90920\n","Epoch: 0 | Iteration: 585/2403 | Classification loss: 0.94781 | Regression loss: 0.47999 | Running loss: 0.91009\n","Epoch: 0 | Iteration: 586/2403 | Classification loss: 0.54009 | Regression loss: 0.27742 | Running loss: 0.90993\n","Epoch: 0 | Iteration: 587/2403 | Classification loss: 0.37967 | Regression loss: 0.38980 | Running loss: 0.90969\n","Epoch: 0 | Iteration: 588/2403 | Classification loss: 0.17880 | Regression loss: 0.19584 | Running loss: 0.90878\n","Epoch: 0 | Iteration: 589/2403 | Classification loss: 0.45667 | Regression loss: 0.38270 | Running loss: 0.90867\n","Epoch: 0 | Iteration: 590/2403 | Classification loss: 0.19094 | Regression loss: 0.28569 | Running loss: 0.90793\n","Epoch: 0 | Iteration: 591/2403 | Classification loss: 0.18920 | Regression loss: 0.25695 | Running loss: 0.90715\n","Epoch: 0 | Iteration: 592/2403 | Classification loss: 0.20974 | Regression loss: 0.24091 | Running loss: 0.90638\n","Epoch: 0 | Iteration: 593/2403 | Classification loss: 0.35374 | Regression loss: 0.32140 | Running loss: 0.90599\n","Epoch: 0 | Iteration: 594/2403 | Classification loss: 0.29697 | Regression loss: 0.32659 | Running loss: 0.90552\n","Epoch: 0 | Iteration: 595/2403 | Classification loss: 0.18240 | Regression loss: 0.30287 | Running loss: 0.90481\n","Epoch: 0 | Iteration: 596/2403 | Classification loss: 0.25647 | Regression loss: 0.30625 | Running loss: 0.90424\n","Epoch: 0 | Iteration: 597/2403 | Classification loss: 0.29006 | Regression loss: 0.32683 | Running loss: 0.90375\n","Epoch: 0 | Iteration: 598/2403 | Classification loss: 0.31683 | Regression loss: 0.34091 | Running loss: 0.90334\n","Epoch: 0 | Iteration: 599/2403 | Classification loss: 0.39957 | Regression loss: 0.35738 | Running loss: 0.90310\n","Epoch: 0 | Iteration: 600/2403 | Classification loss: 0.31758 | Regression loss: 0.39312 | Running loss: 0.90278\n","Epoch: 0 | Iteration: 601/2403 | Classification loss: 0.62465 | Regression loss: 0.44385 | Running loss: 0.90305\n","Epoch: 0 | Iteration: 602/2403 | Classification loss: 0.36768 | Regression loss: 0.46962 | Running loss: 0.90294\n","Epoch: 0 | Iteration: 603/2403 | Classification loss: 0.34365 | Regression loss: 0.40610 | Running loss: 0.90269\n","Epoch: 0 | Iteration: 604/2403 | Classification loss: 0.28673 | Regression loss: 0.38068 | Running loss: 0.90230\n","Epoch: 0 | Iteration: 605/2403 | Classification loss: 0.31780 | Regression loss: 0.36378 | Running loss: 0.90194\n","Epoch: 0 | Iteration: 606/2403 | Classification loss: 0.38334 | Regression loss: 0.28270 | Running loss: 0.90155\n","Epoch: 0 | Iteration: 607/2403 | Classification loss: 0.29098 | Regression loss: 0.25132 | Running loss: 0.90095\n","Epoch: 0 | Iteration: 608/2403 | Classification loss: 0.41989 | Regression loss: 0.38050 | Running loss: 0.90079\n","Epoch: 0 | Iteration: 609/2403 | Classification loss: 0.16680 | Regression loss: 0.26384 | Running loss: 0.90002\n","Epoch: 0 | Iteration: 610/2403 | Classification loss: 0.24658 | Regression loss: 0.27937 | Running loss: 0.89940\n","Epoch: 0 | Iteration: 611/2403 | Classification loss: 0.24122 | Regression loss: 0.33038 | Running loss: 0.89887\n","Epoch: 0 | Iteration: 612/2403 | Classification loss: 0.40463 | Regression loss: 0.40510 | Running loss: 0.89872\n","Epoch: 0 | Iteration: 613/2403 | Classification loss: 0.43517 | Regression loss: 0.32483 | Running loss: 0.89850\n","Epoch: 0 | Iteration: 614/2403 | Classification loss: 0.25188 | Regression loss: 0.38341 | Running loss: 0.89807\n","Epoch: 0 | Iteration: 615/2403 | Classification loss: 0.29490 | Regression loss: 0.39252 | Running loss: 0.89772\n","Epoch: 0 | Iteration: 616/2403 | Classification loss: 0.29182 | Regression loss: 0.27059 | Running loss: 0.89718\n","Epoch: 0 | Iteration: 617/2403 | Classification loss: 0.41900 | Regression loss: 0.21566 | Running loss: 0.89675\n","Epoch: 0 | Iteration: 618/2403 | Classification loss: 0.19571 | Regression loss: 0.24972 | Running loss: 0.89602\n","Epoch: 0 | Iteration: 619/2403 | Classification loss: 0.32172 | Regression loss: 0.30884 | Running loss: 0.89560\n","Epoch: 0 | Iteration: 620/2403 | Classification loss: 0.17215 | Regression loss: 0.22276 | Running loss: 0.89479\n","Epoch: 0 | Iteration: 621/2403 | Classification loss: 0.33690 | Regression loss: 0.30419 | Running loss: 0.89438\n","Epoch: 0 | Iteration: 622/2403 | Classification loss: 0.41476 | Regression loss: 0.37979 | Running loss: 0.89422\n","Epoch: 0 | Iteration: 623/2403 | Classification loss: 0.24280 | Regression loss: 0.25272 | Running loss: 0.89358\n","Epoch: 0 | Iteration: 624/2403 | Classification loss: 0.12797 | Regression loss: 0.21383 | Running loss: 0.89269\n","Epoch: 0 | Iteration: 625/2403 | Classification loss: 0.53470 | Regression loss: 0.39955 | Running loss: 0.89276\n","Epoch: 0 | Iteration: 626/2403 | Classification loss: 0.18937 | Regression loss: 0.28459 | Running loss: 0.89209\n","Epoch: 0 | Iteration: 627/2403 | Classification loss: 0.59292 | Regression loss: 0.42054 | Running loss: 0.89229\n","Epoch: 0 | Iteration: 628/2403 | Classification loss: 0.34278 | Regression loss: 0.29611 | Running loss: 0.89188\n","Epoch: 0 | Iteration: 629/2403 | Classification loss: 0.43323 | Regression loss: 0.35706 | Running loss: 0.89172\n","Epoch: 0 | Iteration: 630/2403 | Classification loss: 0.32967 | Regression loss: 0.26575 | Running loss: 0.89125\n","Epoch: 0 | Iteration: 631/2403 | Classification loss: 0.23574 | Regression loss: 0.28739 | Running loss: 0.89067\n","Epoch: 0 | Iteration: 632/2403 | Classification loss: 0.22637 | Regression loss: 0.32837 | Running loss: 0.89014\n","Epoch: 0 | Iteration: 633/2403 | Classification loss: 0.45350 | Regression loss: 0.37696 | Running loss: 0.89004\n","Epoch: 0 | Iteration: 634/2403 | Classification loss: 0.68585 | Regression loss: 0.57977 | Running loss: 0.89063\n","Epoch: 0 | Iteration: 635/2403 | Classification loss: 0.34248 | Regression loss: 0.38454 | Running loss: 0.89038\n","Epoch: 0 | Iteration: 636/2403 | Classification loss: 0.41500 | Regression loss: 0.28600 | Running loss: 0.89008\n","Epoch: 0 | Iteration: 637/2403 | Classification loss: 0.38030 | Regression loss: 0.41916 | Running loss: 0.88994\n","Epoch: 0 | Iteration: 638/2403 | Classification loss: 0.26636 | Regression loss: 0.26165 | Running loss: 0.88937\n","Epoch: 0 | Iteration: 639/2403 | Classification loss: 0.49274 | Regression loss: 0.37584 | Running loss: 0.88934\n","Epoch: 0 | Iteration: 640/2403 | Classification loss: 0.65342 | Regression loss: 0.45375 | Running loss: 0.88968\n","Epoch: 0 | Iteration: 641/2403 | Classification loss: 0.47451 | Regression loss: 0.38612 | Running loss: 0.88963\n","Epoch: 0 | Iteration: 642/2403 | Classification loss: 0.17272 | Regression loss: 0.28554 | Running loss: 0.88896\n","Epoch: 0 | Iteration: 643/2403 | Classification loss: 0.40806 | Regression loss: 0.28533 | Running loss: 0.88866\n","Epoch: 0 | Iteration: 644/2403 | Classification loss: 0.25628 | Regression loss: 0.25244 | Running loss: 0.88807\n","Epoch: 0 | Iteration: 645/2403 | Classification loss: 0.38296 | Regression loss: 0.33931 | Running loss: 0.88781\n","Epoch: 0 | Iteration: 646/2403 | Classification loss: 0.29659 | Regression loss: 0.25080 | Running loss: 0.88728\n","Epoch: 0 | Iteration: 647/2403 | Classification loss: 0.39107 | Regression loss: 0.27348 | Running loss: 0.88694\n","Epoch: 0 | Iteration: 648/2403 | Classification loss: 0.59523 | Regression loss: 0.47372 | Running loss: 0.88722\n","Epoch: 0 | Iteration: 649/2403 | Classification loss: 0.16355 | Regression loss: 0.24358 | Running loss: 0.88648\n","Epoch: 0 | Iteration: 650/2403 | Classification loss: 0.41657 | Regression loss: 0.33429 | Running loss: 0.88627\n","Epoch: 0 | Iteration: 651/2403 | Classification loss: 0.14039 | Regression loss: 0.23399 | Running loss: 0.88548\n","Epoch: 0 | Iteration: 652/2403 | Classification loss: 0.14841 | Regression loss: 0.30060 | Running loss: 0.88481\n","Epoch: 0 | Iteration: 653/2403 | Classification loss: 0.27188 | Regression loss: 0.32244 | Running loss: 0.88437\n","Epoch: 0 | Iteration: 654/2403 | Classification loss: 0.16024 | Regression loss: 0.23471 | Running loss: 0.88362\n","Epoch: 0 | Iteration: 655/2403 | Classification loss: 0.14315 | Regression loss: 0.23565 | Running loss: 0.88285\n","Epoch: 0 | Iteration: 656/2403 | Classification loss: 0.50702 | Regression loss: 0.34889 | Running loss: 0.88281\n","Epoch: 0 | Iteration: 657/2403 | Classification loss: 0.37462 | Regression loss: 0.35060 | Running loss: 0.88257\n","Epoch: 0 | Iteration: 658/2403 | Classification loss: 0.30659 | Regression loss: 0.30884 | Running loss: 0.88216\n","Epoch: 0 | Iteration: 659/2403 | Classification loss: 0.30783 | Regression loss: 0.24915 | Running loss: 0.88167\n","Epoch: 0 | Iteration: 660/2403 | Classification loss: 0.28161 | Regression loss: 0.33306 | Running loss: 0.88127\n","Epoch: 0 | Iteration: 661/2403 | Classification loss: 0.20446 | Regression loss: 0.32481 | Running loss: 0.88073\n","Epoch: 0 | Iteration: 662/2403 | Classification loss: 0.30355 | Regression loss: 0.37560 | Running loss: 0.88043\n","Epoch: 0 | Iteration: 663/2403 | Classification loss: 0.36847 | Regression loss: 0.37895 | Running loss: 0.88023\n","Epoch: 0 | Iteration: 664/2403 | Classification loss: 0.53732 | Regression loss: 0.32410 | Running loss: 0.88020\n","Epoch: 0 | Iteration: 665/2403 | Classification loss: 0.19244 | Regression loss: 0.21774 | Running loss: 0.87949\n","Epoch: 0 | Iteration: 666/2403 | Classification loss: 0.21726 | Regression loss: 0.26656 | Running loss: 0.87890\n","Epoch: 0 | Iteration: 667/2403 | Classification loss: 0.39855 | Regression loss: 0.49789 | Running loss: 0.87892\n","Epoch: 0 | Iteration: 668/2403 | Classification loss: 0.39403 | Regression loss: 0.40903 | Running loss: 0.87881\n","Epoch: 0 | Iteration: 669/2403 | Classification loss: 0.23563 | Regression loss: 0.30392 | Running loss: 0.87830\n","Epoch: 0 | Iteration: 670/2403 | Classification loss: 0.18365 | Regression loss: 0.27414 | Running loss: 0.87768\n","Epoch: 0 | Iteration: 671/2403 | Classification loss: 0.20106 | Regression loss: 0.35167 | Running loss: 0.87719\n","Epoch: 0 | Iteration: 672/2403 | Classification loss: 0.22656 | Regression loss: 0.28162 | Running loss: 0.87664\n","Epoch: 0 | Iteration: 673/2403 | Classification loss: 0.21026 | Regression loss: 0.31206 | Running loss: 0.87612\n","Epoch: 0 | Iteration: 674/2403 | Classification loss: 0.23900 | Regression loss: 0.44741 | Running loss: 0.87583\n","Epoch: 0 | Iteration: 675/2403 | Classification loss: 0.12604 | Regression loss: 0.28923 | Running loss: 0.87515\n","Epoch: 0 | Iteration: 676/2403 | Classification loss: 0.54160 | Regression loss: 0.52336 | Running loss: 0.87543\n","Epoch: 0 | Iteration: 677/2403 | Classification loss: 0.09187 | Regression loss: 0.34177 | Running loss: 0.87478\n","Epoch: 0 | Iteration: 678/2403 | Classification loss: 0.23286 | Regression loss: 0.34800 | Running loss: 0.87435\n","Epoch: 0 | Iteration: 679/2403 | Classification loss: 0.30536 | Regression loss: 0.37211 | Running loss: 0.87406\n","Epoch: 0 | Iteration: 680/2403 | Classification loss: 0.20825 | Regression loss: 0.27305 | Running loss: 0.87348\n","Epoch: 0 | Iteration: 681/2403 | Classification loss: 0.37176 | Regression loss: 0.21941 | Running loss: 0.87307\n","Epoch: 0 | Iteration: 682/2403 | Classification loss: 0.45247 | Regression loss: 0.49698 | Running loss: 0.87318\n","Epoch: 0 | Iteration: 683/2403 | Classification loss: 0.24948 | Regression loss: 0.32963 | Running loss: 0.87275\n","Epoch: 0 | Iteration: 684/2403 | Classification loss: 0.31246 | Regression loss: 0.34381 | Running loss: 0.87243\n","Epoch: 0 | Iteration: 685/2403 | Classification loss: 0.22297 | Regression loss: 0.32360 | Running loss: 0.87195\n","Epoch: 0 | Iteration: 686/2403 | Classification loss: 0.21779 | Regression loss: 0.31694 | Running loss: 0.87146\n","Epoch: 0 | Iteration: 687/2403 | Classification loss: 0.32057 | Regression loss: 0.30882 | Running loss: 0.87111\n","Epoch: 0 | Iteration: 688/2403 | Classification loss: 0.19023 | Regression loss: 0.38474 | Running loss: 0.87068\n","Epoch: 0 | Iteration: 689/2403 | Classification loss: 0.33507 | Regression loss: 0.35523 | Running loss: 0.87042\n","Epoch: 0 | Iteration: 690/2403 | Classification loss: 0.29441 | Regression loss: 0.32195 | Running loss: 0.87005\n","Epoch: 0 | Iteration: 691/2403 | Classification loss: 0.31719 | Regression loss: 0.36322 | Running loss: 0.86978\n","Epoch: 0 | Iteration: 692/2403 | Classification loss: 0.47680 | Regression loss: 0.33953 | Running loss: 0.86970\n","Epoch: 0 | Iteration: 693/2403 | Classification loss: 0.44716 | Regression loss: 0.37579 | Running loss: 0.86963\n","Epoch: 0 | Iteration: 694/2403 | Classification loss: 0.23584 | Regression loss: 0.23730 | Running loss: 0.86906\n","Epoch: 0 | Iteration: 695/2403 | Classification loss: 0.48811 | Regression loss: 0.36004 | Running loss: 0.86903\n","Epoch: 0 | Iteration: 696/2403 | Classification loss: 0.21923 | Regression loss: 0.31063 | Running loss: 0.86854\n","Epoch: 0 | Iteration: 697/2403 | Classification loss: 0.19543 | Regression loss: 0.19480 | Running loss: 0.86786\n","Epoch: 0 | Iteration: 698/2403 | Classification loss: 0.29346 | Regression loss: 0.28613 | Running loss: 0.86744\n","Epoch: 0 | Iteration: 699/2403 | Classification loss: 0.19546 | Regression loss: 0.31097 | Running loss: 0.86693\n","Epoch: 0 | Iteration: 700/2403 | Classification loss: 0.19765 | Regression loss: 0.22616 | Running loss: 0.86629\n","Epoch: 0 | Iteration: 701/2403 | Classification loss: 0.24499 | Regression loss: 0.41012 | Running loss: 0.86599\n","Epoch: 0 | Iteration: 702/2403 | Classification loss: 0.77071 | Regression loss: 0.38363 | Running loss: 0.86640\n","Epoch: 0 | Iteration: 703/2403 | Classification loss: 0.19137 | Regression loss: 0.29762 | Running loss: 0.86587\n","Epoch: 0 | Iteration: 704/2403 | Classification loss: 0.33003 | Regression loss: 0.36770 | Running loss: 0.86563\n","Epoch: 0 | Iteration: 705/2403 | Classification loss: 0.23604 | Regression loss: 0.37960 | Running loss: 0.86527\n","Epoch: 0 | Iteration: 706/2403 | Classification loss: 0.23183 | Regression loss: 0.31654 | Running loss: 0.86482\n","Epoch: 0 | Iteration: 707/2403 | Classification loss: 0.19769 | Regression loss: 0.31116 | Running loss: 0.86432\n","Epoch: 0 | Iteration: 708/2403 | Classification loss: 0.17469 | Regression loss: 0.29839 | Running loss: 0.86377\n","Epoch: 0 | Iteration: 709/2403 | Classification loss: 0.21975 | Regression loss: 0.24558 | Running loss: 0.86321\n","Epoch: 0 | Iteration: 710/2403 | Classification loss: 0.20374 | Regression loss: 0.29482 | Running loss: 0.86269\n","Epoch: 0 | Iteration: 711/2403 | Classification loss: 0.39061 | Regression loss: 0.40128 | Running loss: 0.86259\n","Epoch: 0 | Iteration: 712/2403 | Classification loss: 0.42248 | Regression loss: 0.30324 | Running loss: 0.86240\n","Epoch: 0 | Iteration: 713/2403 | Classification loss: 0.20761 | Regression loss: 0.31127 | Running loss: 0.86192\n","Epoch: 0 | Iteration: 714/2403 | Classification loss: 0.24035 | Regression loss: 0.30788 | Running loss: 0.86148\n","Epoch: 0 | Iteration: 715/2403 | Classification loss: 0.39848 | Regression loss: 0.38534 | Running loss: 0.86137\n","Epoch: 0 | Iteration: 716/2403 | Classification loss: 0.24446 | Regression loss: 0.25513 | Running loss: 0.86087\n","Epoch: 0 | Iteration: 717/2403 | Classification loss: 0.22302 | Regression loss: 0.22874 | Running loss: 0.86029\n","Epoch: 0 | Iteration: 718/2403 | Classification loss: 0.24965 | Regression loss: 0.29071 | Running loss: 0.85985\n","Epoch: 0 | Iteration: 719/2403 | Classification loss: 0.33706 | Regression loss: 0.40269 | Running loss: 0.85968\n","Epoch: 0 | Iteration: 720/2403 | Classification loss: 0.51247 | Regression loss: 0.38990 | Running loss: 0.85974\n","Epoch: 0 | Iteration: 721/2403 | Classification loss: 0.55194 | Regression loss: 0.38074 | Running loss: 0.85984\n","Epoch: 0 | Iteration: 722/2403 | Classification loss: 0.29080 | Regression loss: 0.29923 | Running loss: 0.85947\n","Epoch: 0 | Iteration: 723/2403 | Classification loss: 0.45623 | Regression loss: 0.39203 | Running loss: 0.85945\n","Epoch: 0 | Iteration: 724/2403 | Classification loss: 0.27789 | Regression loss: 0.27421 | Running loss: 0.85903\n","Epoch: 0 | Iteration: 725/2403 | Classification loss: 0.22472 | Regression loss: 0.29550 | Running loss: 0.85856\n","Epoch: 0 | Iteration: 726/2403 | Classification loss: 0.41066 | Regression loss: 0.35154 | Running loss: 0.85843\n","Epoch: 0 | Iteration: 727/2403 | Classification loss: 0.66682 | Regression loss: 0.32399 | Running loss: 0.85861\n","Epoch: 0 | Iteration: 728/2403 | Classification loss: 0.28372 | Regression loss: 0.43662 | Running loss: 0.85842\n","Epoch: 0 | Iteration: 729/2403 | Classification loss: 0.42462 | Regression loss: 0.31814 | Running loss: 0.85826\n","Epoch: 0 | Iteration: 730/2403 | Classification loss: 0.29987 | Regression loss: 0.31189 | Running loss: 0.85792\n","Epoch: 0 | Iteration: 731/2403 | Classification loss: 0.57235 | Regression loss: 0.41672 | Running loss: 0.85810\n","Epoch: 0 | Iteration: 732/2403 | Classification loss: 0.38686 | Regression loss: 0.33232 | Running loss: 0.85791\n","Epoch: 0 | Iteration: 733/2403 | Classification loss: 0.46595 | Regression loss: 0.68817 | Running loss: 0.85832\n","Epoch: 0 | Iteration: 734/2403 | Classification loss: 0.36166 | Regression loss: 0.26235 | Running loss: 0.85800\n","Epoch: 0 | Iteration: 735/2403 | Classification loss: 0.39605 | Regression loss: 0.29808 | Running loss: 0.85778\n","Epoch: 0 | Iteration: 736/2403 | Classification loss: 0.36345 | Regression loss: 0.35092 | Running loss: 0.85758\n","Epoch: 0 | Iteration: 737/2403 | Classification loss: 0.36194 | Regression loss: 0.36990 | Running loss: 0.85741\n","Epoch: 0 | Iteration: 738/2403 | Classification loss: 0.46425 | Regression loss: 0.41436 | Running loss: 0.85744\n","Epoch: 0 | Iteration: 739/2403 | Classification loss: 0.24588 | Regression loss: 0.23071 | Running loss: 0.85692\n","Epoch: 0 | Iteration: 740/2403 | Classification loss: 0.26714 | Regression loss: 0.25754 | Running loss: 0.85647\n","Epoch: 0 | Iteration: 741/2403 | Classification loss: 0.21318 | Regression loss: 0.25885 | Running loss: 0.85596\n","Epoch: 0 | Iteration: 742/2403 | Classification loss: 0.40422 | Regression loss: 0.33157 | Running loss: 0.85579\n","Epoch: 0 | Iteration: 743/2403 | Classification loss: 0.25322 | Regression loss: 0.26146 | Running loss: 0.85534\n","Epoch: 0 | Iteration: 744/2403 | Classification loss: 0.25821 | Regression loss: 0.20387 | Running loss: 0.85481\n","Epoch: 0 | Iteration: 745/2403 | Classification loss: 0.30417 | Regression loss: 0.27374 | Running loss: 0.85443\n","Epoch: 0 | Iteration: 746/2403 | Classification loss: 0.20291 | Regression loss: 0.27871 | Running loss: 0.85394\n","Epoch: 0 | Iteration: 747/2403 | Classification loss: 0.57237 | Regression loss: 0.35415 | Running loss: 0.85403\n","Epoch: 0 | Iteration: 748/2403 | Classification loss: 0.16486 | Regression loss: 0.32137 | Running loss: 0.85354\n","Epoch: 0 | Iteration: 749/2403 | Classification loss: 0.21121 | Regression loss: 0.21911 | Running loss: 0.85298\n","Epoch: 0 | Iteration: 750/2403 | Classification loss: 0.36837 | Regression loss: 0.24092 | Running loss: 0.85265\n","Epoch: 0 | Iteration: 751/2403 | Classification loss: 0.29195 | Regression loss: 0.35551 | Running loss: 0.85238\n","Epoch: 0 | Iteration: 752/2403 | Classification loss: 0.35508 | Regression loss: 0.37061 | Running loss: 0.85221\n","Epoch: 0 | Iteration: 753/2403 | Classification loss: 0.39526 | Regression loss: 0.42713 | Running loss: 0.85217\n","Epoch: 0 | Iteration: 754/2403 | Classification loss: 1.12460 | Regression loss: 0.49117 | Running loss: 0.85318\n","Epoch: 0 | Iteration: 755/2403 | Classification loss: 0.21388 | Regression loss: 0.35468 | Running loss: 0.85281\n","Epoch: 0 | Iteration: 756/2403 | Classification loss: 0.58173 | Regression loss: 0.51365 | Running loss: 0.85313\n","Epoch: 0 | Iteration: 757/2403 | Classification loss: 0.30280 | Regression loss: 0.37449 | Running loss: 0.85289\n","Epoch: 0 | Iteration: 758/2403 | Classification loss: 0.28504 | Regression loss: 0.25605 | Running loss: 0.85248\n","Epoch: 0 | Iteration: 759/2403 | Classification loss: 0.20686 | Regression loss: 0.23071 | Running loss: 0.85194\n","Epoch: 0 | Iteration: 760/2403 | Classification loss: 0.47104 | Regression loss: 0.41861 | Running loss: 0.85199\n","Epoch: 0 | Iteration: 761/2403 | Classification loss: 0.73593 | Regression loss: 0.46491 | Running loss: 0.85244\n","Epoch: 0 | Iteration: 762/2403 | Classification loss: 0.23506 | Regression loss: 0.34433 | Running loss: 0.85209\n","Epoch: 0 | Iteration: 763/2403 | Classification loss: 0.39331 | Regression loss: 0.32006 | Running loss: 0.85190\n","Epoch: 0 | Iteration: 764/2403 | Classification loss: 0.23239 | Regression loss: 0.27075 | Running loss: 0.85145\n","Epoch: 0 | Iteration: 765/2403 | Classification loss: 0.41301 | Regression loss: 0.28063 | Running loss: 0.85124\n","Epoch: 0 | Iteration: 766/2403 | Classification loss: 0.23091 | Regression loss: 0.29458 | Running loss: 0.85082\n","Epoch: 0 | Iteration: 767/2403 | Classification loss: 0.21073 | Regression loss: 0.26971 | Running loss: 0.85033\n","Epoch: 0 | Iteration: 768/2403 | Classification loss: 0.21887 | Regression loss: 0.27774 | Running loss: 0.84987\n","Epoch: 0 | Iteration: 769/2403 | Classification loss: 0.21135 | Regression loss: 0.33969 | Running loss: 0.84948\n","Epoch: 0 | Iteration: 770/2403 | Classification loss: 0.36549 | Regression loss: 0.50476 | Running loss: 0.84951\n","Epoch: 0 | Iteration: 771/2403 | Classification loss: 0.51522 | Regression loss: 0.35801 | Running loss: 0.84954\n","Epoch: 0 | Iteration: 772/2403 | Classification loss: 0.20606 | Regression loss: 0.25917 | Running loss: 0.84904\n","Epoch: 0 | Iteration: 773/2403 | Classification loss: 0.59815 | Regression loss: 0.44206 | Running loss: 0.84929\n","Epoch: 0 | Iteration: 774/2403 | Classification loss: 0.38493 | Regression loss: 0.41279 | Running loss: 0.84922\n","Epoch: 0 | Iteration: 775/2403 | Classification loss: 0.25064 | Regression loss: 0.29128 | Running loss: 0.84883\n","Epoch: 0 | Iteration: 776/2403 | Classification loss: 0.32421 | Regression loss: 0.36109 | Running loss: 0.84862\n","Epoch: 0 | Iteration: 777/2403 | Classification loss: 0.25960 | Regression loss: 0.31880 | Running loss: 0.84827\n","Epoch: 0 | Iteration: 778/2403 | Classification loss: 0.18458 | Regression loss: 0.26984 | Running loss: 0.84776\n","Epoch: 0 | Iteration: 779/2403 | Classification loss: 0.22016 | Regression loss: 0.31428 | Running loss: 0.84736\n","Epoch: 0 | Iteration: 780/2403 | Classification loss: 0.17204 | Regression loss: 0.21837 | Running loss: 0.84677\n","Epoch: 0 | Iteration: 781/2403 | Classification loss: 0.27527 | Regression loss: 0.36102 | Running loss: 0.84651\n","Epoch: 0 | Iteration: 782/2403 | Classification loss: 0.28359 | Regression loss: 0.21044 | Running loss: 0.84605\n","Epoch: 0 | Iteration: 783/2403 | Classification loss: 0.17130 | Regression loss: 0.23222 | Running loss: 0.84549\n","Epoch: 0 | Iteration: 784/2403 | Classification loss: 0.45624 | Regression loss: 0.47661 | Running loss: 0.84560\n","Epoch: 0 | Iteration: 785/2403 | Classification loss: 0.25476 | Regression loss: 0.30927 | Running loss: 0.84524\n","Epoch: 0 | Iteration: 786/2403 | Classification loss: 0.18297 | Regression loss: 0.27733 | Running loss: 0.84475\n","Epoch: 0 | Iteration: 787/2403 | Classification loss: 0.31466 | Regression loss: 0.33045 | Running loss: 0.84450\n","Epoch: 0 | Iteration: 788/2403 | Classification loss: 0.32466 | Regression loss: 0.27142 | Running loss: 0.84418\n","Epoch: 0 | Iteration: 789/2403 | Classification loss: 0.65502 | Regression loss: 0.39001 | Running loss: 0.84444\n","Epoch: 0 | Iteration: 790/2403 | Classification loss: 0.23426 | Regression loss: 0.28114 | Running loss: 0.84402\n","Epoch: 0 | Iteration: 791/2403 | Classification loss: 0.32686 | Regression loss: 0.38127 | Running loss: 0.84385\n","Epoch: 0 | Iteration: 792/2403 | Classification loss: 0.15034 | Regression loss: 0.33236 | Running loss: 0.84339\n","Epoch: 0 | Iteration: 793/2403 | Classification loss: 0.33685 | Regression loss: 0.31375 | Running loss: 0.84315\n","Epoch: 0 | Iteration: 794/2403 | Classification loss: 0.29311 | Regression loss: 0.27664 | Running loss: 0.84281\n","Epoch: 0 | Iteration: 795/2403 | Classification loss: 0.44788 | Regression loss: 0.41141 | Running loss: 0.84283\n","Epoch: 0 | Iteration: 796/2403 | Classification loss: 0.18786 | Regression loss: 0.25112 | Running loss: 0.84232\n","Epoch: 0 | Iteration: 797/2403 | Classification loss: 0.16480 | Regression loss: 0.25765 | Running loss: 0.84179\n","Epoch: 0 | Iteration: 798/2403 | Classification loss: 0.14520 | Regression loss: 0.20175 | Running loss: 0.84117\n","Epoch: 0 | Iteration: 799/2403 | Classification loss: 0.35964 | Regression loss: 0.36289 | Running loss: 0.84102\n","Epoch: 0 | Iteration: 800/2403 | Classification loss: 0.78395 | Regression loss: 0.52358 | Running loss: 0.84161\n","Epoch: 0 | Iteration: 801/2403 | Classification loss: 0.31232 | Regression loss: 0.32740 | Running loss: 0.84136\n","Epoch: 0 | Iteration: 802/2403 | Classification loss: 0.71317 | Regression loss: 0.50367 | Running loss: 0.84182\n","Epoch: 0 | Iteration: 803/2403 | Classification loss: 0.14497 | Regression loss: 0.24170 | Running loss: 0.84126\n","Epoch: 0 | Iteration: 804/2403 | Classification loss: 0.53132 | Regression loss: 0.41710 | Running loss: 0.84139\n","Epoch: 0 | Iteration: 805/2403 | Classification loss: 0.22409 | Regression loss: 0.26555 | Running loss: 0.84095\n","Epoch: 0 | Iteration: 806/2403 | Classification loss: 0.29297 | Regression loss: 0.29051 | Running loss: 0.84063\n","Epoch: 0 | Iteration: 807/2403 | Classification loss: 0.20453 | Regression loss: 0.24668 | Running loss: 0.84015\n","Epoch: 0 | Iteration: 808/2403 | Classification loss: 0.22726 | Regression loss: 0.24748 | Running loss: 0.83970\n","Epoch: 0 | Iteration: 809/2403 | Classification loss: 0.32471 | Regression loss: 0.30079 | Running loss: 0.83943\n","Epoch: 0 | Iteration: 810/2403 | Classification loss: 0.29895 | Regression loss: 0.30187 | Running loss: 0.83914\n","Epoch: 0 | Iteration: 811/2403 | Classification loss: 0.20380 | Regression loss: 0.29592 | Running loss: 0.83872\n","Epoch: 0 | Iteration: 812/2403 | Classification loss: 0.17018 | Regression loss: 0.22292 | Running loss: 0.83817\n","Epoch: 0 | Iteration: 813/2403 | Classification loss: 0.31777 | Regression loss: 0.29932 | Running loss: 0.83790\n","Epoch: 0 | Iteration: 814/2403 | Classification loss: 0.18654 | Regression loss: 0.24532 | Running loss: 0.83740\n","Epoch: 0 | Iteration: 815/2403 | Classification loss: 0.38312 | Regression loss: 0.42779 | Running loss: 0.83737\n","Epoch: 0 | Iteration: 816/2403 | Classification loss: 0.58102 | Regression loss: 0.40983 | Running loss: 0.83756\n","Epoch: 0 | Iteration: 817/2403 | Classification loss: 0.28292 | Regression loss: 0.26501 | Running loss: 0.83720\n","Epoch: 0 | Iteration: 818/2403 | Classification loss: 0.86708 | Regression loss: 0.58927 | Running loss: 0.83796\n","Epoch: 0 | Iteration: 819/2403 | Classification loss: 0.41733 | Regression loss: 0.33258 | Running loss: 0.83785\n","Epoch: 0 | Iteration: 820/2403 | Classification loss: 0.89187 | Regression loss: 0.75069 | Running loss: 0.83883\n","Epoch: 0 | Iteration: 821/2403 | Classification loss: 0.56051 | Regression loss: 0.36649 | Running loss: 0.83894\n","Epoch: 0 | Iteration: 822/2403 | Classification loss: 0.22697 | Regression loss: 0.28100 | Running loss: 0.83854\n","Epoch: 0 | Iteration: 823/2403 | Classification loss: 0.21262 | Regression loss: 0.26301 | Running loss: 0.83810\n","Epoch: 0 | Iteration: 824/2403 | Classification loss: 0.40468 | Regression loss: 0.26951 | Running loss: 0.83790\n","Epoch: 0 | Iteration: 825/2403 | Classification loss: 0.18522 | Regression loss: 0.26016 | Running loss: 0.83742\n","Epoch: 0 | Iteration: 826/2403 | Classification loss: 0.34985 | Regression loss: 0.27727 | Running loss: 0.83717\n","Epoch: 0 | Iteration: 827/2403 | Classification loss: 0.23634 | Regression loss: 0.29779 | Running loss: 0.83680\n","Epoch: 0 | Iteration: 828/2403 | Classification loss: 0.44170 | Regression loss: 0.38601 | Running loss: 0.83679\n","Epoch: 0 | Iteration: 829/2403 | Classification loss: 0.35752 | Regression loss: 0.31936 | Running loss: 0.83660\n","Epoch: 0 | Iteration: 830/2403 | Classification loss: 0.16021 | Regression loss: 0.22961 | Running loss: 0.83606\n","Epoch: 0 | Iteration: 831/2403 | Classification loss: 0.40760 | Regression loss: 0.46552 | Running loss: 0.83610\n","Epoch: 0 | Iteration: 832/2403 | Classification loss: 0.26461 | Regression loss: 0.26471 | Running loss: 0.83573\n","Epoch: 0 | Iteration: 833/2403 | Classification loss: 0.23776 | Regression loss: 0.25949 | Running loss: 0.83533\n","Epoch: 0 | Iteration: 834/2403 | Classification loss: 0.30488 | Regression loss: 0.33752 | Running loss: 0.83510\n","Epoch: 0 | Iteration: 835/2403 | Classification loss: 0.36272 | Regression loss: 0.45542 | Running loss: 0.83508\n","Epoch: 0 | Iteration: 836/2403 | Classification loss: 0.24789 | Regression loss: 0.34354 | Running loss: 0.83479\n","Epoch: 0 | Iteration: 837/2403 | Classification loss: 0.29631 | Regression loss: 0.32914 | Running loss: 0.83454\n","Epoch: 0 | Iteration: 838/2403 | Classification loss: 0.56355 | Regression loss: 0.39097 | Running loss: 0.83468\n","Epoch: 0 | Iteration: 839/2403 | Classification loss: 0.25773 | Regression loss: 0.30738 | Running loss: 0.83436\n","Epoch: 0 | Iteration: 840/2403 | Classification loss: 0.23934 | Regression loss: 0.31675 | Running loss: 0.83403\n","Epoch: 0 | Iteration: 841/2403 | Classification loss: 0.24090 | Regression loss: 0.29915 | Running loss: 0.83368\n","Epoch: 0 | Iteration: 842/2403 | Classification loss: 0.50470 | Regression loss: 0.43926 | Running loss: 0.83381\n","Epoch: 0 | Iteration: 843/2403 | Classification loss: 0.19198 | Regression loss: 0.28039 | Running loss: 0.83338\n","Epoch: 0 | Iteration: 844/2403 | Classification loss: 0.12265 | Regression loss: 0.19114 | Running loss: 0.83276\n","Epoch: 0 | Iteration: 845/2403 | Classification loss: 0.26481 | Regression loss: 0.27071 | Running loss: 0.83241\n","Epoch: 0 | Iteration: 846/2403 | Classification loss: 0.22256 | Regression loss: 0.39741 | Running loss: 0.83216\n","Epoch: 0 | Iteration: 847/2403 | Classification loss: 0.25164 | Regression loss: 0.36497 | Running loss: 0.83191\n","Epoch: 0 | Iteration: 848/2403 | Classification loss: 0.41420 | Regression loss: 0.38687 | Running loss: 0.83187\n","Epoch: 0 | Iteration: 849/2403 | Classification loss: 0.24457 | Regression loss: 0.33155 | Running loss: 0.83157\n","Epoch: 0 | Iteration: 850/2403 | Classification loss: 0.46024 | Regression loss: 0.39552 | Running loss: 0.83160\n","Epoch: 0 | Iteration: 851/2403 | Classification loss: 0.30569 | Regression loss: 0.23405 | Running loss: 0.83125\n","Epoch: 0 | Iteration: 852/2403 | Classification loss: 0.25745 | Regression loss: 0.30084 | Running loss: 0.83093\n","Epoch: 0 | Iteration: 853/2403 | Classification loss: 0.40808 | Regression loss: 0.42680 | Running loss: 0.83094\n","Epoch: 0 | Iteration: 854/2403 | Classification loss: 0.24467 | Regression loss: 0.28825 | Running loss: 0.83059\n","Epoch: 0 | Iteration: 855/2403 | Classification loss: 0.24967 | Regression loss: 0.36726 | Running loss: 0.83034\n","Epoch: 0 | Iteration: 856/2403 | Classification loss: 0.22362 | Regression loss: 0.31436 | Running loss: 0.83000\n","Epoch: 0 | Iteration: 857/2403 | Classification loss: 0.25549 | Regression loss: 0.21478 | Running loss: 0.82958\n","Epoch: 0 | Iteration: 858/2403 | Classification loss: 0.18094 | Regression loss: 0.28155 | Running loss: 0.82915\n","Epoch: 0 | Iteration: 859/2403 | Classification loss: 0.16250 | Regression loss: 0.27429 | Running loss: 0.82869\n","Epoch: 0 | Iteration: 860/2403 | Classification loss: 0.29882 | Regression loss: 0.31291 | Running loss: 0.82844\n","Epoch: 0 | Iteration: 861/2403 | Classification loss: 0.39721 | Regression loss: 0.36080 | Running loss: 0.82836\n","Epoch: 0 | Iteration: 862/2403 | Classification loss: 0.34935 | Regression loss: 0.32534 | Running loss: 0.82818\n","Epoch: 0 | Iteration: 863/2403 | Classification loss: 0.16973 | Regression loss: 0.28896 | Running loss: 0.82775\n","Epoch: 0 | Iteration: 864/2403 | Classification loss: 0.51831 | Regression loss: 0.43969 | Running loss: 0.82790\n","Epoch: 0 | Iteration: 865/2403 | Classification loss: 0.27451 | Regression loss: 0.25659 | Running loss: 0.82756\n","Epoch: 0 | Iteration: 866/2403 | Classification loss: 0.22554 | Regression loss: 0.31940 | Running loss: 0.82723\n","Epoch: 0 | Iteration: 867/2403 | Classification loss: 0.53424 | Regression loss: 0.25495 | Running loss: 0.82719\n","Epoch: 0 | Iteration: 868/2403 | Classification loss: 0.39643 | Regression loss: 0.45360 | Running loss: 0.82722\n","Epoch: 0 | Iteration: 869/2403 | Classification loss: 0.21047 | Regression loss: 0.31709 | Running loss: 0.82687\n","Epoch: 0 | Iteration: 870/2403 | Classification loss: 0.30890 | Regression loss: 0.28323 | Running loss: 0.82660\n","Epoch: 0 | Iteration: 871/2403 | Classification loss: 0.25335 | Regression loss: 0.21148 | Running loss: 0.82619\n","Epoch: 0 | Iteration: 872/2403 | Classification loss: 0.38222 | Regression loss: 0.39271 | Running loss: 0.82613\n","Epoch: 0 | Iteration: 873/2403 | Classification loss: 0.09747 | Regression loss: 0.21029 | Running loss: 0.82553\n","Epoch: 0 | Iteration: 874/2403 | Classification loss: 0.28349 | Regression loss: 0.40777 | Running loss: 0.82538\n","Epoch: 0 | Iteration: 875/2403 | Classification loss: 0.18478 | Regression loss: 0.26092 | Running loss: 0.82495\n","Epoch: 0 | Iteration: 876/2403 | Classification loss: 0.88624 | Regression loss: 0.35325 | Running loss: 0.82542\n","Epoch: 0 | Iteration: 877/2403 | Classification loss: 0.44435 | Regression loss: 0.42651 | Running loss: 0.82547\n","Epoch: 0 | Iteration: 878/2403 | Classification loss: 0.53967 | Regression loss: 0.34979 | Running loss: 0.82554\n","Epoch: 0 | Iteration: 879/2403 | Classification loss: 0.31038 | Regression loss: 0.27449 | Running loss: 0.82527\n","Epoch: 0 | Iteration: 880/2403 | Classification loss: 0.21984 | Regression loss: 0.30004 | Running loss: 0.82492\n","Epoch: 0 | Iteration: 881/2403 | Classification loss: 0.29232 | Regression loss: 0.29668 | Running loss: 0.82466\n","Epoch: 0 | Iteration: 882/2403 | Classification loss: 0.28381 | Regression loss: 0.25436 | Running loss: 0.82433\n","Epoch: 0 | Iteration: 883/2403 | Classification loss: 0.22876 | Regression loss: 0.27472 | Running loss: 0.82397\n","Epoch: 0 | Iteration: 884/2403 | Classification loss: 0.47045 | Regression loss: 0.32306 | Running loss: 0.82393\n","Epoch: 0 | Iteration: 885/2403 | Classification loss: 0.59376 | Regression loss: 0.33098 | Running loss: 0.82405\n","Epoch: 0 | Iteration: 886/2403 | Classification loss: 0.18535 | Regression loss: 0.27587 | Running loss: 0.82364\n","Epoch: 0 | Iteration: 887/2403 | Classification loss: 0.42502 | Regression loss: 0.43267 | Running loss: 0.82368\n","Epoch: 0 | Iteration: 888/2403 | Classification loss: 0.35612 | Regression loss: 0.35184 | Running loss: 0.82355\n","Epoch: 0 | Iteration: 889/2403 | Classification loss: 0.38001 | Regression loss: 0.33320 | Running loss: 0.82342\n","Epoch: 0 | Iteration: 890/2403 | Classification loss: 0.27832 | Regression loss: 0.30786 | Running loss: 0.82315\n","Epoch: 0 | Iteration: 891/2403 | Classification loss: 0.42635 | Regression loss: 0.30643 | Running loss: 0.82305\n","Epoch: 0 | Iteration: 892/2403 | Classification loss: 0.30724 | Regression loss: 0.28526 | Running loss: 0.82279\n","Epoch: 0 | Iteration: 893/2403 | Classification loss: 0.45959 | Regression loss: 0.41517 | Running loss: 0.82285\n","Epoch: 0 | Iteration: 894/2403 | Classification loss: 0.28228 | Regression loss: 0.26779 | Running loss: 0.82255\n","Epoch: 0 | Iteration: 895/2403 | Classification loss: 0.27059 | Regression loss: 0.36392 | Running loss: 0.82234\n","Epoch: 0 | Iteration: 896/2403 | Classification loss: 0.10643 | Regression loss: 0.22085 | Running loss: 0.82179\n","Epoch: 0 | Iteration: 897/2403 | Classification loss: 0.14330 | Regression loss: 0.26819 | Running loss: 0.82133\n","Epoch: 0 | Iteration: 898/2403 | Classification loss: 0.96885 | Regression loss: 0.56159 | Running loss: 0.82212\n","Epoch: 0 | Iteration: 899/2403 | Classification loss: 0.38339 | Regression loss: 0.32567 | Running loss: 0.82199\n","Epoch: 0 | Iteration: 900/2403 | Classification loss: 0.44220 | Regression loss: 0.37866 | Running loss: 0.82199\n","Epoch: 0 | Iteration: 901/2403 | Classification loss: 0.30504 | Regression loss: 0.21288 | Running loss: 0.82165\n","Epoch: 0 | Iteration: 902/2403 | Classification loss: 0.44470 | Regression loss: 0.31183 | Running loss: 0.82158\n","Epoch: 0 | Iteration: 903/2403 | Classification loss: 0.34984 | Regression loss: 0.29194 | Running loss: 0.82138\n","Epoch: 0 | Iteration: 904/2403 | Classification loss: 0.58647 | Regression loss: 0.34921 | Running loss: 0.82151\n","Epoch: 0 | Iteration: 905/2403 | Classification loss: 0.32184 | Regression loss: 0.40497 | Running loss: 0.82140\n","Epoch: 0 | Iteration: 906/2403 | Classification loss: 0.30062 | Regression loss: 0.21187 | Running loss: 0.82106\n","Epoch: 0 | Iteration: 907/2403 | Classification loss: 0.51545 | Regression loss: 0.40773 | Running loss: 0.82117\n","Epoch: 0 | Iteration: 908/2403 | Classification loss: 0.52261 | Regression loss: 0.38674 | Running loss: 0.82127\n","Epoch: 0 | Iteration: 909/2403 | Classification loss: 0.17020 | Regression loss: 0.28771 | Running loss: 0.82087\n","Epoch: 0 | Iteration: 910/2403 | Classification loss: 0.44608 | Regression loss: 0.34235 | Running loss: 0.82084\n","Epoch: 0 | Iteration: 911/2403 | Classification loss: 0.24016 | Regression loss: 0.29847 | Running loss: 0.82053\n","Epoch: 0 | Iteration: 912/2403 | Classification loss: 0.15078 | Regression loss: 0.23829 | Running loss: 0.82005\n","Epoch: 0 | Iteration: 913/2403 | Classification loss: 0.33844 | Regression loss: 0.23487 | Running loss: 0.81978\n","Epoch: 0 | Iteration: 914/2403 | Classification loss: 0.14936 | Regression loss: 0.21393 | Running loss: 0.81928\n","Epoch: 0 | Iteration: 915/2403 | Classification loss: 0.21762 | Regression loss: 0.27516 | Running loss: 0.81893\n","Epoch: 0 | Iteration: 916/2403 | Classification loss: 0.33256 | Regression loss: 0.31133 | Running loss: 0.81874\n","Epoch: 0 | Iteration: 917/2403 | Classification loss: 0.26149 | Regression loss: 0.28251 | Running loss: 0.81844\n","Epoch: 0 | Iteration: 918/2403 | Classification loss: 0.35075 | Regression loss: 0.32553 | Running loss: 0.81828\n","Epoch: 0 | Iteration: 919/2403 | Classification loss: 0.65049 | Regression loss: 0.32461 | Running loss: 0.81845\n","Epoch: 0 | Iteration: 920/2403 | Classification loss: 0.26295 | Regression loss: 0.25762 | Running loss: 0.81813\n","Epoch: 0 | Iteration: 921/2403 | Classification loss: 0.44543 | Regression loss: 0.39123 | Running loss: 0.81815\n","Epoch: 0 | Iteration: 922/2403 | Classification loss: 0.70399 | Regression loss: 0.45725 | Running loss: 0.81852\n","Epoch: 0 | Iteration: 923/2403 | Classification loss: 0.19925 | Regression loss: 0.25898 | Running loss: 0.81813\n","Epoch: 0 | Iteration: 924/2403 | Classification loss: 0.22134 | Regression loss: 0.29983 | Running loss: 0.81781\n","Epoch: 0 | Iteration: 925/2403 | Classification loss: 0.69171 | Regression loss: 0.39061 | Running loss: 0.81809\n","Epoch: 0 | Iteration: 926/2403 | Classification loss: 0.49975 | Regression loss: 0.40283 | Running loss: 0.81819\n","Epoch: 0 | Iteration: 927/2403 | Classification loss: 0.29438 | Regression loss: 0.19326 | Running loss: 0.81783\n","Epoch: 0 | Iteration: 928/2403 | Classification loss: 0.40640 | Regression loss: 0.28501 | Running loss: 0.81769\n","Epoch: 0 | Iteration: 929/2403 | Classification loss: 0.58091 | Regression loss: 0.48396 | Running loss: 0.81796\n","Epoch: 0 | Iteration: 930/2403 | Classification loss: 0.48694 | Regression loss: 0.38290 | Running loss: 0.81802\n","Epoch: 0 | Iteration: 931/2403 | Classification loss: 0.34781 | Regression loss: 0.22350 | Running loss: 0.81775\n","Epoch: 0 | Iteration: 932/2403 | Classification loss: 2.92378 | Regression loss: 0.47372 | Running loss: 0.82052\n","Epoch: 0 | Iteration: 933/2403 | Classification loss: 0.40289 | Regression loss: 0.40351 | Running loss: 0.82050\n","Epoch: 0 | Iteration: 934/2403 | Classification loss: 0.21062 | Regression loss: 0.23867 | Running loss: 0.82011\n","Epoch: 0 | Iteration: 935/2403 | Classification loss: 0.61388 | Regression loss: 0.41598 | Running loss: 0.82033\n","Epoch: 0 | Iteration: 936/2403 | Classification loss: 0.36348 | Regression loss: 0.28842 | Running loss: 0.82015\n","Epoch: 0 | Iteration: 937/2403 | Classification loss: 0.21571 | Regression loss: 0.30977 | Running loss: 0.81984\n","Epoch: 0 | Iteration: 938/2403 | Classification loss: 0.47768 | Regression loss: 0.30842 | Running loss: 0.81980\n","Epoch: 0 | Iteration: 939/2403 | Classification loss: 0.31968 | Regression loss: 0.32326 | Running loss: 0.81961\n","Epoch: 0 | Iteration: 940/2403 | Classification loss: 0.32252 | Regression loss: 0.33129 | Running loss: 0.81943\n","Epoch: 0 | Iteration: 941/2403 | Classification loss: 0.14161 | Regression loss: 0.26145 | Running loss: 0.81899\n","Epoch: 0 | Iteration: 942/2403 | Classification loss: 0.13089 | Regression loss: 0.21305 | Running loss: 0.81849\n","Epoch: 0 | Iteration: 943/2403 | Classification loss: 0.14181 | Regression loss: 0.21207 | Running loss: 0.81800\n","Epoch: 0 | Iteration: 944/2403 | Classification loss: 0.54147 | Regression loss: 0.66852 | Running loss: 0.81841\n","Epoch: 0 | Iteration: 945/2403 | Classification loss: 0.24084 | Regression loss: 0.24450 | Running loss: 0.81806\n","Epoch: 0 | Iteration: 946/2403 | Classification loss: 0.23168 | Regression loss: 0.31722 | Running loss: 0.81777\n","Epoch: 0 | Iteration: 947/2403 | Classification loss: 0.20284 | Regression loss: 0.29901 | Running loss: 0.81744\n","Epoch: 0 | Iteration: 948/2403 | Classification loss: 0.18677 | Regression loss: 0.28859 | Running loss: 0.81708\n","Epoch: 0 | Iteration: 949/2403 | Classification loss: 0.24659 | Regression loss: 0.30618 | Running loss: 0.81680\n","Epoch: 0 | Iteration: 950/2403 | Classification loss: 0.28081 | Regression loss: 0.27298 | Running loss: 0.81652\n","Epoch: 0 | Iteration: 951/2403 | Classification loss: 0.31927 | Regression loss: 0.31670 | Running loss: 0.81633\n","Epoch: 0 | Iteration: 952/2403 | Classification loss: 0.20486 | Regression loss: 0.22613 | Running loss: 0.81593\n","Epoch: 0 | Iteration: 953/2403 | Classification loss: 1.24545 | Regression loss: 0.80680 | Running loss: 0.81723\n","Epoch: 0 | Iteration: 954/2403 | Classification loss: 0.47201 | Regression loss: 0.32376 | Running loss: 0.81720\n","Epoch: 0 | Iteration: 955/2403 | Classification loss: 0.23084 | Regression loss: 0.25205 | Running loss: 0.81685\n","Epoch: 0 | Iteration: 956/2403 | Classification loss: 0.39705 | Regression loss: 0.31200 | Running loss: 0.81674\n","Epoch: 0 | Iteration: 957/2403 | Classification loss: 0.25417 | Regression loss: 0.19366 | Running loss: 0.81636\n","Epoch: 0 | Iteration: 958/2403 | Classification loss: 0.26786 | Regression loss: 0.20224 | Running loss: 0.81599\n","Epoch: 0 | Iteration: 959/2403 | Classification loss: 0.32893 | Regression loss: 0.27599 | Running loss: 0.81577\n","Epoch: 0 | Iteration: 960/2403 | Classification loss: 0.26169 | Regression loss: 0.31409 | Running loss: 0.81552\n","Epoch: 0 | Iteration: 961/2403 | Classification loss: 0.15360 | Regression loss: 0.23797 | Running loss: 0.81508\n","Epoch: 0 | Iteration: 962/2403 | Classification loss: 1.18404 | Regression loss: 0.33863 | Running loss: 0.81582\n","Epoch: 0 | Iteration: 963/2403 | Classification loss: 3.93108 | Regression loss: 0.33073 | Running loss: 0.81940\n","Epoch: 0 | Iteration: 964/2403 | Classification loss: 0.47380 | Regression loss: 0.23265 | Running loss: 0.81928\n","Epoch: 0 | Iteration: 965/2403 | Classification loss: 0.33942 | Regression loss: 0.29413 | Running loss: 0.81909\n","Epoch: 0 | Iteration: 966/2403 | Classification loss: 0.15975 | Regression loss: 0.19813 | Running loss: 0.81861\n","Epoch: 0 | Iteration: 967/2403 | Classification loss: 0.27143 | Regression loss: 0.28496 | Running loss: 0.81834\n","Epoch: 0 | Iteration: 968/2403 | Classification loss: 0.31277 | Regression loss: 0.35047 | Running loss: 0.81818\n","Epoch: 0 | Iteration: 969/2403 | Classification loss: 0.21985 | Regression loss: 0.23958 | Running loss: 0.81781\n","Epoch: 0 | Iteration: 970/2403 | Classification loss: 0.42751 | Regression loss: 0.39180 | Running loss: 0.81781\n","Epoch: 0 | Iteration: 971/2403 | Classification loss: 0.12210 | Regression loss: 0.18594 | Running loss: 0.81728\n","Epoch: 0 | Iteration: 972/2403 | Classification loss: 0.25856 | Regression loss: 0.25990 | Running loss: 0.81698\n","Epoch: 0 | Iteration: 973/2403 | Classification loss: 0.16110 | Regression loss: 0.20341 | Running loss: 0.81651\n","Epoch: 0 | Iteration: 974/2403 | Classification loss: 0.31062 | Regression loss: 0.42700 | Running loss: 0.81643\n","Epoch: 0 | Iteration: 975/2403 | Classification loss: 0.31540 | Regression loss: 0.27651 | Running loss: 0.81620\n","Epoch: 0 | Iteration: 976/2403 | Classification loss: 0.15370 | Regression loss: 0.17478 | Running loss: 0.81570\n","Epoch: 0 | Iteration: 977/2403 | Classification loss: 0.15414 | Regression loss: 0.25831 | Running loss: 0.81529\n","Epoch: 0 | Iteration: 978/2403 | Classification loss: 0.25650 | Regression loss: 0.33939 | Running loss: 0.81506\n","Epoch: 0 | Iteration: 979/2403 | Classification loss: 0.24425 | Regression loss: 0.27950 | Running loss: 0.81477\n","Epoch: 0 | Iteration: 980/2403 | Classification loss: 0.26414 | Regression loss: 0.23397 | Running loss: 0.81444\n","Epoch: 0 | Iteration: 981/2403 | Classification loss: 0.24948 | Regression loss: 0.27078 | Running loss: 0.81414\n","Epoch: 0 | Iteration: 982/2403 | Classification loss: 0.18765 | Regression loss: 0.25115 | Running loss: 0.81376\n","Epoch: 0 | Iteration: 983/2403 | Classification loss: 0.41566 | Regression loss: 0.25830 | Running loss: 0.81362\n","Epoch: 0 | Iteration: 984/2403 | Classification loss: 0.46926 | Regression loss: 0.37992 | Running loss: 0.81366\n","Epoch: 0 | Iteration: 985/2403 | Classification loss: 0.21834 | Regression loss: 0.25416 | Running loss: 0.81331\n","Epoch: 0 | Iteration: 986/2403 | Classification loss: 0.41294 | Regression loss: 0.37180 | Running loss: 0.81328\n","Epoch: 0 | Iteration: 987/2403 | Classification loss: 0.23704 | Regression loss: 0.26486 | Running loss: 0.81296\n","Epoch: 0 | Iteration: 988/2403 | Classification loss: 0.23357 | Regression loss: 0.19165 | Running loss: 0.81257\n","Epoch: 0 | Iteration: 989/2403 | Classification loss: 0.45680 | Regression loss: 0.37544 | Running loss: 0.81259\n","Epoch: 0 | Iteration: 990/2403 | Classification loss: 0.29793 | Regression loss: 0.30941 | Running loss: 0.81238\n","Epoch: 0 | Iteration: 991/2403 | Classification loss: 0.32696 | Regression loss: 0.32620 | Running loss: 0.81222\n","Epoch: 0 | Iteration: 992/2403 | Classification loss: 0.53438 | Regression loss: 0.48542 | Running loss: 0.81243\n","Epoch: 0 | Iteration: 993/2403 | Classification loss: 0.34981 | Regression loss: 0.26769 | Running loss: 0.81224\n","Epoch: 0 | Iteration: 994/2403 | Classification loss: 0.23470 | Regression loss: 0.24003 | Running loss: 0.81190\n","Epoch: 0 | Iteration: 995/2403 | Classification loss: 0.18029 | Regression loss: 0.22380 | Running loss: 0.81149\n","Epoch: 0 | Iteration: 996/2403 | Classification loss: 0.15878 | Regression loss: 0.15535 | Running loss: 0.81099\n","Epoch: 0 | Iteration: 997/2403 | Classification loss: 0.36484 | Regression loss: 0.42812 | Running loss: 0.81097\n","Epoch: 0 | Iteration: 998/2403 | Classification loss: 0.31938 | Regression loss: 0.27693 | Running loss: 0.81076\n","Epoch: 0 | Iteration: 999/2403 | Classification loss: 0.38969 | Regression loss: 0.39546 | Running loss: 0.81073\n","Epoch: 0 | Iteration: 1000/2403 | Classification loss: 0.22729 | Regression loss: 0.28113 | Running loss: 0.81043\n","Epoch: 0 | Iteration: 1001/2403 | Classification loss: 0.35506 | Regression loss: 0.34981 | Running loss: 0.81032\n","Epoch: 0 | Iteration: 1002/2403 | Classification loss: 0.23165 | Regression loss: 0.25758 | Running loss: 0.81000\n","Epoch: 0 | Iteration: 1003/2403 | Classification loss: 0.07843 | Regression loss: 0.16764 | Running loss: 0.80944\n","Epoch: 0 | Iteration: 1004/2403 | Classification loss: 0.51329 | Regression loss: 0.26909 | Running loss: 0.80941\n","Epoch: 0 | Iteration: 1005/2403 | Classification loss: 0.39912 | Regression loss: 0.29252 | Running loss: 0.80929\n","Epoch: 0 | Iteration: 1006/2403 | Classification loss: 0.29886 | Regression loss: 0.26686 | Running loss: 0.80905\n","Epoch: 0 | Iteration: 1007/2403 | Classification loss: 0.31477 | Regression loss: 0.25903 | Running loss: 0.80882\n","Epoch: 0 | Iteration: 1008/2403 | Classification loss: 0.23323 | Regression loss: 0.24310 | Running loss: 0.80849\n","Epoch: 0 | Iteration: 1009/2403 | Classification loss: 0.28162 | Regression loss: 0.22193 | Running loss: 0.80819\n","Epoch: 0 | Iteration: 1010/2403 | Classification loss: 0.26143 | Regression loss: 0.25078 | Running loss: 0.80789\n","Epoch: 0 | Iteration: 1011/2403 | Classification loss: 0.21388 | Regression loss: 0.25230 | Running loss: 0.80756\n","Epoch: 0 | Iteration: 1012/2403 | Classification loss: 0.29957 | Regression loss: 0.29511 | Running loss: 0.80735\n","Epoch: 0 | Iteration: 1013/2403 | Classification loss: 0.28353 | Regression loss: 0.31576 | Running loss: 0.80714\n","Epoch: 0 | Iteration: 1014/2403 | Classification loss: 0.36230 | Regression loss: 0.38813 | Running loss: 0.80708\n","Epoch: 0 | Iteration: 1015/2403 | Classification loss: 2.28906 | Regression loss: 0.69682 | Running loss: 0.80923\n","Epoch: 0 | Iteration: 1016/2403 | Classification loss: 0.16754 | Regression loss: 0.25814 | Running loss: 0.80885\n","Epoch: 0 | Iteration: 1017/2403 | Classification loss: 0.30739 | Regression loss: 0.30017 | Running loss: 0.80866\n","Epoch: 0 | Iteration: 1018/2403 | Classification loss: 0.58048 | Regression loss: 0.37348 | Running loss: 0.80880\n","Epoch: 0 | Iteration: 1019/2403 | Classification loss: 0.57721 | Regression loss: 0.59776 | Running loss: 0.80916\n","Epoch: 0 | Iteration: 1020/2403 | Classification loss: 0.38058 | Regression loss: 0.28053 | Running loss: 0.80901\n","Epoch: 0 | Iteration: 1021/2403 | Classification loss: 0.38528 | Regression loss: 0.26360 | Running loss: 0.80886\n","Epoch: 0 | Iteration: 1022/2403 | Classification loss: 0.30653 | Regression loss: 0.30435 | Running loss: 0.80866\n","Epoch: 0 | Iteration: 1023/2403 | Classification loss: 0.14914 | Regression loss: 0.25690 | Running loss: 0.80827\n","Epoch: 0 | Iteration: 1024/2403 | Classification loss: 1.12071 | Regression loss: 0.43551 | Running loss: 0.80900\n","Epoch: 0 | Iteration: 1025/2403 | Classification loss: 0.33523 | Regression loss: 0.30804 | Running loss: 0.80884\n","Epoch: 0 | Iteration: 1026/2403 | Classification loss: 0.13904 | Regression loss: 0.23774 | Running loss: 0.80842\n","Epoch: 0 | Iteration: 1027/2403 | Classification loss: 0.20126 | Regression loss: 0.29111 | Running loss: 0.80811\n","Epoch: 0 | Iteration: 1028/2403 | Classification loss: 0.13296 | Regression loss: 0.24414 | Running loss: 0.80769\n","Epoch: 0 | Iteration: 1029/2403 | Classification loss: 0.16747 | Regression loss: 0.26682 | Running loss: 0.80733\n","Epoch: 0 | Iteration: 1030/2403 | Classification loss: 0.40114 | Regression loss: 0.48052 | Running loss: 0.80740\n","Epoch: 0 | Iteration: 1031/2403 | Classification loss: 0.17922 | Regression loss: 0.22656 | Running loss: 0.80701\n","Epoch: 0 | Iteration: 1032/2403 | Classification loss: 0.30992 | Regression loss: 0.29399 | Running loss: 0.80681\n","Epoch: 0 | Iteration: 1033/2403 | Classification loss: 0.20323 | Regression loss: 0.21097 | Running loss: 0.80643\n","Epoch: 0 | Iteration: 1034/2403 | Classification loss: 0.25607 | Regression loss: 0.30750 | Running loss: 0.80620\n","Epoch: 0 | Iteration: 1035/2403 | Classification loss: 0.20577 | Regression loss: 0.33747 | Running loss: 0.80594\n","Epoch: 0 | Iteration: 1036/2403 | Classification loss: 0.22710 | Regression loss: 0.34709 | Running loss: 0.80572\n","Epoch: 0 | Iteration: 1037/2403 | Classification loss: 0.14373 | Regression loss: 0.35459 | Running loss: 0.80542\n","Epoch: 0 | Iteration: 1038/2403 | Classification loss: 0.10531 | Regression loss: 0.28891 | Running loss: 0.80503\n","Epoch: 0 | Iteration: 1039/2403 | Classification loss: 0.15760 | Regression loss: 0.24463 | Running loss: 0.80464\n","Epoch: 0 | Iteration: 1040/2403 | Classification loss: 0.10367 | Regression loss: 0.18038 | Running loss: 0.80414\n","Epoch: 0 | Iteration: 1041/2403 | Classification loss: 0.34241 | Regression loss: 0.36052 | Running loss: 0.80404\n","Epoch: 0 | Iteration: 1042/2403 | Classification loss: 0.09868 | Regression loss: 0.20337 | Running loss: 0.80356\n","Epoch: 0 | Iteration: 1043/2403 | Classification loss: 0.13863 | Regression loss: 0.24626 | Running loss: 0.80316\n","Epoch: 0 | Iteration: 1044/2403 | Classification loss: 0.52009 | Regression loss: 0.42803 | Running loss: 0.80330\n","Epoch: 0 | Iteration: 1045/2403 | Classification loss: 0.14795 | Regression loss: 0.32246 | Running loss: 0.80298\n","Epoch: 0 | Iteration: 1046/2403 | Classification loss: 0.19506 | Regression loss: 0.30868 | Running loss: 0.80269\n","Epoch: 0 | Iteration: 1047/2403 | Classification loss: 0.17764 | Regression loss: 0.31430 | Running loss: 0.80240\n","Epoch: 0 | Iteration: 1048/2403 | Classification loss: 0.07270 | Regression loss: 0.26160 | Running loss: 0.80195\n","Epoch: 0 | Iteration: 1049/2403 | Classification loss: 0.09442 | Regression loss: 0.27787 | Running loss: 0.80154\n","Epoch: 0 | Iteration: 1050/2403 | Classification loss: 0.16476 | Regression loss: 0.25692 | Running loss: 0.80118\n","Epoch: 0 | Iteration: 1051/2403 | Classification loss: 0.22461 | Regression loss: 0.31876 | Running loss: 0.80093\n","Epoch: 0 | Iteration: 1052/2403 | Classification loss: 0.10045 | Regression loss: 0.20127 | Running loss: 0.80046\n","Epoch: 0 | Iteration: 1053/2403 | Classification loss: 0.17722 | Regression loss: 0.27832 | Running loss: 0.80013\n","Epoch: 0 | Iteration: 1054/2403 | Classification loss: 0.22037 | Regression loss: 0.34680 | Running loss: 0.79991\n","Epoch: 0 | Iteration: 1055/2403 | Classification loss: 0.35916 | Regression loss: 0.33783 | Running loss: 0.79981\n","Epoch: 0 | Iteration: 1056/2403 | Classification loss: 0.29664 | Regression loss: 0.25979 | Running loss: 0.79958\n","Epoch: 0 | Iteration: 1057/2403 | Classification loss: 0.22321 | Regression loss: 0.27197 | Running loss: 0.79929\n","Epoch: 0 | Iteration: 1058/2403 | Classification loss: 0.11298 | Regression loss: 0.23731 | Running loss: 0.79887\n","Epoch: 0 | Iteration: 1059/2403 | Classification loss: 0.25721 | Regression loss: 0.32174 | Running loss: 0.79866\n","Epoch: 0 | Iteration: 1060/2403 | Classification loss: 0.13664 | Regression loss: 0.28561 | Running loss: 0.79831\n","Epoch: 0 | Iteration: 1061/2403 | Classification loss: 1.26003 | Regression loss: 0.46940 | Running loss: 0.79918\n","Epoch: 0 | Iteration: 1062/2403 | Classification loss: 0.32735 | Regression loss: 0.31105 | Running loss: 0.79903\n","Epoch: 0 | Iteration: 1063/2403 | Classification loss: 0.22644 | Regression loss: 0.28357 | Running loss: 0.79876\n","Epoch: 0 | Iteration: 1064/2403 | Classification loss: 0.27968 | Regression loss: 0.18210 | Running loss: 0.79844\n","Epoch: 0 | Iteration: 1065/2403 | Classification loss: 0.25001 | Regression loss: 0.27931 | Running loss: 0.79819\n","Epoch: 0 | Iteration: 1066/2403 | Classification loss: 0.21313 | Regression loss: 0.33529 | Running loss: 0.79796\n","Epoch: 0 | Iteration: 1067/2403 | Classification loss: 0.19466 | Regression loss: 0.24649 | Running loss: 0.79762\n","Epoch: 0 | Iteration: 1068/2403 | Classification loss: 0.14520 | Regression loss: 0.23290 | Running loss: 0.79723\n","Epoch: 0 | Iteration: 1069/2403 | Classification loss: 0.49805 | Regression loss: 0.25660 | Running loss: 0.79719\n","Epoch: 0 | Iteration: 1070/2403 | Classification loss: 1.17375 | Regression loss: 0.51734 | Running loss: 0.79802\n","Epoch: 0 | Iteration: 1071/2403 | Classification loss: 0.42586 | Regression loss: 0.34327 | Running loss: 0.79800\n","Epoch: 0 | Iteration: 1072/2403 | Classification loss: 0.38786 | Regression loss: 0.34662 | Running loss: 0.79794\n","Epoch: 0 | Iteration: 1073/2403 | Classification loss: 0.76673 | Regression loss: 0.45456 | Running loss: 0.79833\n","Epoch: 0 | Iteration: 1074/2403 | Classification loss: 0.16242 | Regression loss: 0.22655 | Running loss: 0.79795\n","Epoch: 0 | Iteration: 1075/2403 | Classification loss: 0.17442 | Regression loss: 0.28547 | Running loss: 0.79764\n","Epoch: 0 | Iteration: 1076/2403 | Classification loss: 0.21557 | Regression loss: 0.26638 | Running loss: 0.79734\n","Epoch: 0 | Iteration: 1077/2403 | Classification loss: 0.16427 | Regression loss: 0.21058 | Running loss: 0.79695\n","Epoch: 0 | Iteration: 1078/2403 | Classification loss: 0.13170 | Regression loss: 0.17197 | Running loss: 0.79649\n","Epoch: 0 | Iteration: 1079/2403 | Classification loss: 0.16220 | Regression loss: 0.22730 | Running loss: 0.79612\n","Epoch: 0 | Iteration: 1080/2403 | Classification loss: 0.14035 | Regression loss: 0.26200 | Running loss: 0.79575\n","Epoch: 0 | Iteration: 1081/2403 | Classification loss: 0.18194 | Regression loss: 0.20704 | Running loss: 0.79538\n","Epoch: 0 | Iteration: 1082/2403 | Classification loss: 0.08202 | Regression loss: 0.17572 | Running loss: 0.79488\n","Epoch: 0 | Iteration: 1083/2403 | Classification loss: 0.24088 | Regression loss: 0.35907 | Running loss: 0.79470\n","Epoch: 0 | Iteration: 1084/2403 | Classification loss: 0.24600 | Regression loss: 0.26320 | Running loss: 0.79444\n","Epoch: 0 | Iteration: 1085/2403 | Classification loss: 0.18188 | Regression loss: 0.25938 | Running loss: 0.79411\n","Epoch: 0 | Iteration: 1086/2403 | Classification loss: 0.11457 | Regression loss: 0.21096 | Running loss: 0.79368\n","Epoch: 0 | Iteration: 1087/2403 | Classification loss: 0.64707 | Regression loss: 0.74194 | Running loss: 0.79423\n","Epoch: 0 | Iteration: 1088/2403 | Classification loss: 0.70717 | Regression loss: 0.50947 | Running loss: 0.79461\n","Epoch: 0 | Iteration: 1089/2403 | Classification loss: 0.70355 | Regression loss: 0.50966 | Running loss: 0.79500\n","Epoch: 0 | Iteration: 1090/2403 | Classification loss: 0.43180 | Regression loss: 0.50509 | Running loss: 0.79513\n","Epoch: 0 | Iteration: 1091/2403 | Classification loss: 0.24880 | Regression loss: 0.27503 | Running loss: 0.79488\n","Epoch: 0 | Iteration: 1092/2403 | Classification loss: 0.29859 | Regression loss: 0.26021 | Running loss: 0.79466\n","Epoch: 0 | Iteration: 1093/2403 | Classification loss: 0.29806 | Regression loss: 0.22484 | Running loss: 0.79442\n","Epoch: 0 | Iteration: 1094/2403 | Classification loss: 0.33348 | Regression loss: 0.41505 | Running loss: 0.79437\n","Epoch: 0 | Iteration: 1095/2403 | Classification loss: 0.50783 | Regression loss: 0.34295 | Running loss: 0.79443\n","Epoch: 0 | Iteration: 1096/2403 | Classification loss: 0.16803 | Regression loss: 0.22713 | Running loss: 0.79406\n","Epoch: 0 | Iteration: 1097/2403 | Classification loss: 0.35236 | Regression loss: 0.49862 | Running loss: 0.79411\n","Epoch: 0 | Iteration: 1098/2403 | Classification loss: 0.43585 | Regression loss: 0.29868 | Running loss: 0.79406\n","Epoch: 0 | Iteration: 1099/2403 | Classification loss: 0.25713 | Regression loss: 0.27396 | Running loss: 0.79382\n","Epoch: 0 | Iteration: 1100/2403 | Classification loss: 0.42010 | Regression loss: 0.30611 | Running loss: 0.79376\n","Epoch: 0 | Iteration: 1101/2403 | Classification loss: 0.29857 | Regression loss: 0.32450 | Running loss: 0.79360\n","Epoch: 0 | Iteration: 1102/2403 | Classification loss: 0.15077 | Regression loss: 0.27671 | Running loss: 0.79327\n","Epoch: 0 | Iteration: 1103/2403 | Classification loss: 0.39490 | Regression loss: 0.43304 | Running loss: 0.79330\n","Epoch: 0 | Iteration: 1104/2403 | Classification loss: 0.17684 | Regression loss: 0.25031 | Running loss: 0.79297\n","Epoch: 0 | Iteration: 1105/2403 | Classification loss: 0.40348 | Regression loss: 0.35933 | Running loss: 0.79294\n","Epoch: 0 | Iteration: 1106/2403 | Classification loss: 0.49317 | Regression loss: 0.48394 | Running loss: 0.79311\n","Epoch: 0 | Iteration: 1107/2403 | Classification loss: 0.20739 | Regression loss: 0.24761 | Running loss: 0.79280\n","Epoch: 0 | Iteration: 1108/2403 | Classification loss: 0.42744 | Regression loss: 0.31248 | Running loss: 0.79276\n","Epoch: 0 | Iteration: 1109/2403 | Classification loss: 0.25251 | Regression loss: 0.28434 | Running loss: 0.79253\n","Epoch: 0 | Iteration: 1110/2403 | Classification loss: 0.47351 | Regression loss: 0.31833 | Running loss: 0.79253\n","Epoch: 0 | Iteration: 1111/2403 | Classification loss: 0.28062 | Regression loss: 0.22711 | Running loss: 0.79227\n","Epoch: 0 | Iteration: 1112/2403 | Classification loss: 0.15673 | Regression loss: 0.24522 | Running loss: 0.79192\n","Epoch: 0 | Iteration: 1113/2403 | Classification loss: 0.51909 | Regression loss: 0.40153 | Running loss: 0.79203\n","Epoch: 0 | Iteration: 1114/2403 | Classification loss: 0.25205 | Regression loss: 0.32299 | Running loss: 0.79184\n","Epoch: 0 | Iteration: 1115/2403 | Classification loss: 0.46328 | Regression loss: 0.31992 | Running loss: 0.79183\n","Epoch: 0 | Iteration: 1116/2403 | Classification loss: 0.22993 | Regression loss: 0.22816 | Running loss: 0.79153\n","Epoch: 0 | Iteration: 1117/2403 | Classification loss: 0.15083 | Regression loss: 0.25785 | Running loss: 0.79119\n","Epoch: 0 | Iteration: 1118/2403 | Classification loss: 0.13666 | Regression loss: 0.27045 | Running loss: 0.79085\n","Epoch: 0 | Iteration: 1119/2403 | Classification loss: 0.41155 | Regression loss: 0.40705 | Running loss: 0.79087\n","Epoch: 0 | Iteration: 1120/2403 | Classification loss: 0.49514 | Regression loss: 0.34978 | Running loss: 0.79092\n","Epoch: 0 | Iteration: 1121/2403 | Classification loss: 0.29548 | Regression loss: 0.29533 | Running loss: 0.79074\n","Epoch: 0 | Iteration: 1122/2403 | Classification loss: 0.23869 | Regression loss: 0.24422 | Running loss: 0.79047\n","Epoch: 0 | Iteration: 1123/2403 | Classification loss: 0.22005 | Regression loss: 0.21458 | Running loss: 0.79015\n","Epoch: 0 | Iteration: 1124/2403 | Classification loss: 0.50720 | Regression loss: 0.39874 | Running loss: 0.79025\n","Epoch: 0 | Iteration: 1125/2403 | Classification loss: 0.45003 | Regression loss: 0.33734 | Running loss: 0.79025\n","Epoch: 0 | Iteration: 1126/2403 | Classification loss: 0.45777 | Regression loss: 0.28286 | Running loss: 0.79021\n","Epoch: 0 | Iteration: 1127/2403 | Classification loss: 0.19017 | Regression loss: 0.28420 | Running loss: 0.78992\n","Epoch: 0 | Iteration: 1128/2403 | Classification loss: 0.24345 | Regression loss: 0.25136 | Running loss: 0.78966\n","Epoch: 0 | Iteration: 1129/2403 | Classification loss: 0.19884 | Regression loss: 0.30085 | Running loss: 0.78941\n","Epoch: 0 | Iteration: 1130/2403 | Classification loss: 0.25572 | Regression loss: 0.32057 | Running loss: 0.78922\n","Epoch: 0 | Iteration: 1131/2403 | Classification loss: 0.40231 | Regression loss: 0.39262 | Running loss: 0.78922\n","Epoch: 0 | Iteration: 1132/2403 | Classification loss: 0.52230 | Regression loss: 0.37577 | Running loss: 0.78932\n","Epoch: 0 | Iteration: 1133/2403 | Classification loss: 0.23209 | Regression loss: 0.26104 | Running loss: 0.78906\n","Epoch: 0 | Iteration: 1134/2403 | Classification loss: 0.17057 | Regression loss: 0.17924 | Running loss: 0.78867\n","Epoch: 0 | Iteration: 1135/2403 | Classification loss: 0.14728 | Regression loss: 0.21788 | Running loss: 0.78830\n","Epoch: 0 | Iteration: 1136/2403 | Classification loss: 0.17093 | Regression loss: 0.19785 | Running loss: 0.78793\n","Epoch: 0 | Iteration: 1137/2403 | Classification loss: 0.08185 | Regression loss: 0.19277 | Running loss: 0.78748\n","Epoch: 0 | Iteration: 1138/2403 | Classification loss: 0.28680 | Regression loss: 0.46542 | Running loss: 0.78745\n","Epoch: 0 | Iteration: 1139/2403 | Classification loss: 1.08903 | Regression loss: 0.34339 | Running loss: 0.78801\n","Epoch: 0 | Iteration: 1140/2403 | Classification loss: 0.23693 | Regression loss: 0.28503 | Running loss: 0.78778\n","Epoch: 0 | Iteration: 1141/2403 | Classification loss: 0.36750 | Regression loss: 0.27794 | Running loss: 0.78765\n","Epoch: 0 | Iteration: 1142/2403 | Classification loss: 0.22311 | Regression loss: 0.30526 | Running loss: 0.78743\n","Epoch: 0 | Iteration: 1143/2403 | Classification loss: 0.33176 | Regression loss: 0.26160 | Running loss: 0.78726\n","Epoch: 0 | Iteration: 1144/2403 | Classification loss: 0.25118 | Regression loss: 0.41401 | Running loss: 0.78715\n","Epoch: 0 | Iteration: 1145/2403 | Classification loss: 0.22253 | Regression loss: 0.33230 | Running loss: 0.78695\n","Epoch: 0 | Iteration: 1146/2403 | Classification loss: 0.90017 | Regression loss: 0.38895 | Running loss: 0.78739\n","Epoch: 0 | Iteration: 1147/2403 | Classification loss: 0.40976 | Regression loss: 0.27784 | Running loss: 0.78730\n","Epoch: 0 | Iteration: 1148/2403 | Classification loss: 0.13675 | Regression loss: 0.15620 | Running loss: 0.78687\n","Epoch: 0 | Iteration: 1149/2403 | Classification loss: 0.26549 | Regression loss: 0.23535 | Running loss: 0.78662\n","Epoch: 0 | Iteration: 1150/2403 | Classification loss: 0.57572 | Regression loss: 0.32116 | Running loss: 0.78671\n","Epoch: 0 | Iteration: 1151/2403 | Classification loss: 0.26575 | Regression loss: 0.27979 | Running loss: 0.78651\n","Epoch: 0 | Iteration: 1152/2403 | Classification loss: 0.38218 | Regression loss: 0.36277 | Running loss: 0.78647\n","Epoch: 0 | Iteration: 1153/2403 | Classification loss: 0.42675 | Regression loss: 0.33884 | Running loss: 0.78645\n","Epoch: 0 | Iteration: 1154/2403 | Classification loss: 0.38378 | Regression loss: 0.30085 | Running loss: 0.78636\n","Epoch: 0 | Iteration: 1155/2403 | Classification loss: 0.24034 | Regression loss: 0.35540 | Running loss: 0.78620\n","Epoch: 0 | Iteration: 1156/2403 | Classification loss: 0.41425 | Regression loss: 0.36907 | Running loss: 0.78620\n","Epoch: 0 | Iteration: 1157/2403 | Classification loss: 0.29887 | Regression loss: 0.24067 | Running loss: 0.78598\n","Epoch: 0 | Iteration: 1158/2403 | Classification loss: 0.39122 | Regression loss: 0.37003 | Running loss: 0.78596\n","Epoch: 0 | Iteration: 1159/2403 | Classification loss: 0.17011 | Regression loss: 0.29119 | Running loss: 0.78568\n","Epoch: 0 | Iteration: 1160/2403 | Classification loss: 0.16616 | Regression loss: 0.25255 | Running loss: 0.78536\n","Epoch: 0 | Iteration: 1161/2403 | Classification loss: 0.31279 | Regression loss: 0.31374 | Running loss: 0.78523\n","Epoch: 0 | Iteration: 1162/2403 | Classification loss: 0.20201 | Regression loss: 0.25680 | Running loss: 0.78495\n","Epoch: 0 | Iteration: 1163/2403 | Classification loss: 0.24950 | Regression loss: 0.29461 | Running loss: 0.78474\n","Epoch: 0 | Iteration: 1164/2403 | Classification loss: 0.31011 | Regression loss: 0.40134 | Running loss: 0.78468\n","Epoch: 0 | Iteration: 1165/2403 | Classification loss: 0.16282 | Regression loss: 0.20874 | Running loss: 0.78432\n","Epoch: 0 | Iteration: 1166/2403 | Classification loss: 0.19293 | Regression loss: 0.23077 | Running loss: 0.78401\n","Epoch: 0 | Iteration: 1167/2403 | Classification loss: 0.18492 | Regression loss: 0.22392 | Running loss: 0.78369\n","Epoch: 0 | Iteration: 1168/2403 | Classification loss: 0.24522 | Regression loss: 0.25887 | Running loss: 0.78345\n","Epoch: 0 | Iteration: 1169/2403 | Classification loss: 0.24098 | Regression loss: 0.23836 | Running loss: 0.78319\n","Epoch: 0 | Iteration: 1170/2403 | Classification loss: 0.42144 | Regression loss: 0.34101 | Running loss: 0.78317\n","Epoch: 0 | Iteration: 1171/2403 | Classification loss: 0.33269 | Regression loss: 0.32146 | Running loss: 0.78306\n","Epoch: 0 | Iteration: 1172/2403 | Classification loss: 0.68045 | Regression loss: 0.57935 | Running loss: 0.78347\n","Epoch: 0 | Iteration: 1173/2403 | Classification loss: 0.80061 | Regression loss: 0.47626 | Running loss: 0.78389\n","Epoch: 0 | Iteration: 1174/2403 | Classification loss: 0.42896 | Regression loss: 0.39370 | Running loss: 0.78392\n","Epoch: 0 | Iteration: 1175/2403 | Classification loss: 0.40745 | Regression loss: 0.31711 | Running loss: 0.78387\n","Epoch: 0 | Iteration: 1176/2403 | Classification loss: 0.24350 | Regression loss: 0.22020 | Running loss: 0.78360\n","Epoch: 0 | Iteration: 1177/2403 | Classification loss: 0.51402 | Regression loss: 0.37242 | Running loss: 0.78369\n","Epoch: 0 | Iteration: 1178/2403 | Classification loss: 0.22880 | Regression loss: 0.30306 | Running loss: 0.78347\n","Epoch: 0 | Iteration: 1179/2403 | Classification loss: 0.43212 | Regression loss: 0.39554 | Running loss: 0.78351\n","Epoch: 0 | Iteration: 1180/2403 | Classification loss: 0.08980 | Regression loss: 0.21469 | Running loss: 0.78311\n","Epoch: 0 | Iteration: 1181/2403 | Classification loss: 0.22446 | Regression loss: 0.28085 | Running loss: 0.78287\n","Epoch: 0 | Iteration: 1182/2403 | Classification loss: 0.27838 | Regression loss: 0.29247 | Running loss: 0.78269\n","Epoch: 0 | Iteration: 1183/2403 | Classification loss: 0.34386 | Regression loss: 0.32913 | Running loss: 0.78260\n","Epoch: 0 | Iteration: 1184/2403 | Classification loss: 0.63430 | Regression loss: 0.39554 | Running loss: 0.78281\n","Epoch: 0 | Iteration: 1185/2403 | Classification loss: 0.18442 | Regression loss: 0.20114 | Running loss: 0.78247\n","Epoch: 0 | Iteration: 1186/2403 | Classification loss: 0.23665 | Regression loss: 0.31154 | Running loss: 0.78228\n","Epoch: 0 | Iteration: 1187/2403 | Classification loss: 0.39174 | Regression loss: 0.36863 | Running loss: 0.78226\n","Epoch: 0 | Iteration: 1188/2403 | Classification loss: 0.28557 | Regression loss: 0.29064 | Running loss: 0.78208\n","Epoch: 0 | Iteration: 1189/2403 | Classification loss: 0.13945 | Regression loss: 0.26927 | Running loss: 0.78177\n","Epoch: 0 | Iteration: 1190/2403 | Classification loss: 0.27253 | Regression loss: 0.30250 | Running loss: 0.78160\n","Epoch: 0 | Iteration: 1191/2403 | Classification loss: 0.21398 | Regression loss: 0.26525 | Running loss: 0.78134\n","Epoch: 0 | Iteration: 1192/2403 | Classification loss: 0.50361 | Regression loss: 0.43007 | Running loss: 0.78147\n","Epoch: 0 | Iteration: 1193/2403 | Classification loss: 0.16885 | Regression loss: 0.17883 | Running loss: 0.78111\n","Epoch: 0 | Iteration: 1194/2403 | Classification loss: 0.18155 | Regression loss: 0.23355 | Running loss: 0.78080\n","Epoch: 0 | Iteration: 1195/2403 | Classification loss: 0.23207 | Regression loss: 0.25903 | Running loss: 0.78056\n","Epoch: 0 | Iteration: 1196/2403 | Classification loss: 0.21573 | Regression loss: 0.29219 | Running loss: 0.78033\n","Epoch: 0 | Iteration: 1197/2403 | Classification loss: 0.38344 | Regression loss: 0.28166 | Running loss: 0.78023\n","Epoch: 0 | Iteration: 1198/2403 | Classification loss: 0.27098 | Regression loss: 0.36134 | Running loss: 0.78011\n","Epoch: 0 | Iteration: 1199/2403 | Classification loss: 0.32770 | Regression loss: 0.30058 | Running loss: 0.77998\n","Epoch: 0 | Iteration: 1200/2403 | Classification loss: 0.25621 | Regression loss: 0.28685 | Running loss: 0.77979\n","Epoch: 0 | Iteration: 1201/2403 | Classification loss: 0.26874 | Regression loss: 0.23169 | Running loss: 0.77955\n","Epoch: 0 | Iteration: 1202/2403 | Classification loss: 0.12223 | Regression loss: 0.20849 | Running loss: 0.77918\n","Epoch: 0 | Iteration: 1203/2403 | Classification loss: 0.73971 | Regression loss: 0.32818 | Running loss: 0.77942\n","Epoch: 0 | Iteration: 1204/2403 | Classification loss: 0.42957 | Regression loss: 0.26839 | Running loss: 0.77935\n","Epoch: 0 | Iteration: 1205/2403 | Classification loss: 0.21905 | Regression loss: 0.18478 | Running loss: 0.77904\n","Epoch: 0 | Iteration: 1206/2403 | Classification loss: 0.21070 | Regression loss: 0.22815 | Running loss: 0.77876\n","Epoch: 0 | Iteration: 1207/2403 | Classification loss: 0.29217 | Regression loss: 0.20981 | Running loss: 0.77853\n","Epoch: 0 | Iteration: 1208/2403 | Classification loss: 0.21729 | Regression loss: 0.23971 | Running loss: 0.77826\n","Epoch: 0 | Iteration: 1209/2403 | Classification loss: 0.17442 | Regression loss: 0.27721 | Running loss: 0.77799\n","Epoch: 0 | Iteration: 1210/2403 | Classification loss: 0.28035 | Regression loss: 0.22718 | Running loss: 0.77777\n","Epoch: 0 | Iteration: 1211/2403 | Classification loss: 0.37165 | Regression loss: 0.35214 | Running loss: 0.77772\n","Epoch: 0 | Iteration: 1212/2403 | Classification loss: 0.40411 | Regression loss: 0.25157 | Running loss: 0.77762\n","Epoch: 0 | Iteration: 1213/2403 | Classification loss: 0.10646 | Regression loss: 0.25502 | Running loss: 0.77728\n","Epoch: 0 | Iteration: 1214/2403 | Classification loss: 0.20313 | Regression loss: 0.19886 | Running loss: 0.77697\n","Epoch: 0 | Iteration: 1215/2403 | Classification loss: 0.31954 | Regression loss: 0.25583 | Running loss: 0.77681\n","Epoch: 0 | Iteration: 1216/2403 | Classification loss: 0.11783 | Regression loss: 0.25456 | Running loss: 0.77647\n","Epoch: 0 | Iteration: 1217/2403 | Classification loss: 0.28482 | Regression loss: 0.23599 | Running loss: 0.77626\n","Epoch: 0 | Iteration: 1218/2403 | Classification loss: 0.29288 | Regression loss: 0.21510 | Running loss: 0.77604\n","Epoch: 0 | Iteration: 1219/2403 | Classification loss: 0.13971 | Regression loss: 0.23584 | Running loss: 0.77571\n","Epoch: 0 | Iteration: 1220/2403 | Classification loss: 0.15344 | Regression loss: 0.30360 | Running loss: 0.77545\n","Epoch: 0 | Iteration: 1221/2403 | Classification loss: 0.35331 | Regression loss: 0.47940 | Running loss: 0.77550\n","Epoch: 0 | Iteration: 1222/2403 | Classification loss: 0.12805 | Regression loss: 0.20279 | Running loss: 0.77514\n","Epoch: 0 | Iteration: 1223/2403 | Classification loss: 0.52099 | Regression loss: 0.31771 | Running loss: 0.77519\n","Epoch: 0 | Iteration: 1224/2403 | Classification loss: 0.63581 | Regression loss: 0.52805 | Running loss: 0.77550\n","Epoch: 0 | Iteration: 1225/2403 | Classification loss: 0.23287 | Regression loss: 0.22901 | Running loss: 0.77525\n","Epoch: 0 | Iteration: 1226/2403 | Classification loss: 0.27233 | Regression loss: 0.23197 | Running loss: 0.77503\n","Epoch: 0 | Iteration: 1227/2403 | Classification loss: 0.32965 | Regression loss: 0.28795 | Running loss: 0.77490\n","Epoch: 0 | Iteration: 1228/2403 | Classification loss: 0.22391 | Regression loss: 0.27694 | Running loss: 0.77468\n","Epoch: 0 | Iteration: 1229/2403 | Classification loss: 0.14685 | Regression loss: 0.17791 | Running loss: 0.77431\n","Epoch: 0 | Iteration: 1230/2403 | Classification loss: 0.47298 | Regression loss: 0.30677 | Running loss: 0.77431\n","Epoch: 0 | Iteration: 1231/2403 | Classification loss: 0.71349 | Regression loss: 0.72179 | Running loss: 0.77485\n","Epoch: 0 | Iteration: 1232/2403 | Classification loss: 0.23541 | Regression loss: 0.38772 | Running loss: 0.77473\n","Epoch: 0 | Iteration: 1233/2403 | Classification loss: 0.27011 | Regression loss: 0.26634 | Running loss: 0.77454\n","Epoch: 0 | Iteration: 1234/2403 | Classification loss: 0.15460 | Regression loss: 0.31397 | Running loss: 0.77429\n","Epoch: 0 | Iteration: 1235/2403 | Classification loss: 0.46255 | Regression loss: 0.66275 | Running loss: 0.77457\n","Epoch: 0 | Iteration: 1236/2403 | Classification loss: 0.61768 | Regression loss: 0.37131 | Running loss: 0.77475\n","Epoch: 0 | Iteration: 1237/2403 | Classification loss: 0.10824 | Regression loss: 0.28795 | Running loss: 0.77444\n","Epoch: 0 | Iteration: 1238/2403 | Classification loss: 0.42366 | Regression loss: 0.38512 | Running loss: 0.77447\n","Epoch: 0 | Iteration: 1239/2403 | Classification loss: 0.15879 | Regression loss: 0.24148 | Running loss: 0.77416\n","Epoch: 0 | Iteration: 1240/2403 | Classification loss: 0.22502 | Regression loss: 0.25321 | Running loss: 0.77393\n","Epoch: 0 | Iteration: 1241/2403 | Classification loss: 0.21215 | Regression loss: 0.26498 | Running loss: 0.77369\n","Epoch: 0 | Iteration: 1242/2403 | Classification loss: 0.38562 | Regression loss: 0.41362 | Running loss: 0.77371\n","Epoch: 0 | Iteration: 1243/2403 | Classification loss: 0.13544 | Regression loss: 0.19775 | Running loss: 0.77335\n","Epoch: 0 | Iteration: 1244/2403 | Classification loss: 0.20214 | Regression loss: 0.23547 | Running loss: 0.77308\n","Epoch: 0 | Iteration: 1245/2403 | Classification loss: 0.33188 | Regression loss: 0.25709 | Running loss: 0.77294\n","Epoch: 0 | Iteration: 1246/2403 | Classification loss: 0.19816 | Regression loss: 0.24942 | Running loss: 0.77267\n","Epoch: 0 | Iteration: 1247/2403 | Classification loss: 0.17241 | Regression loss: 0.23374 | Running loss: 0.77238\n","Epoch: 0 | Iteration: 1248/2403 | Classification loss: 0.12412 | Regression loss: 0.19129 | Running loss: 0.77201\n","Epoch: 0 | Iteration: 1249/2403 | Classification loss: 0.55886 | Regression loss: 0.40419 | Running loss: 0.77217\n","Epoch: 0 | Iteration: 1250/2403 | Classification loss: 0.14873 | Regression loss: 0.18113 | Running loss: 0.77181\n","Epoch: 0 | Iteration: 1251/2403 | Classification loss: 0.28097 | Regression loss: 0.33769 | Running loss: 0.77169\n","Epoch: 0 | Iteration: 1252/2403 | Classification loss: 0.39802 | Regression loss: 0.50248 | Running loss: 0.77179\n","Epoch: 0 | Iteration: 1253/2403 | Classification loss: 0.22402 | Regression loss: 0.28213 | Running loss: 0.77158\n","Epoch: 0 | Iteration: 1254/2403 | Classification loss: 0.21546 | Regression loss: 0.27027 | Running loss: 0.77135\n","Epoch: 0 | Iteration: 1255/2403 | Classification loss: 0.16249 | Regression loss: 0.20026 | Running loss: 0.77103\n","Epoch: 0 | Iteration: 1256/2403 | Classification loss: 0.10895 | Regression loss: 0.21257 | Running loss: 0.77067\n","Epoch: 0 | Iteration: 1257/2403 | Classification loss: 0.12159 | Regression loss: 0.23732 | Running loss: 0.77034\n","Epoch: 0 | Iteration: 1258/2403 | Classification loss: 0.10679 | Regression loss: 0.22348 | Running loss: 0.76999\n","Epoch: 0 | Iteration: 1259/2403 | Classification loss: 0.13136 | Regression loss: 0.18229 | Running loss: 0.76963\n","Epoch: 0 | Iteration: 1260/2403 | Classification loss: 0.10974 | Regression loss: 0.21480 | Running loss: 0.76928\n","Epoch: 0 | Iteration: 1261/2403 | Classification loss: 0.42428 | Regression loss: 0.31260 | Running loss: 0.76925\n","Epoch: 0 | Iteration: 1262/2403 | Classification loss: 0.20890 | Regression loss: 0.45435 | Running loss: 0.76917\n","Epoch: 0 | Iteration: 1263/2403 | Classification loss: 0.17086 | Regression loss: 0.29932 | Running loss: 0.76893\n","Epoch: 0 | Iteration: 1264/2403 | Classification loss: 0.32777 | Regression loss: 0.34249 | Running loss: 0.76885\n","Epoch: 0 | Iteration: 1265/2403 | Classification loss: 0.22596 | Regression loss: 0.23126 | Running loss: 0.76861\n","Epoch: 0 | Iteration: 1266/2403 | Classification loss: 0.17608 | Regression loss: 0.23501 | Running loss: 0.76832\n","Epoch: 0 | Iteration: 1267/2403 | Classification loss: 0.11682 | Regression loss: 0.23026 | Running loss: 0.76799\n","Epoch: 0 | Iteration: 1268/2403 | Classification loss: 0.10911 | Regression loss: 0.26121 | Running loss: 0.76768\n","Epoch: 0 | Iteration: 1269/2403 | Classification loss: 0.31750 | Regression loss: 0.38652 | Running loss: 0.76763\n","Epoch: 0 | Iteration: 1270/2403 | Classification loss: 0.88390 | Regression loss: 0.45962 | Running loss: 0.76808\n","Epoch: 0 | Iteration: 1271/2403 | Classification loss: 0.32122 | Regression loss: 0.29685 | Running loss: 0.76796\n","Epoch: 0 | Iteration: 1272/2403 | Classification loss: 0.20595 | Regression loss: 0.39075 | Running loss: 0.76783\n","Epoch: 0 | Iteration: 1273/2403 | Classification loss: 0.42988 | Regression loss: 0.34548 | Running loss: 0.76783\n","Epoch: 0 | Iteration: 1274/2403 | Classification loss: 0.26842 | Regression loss: 0.30281 | Running loss: 0.76768\n","Epoch: 0 | Iteration: 1275/2403 | Classification loss: 0.32496 | Regression loss: 0.32457 | Running loss: 0.76759\n","Epoch: 0 | Iteration: 1276/2403 | Classification loss: 0.15109 | Regression loss: 0.31252 | Running loss: 0.76735\n","Epoch: 0 | Iteration: 1277/2403 | Classification loss: 0.32616 | Regression loss: 0.27905 | Running loss: 0.76722\n","Epoch: 0 | Iteration: 1278/2403 | Classification loss: 0.33183 | Regression loss: 0.36387 | Running loss: 0.76717\n","Epoch: 0 | Iteration: 1279/2403 | Classification loss: 0.07492 | Regression loss: 0.17513 | Running loss: 0.76676\n","Epoch: 0 | Iteration: 1280/2403 | Classification loss: 0.50119 | Regression loss: 0.46376 | Running loss: 0.76692\n","Epoch: 0 | Iteration: 1281/2403 | Classification loss: 0.29930 | Regression loss: 0.26797 | Running loss: 0.76676\n","Epoch: 0 | Iteration: 1282/2403 | Classification loss: 1.58202 | Regression loss: 0.54825 | Running loss: 0.76782\n","Epoch: 0 | Iteration: 1283/2403 | Classification loss: 0.14697 | Regression loss: 0.18291 | Running loss: 0.76748\n","Epoch: 0 | Iteration: 1284/2403 | Classification loss: 0.29987 | Regression loss: 0.26633 | Running loss: 0.76733\n","Epoch: 0 | Iteration: 1285/2403 | Classification loss: 0.19374 | Regression loss: 0.23354 | Running loss: 0.76706\n","Epoch: 0 | Iteration: 1286/2403 | Classification loss: 0.11615 | Regression loss: 0.22118 | Running loss: 0.76673\n","Epoch: 0 | Iteration: 1287/2403 | Classification loss: 1.04729 | Regression loss: 0.45085 | Running loss: 0.76730\n","Epoch: 0 | Iteration: 1288/2403 | Classification loss: 0.19381 | Regression loss: 0.15572 | Running loss: 0.76697\n","Epoch: 0 | Iteration: 1289/2403 | Classification loss: 0.09930 | Regression loss: 0.15451 | Running loss: 0.76657\n","Epoch: 0 | Iteration: 1290/2403 | Classification loss: 0.18408 | Regression loss: 0.21572 | Running loss: 0.76629\n","Epoch: 0 | Iteration: 1291/2403 | Classification loss: 0.08862 | Regression loss: 0.14650 | Running loss: 0.76588\n","Epoch: 0 | Iteration: 1292/2403 | Classification loss: 0.32425 | Regression loss: 0.24332 | Running loss: 0.76572\n","Epoch: 0 | Iteration: 1293/2403 | Classification loss: 0.10648 | Regression loss: 0.26310 | Running loss: 0.76542\n","Epoch: 0 | Iteration: 1294/2403 | Classification loss: 0.26023 | Regression loss: 0.26035 | Running loss: 0.76523\n","Epoch: 0 | Iteration: 1295/2403 | Classification loss: 0.16477 | Regression loss: 0.27171 | Running loss: 0.76497\n","Epoch: 0 | Iteration: 1296/2403 | Classification loss: 0.18746 | Regression loss: 0.24441 | Running loss: 0.76472\n","Epoch: 0 | Iteration: 1297/2403 | Classification loss: 0.12009 | Regression loss: 0.25562 | Running loss: 0.76442\n","Epoch: 0 | Iteration: 1298/2403 | Classification loss: 0.51014 | Regression loss: 0.33887 | Running loss: 0.76448\n","Epoch: 0 | Iteration: 1299/2403 | Classification loss: 0.33779 | Regression loss: 0.35379 | Running loss: 0.76443\n","Epoch: 0 | Iteration: 1300/2403 | Classification loss: 0.27454 | Regression loss: 0.35075 | Running loss: 0.76432\n","Epoch: 0 | Iteration: 1301/2403 | Classification loss: 0.19304 | Regression loss: 0.30078 | Running loss: 0.76411\n","Epoch: 0 | Iteration: 1302/2403 | Classification loss: 0.34115 | Regression loss: 0.34279 | Running loss: 0.76405\n","Epoch: 0 | Iteration: 1303/2403 | Classification loss: 0.09876 | Regression loss: 0.21761 | Running loss: 0.76371\n","Epoch: 0 | Iteration: 1304/2403 | Classification loss: 0.58421 | Regression loss: 0.50152 | Running loss: 0.76395\n","Epoch: 0 | Iteration: 1305/2403 | Classification loss: 0.14138 | Regression loss: 0.32080 | Running loss: 0.76372\n","Epoch: 0 | Iteration: 1306/2403 | Classification loss: 0.28955 | Regression loss: 0.29591 | Running loss: 0.76359\n","Epoch: 0 | Iteration: 1307/2403 | Classification loss: 0.24939 | Regression loss: 0.27152 | Running loss: 0.76340\n","Epoch: 0 | Iteration: 1308/2403 | Classification loss: 0.25744 | Regression loss: 0.29161 | Running loss: 0.76324\n","Epoch: 0 | Iteration: 1309/2403 | Classification loss: 0.08528 | Regression loss: 0.19997 | Running loss: 0.76287\n","Epoch: 0 | Iteration: 1310/2403 | Classification loss: 0.17515 | Regression loss: 0.22190 | Running loss: 0.76259\n","Epoch: 0 | Iteration: 1311/2403 | Classification loss: 0.11082 | Regression loss: 0.21827 | Running loss: 0.76226\n","Epoch: 0 | Iteration: 1312/2403 | Classification loss: 0.25751 | Regression loss: 0.27576 | Running loss: 0.76209\n","Epoch: 0 | Iteration: 1313/2403 | Classification loss: 0.14114 | Regression loss: 0.20712 | Running loss: 0.76177\n","Epoch: 0 | Iteration: 1314/2403 | Classification loss: 0.39549 | Regression loss: 0.49839 | Running loss: 0.76187\n","Epoch: 0 | Iteration: 1315/2403 | Classification loss: 0.13038 | Regression loss: 0.21561 | Running loss: 0.76156\n","Epoch: 0 | Iteration: 1316/2403 | Classification loss: 0.40901 | Regression loss: 0.31893 | Running loss: 0.76153\n","Epoch: 0 | Iteration: 1317/2403 | Classification loss: 0.11680 | Regression loss: 0.21621 | Running loss: 0.76121\n","Epoch: 0 | Iteration: 1318/2403 | Classification loss: 0.32698 | Regression loss: 0.35162 | Running loss: 0.76114\n","Epoch: 0 | Iteration: 1319/2403 | Classification loss: 0.22203 | Regression loss: 0.19904 | Running loss: 0.76088\n","Epoch: 0 | Iteration: 1320/2403 | Classification loss: 0.23233 | Regression loss: 0.28888 | Running loss: 0.76070\n","Epoch: 0 | Iteration: 1321/2403 | Classification loss: 0.14459 | Regression loss: 0.28125 | Running loss: 0.76045\n","Epoch: 0 | Iteration: 1322/2403 | Classification loss: 0.11354 | Regression loss: 0.21417 | Running loss: 0.76012\n","Epoch: 0 | Iteration: 1323/2403 | Classification loss: 0.42199 | Regression loss: 0.33888 | Running loss: 0.76012\n","Epoch: 0 | Iteration: 1324/2403 | Classification loss: 0.09964 | Regression loss: 0.22424 | Running loss: 0.75979\n","Epoch: 0 | Iteration: 1325/2403 | Classification loss: 0.29072 | Regression loss: 0.25027 | Running loss: 0.75963\n","Epoch: 0 | Iteration: 1326/2403 | Classification loss: 0.17770 | Regression loss: 0.27958 | Running loss: 0.75940\n","Epoch: 0 | Iteration: 1327/2403 | Classification loss: 0.28779 | Regression loss: 0.30956 | Running loss: 0.75928\n","Epoch: 0 | Iteration: 1328/2403 | Classification loss: 0.67329 | Regression loss: 0.55559 | Running loss: 0.75963\n","Epoch: 0 | Iteration: 1329/2403 | Classification loss: 0.20876 | Regression loss: 0.25193 | Running loss: 0.75941\n","Epoch: 0 | Iteration: 1330/2403 | Classification loss: 0.09819 | Regression loss: 0.22033 | Running loss: 0.75908\n","Epoch: 0 | Iteration: 1331/2403 | Classification loss: 0.19317 | Regression loss: 0.27801 | Running loss: 0.75886\n","Epoch: 0 | Iteration: 1332/2403 | Classification loss: 0.67718 | Regression loss: 0.30846 | Running loss: 0.75903\n","Epoch: 0 | Iteration: 1333/2403 | Classification loss: 0.20136 | Regression loss: 0.28154 | Running loss: 0.75882\n","Epoch: 0 | Iteration: 1334/2403 | Classification loss: 0.16316 | Regression loss: 0.28887 | Running loss: 0.75859\n","Epoch: 0 | Iteration: 1335/2403 | Classification loss: 0.29604 | Regression loss: 0.26996 | Running loss: 0.75845\n","Epoch: 0 | Iteration: 1336/2403 | Classification loss: 0.18214 | Regression loss: 0.23782 | Running loss: 0.75819\n","Epoch: 0 | Iteration: 1337/2403 | Classification loss: 0.08673 | Regression loss: 0.20301 | Running loss: 0.75784\n","Epoch: 0 | Iteration: 1338/2403 | Classification loss: 0.06826 | Regression loss: 0.19962 | Running loss: 0.75748\n","Epoch: 0 | Iteration: 1339/2403 | Classification loss: 0.18865 | Regression loss: 0.23266 | Running loss: 0.75723\n","Epoch: 0 | Iteration: 1340/2403 | Classification loss: 0.46542 | Regression loss: 0.29391 | Running loss: 0.75723\n","Epoch: 0 | Iteration: 1341/2403 | Classification loss: 0.19825 | Regression loss: 0.24090 | Running loss: 0.75699\n","Epoch: 0 | Iteration: 1342/2403 | Classification loss: 0.14464 | Regression loss: 0.20797 | Running loss: 0.75669\n","Epoch: 0 | Iteration: 1343/2403 | Classification loss: 0.19646 | Regression loss: 0.29059 | Running loss: 0.75649\n","Epoch: 0 | Iteration: 1344/2403 | Classification loss: 0.13711 | Regression loss: 0.31286 | Running loss: 0.75626\n","Epoch: 0 | Iteration: 1345/2403 | Classification loss: 0.30771 | Regression loss: 0.28895 | Running loss: 0.75614\n","Epoch: 0 | Iteration: 1346/2403 | Classification loss: 0.27907 | Regression loss: 0.35186 | Running loss: 0.75605\n","Epoch: 0 | Iteration: 1347/2403 | Classification loss: 0.15149 | Regression loss: 0.24563 | Running loss: 0.75578\n","Epoch: 0 | Iteration: 1348/2403 | Classification loss: 0.13898 | Regression loss: 0.21105 | Running loss: 0.75548\n","Epoch: 0 | Iteration: 1349/2403 | Classification loss: 0.14467 | Regression loss: 0.20324 | Running loss: 0.75518\n","Epoch: 0 | Iteration: 1350/2403 | Classification loss: 0.43561 | Regression loss: 0.28473 | Running loss: 0.75515\n","Epoch: 0 | Iteration: 1351/2403 | Classification loss: 0.69013 | Regression loss: 0.28747 | Running loss: 0.75532\n","Epoch: 0 | Iteration: 1352/2403 | Classification loss: 0.12890 | Regression loss: 0.21629 | Running loss: 0.75502\n","Epoch: 0 | Iteration: 1353/2403 | Classification loss: 0.20609 | Regression loss: 0.24783 | Running loss: 0.75479\n","Epoch: 0 | Iteration: 1354/2403 | Classification loss: 0.34720 | Regression loss: 0.23105 | Running loss: 0.75466\n","Epoch: 0 | Iteration: 1355/2403 | Classification loss: 0.22971 | Regression loss: 0.29206 | Running loss: 0.75449\n","Epoch: 0 | Iteration: 1356/2403 | Classification loss: 0.19854 | Regression loss: 0.20658 | Running loss: 0.75423\n","Epoch: 0 | Iteration: 1357/2403 | Classification loss: 0.18682 | Regression loss: 0.23444 | Running loss: 0.75399\n","Epoch: 0 | Iteration: 1358/2403 | Classification loss: 0.09765 | Regression loss: 0.18947 | Running loss: 0.75364\n","Epoch: 0 | Iteration: 1359/2403 | Classification loss: 0.28046 | Regression loss: 0.29007 | Running loss: 0.75351\n","Epoch: 0 | Iteration: 1360/2403 | Classification loss: 0.24574 | Regression loss: 0.36254 | Running loss: 0.75340\n","Epoch: 0 | Iteration: 1361/2403 | Classification loss: 0.18535 | Regression loss: 0.28336 | Running loss: 0.75319\n","Epoch: 0 | Iteration: 1362/2403 | Classification loss: 0.57436 | Regression loss: 0.38088 | Running loss: 0.75334\n","Epoch: 0 | Iteration: 1363/2403 | Classification loss: 1.34291 | Regression loss: 0.35122 | Running loss: 0.75403\n","Epoch: 0 | Iteration: 1364/2403 | Classification loss: 0.32924 | Regression loss: 0.23936 | Running loss: 0.75390\n","Epoch: 0 | Iteration: 1365/2403 | Classification loss: 0.21665 | Regression loss: 0.25370 | Running loss: 0.75369\n","Epoch: 0 | Iteration: 1366/2403 | Classification loss: 0.54276 | Regression loss: 0.44276 | Running loss: 0.75386\n","Epoch: 0 | Iteration: 1367/2403 | Classification loss: 0.34540 | Regression loss: 0.39866 | Running loss: 0.75385\n","Epoch: 0 | Iteration: 1368/2403 | Classification loss: 0.22358 | Regression loss: 0.26507 | Running loss: 0.75366\n","Epoch: 0 | Iteration: 1369/2403 | Classification loss: 0.52085 | Regression loss: 0.38093 | Running loss: 0.75376\n","Epoch: 0 | Iteration: 1370/2403 | Classification loss: 0.22138 | Regression loss: 0.24222 | Running loss: 0.75355\n","Epoch: 0 | Iteration: 1371/2403 | Classification loss: 0.26955 | Regression loss: 0.36579 | Running loss: 0.75347\n","Epoch: 0 | Iteration: 1372/2403 | Classification loss: 0.24038 | Regression loss: 0.21024 | Running loss: 0.75325\n","Epoch: 0 | Iteration: 1373/2403 | Classification loss: 0.25642 | Regression loss: 0.29620 | Running loss: 0.75310\n","Epoch: 0 | Iteration: 1374/2403 | Classification loss: 0.28132 | Regression loss: 0.27035 | Running loss: 0.75295\n","Epoch: 0 | Iteration: 1375/2403 | Classification loss: 0.13750 | Regression loss: 0.23837 | Running loss: 0.75268\n","Epoch: 0 | Iteration: 1376/2403 | Classification loss: 0.35812 | Regression loss: 0.39794 | Running loss: 0.75268\n","Epoch: 0 | Iteration: 1377/2403 | Classification loss: 0.09017 | Regression loss: 0.20035 | Running loss: 0.75235\n","Epoch: 0 | Iteration: 1378/2403 | Classification loss: 0.33570 | Regression loss: 0.36030 | Running loss: 0.75230\n","Epoch: 0 | Iteration: 1379/2403 | Classification loss: 0.53605 | Regression loss: 0.42808 | Running loss: 0.75246\n","Epoch: 0 | Iteration: 1380/2403 | Classification loss: 0.43855 | Regression loss: 0.32223 | Running loss: 0.75246\n","Epoch: 0 | Iteration: 1381/2403 | Classification loss: 0.32735 | Regression loss: 0.44135 | Running loss: 0.75248\n","Epoch: 0 | Iteration: 1382/2403 | Classification loss: 0.39537 | Regression loss: 0.30205 | Running loss: 0.75244\n","Epoch: 0 | Iteration: 1383/2403 | Classification loss: 0.22370 | Regression loss: 0.18554 | Running loss: 0.75219\n","Epoch: 0 | Iteration: 1384/2403 | Classification loss: 0.29128 | Regression loss: 0.19517 | Running loss: 0.75200\n","Epoch: 0 | Iteration: 1385/2403 | Classification loss: 0.23218 | Regression loss: 0.20928 | Running loss: 0.75177\n","Epoch: 0 | Iteration: 1386/2403 | Classification loss: 0.25492 | Regression loss: 0.26510 | Running loss: 0.75160\n","Epoch: 0 | Iteration: 1387/2403 | Classification loss: 0.27406 | Regression loss: 0.34610 | Running loss: 0.75151\n","Epoch: 0 | Iteration: 1388/2403 | Classification loss: 0.24225 | Regression loss: 0.26284 | Running loss: 0.75133\n","Epoch: 0 | Iteration: 1389/2403 | Classification loss: 0.35656 | Regression loss: 0.28737 | Running loss: 0.75126\n","Epoch: 0 | Iteration: 1390/2403 | Classification loss: 0.20858 | Regression loss: 0.20747 | Running loss: 0.75101\n","Epoch: 0 | Iteration: 1391/2403 | Classification loss: 0.32293 | Regression loss: 0.31658 | Running loss: 0.75093\n","Epoch: 0 | Iteration: 1392/2403 | Classification loss: 0.12858 | Regression loss: 0.17816 | Running loss: 0.75061\n","Epoch: 0 | Iteration: 1393/2403 | Classification loss: 0.40377 | Regression loss: 0.39837 | Running loss: 0.75065\n","Epoch: 0 | Iteration: 1394/2403 | Classification loss: 0.48927 | Regression loss: 0.56328 | Running loss: 0.75087\n","Epoch: 0 | Iteration: 1395/2403 | Classification loss: 0.37641 | Regression loss: 0.37889 | Running loss: 0.75087\n","Epoch: 0 | Iteration: 1396/2403 | Classification loss: 0.38530 | Regression loss: 0.32095 | Running loss: 0.75084\n","Epoch: 0 | Iteration: 1397/2403 | Classification loss: 0.22678 | Regression loss: 0.18039 | Running loss: 0.75059\n","Epoch: 0 | Iteration: 1398/2403 | Classification loss: 0.46019 | Regression loss: 0.38125 | Running loss: 0.75066\n","Epoch: 0 | Iteration: 1399/2403 | Classification loss: 0.26772 | Regression loss: 0.28382 | Running loss: 0.75052\n","Epoch: 0 | Iteration: 1400/2403 | Classification loss: 0.35977 | Regression loss: 0.31663 | Running loss: 0.75046\n","Epoch: 0 | Iteration: 1401/2403 | Classification loss: 0.39686 | Regression loss: 0.24785 | Running loss: 0.75039\n","Epoch: 0 | Iteration: 1402/2403 | Classification loss: 0.23194 | Regression loss: 0.23478 | Running loss: 0.75019\n","Epoch: 0 | Iteration: 1403/2403 | Classification loss: 0.23328 | Regression loss: 0.28215 | Running loss: 0.75002\n","Epoch: 0 | Iteration: 1404/2403 | Classification loss: 0.16996 | Regression loss: 0.30191 | Running loss: 0.74982\n","Epoch: 0 | Iteration: 1405/2403 | Classification loss: 0.09939 | Regression loss: 0.20192 | Running loss: 0.74950\n","Epoch: 0 | Iteration: 1406/2403 | Classification loss: 0.14341 | Regression loss: 0.34121 | Running loss: 0.74931\n","Epoch: 0 | Iteration: 1407/2403 | Classification loss: 0.31259 | Regression loss: 0.21217 | Running loss: 0.74915\n","Epoch: 0 | Iteration: 1408/2403 | Classification loss: 0.33968 | Regression loss: 0.26054 | Running loss: 0.74905\n","Epoch: 0 | Iteration: 1409/2403 | Classification loss: 0.23833 | Regression loss: 0.27981 | Running loss: 0.74888\n","Epoch: 0 | Iteration: 1410/2403 | Classification loss: 0.20385 | Regression loss: 0.19584 | Running loss: 0.74864\n","Epoch: 0 | Iteration: 1411/2403 | Classification loss: 0.24227 | Regression loss: 0.23405 | Running loss: 0.74844\n","Epoch: 0 | Iteration: 1412/2403 | Classification loss: 0.50031 | Regression loss: 0.39160 | Running loss: 0.74854\n","Epoch: 0 | Iteration: 1413/2403 | Classification loss: 0.16875 | Regression loss: 0.35592 | Running loss: 0.74839\n","Epoch: 0 | Iteration: 1414/2403 | Classification loss: 0.19660 | Regression loss: 0.23674 | Running loss: 0.74816\n","Epoch: 0 | Iteration: 1415/2403 | Classification loss: 0.25976 | Regression loss: 0.18941 | Running loss: 0.74795\n","Epoch: 0 | Iteration: 1416/2403 | Classification loss: 0.20360 | Regression loss: 0.26461 | Running loss: 0.74775\n","Epoch: 0 | Iteration: 1417/2403 | Classification loss: 0.17521 | Regression loss: 0.33177 | Running loss: 0.74758\n","Epoch: 0 | Iteration: 1418/2403 | Classification loss: 1.54947 | Regression loss: 0.32882 | Running loss: 0.74838\n","Epoch: 0 | Iteration: 1419/2403 | Classification loss: 0.37227 | Regression loss: 0.50280 | Running loss: 0.74847\n","Epoch: 0 | Iteration: 1420/2403 | Classification loss: 0.19507 | Regression loss: 0.17159 | Running loss: 0.74820\n","Epoch: 0 | Iteration: 1421/2403 | Classification loss: 0.29960 | Regression loss: 0.19889 | Running loss: 0.74803\n","Epoch: 0 | Iteration: 1422/2403 | Classification loss: 0.25089 | Regression loss: 0.22101 | Running loss: 0.74783\n","Epoch: 0 | Iteration: 1423/2403 | Classification loss: 0.13613 | Regression loss: 0.17510 | Running loss: 0.74753\n","Epoch: 0 | Iteration: 1424/2403 | Classification loss: 0.26421 | Regression loss: 0.21490 | Running loss: 0.74734\n","Epoch: 0 | Iteration: 1425/2403 | Classification loss: 0.33958 | Regression loss: 0.42807 | Running loss: 0.74735\n","Epoch: 0 | Iteration: 1426/2403 | Classification loss: 0.20647 | Regression loss: 0.20346 | Running loss: 0.74711\n","Epoch: 0 | Iteration: 1427/2403 | Classification loss: 0.30543 | Regression loss: 0.37540 | Running loss: 0.74707\n","Epoch: 0 | Iteration: 1428/2403 | Classification loss: 0.28504 | Regression loss: 0.22882 | Running loss: 0.74690\n","Epoch: 0 | Iteration: 1429/2403 | Classification loss: 0.08307 | Regression loss: 0.20745 | Running loss: 0.74659\n","Epoch: 0 | Iteration: 1430/2403 | Classification loss: 0.37595 | Regression loss: 0.28333 | Running loss: 0.74652\n","Epoch: 0 | Iteration: 1431/2403 | Classification loss: 0.15969 | Regression loss: 0.24990 | Running loss: 0.74629\n","Epoch: 0 | Iteration: 1432/2403 | Classification loss: 0.42068 | Regression loss: 0.37655 | Running loss: 0.74632\n","Epoch: 0 | Iteration: 1433/2403 | Classification loss: 0.29105 | Regression loss: 0.26962 | Running loss: 0.74619\n","Epoch: 0 | Iteration: 1434/2403 | Classification loss: 0.22596 | Regression loss: 0.28590 | Running loss: 0.74603\n","Epoch: 0 | Iteration: 1435/2403 | Classification loss: 0.12205 | Regression loss: 0.21231 | Running loss: 0.74574\n","Epoch: 0 | Iteration: 1436/2403 | Classification loss: 0.30695 | Regression loss: 0.25662 | Running loss: 0.74562\n","Epoch: 0 | Iteration: 1437/2403 | Classification loss: 0.42955 | Regression loss: 0.40195 | Running loss: 0.74568\n","Epoch: 0 | Iteration: 1438/2403 | Classification loss: 0.21941 | Regression loss: 0.29940 | Running loss: 0.74552\n","Epoch: 0 | Iteration: 1439/2403 | Classification loss: 0.33116 | Regression loss: 0.24980 | Running loss: 0.74541\n","Epoch: 0 | Iteration: 1440/2403 | Classification loss: 0.38331 | Regression loss: 0.20264 | Running loss: 0.74529\n","Epoch: 0 | Iteration: 1441/2403 | Classification loss: 0.19234 | Regression loss: 0.27444 | Running loss: 0.74510\n","Epoch: 0 | Iteration: 1442/2403 | Classification loss: 0.30493 | Regression loss: 0.24782 | Running loss: 0.74497\n","Epoch: 0 | Iteration: 1443/2403 | Classification loss: 0.13632 | Regression loss: 0.17250 | Running loss: 0.74467\n","Epoch: 0 | Iteration: 1444/2403 | Classification loss: 0.15520 | Regression loss: 0.15982 | Running loss: 0.74437\n","Epoch: 0 | Iteration: 1445/2403 | Classification loss: 0.39854 | Regression loss: 0.27796 | Running loss: 0.74432\n","Epoch: 0 | Iteration: 1446/2403 | Classification loss: 0.10226 | Regression loss: 0.19973 | Running loss: 0.74401\n","Epoch: 0 | Iteration: 1447/2403 | Classification loss: 0.16188 | Regression loss: 0.26107 | Running loss: 0.74379\n","Epoch: 0 | Iteration: 1448/2403 | Classification loss: 0.31099 | Regression loss: 0.36204 | Running loss: 0.74374\n","Epoch: 0 | Iteration: 1449/2403 | Classification loss: 0.29631 | Regression loss: 0.25213 | Running loss: 0.74361\n","Epoch: 0 | Iteration: 1450/2403 | Classification loss: 0.22449 | Regression loss: 0.22058 | Running loss: 0.74340\n","Epoch: 0 | Iteration: 1451/2403 | Classification loss: 0.13219 | Regression loss: 0.29175 | Running loss: 0.74318\n","Epoch: 0 | Iteration: 1452/2403 | Classification loss: 0.24574 | Regression loss: 0.23581 | Running loss: 0.74300\n","Epoch: 0 | Iteration: 1453/2403 | Classification loss: 1.04376 | Regression loss: 0.30532 | Running loss: 0.74342\n","Epoch: 0 | Iteration: 1454/2403 | Classification loss: 1.69513 | Regression loss: 0.39950 | Running loss: 0.74435\n","Epoch: 0 | Iteration: 1455/2403 | Classification loss: 0.19787 | Regression loss: 0.29120 | Running loss: 0.74417\n","Epoch: 0 | Iteration: 1456/2403 | Classification loss: 0.25764 | Regression loss: 0.70508 | Running loss: 0.74432\n","Epoch: 0 | Iteration: 1457/2403 | Classification loss: 0.28222 | Regression loss: 0.29041 | Running loss: 0.74421\n","Epoch: 0 | Iteration: 1458/2403 | Classification loss: 0.20632 | Regression loss: 0.27808 | Running loss: 0.74403\n","Epoch: 0 | Iteration: 1459/2403 | Classification loss: 0.37043 | Regression loss: 0.26107 | Running loss: 0.74395\n","Epoch: 0 | Iteration: 1460/2403 | Classification loss: 0.37963 | Regression loss: 0.33682 | Running loss: 0.74393\n","Epoch: 0 | Iteration: 1461/2403 | Classification loss: 0.16637 | Regression loss: 0.27473 | Running loss: 0.74373\n","Epoch: 0 | Iteration: 1462/2403 | Classification loss: 0.23219 | Regression loss: 0.17060 | Running loss: 0.74349\n","Epoch: 0 | Iteration: 1463/2403 | Classification loss: 0.27853 | Regression loss: 0.43773 | Running loss: 0.74347\n","Epoch: 0 | Iteration: 1464/2403 | Classification loss: 0.32343 | Regression loss: 0.32846 | Running loss: 0.74341\n","Epoch: 0 | Iteration: 1465/2403 | Classification loss: 0.10973 | Regression loss: 0.22069 | Running loss: 0.74313\n","Epoch: 0 | Iteration: 1466/2403 | Classification loss: 0.18068 | Regression loss: 0.27338 | Running loss: 0.74293\n","Epoch: 0 | Iteration: 1467/2403 | Classification loss: 0.99281 | Regression loss: 0.22088 | Running loss: 0.74325\n","Epoch: 0 | Iteration: 1468/2403 | Classification loss: 0.29751 | Regression loss: 0.64553 | Running loss: 0.74339\n","Epoch: 0 | Iteration: 1469/2403 | Classification loss: 0.21038 | Regression loss: 0.25340 | Running loss: 0.74320\n","Epoch: 0 | Iteration: 1470/2403 | Classification loss: 0.37586 | Regression loss: 0.32401 | Running loss: 0.74317\n","Epoch: 0 | Iteration: 1471/2403 | Classification loss: 0.40843 | Regression loss: 0.33540 | Running loss: 0.74317\n","Epoch: 0 | Iteration: 1472/2403 | Classification loss: 0.16257 | Regression loss: 0.27984 | Running loss: 0.74296\n","Epoch: 0 | Iteration: 1473/2403 | Classification loss: 0.18731 | Regression loss: 0.24587 | Running loss: 0.74275\n","Epoch: 0 | Iteration: 1474/2403 | Classification loss: 0.19201 | Regression loss: 0.27952 | Running loss: 0.74257\n","Epoch: 0 | Iteration: 1475/2403 | Classification loss: 0.57106 | Regression loss: 0.28450 | Running loss: 0.74265\n","Epoch: 0 | Iteration: 1476/2403 | Classification loss: 0.64473 | Regression loss: 0.36359 | Running loss: 0.74283\n","Epoch: 0 | Iteration: 1477/2403 | Classification loss: 0.26428 | Regression loss: 0.27842 | Running loss: 0.74269\n","Epoch: 0 | Iteration: 1478/2403 | Classification loss: 0.26385 | Regression loss: 0.34099 | Running loss: 0.74260\n","Epoch: 0 | Iteration: 1479/2403 | Classification loss: 0.20895 | Regression loss: 0.22154 | Running loss: 0.74239\n","Epoch: 0 | Iteration: 1480/2403 | Classification loss: 0.20118 | Regression loss: 0.33102 | Running loss: 0.74225\n","Epoch: 0 | Iteration: 1481/2403 | Classification loss: 0.34547 | Regression loss: 0.33822 | Running loss: 0.74221\n","Epoch: 0 | Iteration: 1482/2403 | Classification loss: 0.09155 | Regression loss: 0.15496 | Running loss: 0.74187\n","Epoch: 0 | Iteration: 1483/2403 | Classification loss: 0.32888 | Regression loss: 0.34085 | Running loss: 0.74182\n","Epoch: 0 | Iteration: 1484/2403 | Classification loss: 0.53714 | Regression loss: 0.36183 | Running loss: 0.74193\n","Epoch: 0 | Iteration: 1485/2403 | Classification loss: 0.15762 | Regression loss: 0.25251 | Running loss: 0.74171\n","Epoch: 0 | Iteration: 1486/2403 | Classification loss: 0.23199 | Regression loss: 0.30691 | Running loss: 0.74157\n","Epoch: 0 | Iteration: 1487/2403 | Classification loss: 0.18367 | Regression loss: 0.22271 | Running loss: 0.74134\n","Epoch: 0 | Iteration: 1488/2403 | Classification loss: 0.35819 | Regression loss: 0.32465 | Running loss: 0.74130\n","Epoch: 0 | Iteration: 1489/2403 | Classification loss: 0.24195 | Regression loss: 0.32882 | Running loss: 0.74119\n","Epoch: 0 | Iteration: 1490/2403 | Classification loss: 0.32308 | Regression loss: 0.32954 | Running loss: 0.74113\n","Epoch: 0 | Iteration: 1491/2403 | Classification loss: 0.09260 | Regression loss: 0.31989 | Running loss: 0.74091\n","Epoch: 0 | Iteration: 1492/2403 | Classification loss: 0.29235 | Regression loss: 0.26482 | Running loss: 0.74079\n","Epoch: 0 | Iteration: 1493/2403 | Classification loss: 0.09254 | Regression loss: 0.21364 | Running loss: 0.74050\n","Epoch: 0 | Iteration: 1494/2403 | Classification loss: 0.52081 | Regression loss: 0.37162 | Running loss: 0.74060\n","Epoch: 0 | Iteration: 1495/2403 | Classification loss: 0.23033 | Regression loss: 0.27090 | Running loss: 0.74044\n","Epoch: 0 | Iteration: 1496/2403 | Classification loss: 0.45419 | Regression loss: 0.29725 | Running loss: 0.74044\n","Epoch: 0 | Iteration: 1497/2403 | Classification loss: 0.24084 | Regression loss: 0.21920 | Running loss: 0.74026\n","Epoch: 0 | Iteration: 1498/2403 | Classification loss: 0.16018 | Regression loss: 0.27124 | Running loss: 0.74005\n","Epoch: 0 | Iteration: 1499/2403 | Classification loss: 0.11925 | Regression loss: 0.23782 | Running loss: 0.73980\n","Epoch: 0 | Iteration: 1500/2403 | Classification loss: 0.27227 | Regression loss: 0.19345 | Running loss: 0.73961\n","Epoch: 0 | Iteration: 1501/2403 | Classification loss: 0.22423 | Regression loss: 0.22773 | Running loss: 0.73942\n","Epoch: 0 | Iteration: 1502/2403 | Classification loss: 0.10351 | Regression loss: 0.23653 | Running loss: 0.73915\n","Epoch: 0 | Iteration: 1503/2403 | Classification loss: 0.40926 | Regression loss: 0.40161 | Running loss: 0.73920\n","Epoch: 0 | Iteration: 1504/2403 | Classification loss: 0.14395 | Regression loss: 0.30635 | Running loss: 0.73901\n","Epoch: 0 | Iteration: 1505/2403 | Classification loss: 0.22439 | Regression loss: 0.30001 | Running loss: 0.73887\n","Epoch: 0 | Iteration: 1506/2403 | Classification loss: 0.35001 | Regression loss: 0.27803 | Running loss: 0.73879\n","Epoch: 0 | Iteration: 1507/2403 | Classification loss: 0.15327 | Regression loss: 0.28000 | Running loss: 0.73859\n","Epoch: 0 | Iteration: 1508/2403 | Classification loss: 0.10971 | Regression loss: 0.25848 | Running loss: 0.73835\n","Epoch: 0 | Iteration: 1509/2403 | Classification loss: 0.14177 | Regression loss: 0.20916 | Running loss: 0.73809\n","Epoch: 0 | Iteration: 1510/2403 | Classification loss: 0.44896 | Regression loss: 0.42654 | Running loss: 0.73818\n","Epoch: 0 | Iteration: 1511/2403 | Classification loss: 0.28946 | Regression loss: 0.31031 | Running loss: 0.73809\n","Epoch: 0 | Iteration: 1512/2403 | Classification loss: 0.26057 | Regression loss: 0.19897 | Running loss: 0.73790\n","Epoch: 0 | Iteration: 1513/2403 | Classification loss: 1.22020 | Regression loss: 0.25458 | Running loss: 0.73839\n","Epoch: 0 | Iteration: 1514/2403 | Classification loss: 0.32006 | Regression loss: 0.32849 | Running loss: 0.73833\n","Epoch: 0 | Iteration: 1515/2403 | Classification loss: 0.21278 | Regression loss: 0.15622 | Running loss: 0.73809\n","Epoch: 0 | Iteration: 1516/2403 | Classification loss: 0.52459 | Regression loss: 0.46666 | Running loss: 0.73826\n","Epoch: 0 | Iteration: 1517/2403 | Classification loss: 0.42581 | Regression loss: 0.43989 | Running loss: 0.73834\n","Epoch: 0 | Iteration: 1518/2403 | Classification loss: 0.30771 | Regression loss: 0.20942 | Running loss: 0.73819\n","Epoch: 0 | Iteration: 1519/2403 | Classification loss: 0.60687 | Regression loss: 0.29060 | Running loss: 0.73830\n","Epoch: 0 | Iteration: 1520/2403 | Classification loss: 0.23415 | Regression loss: 0.24835 | Running loss: 0.73813\n","Epoch: 0 | Iteration: 1521/2403 | Classification loss: 0.21633 | Regression loss: 0.20865 | Running loss: 0.73792\n","Epoch: 0 | Iteration: 1522/2403 | Classification loss: 0.32292 | Regression loss: 0.31835 | Running loss: 0.73786\n","Epoch: 0 | Iteration: 1523/2403 | Classification loss: 0.15582 | Regression loss: 0.23095 | Running loss: 0.73763\n","Epoch: 0 | Iteration: 1524/2403 | Classification loss: 0.24571 | Regression loss: 0.19074 | Running loss: 0.73743\n","Epoch: 0 | Iteration: 1525/2403 | Classification loss: 0.22195 | Regression loss: 0.22675 | Running loss: 0.73724\n","Epoch: 0 | Iteration: 1526/2403 | Classification loss: 0.24168 | Regression loss: 0.28075 | Running loss: 0.73710\n","Epoch: 0 | Iteration: 1527/2403 | Classification loss: 0.23270 | Regression loss: 0.20387 | Running loss: 0.73691\n","Epoch: 0 | Iteration: 1528/2403 | Classification loss: 0.27547 | Regression loss: 0.36886 | Running loss: 0.73685\n","Epoch: 0 | Iteration: 1529/2403 | Classification loss: 0.18515 | Regression loss: 0.21621 | Running loss: 0.73663\n","Epoch: 0 | Iteration: 1530/2403 | Classification loss: 0.29466 | Regression loss: 0.32741 | Running loss: 0.73655\n","Epoch: 0 | Iteration: 1531/2403 | Classification loss: 0.35778 | Regression loss: 0.31400 | Running loss: 0.73651\n","Epoch: 0 | Iteration: 1532/2403 | Classification loss: 0.14066 | Regression loss: 0.25214 | Running loss: 0.73628\n","Epoch: 0 | Iteration: 1533/2403 | Classification loss: 0.19866 | Regression loss: 0.22752 | Running loss: 0.73608\n","Epoch: 0 | Iteration: 1534/2403 | Classification loss: 0.41008 | Regression loss: 0.30773 | Running loss: 0.73607\n","Epoch: 0 | Iteration: 1535/2403 | Classification loss: 0.31126 | Regression loss: 0.28865 | Running loss: 0.73598\n","Epoch: 0 | Iteration: 1536/2403 | Classification loss: 1.57127 | Regression loss: 0.40092 | Running loss: 0.73679\n","Epoch: 0 | Iteration: 1537/2403 | Classification loss: 0.14398 | Regression loss: 0.24540 | Running loss: 0.73656\n","Epoch: 0 | Iteration: 1538/2403 | Classification loss: 0.24268 | Regression loss: 0.36648 | Running loss: 0.73648\n","Epoch: 0 | Iteration: 1539/2403 | Classification loss: 0.26550 | Regression loss: 0.27971 | Running loss: 0.73635\n","Epoch: 0 | Iteration: 1540/2403 | Classification loss: 0.25286 | Regression loss: 0.34858 | Running loss: 0.73627\n","Epoch: 0 | Iteration: 1541/2403 | Classification loss: 0.68426 | Regression loss: 0.41039 | Running loss: 0.73650\n","Epoch: 0 | Iteration: 1542/2403 | Classification loss: 0.34757 | Regression loss: 0.28238 | Running loss: 0.73643\n","Epoch: 0 | Iteration: 1543/2403 | Classification loss: 0.21617 | Regression loss: 0.18845 | Running loss: 0.73621\n","Epoch: 0 | Iteration: 1544/2403 | Classification loss: 0.27652 | Regression loss: 0.26641 | Running loss: 0.73609\n","Epoch: 0 | Iteration: 1545/2403 | Classification loss: 0.29036 | Regression loss: 0.34755 | Running loss: 0.73603\n","Epoch: 0 | Iteration: 1546/2403 | Classification loss: 0.15106 | Regression loss: 0.24479 | Running loss: 0.73581\n","Epoch: 0 | Iteration: 1547/2403 | Classification loss: 0.64582 | Regression loss: 0.32942 | Running loss: 0.73596\n","Epoch: 0 | Iteration: 1548/2403 | Classification loss: 0.46262 | Regression loss: 0.26583 | Running loss: 0.73596\n","Epoch: 0 | Iteration: 1549/2403 | Classification loss: 0.21355 | Regression loss: 0.26788 | Running loss: 0.73579\n","Epoch: 0 | Iteration: 1550/2403 | Classification loss: 0.32677 | Regression loss: 0.32212 | Running loss: 0.73573\n","Epoch: 0 | Iteration: 1551/2403 | Classification loss: 0.16806 | Regression loss: 0.29439 | Running loss: 0.73556\n","Epoch: 0 | Iteration: 1552/2403 | Classification loss: 0.16026 | Regression loss: 0.19413 | Running loss: 0.73531\n","Epoch: 0 | Iteration: 1553/2403 | Classification loss: 0.20373 | Regression loss: 0.26203 | Running loss: 0.73514\n","Epoch: 0 | Iteration: 1554/2403 | Classification loss: 0.20164 | Regression loss: 0.17656 | Running loss: 0.73491\n","Epoch: 0 | Iteration: 1555/2403 | Classification loss: 0.12547 | Regression loss: 0.24389 | Running loss: 0.73467\n","Epoch: 0 | Iteration: 1556/2403 | Classification loss: 0.10708 | Regression loss: 0.25849 | Running loss: 0.73444\n","Epoch: 0 | Iteration: 1557/2403 | Classification loss: 0.30546 | Regression loss: 0.33566 | Running loss: 0.73438\n","Epoch: 0 | Iteration: 1558/2403 | Classification loss: 0.20863 | Regression loss: 0.27343 | Running loss: 0.73422\n","Epoch: 0 | Iteration: 1559/2403 | Classification loss: 0.21407 | Regression loss: 0.29117 | Running loss: 0.73407\n","Epoch: 0 | Iteration: 1560/2403 | Classification loss: 0.20523 | Regression loss: 0.28519 | Running loss: 0.73391\n","Epoch: 0 | Iteration: 1561/2403 | Classification loss: 0.19876 | Regression loss: 0.22170 | Running loss: 0.73371\n","Epoch: 0 | Iteration: 1562/2403 | Classification loss: 0.36806 | Regression loss: 0.33982 | Running loss: 0.73370\n","Epoch: 0 | Iteration: 1563/2403 | Classification loss: 0.09475 | Regression loss: 0.20035 | Running loss: 0.73341\n","Epoch: 0 | Iteration: 1564/2403 | Classification loss: 0.12533 | Regression loss: 0.19520 | Running loss: 0.73315\n","Epoch: 0 | Iteration: 1565/2403 | Classification loss: 0.15630 | Regression loss: 0.27231 | Running loss: 0.73296\n","Epoch: 0 | Iteration: 1566/2403 | Classification loss: 0.27698 | Regression loss: 0.26086 | Running loss: 0.73283\n","Epoch: 0 | Iteration: 1567/2403 | Classification loss: 0.12642 | Regression loss: 0.19004 | Running loss: 0.73257\n","Epoch: 0 | Iteration: 1568/2403 | Classification loss: 0.06059 | Regression loss: 0.18229 | Running loss: 0.73225\n","Epoch: 0 | Iteration: 1569/2403 | Classification loss: 0.07898 | Regression loss: 0.19923 | Running loss: 0.73196\n","Epoch: 0 | Iteration: 1570/2403 | Classification loss: 0.26717 | Regression loss: 0.28501 | Running loss: 0.73185\n","Epoch: 0 | Iteration: 1571/2403 | Classification loss: 0.11776 | Regression loss: 0.22940 | Running loss: 0.73160\n","Epoch: 0 | Iteration: 1572/2403 | Classification loss: 0.15454 | Regression loss: 0.26895 | Running loss: 0.73141\n","Epoch: 0 | Iteration: 1573/2403 | Classification loss: 0.26599 | Regression loss: 0.33186 | Running loss: 0.73132\n","Epoch: 0 | Iteration: 1574/2403 | Classification loss: 0.26022 | Regression loss: 0.35912 | Running loss: 0.73125\n","Epoch: 0 | Iteration: 1575/2403 | Classification loss: 0.17235 | Regression loss: 0.22331 | Running loss: 0.73104\n","Epoch: 0 | Iteration: 1576/2403 | Classification loss: 0.33015 | Regression loss: 0.27982 | Running loss: 0.73096\n","Epoch: 0 | Iteration: 1577/2403 | Classification loss: 0.14420 | Regression loss: 0.17355 | Running loss: 0.73070\n","Epoch: 0 | Iteration: 1578/2403 | Classification loss: 0.22339 | Regression loss: 0.24293 | Running loss: 0.73053\n","Epoch: 0 | Iteration: 1579/2403 | Classification loss: 0.13240 | Regression loss: 0.22191 | Running loss: 0.73029\n","Epoch: 0 | Iteration: 1580/2403 | Classification loss: 0.22558 | Regression loss: 0.29141 | Running loss: 0.73016\n","Epoch: 0 | Iteration: 1581/2403 | Classification loss: 0.08022 | Regression loss: 0.20165 | Running loss: 0.72988\n","Epoch: 0 | Iteration: 1582/2403 | Classification loss: 0.16938 | Regression loss: 0.15634 | Running loss: 0.72962\n","Epoch: 0 | Iteration: 1583/2403 | Classification loss: 0.15322 | Regression loss: 0.20394 | Running loss: 0.72939\n","Epoch: 0 | Iteration: 1584/2403 | Classification loss: 0.24509 | Regression loss: 0.17448 | Running loss: 0.72919\n","Epoch: 0 | Iteration: 1585/2403 | Classification loss: 0.18199 | Regression loss: 0.20533 | Running loss: 0.72897\n","Epoch: 0 | Iteration: 1586/2403 | Classification loss: 0.33219 | Regression loss: 0.26780 | Running loss: 0.72889\n","Epoch: 0 | Iteration: 1587/2403 | Classification loss: 0.38434 | Regression loss: 0.26475 | Running loss: 0.72884\n","Epoch: 0 | Iteration: 1588/2403 | Classification loss: 0.26972 | Regression loss: 0.24860 | Running loss: 0.72871\n","Epoch: 0 | Iteration: 1589/2403 | Classification loss: 0.34481 | Regression loss: 0.30087 | Running loss: 0.72866\n","Epoch: 0 | Iteration: 1590/2403 | Classification loss: 0.13007 | Regression loss: 0.19531 | Running loss: 0.72840\n","Epoch: 0 | Iteration: 1591/2403 | Classification loss: 0.18516 | Regression loss: 0.29875 | Running loss: 0.72825\n","Epoch: 0 | Iteration: 1592/2403 | Classification loss: 0.16079 | Regression loss: 0.23227 | Running loss: 0.72804\n","Epoch: 0 | Iteration: 1593/2403 | Classification loss: 0.16440 | Regression loss: 0.25399 | Running loss: 0.72785\n","Epoch: 0 | Iteration: 1594/2403 | Classification loss: 0.37772 | Regression loss: 0.26350 | Running loss: 0.72779\n","Epoch: 0 | Iteration: 1595/2403 | Classification loss: 0.31502 | Regression loss: 0.30037 | Running loss: 0.72772\n","Epoch: 0 | Iteration: 1596/2403 | Classification loss: 0.27435 | Regression loss: 0.31605 | Running loss: 0.72763\n","Epoch: 0 | Iteration: 1597/2403 | Classification loss: 0.77301 | Regression loss: 0.29200 | Running loss: 0.72785\n","Epoch: 0 | Iteration: 1598/2403 | Classification loss: 0.49602 | Regression loss: 0.68559 | Running loss: 0.72813\n","Epoch: 0 | Iteration: 1599/2403 | Classification loss: 0.24087 | Regression loss: 0.30783 | Running loss: 0.72802\n","Epoch: 0 | Iteration: 1600/2403 | Classification loss: 0.06316 | Regression loss: 0.15824 | Running loss: 0.72770\n","Epoch: 0 | Iteration: 1601/2403 | Classification loss: 0.15985 | Regression loss: 0.25184 | Running loss: 0.72750\n","Epoch: 0 | Iteration: 1602/2403 | Classification loss: 0.28454 | Regression loss: 0.33654 | Running loss: 0.72744\n","Epoch: 0 | Iteration: 1603/2403 | Classification loss: 0.28049 | Regression loss: 0.42355 | Running loss: 0.72742\n","Epoch: 0 | Iteration: 1604/2403 | Classification loss: 0.25595 | Regression loss: 0.30984 | Running loss: 0.72732\n","Epoch: 0 | Iteration: 1605/2403 | Classification loss: 0.11769 | Regression loss: 0.17436 | Running loss: 0.72705\n","Epoch: 0 | Iteration: 1606/2403 | Classification loss: 0.06399 | Regression loss: 0.17385 | Running loss: 0.72675\n","Epoch: 0 | Iteration: 1607/2403 | Classification loss: 0.27075 | Regression loss: 0.20150 | Running loss: 0.72659\n","Epoch: 0 | Iteration: 1608/2403 | Classification loss: 0.08674 | Regression loss: 0.24056 | Running loss: 0.72634\n","Epoch: 0 | Iteration: 1609/2403 | Classification loss: 0.19357 | Regression loss: 0.17699 | Running loss: 0.72612\n","Epoch: 0 | Iteration: 1610/2403 | Classification loss: 0.15882 | Regression loss: 0.31706 | Running loss: 0.72596\n","Epoch: 0 | Iteration: 1611/2403 | Classification loss: 0.39760 | Regression loss: 0.33703 | Running loss: 0.72597\n","Epoch: 0 | Iteration: 1612/2403 | Classification loss: 0.15140 | Regression loss: 0.23488 | Running loss: 0.72576\n","Epoch: 0 | Iteration: 1613/2403 | Classification loss: 0.07722 | Regression loss: 0.23591 | Running loss: 0.72550\n","Epoch: 0 | Iteration: 1614/2403 | Classification loss: 0.25213 | Regression loss: 0.28122 | Running loss: 0.72538\n","Epoch: 0 | Iteration: 1615/2403 | Classification loss: 0.10739 | Regression loss: 0.20279 | Running loss: 0.72513\n","Epoch: 0 | Iteration: 1616/2403 | Classification loss: 0.11858 | Regression loss: 0.19574 | Running loss: 0.72487\n","Epoch: 0 | Iteration: 1617/2403 | Classification loss: 0.41393 | Regression loss: 0.46358 | Running loss: 0.72497\n","Epoch: 0 | Iteration: 1618/2403 | Classification loss: 0.56518 | Regression loss: 0.45594 | Running loss: 0.72515\n","Epoch: 0 | Iteration: 1619/2403 | Classification loss: 0.14697 | Regression loss: 0.23451 | Running loss: 0.72494\n","Epoch: 0 | Iteration: 1620/2403 | Classification loss: 0.56825 | Regression loss: 0.20111 | Running loss: 0.72496\n","Epoch: 0 | Iteration: 1621/2403 | Classification loss: 0.31547 | Regression loss: 0.38601 | Running loss: 0.72495\n","Epoch: 0 | Iteration: 1622/2403 | Classification loss: 0.38649 | Regression loss: 0.33930 | Running loss: 0.72495\n","Epoch: 0 | Iteration: 1623/2403 | Classification loss: 0.30467 | Regression loss: 0.28101 | Running loss: 0.72486\n","Epoch: 0 | Iteration: 1624/2403 | Classification loss: 0.14986 | Regression loss: 0.25438 | Running loss: 0.72467\n","Epoch: 0 | Iteration: 1625/2403 | Classification loss: 0.12223 | Regression loss: 0.22960 | Running loss: 0.72444\n","Epoch: 0 | Iteration: 1626/2403 | Classification loss: 0.38182 | Regression loss: 0.23623 | Running loss: 0.72437\n","Epoch: 0 | Iteration: 1627/2403 | Classification loss: 0.21330 | Regression loss: 0.22006 | Running loss: 0.72419\n","Epoch: 0 | Iteration: 1628/2403 | Classification loss: 0.17989 | Regression loss: 0.28922 | Running loss: 0.72404\n","Epoch: 0 | Iteration: 1629/2403 | Classification loss: 0.19239 | Regression loss: 0.20333 | Running loss: 0.72383\n","Epoch: 0 | Iteration: 1630/2403 | Classification loss: 0.53956 | Regression loss: 0.23225 | Running loss: 0.72386\n","Epoch: 0 | Iteration: 1631/2403 | Classification loss: 0.29880 | Regression loss: 0.31629 | Running loss: 0.72380\n","Epoch: 0 | Iteration: 1632/2403 | Classification loss: 0.12552 | Regression loss: 0.15254 | Running loss: 0.72352\n","Epoch: 0 | Iteration: 1633/2403 | Classification loss: 0.16508 | Regression loss: 0.27785 | Running loss: 0.72335\n","Epoch: 0 | Iteration: 1634/2403 | Classification loss: 0.36892 | Regression loss: 0.31176 | Running loss: 0.72333\n","Epoch: 0 | Iteration: 1635/2403 | Classification loss: 0.23552 | Regression loss: 0.22353 | Running loss: 0.72316\n","Epoch: 0 | Iteration: 1636/2403 | Classification loss: 0.34937 | Regression loss: 0.45677 | Running loss: 0.72322\n","Epoch: 0 | Iteration: 1637/2403 | Classification loss: 0.19660 | Regression loss: 0.20438 | Running loss: 0.72302\n","Epoch: 0 | Iteration: 1638/2403 | Classification loss: 0.27148 | Regression loss: 0.36860 | Running loss: 0.72297\n","Epoch: 0 | Iteration: 1639/2403 | Classification loss: 0.28293 | Regression loss: 0.36053 | Running loss: 0.72292\n","Epoch: 0 | Iteration: 1640/2403 | Classification loss: 0.33490 | Regression loss: 0.44977 | Running loss: 0.72296\n","Epoch: 0 | Iteration: 1641/2403 | Classification loss: 0.22937 | Regression loss: 0.19811 | Running loss: 0.72278\n","Epoch: 0 | Iteration: 1642/2403 | Classification loss: 0.29923 | Regression loss: 0.25578 | Running loss: 0.72267\n","Epoch: 0 | Iteration: 1643/2403 | Classification loss: 0.35560 | Regression loss: 0.36280 | Running loss: 0.72267\n","Epoch: 0 | Iteration: 1644/2403 | Classification loss: 0.39532 | Regression loss: 0.29029 | Running loss: 0.72265\n","Epoch: 0 | Iteration: 1645/2403 | Classification loss: 0.22211 | Regression loss: 0.22110 | Running loss: 0.72248\n","Epoch: 0 | Iteration: 1646/2403 | Classification loss: 0.24856 | Regression loss: 0.29774 | Running loss: 0.72237\n","Epoch: 0 | Iteration: 1647/2403 | Classification loss: 0.22651 | Regression loss: 0.31240 | Running loss: 0.72226\n","Epoch: 0 | Iteration: 1648/2403 | Classification loss: 0.18722 | Regression loss: 0.22964 | Running loss: 0.72208\n","Epoch: 0 | Iteration: 1649/2403 | Classification loss: 0.30885 | Regression loss: 0.35498 | Running loss: 0.72204\n","Epoch: 0 | Iteration: 1650/2403 | Classification loss: 0.25750 | Regression loss: 0.17581 | Running loss: 0.72187\n","Epoch: 0 | Iteration: 1651/2403 | Classification loss: 0.21053 | Regression loss: 0.19219 | Running loss: 0.72167\n","Epoch: 0 | Iteration: 1652/2403 | Classification loss: 0.09841 | Regression loss: 0.18376 | Running loss: 0.72141\n","Epoch: 0 | Iteration: 1653/2403 | Classification loss: 0.22076 | Regression loss: 0.33128 | Running loss: 0.72130\n","Epoch: 0 | Iteration: 1654/2403 | Classification loss: 0.16931 | Regression loss: 0.21201 | Running loss: 0.72110\n","Epoch: 0 | Iteration: 1655/2403 | Classification loss: 0.24757 | Regression loss: 0.31048 | Running loss: 0.72100\n","Epoch: 0 | Iteration: 1656/2403 | Classification loss: 0.20746 | Regression loss: 0.23246 | Running loss: 0.72083\n","Epoch: 0 | Iteration: 1657/2403 | Classification loss: 0.19141 | Regression loss: 0.17246 | Running loss: 0.72061\n","Epoch: 0 | Iteration: 1658/2403 | Classification loss: 0.31638 | Regression loss: 0.28900 | Running loss: 0.72055\n","Epoch: 0 | Iteration: 1659/2403 | Classification loss: 0.19009 | Regression loss: 0.26240 | Running loss: 0.72038\n","Epoch: 0 | Iteration: 1660/2403 | Classification loss: 0.30746 | Regression loss: 0.26647 | Running loss: 0.72030\n","Epoch: 0 | Iteration: 1661/2403 | Classification loss: 0.35487 | Regression loss: 0.37702 | Running loss: 0.72030\n","Epoch: 0 | Iteration: 1662/2403 | Classification loss: 0.08098 | Regression loss: 0.18684 | Running loss: 0.72003\n","Epoch: 0 | Iteration: 1663/2403 | Classification loss: 0.33910 | Regression loss: 0.62793 | Running loss: 0.72018\n","Epoch: 0 | Iteration: 1664/2403 | Classification loss: 0.22721 | Regression loss: 0.32079 | Running loss: 0.72008\n","Epoch: 0 | Iteration: 1665/2403 | Classification loss: 0.20174 | Regression loss: 0.28694 | Running loss: 0.71994\n","Epoch: 0 | Iteration: 1666/2403 | Classification loss: 0.08384 | Regression loss: 0.15312 | Running loss: 0.71965\n","Epoch: 0 | Iteration: 1667/2403 | Classification loss: 0.56170 | Regression loss: 0.62832 | Running loss: 0.71993\n","Epoch: 0 | Iteration: 1668/2403 | Classification loss: 0.26781 | Regression loss: 0.23471 | Running loss: 0.71980\n","Epoch: 0 | Iteration: 1669/2403 | Classification loss: 0.26678 | Regression loss: 0.33151 | Running loss: 0.71973\n","Epoch: 0 | Iteration: 1670/2403 | Classification loss: 0.19922 | Regression loss: 0.20106 | Running loss: 0.71953\n","Epoch: 0 | Iteration: 1671/2403 | Classification loss: 0.09014 | Regression loss: 0.21846 | Running loss: 0.71929\n","Epoch: 0 | Iteration: 1672/2403 | Classification loss: 0.28086 | Regression loss: 0.54510 | Running loss: 0.71935\n","Epoch: 0 | Iteration: 1673/2403 | Classification loss: 0.61638 | Regression loss: 0.32951 | Running loss: 0.71949\n","Epoch: 0 | Iteration: 1674/2403 | Classification loss: 0.32136 | Regression loss: 0.24113 | Running loss: 0.71939\n","Epoch: 0 | Iteration: 1675/2403 | Classification loss: 0.25749 | Regression loss: 0.22641 | Running loss: 0.71925\n","Epoch: 0 | Iteration: 1676/2403 | Classification loss: 0.35910 | Regression loss: 0.33991 | Running loss: 0.71924\n","Epoch: 0 | Iteration: 1677/2403 | Classification loss: 0.11121 | Regression loss: 0.23188 | Running loss: 0.71902\n","Epoch: 0 | Iteration: 1678/2403 | Classification loss: 0.22708 | Regression loss: 0.29962 | Running loss: 0.71890\n","Epoch: 0 | Iteration: 1679/2403 | Classification loss: 0.15971 | Regression loss: 0.24258 | Running loss: 0.71871\n","Epoch: 0 | Iteration: 1680/2403 | Classification loss: 0.22353 | Regression loss: 0.26896 | Running loss: 0.71858\n","Epoch: 0 | Iteration: 1681/2403 | Classification loss: 0.37226 | Regression loss: 0.29579 | Running loss: 0.71855\n","Epoch: 0 | Iteration: 1682/2403 | Classification loss: 0.30172 | Regression loss: 0.23815 | Running loss: 0.71844\n","Epoch: 0 | Iteration: 1683/2403 | Classification loss: 0.14185 | Regression loss: 0.19351 | Running loss: 0.71821\n","Epoch: 0 | Iteration: 1684/2403 | Classification loss: 0.14260 | Regression loss: 0.19167 | Running loss: 0.71799\n","Epoch: 0 | Iteration: 1685/2403 | Classification loss: 0.55475 | Regression loss: 0.33671 | Running loss: 0.71809\n","Epoch: 0 | Iteration: 1686/2403 | Classification loss: 0.22238 | Regression loss: 0.26561 | Running loss: 0.71795\n","Epoch: 0 | Iteration: 1687/2403 | Classification loss: 0.37308 | Regression loss: 0.18876 | Running loss: 0.71786\n","Epoch: 0 | Iteration: 1688/2403 | Classification loss: 0.39813 | Regression loss: 0.60850 | Running loss: 0.71803\n","Epoch: 0 | Iteration: 1689/2403 | Classification loss: 0.10402 | Regression loss: 0.19214 | Running loss: 0.71778\n","Epoch: 0 | Iteration: 1690/2403 | Classification loss: 0.43845 | Regression loss: 0.35386 | Running loss: 0.71783\n","Epoch: 0 | Iteration: 1691/2403 | Classification loss: 0.18567 | Regression loss: 0.26130 | Running loss: 0.71767\n","Epoch: 0 | Iteration: 1692/2403 | Classification loss: 0.40581 | Regression loss: 0.36753 | Running loss: 0.71770\n","Epoch: 0 | Iteration: 1693/2403 | Classification loss: 0.57913 | Regression loss: 0.38224 | Running loss: 0.71784\n","Epoch: 0 | Iteration: 1694/2403 | Classification loss: 0.21340 | Regression loss: 0.12150 | Running loss: 0.71762\n","Epoch: 0 | Iteration: 1695/2403 | Classification loss: 0.23253 | Regression loss: 0.29242 | Running loss: 0.71750\n","Epoch: 0 | Iteration: 1696/2403 | Classification loss: 0.26785 | Regression loss: 0.21499 | Running loss: 0.71736\n","Epoch: 0 | Iteration: 1697/2403 | Classification loss: 0.20999 | Regression loss: 0.29386 | Running loss: 0.71724\n","Epoch: 0 | Iteration: 1698/2403 | Classification loss: 0.16617 | Regression loss: 0.25361 | Running loss: 0.71706\n","Epoch: 0 | Iteration: 1699/2403 | Classification loss: 0.14503 | Regression loss: 0.22815 | Running loss: 0.71686\n","Epoch: 0 | Iteration: 1700/2403 | Classification loss: 0.09404 | Regression loss: 0.17649 | Running loss: 0.71660\n","Epoch: 0 | Iteration: 1701/2403 | Classification loss: 0.23999 | Regression loss: 0.27147 | Running loss: 0.71648\n","Epoch: 0 | Iteration: 1702/2403 | Classification loss: 0.61316 | Regression loss: 0.41573 | Running loss: 0.71666\n","Epoch: 0 | Iteration: 1703/2403 | Classification loss: 0.15732 | Regression loss: 0.25019 | Running loss: 0.71648\n","Epoch: 0 | Iteration: 1704/2403 | Classification loss: 0.25603 | Regression loss: 0.27172 | Running loss: 0.71637\n","Epoch: 0 | Iteration: 1705/2403 | Classification loss: 0.38110 | Regression loss: 0.26361 | Running loss: 0.71633\n","Epoch: 0 | Iteration: 1706/2403 | Classification loss: 0.35623 | Regression loss: 0.35702 | Running loss: 0.71633\n","Epoch: 0 | Iteration: 1707/2403 | Classification loss: 0.29719 | Regression loss: 0.22999 | Running loss: 0.71621\n","Epoch: 0 | Iteration: 1708/2403 | Classification loss: 0.17421 | Regression loss: 0.28677 | Running loss: 0.71607\n","Epoch: 0 | Iteration: 1709/2403 | Classification loss: 0.28637 | Regression loss: 0.31756 | Running loss: 0.71600\n","Epoch: 0 | Iteration: 1710/2403 | Classification loss: 0.14163 | Regression loss: 0.20783 | Running loss: 0.71579\n","Epoch: 0 | Iteration: 1711/2403 | Classification loss: 0.72825 | Regression loss: 0.38508 | Running loss: 0.71602\n","Epoch: 0 | Iteration: 1712/2403 | Classification loss: 0.07041 | Regression loss: 0.12794 | Running loss: 0.71572\n","Epoch: 0 | Iteration: 1713/2403 | Classification loss: 0.27209 | Regression loss: 0.24024 | Running loss: 0.71560\n","Epoch: 0 | Iteration: 1714/2403 | Classification loss: 0.20215 | Regression loss: 0.27465 | Running loss: 0.71546\n","Epoch: 0 | Iteration: 1715/2403 | Classification loss: 0.12599 | Regression loss: 0.18933 | Running loss: 0.71522\n","Epoch: 0 | Iteration: 1716/2403 | Classification loss: 0.49914 | Regression loss: 0.31225 | Running loss: 0.71528\n","Epoch: 0 | Iteration: 1717/2403 | Classification loss: 0.26272 | Regression loss: 0.23325 | Running loss: 0.71515\n","Epoch: 0 | Iteration: 1718/2403 | Classification loss: 0.11942 | Regression loss: 0.23192 | Running loss: 0.71494\n","Epoch: 0 | Iteration: 1719/2403 | Classification loss: 0.17331 | Regression loss: 0.16564 | Running loss: 0.71472\n","Epoch: 0 | Iteration: 1720/2403 | Classification loss: 0.11160 | Regression loss: 0.21217 | Running loss: 0.71449\n","Epoch: 0 | Iteration: 1721/2403 | Classification loss: 0.30263 | Regression loss: 0.34427 | Running loss: 0.71446\n","Epoch: 0 | Iteration: 1722/2403 | Classification loss: 0.24918 | Regression loss: 0.28151 | Running loss: 0.71435\n","Epoch: 0 | Iteration: 1723/2403 | Classification loss: 0.05482 | Regression loss: 0.14480 | Running loss: 0.71405\n","Epoch: 0 | Iteration: 1724/2403 | Classification loss: 0.20912 | Regression loss: 0.16070 | Running loss: 0.71385\n","Epoch: 0 | Iteration: 1725/2403 | Classification loss: 0.13713 | Regression loss: 0.21658 | Running loss: 0.71364\n","Epoch: 0 | Iteration: 1726/2403 | Classification loss: 0.18702 | Regression loss: 0.27990 | Running loss: 0.71350\n","Epoch: 0 | Iteration: 1727/2403 | Classification loss: 0.06996 | Regression loss: 0.18557 | Running loss: 0.71323\n","Epoch: 0 | Iteration: 1728/2403 | Classification loss: 0.29027 | Regression loss: 0.27310 | Running loss: 0.71315\n","Epoch: 0 | Iteration: 1729/2403 | Classification loss: 0.55322 | Regression loss: 0.45502 | Running loss: 0.71332\n","Epoch: 0 | Iteration: 1730/2403 | Classification loss: 0.23829 | Regression loss: 0.24745 | Running loss: 0.71319\n","Epoch: 0 | Iteration: 1731/2403 | Classification loss: 0.15413 | Regression loss: 0.22854 | Running loss: 0.71299\n","Epoch: 0 | Iteration: 1732/2403 | Classification loss: 0.68584 | Regression loss: 0.36568 | Running loss: 0.71319\n","Epoch: 0 | Iteration: 1733/2403 | Classification loss: 0.07878 | Regression loss: 0.16978 | Running loss: 0.71292\n","Epoch: 0 | Iteration: 1734/2403 | Classification loss: 0.16411 | Regression loss: 0.17354 | Running loss: 0.71271\n","Epoch: 0 | Iteration: 1735/2403 | Classification loss: 0.41531 | Regression loss: 0.30462 | Running loss: 0.71271\n","Epoch: 0 | Iteration: 1736/2403 | Classification loss: 0.21719 | Regression loss: 0.34926 | Running loss: 0.71263\n","Epoch: 0 | Iteration: 1737/2403 | Classification loss: 0.21630 | Regression loss: 0.32204 | Running loss: 0.71253\n","Epoch: 0 | Iteration: 1738/2403 | Classification loss: 0.35286 | Regression loss: 0.24449 | Running loss: 0.71246\n","Epoch: 0 | Iteration: 1739/2403 | Classification loss: 0.20139 | Regression loss: 0.31546 | Running loss: 0.71235\n","Epoch: 0 | Iteration: 1740/2403 | Classification loss: 0.17177 | Regression loss: 0.25063 | Running loss: 0.71218\n","Epoch: 0 | Iteration: 1741/2403 | Classification loss: 0.22149 | Regression loss: 0.19044 | Running loss: 0.71201\n","Epoch: 0 | Iteration: 1742/2403 | Classification loss: 0.12410 | Regression loss: 0.24957 | Running loss: 0.71181\n","Epoch: 0 | Iteration: 1743/2403 | Classification loss: 0.36857 | Regression loss: 0.41419 | Running loss: 0.71185\n","Epoch: 0 | Iteration: 1744/2403 | Classification loss: 0.27960 | Regression loss: 0.18738 | Running loss: 0.71171\n","Epoch: 0 | Iteration: 1745/2403 | Classification loss: 0.12507 | Regression loss: 0.24810 | Running loss: 0.71152\n","Epoch: 0 | Iteration: 1746/2403 | Classification loss: 0.07575 | Regression loss: 0.22755 | Running loss: 0.71129\n","Epoch: 0 | Iteration: 1747/2403 | Classification loss: 0.13604 | Regression loss: 0.25348 | Running loss: 0.71110\n","Epoch: 0 | Iteration: 1748/2403 | Classification loss: 0.09339 | Regression loss: 0.20460 | Running loss: 0.71087\n","Epoch: 0 | Iteration: 1749/2403 | Classification loss: 0.20416 | Regression loss: 0.19796 | Running loss: 0.71069\n","Epoch: 0 | Iteration: 1750/2403 | Classification loss: 0.20130 | Regression loss: 0.24688 | Running loss: 0.71054\n","Epoch: 0 | Iteration: 1751/2403 | Classification loss: 0.19932 | Regression loss: 0.26965 | Running loss: 0.71040\n","Epoch: 0 | Iteration: 1752/2403 | Classification loss: 0.19493 | Regression loss: 0.27532 | Running loss: 0.71026\n","Epoch: 0 | Iteration: 1753/2403 | Classification loss: 0.14451 | Regression loss: 0.14829 | Running loss: 0.71003\n","Epoch: 0 | Iteration: 1754/2403 | Classification loss: 0.15026 | Regression loss: 0.19761 | Running loss: 0.70982\n","Epoch: 0 | Iteration: 1755/2403 | Classification loss: 0.07475 | Regression loss: 0.17658 | Running loss: 0.70956\n","Epoch: 0 | Iteration: 1756/2403 | Classification loss: 0.13429 | Regression loss: 0.19626 | Running loss: 0.70934\n","Epoch: 0 | Iteration: 1757/2403 | Classification loss: 0.09246 | Regression loss: 0.25774 | Running loss: 0.70914\n","Epoch: 0 | Iteration: 1758/2403 | Classification loss: 0.19106 | Regression loss: 0.22992 | Running loss: 0.70897\n","Epoch: 0 | Iteration: 1759/2403 | Classification loss: 0.39034 | Regression loss: 0.33088 | Running loss: 0.70898\n","Epoch: 0 | Iteration: 1760/2403 | Classification loss: 0.09088 | Regression loss: 0.16552 | Running loss: 0.70872\n","Epoch: 0 | Iteration: 1761/2403 | Classification loss: 0.07506 | Regression loss: 0.23510 | Running loss: 0.70850\n","Epoch: 0 | Iteration: 1762/2403 | Classification loss: 0.16592 | Regression loss: 0.23671 | Running loss: 0.70832\n","Epoch: 0 | Iteration: 1763/2403 | Classification loss: 0.09458 | Regression loss: 0.19217 | Running loss: 0.70808\n","Epoch: 0 | Iteration: 1764/2403 | Classification loss: 0.22245 | Regression loss: 0.21856 | Running loss: 0.70793\n","Epoch: 0 | Iteration: 1765/2403 | Classification loss: 0.17134 | Regression loss: 0.23972 | Running loss: 0.70776\n","Epoch: 0 | Iteration: 1766/2403 | Classification loss: 0.38515 | Regression loss: 0.72827 | Running loss: 0.70799\n","Epoch: 0 | Iteration: 1767/2403 | Classification loss: 0.35524 | Regression loss: 0.26795 | Running loss: 0.70795\n","Epoch: 0 | Iteration: 1768/2403 | Classification loss: 0.18657 | Regression loss: 0.41454 | Running loss: 0.70789\n","Epoch: 0 | Iteration: 1769/2403 | Classification loss: 0.54215 | Regression loss: 0.31215 | Running loss: 0.70797\n","Epoch: 0 | Iteration: 1770/2403 | Classification loss: 0.44725 | Regression loss: 0.45985 | Running loss: 0.70808\n","Epoch: 0 | Iteration: 1771/2403 | Classification loss: 0.14150 | Regression loss: 0.19360 | Running loss: 0.70787\n","Epoch: 0 | Iteration: 1772/2403 | Classification loss: 0.07389 | Regression loss: 0.16216 | Running loss: 0.70760\n","Epoch: 0 | Iteration: 1773/2403 | Classification loss: 0.34164 | Regression loss: 0.35008 | Running loss: 0.70760\n","Epoch: 0 | Iteration: 1774/2403 | Classification loss: 0.28572 | Regression loss: 0.27534 | Running loss: 0.70751\n","Epoch: 0 | Iteration: 1775/2403 | Classification loss: 0.09040 | Regression loss: 0.16217 | Running loss: 0.70726\n","Epoch: 0 | Iteration: 1776/2403 | Classification loss: 0.05340 | Regression loss: 0.14652 | Running loss: 0.70697\n","Epoch: 0 | Iteration: 1777/2403 | Classification loss: 0.39113 | Regression loss: 0.36017 | Running loss: 0.70700\n","Epoch: 0 | Iteration: 1778/2403 | Classification loss: 0.11934 | Regression loss: 0.18465 | Running loss: 0.70677\n","Epoch: 0 | Iteration: 1779/2403 | Classification loss: 0.11481 | Regression loss: 0.19661 | Running loss: 0.70655\n","Epoch: 0 | Iteration: 1780/2403 | Classification loss: 0.08888 | Regression loss: 0.15165 | Running loss: 0.70629\n","Epoch: 0 | Iteration: 1781/2403 | Classification loss: 0.12939 | Regression loss: 0.20783 | Running loss: 0.70608\n","Epoch: 0 | Iteration: 1782/2403 | Classification loss: 0.27843 | Regression loss: 0.26659 | Running loss: 0.70599\n","Epoch: 0 | Iteration: 1783/2403 | Classification loss: 0.22674 | Regression loss: 0.41497 | Running loss: 0.70595\n","Epoch: 0 | Iteration: 1784/2403 | Classification loss: 0.08414 | Regression loss: 0.14442 | Running loss: 0.70568\n","Epoch: 0 | Iteration: 1785/2403 | Classification loss: 0.54999 | Regression loss: 0.34877 | Running loss: 0.70579\n","Epoch: 0 | Iteration: 1786/2403 | Classification loss: 0.17841 | Regression loss: 0.20837 | Running loss: 0.70561\n","Epoch: 0 | Iteration: 1787/2403 | Classification loss: 0.07482 | Regression loss: 0.20532 | Running loss: 0.70538\n","Epoch: 0 | Iteration: 1788/2403 | Classification loss: 0.38055 | Regression loss: 0.28541 | Running loss: 0.70535\n","Epoch: 0 | Iteration: 1789/2403 | Classification loss: 0.07342 | Regression loss: 0.14880 | Running loss: 0.70508\n","Epoch: 0 | Iteration: 1790/2403 | Classification loss: 0.21945 | Regression loss: 0.40387 | Running loss: 0.70504\n","Epoch: 0 | Iteration: 1791/2403 | Classification loss: 0.28888 | Regression loss: 0.22674 | Running loss: 0.70493\n","Epoch: 0 | Iteration: 1792/2403 | Classification loss: 0.19359 | Regression loss: 0.22884 | Running loss: 0.70477\n","Epoch: 0 | Iteration: 1793/2403 | Classification loss: 0.23571 | Regression loss: 0.17491 | Running loss: 0.70461\n","Epoch: 0 | Iteration: 1794/2403 | Classification loss: 0.22390 | Regression loss: 0.20110 | Running loss: 0.70445\n","Epoch: 0 | Iteration: 1795/2403 | Classification loss: 0.38819 | Regression loss: 0.27918 | Running loss: 0.70443\n","Epoch: 0 | Iteration: 1796/2403 | Classification loss: 0.24433 | Regression loss: 0.18483 | Running loss: 0.70428\n","Epoch: 0 | Iteration: 1797/2403 | Classification loss: 0.32140 | Regression loss: 0.33519 | Running loss: 0.70425\n","Epoch: 0 | Iteration: 1798/2403 | Classification loss: 0.19390 | Regression loss: 0.23330 | Running loss: 0.70410\n","Epoch: 0 | Iteration: 1799/2403 | Classification loss: 0.26275 | Regression loss: 0.41727 | Running loss: 0.70409\n","Epoch: 0 | Iteration: 1800/2403 | Classification loss: 0.27104 | Regression loss: 0.37435 | Running loss: 0.70405\n","Epoch: 0 | Iteration: 1801/2403 | Classification loss: 0.33238 | Regression loss: 0.19814 | Running loss: 0.70396\n","Epoch: 0 | Iteration: 1802/2403 | Classification loss: 0.37494 | Regression loss: 0.31594 | Running loss: 0.70395\n","Epoch: 0 | Iteration: 1803/2403 | Classification loss: 0.42008 | Regression loss: 0.33202 | Running loss: 0.70398\n","Epoch: 0 | Iteration: 1804/2403 | Classification loss: 0.25196 | Regression loss: 0.34691 | Running loss: 0.70392\n","Epoch: 0 | Iteration: 1805/2403 | Classification loss: 0.25393 | Regression loss: 0.26382 | Running loss: 0.70382\n","Epoch: 0 | Iteration: 1806/2403 | Classification loss: 0.20659 | Regression loss: 0.41214 | Running loss: 0.70377\n","Epoch: 0 | Iteration: 1807/2403 | Classification loss: 0.23931 | Regression loss: 0.20267 | Running loss: 0.70362\n","Epoch: 0 | Iteration: 1808/2403 | Classification loss: 0.16007 | Regression loss: 0.28192 | Running loss: 0.70348\n","Epoch: 0 | Iteration: 1809/2403 | Classification loss: 0.11966 | Regression loss: 0.20066 | Running loss: 0.70327\n","Epoch: 0 | Iteration: 1810/2403 | Classification loss: 0.28881 | Regression loss: 0.29564 | Running loss: 0.70320\n","Epoch: 0 | Iteration: 1811/2403 | Classification loss: 0.39818 | Regression loss: 0.25738 | Running loss: 0.70317\n","Epoch: 0 | Iteration: 1812/2403 | Classification loss: 0.16646 | Regression loss: 0.18931 | Running loss: 0.70298\n","Epoch: 0 | Iteration: 1813/2403 | Classification loss: 0.09898 | Regression loss: 0.27285 | Running loss: 0.70280\n","Epoch: 0 | Iteration: 1814/2403 | Classification loss: 0.21635 | Regression loss: 0.17953 | Running loss: 0.70263\n","Epoch: 0 | Iteration: 1815/2403 | Classification loss: 0.08037 | Regression loss: 0.16282 | Running loss: 0.70238\n","Epoch: 0 | Iteration: 1816/2403 | Classification loss: 0.11573 | Regression loss: 0.22671 | Running loss: 0.70218\n","Epoch: 0 | Iteration: 1817/2403 | Classification loss: 0.33365 | Regression loss: 0.37425 | Running loss: 0.70218\n","Epoch: 0 | Iteration: 1818/2403 | Classification loss: 0.51797 | Regression loss: 0.32273 | Running loss: 0.70226\n","Epoch: 0 | Iteration: 1819/2403 | Classification loss: 0.06080 | Regression loss: 0.23067 | Running loss: 0.70203\n","Epoch: 0 | Iteration: 1820/2403 | Classification loss: 0.22798 | Regression loss: 0.24886 | Running loss: 0.70191\n","Epoch: 0 | Iteration: 1821/2403 | Classification loss: 0.18746 | Regression loss: 0.33342 | Running loss: 0.70181\n","Epoch: 0 | Iteration: 1822/2403 | Classification loss: 0.08480 | Regression loss: 0.23761 | Running loss: 0.70160\n","Epoch: 0 | Iteration: 1823/2403 | Classification loss: 0.08971 | Regression loss: 0.20426 | Running loss: 0.70138\n","Epoch: 0 | Iteration: 1824/2403 | Classification loss: 0.24732 | Regression loss: 0.31625 | Running loss: 0.70130\n","Epoch: 0 | Iteration: 1825/2403 | Classification loss: 0.44055 | Regression loss: 0.42035 | Running loss: 0.70139\n","Epoch: 0 | Iteration: 1826/2403 | Classification loss: 0.45020 | Regression loss: 0.36723 | Running loss: 0.70145\n","Epoch: 0 | Iteration: 1827/2403 | Classification loss: 0.28829 | Regression loss: 0.26101 | Running loss: 0.70137\n","Epoch: 0 | Iteration: 1828/2403 | Classification loss: 0.44669 | Regression loss: 0.34572 | Running loss: 0.70142\n","Epoch: 0 | Iteration: 1829/2403 | Classification loss: 0.09085 | Regression loss: 0.20276 | Running loss: 0.70120\n","Epoch: 0 | Iteration: 1830/2403 | Classification loss: 0.26924 | Regression loss: 0.24776 | Running loss: 0.70110\n","Epoch: 0 | Iteration: 1831/2403 | Classification loss: 0.05122 | Regression loss: 0.15918 | Running loss: 0.70083\n","Epoch: 0 | Iteration: 1832/2403 | Classification loss: 0.29133 | Regression loss: 0.22813 | Running loss: 0.70073\n","Epoch: 0 | Iteration: 1833/2403 | Classification loss: 0.28315 | Regression loss: 0.22930 | Running loss: 0.70063\n","Epoch: 0 | Iteration: 1834/2403 | Classification loss: 0.45126 | Regression loss: 0.36873 | Running loss: 0.70069\n","Epoch: 0 | Iteration: 1835/2403 | Classification loss: 0.21748 | Regression loss: 0.25053 | Running loss: 0.70057\n","Epoch: 0 | Iteration: 1836/2403 | Classification loss: 0.21216 | Regression loss: 0.26568 | Running loss: 0.70044\n","Epoch: 0 | Iteration: 1837/2403 | Classification loss: 0.28298 | Regression loss: 0.28120 | Running loss: 0.70037\n","Epoch: 0 | Iteration: 1838/2403 | Classification loss: 0.11189 | Regression loss: 0.15875 | Running loss: 0.70014\n","Epoch: 0 | Iteration: 1839/2403 | Classification loss: 0.22874 | Regression loss: 0.29823 | Running loss: 0.70004\n","Epoch: 0 | Iteration: 1840/2403 | Classification loss: 0.42697 | Regression loss: 0.39157 | Running loss: 0.70011\n","Epoch: 0 | Iteration: 1841/2403 | Classification loss: 0.19275 | Regression loss: 0.32802 | Running loss: 0.70001\n","Epoch: 0 | Iteration: 1842/2403 | Classification loss: 0.22822 | Regression loss: 0.25853 | Running loss: 0.69989\n","Epoch: 0 | Iteration: 1843/2403 | Classification loss: 0.26963 | Regression loss: 0.29784 | Running loss: 0.69982\n","Epoch: 0 | Iteration: 1844/2403 | Classification loss: 0.33255 | Regression loss: 0.27270 | Running loss: 0.69977\n","Epoch: 0 | Iteration: 1845/2403 | Classification loss: 0.63279 | Regression loss: 0.22679 | Running loss: 0.69986\n","Epoch: 0 | Iteration: 1846/2403 | Classification loss: 0.28298 | Regression loss: 0.24684 | Running loss: 0.69976\n","Epoch: 0 | Iteration: 1847/2403 | Classification loss: 0.23840 | Regression loss: 0.27408 | Running loss: 0.69966\n","Epoch: 0 | Iteration: 1848/2403 | Classification loss: 0.06925 | Regression loss: 0.18663 | Running loss: 0.69942\n","Epoch: 0 | Iteration: 1849/2403 | Classification loss: 0.14893 | Regression loss: 0.18861 | Running loss: 0.69923\n","Epoch: 0 | Iteration: 1850/2403 | Classification loss: 0.30219 | Regression loss: 0.43202 | Running loss: 0.69925\n","Epoch: 0 | Iteration: 1851/2403 | Classification loss: 0.26459 | Regression loss: 0.23631 | Running loss: 0.69914\n","Epoch: 0 | Iteration: 1852/2403 | Classification loss: 0.27824 | Regression loss: 0.26929 | Running loss: 0.69906\n","Epoch: 0 | Iteration: 1853/2403 | Classification loss: 0.25205 | Regression loss: 0.20086 | Running loss: 0.69892\n","Epoch: 0 | Iteration: 1854/2403 | Classification loss: 0.21488 | Regression loss: 0.27327 | Running loss: 0.69881\n","Epoch: 0 | Iteration: 1855/2403 | Classification loss: 0.07566 | Regression loss: 0.18542 | Running loss: 0.69857\n","Epoch: 0 | Iteration: 1856/2403 | Classification loss: 0.11904 | Regression loss: 0.14577 | Running loss: 0.69834\n","Epoch: 0 | Iteration: 1857/2403 | Classification loss: 0.34413 | Regression loss: 0.26689 | Running loss: 0.69829\n","Epoch: 0 | Iteration: 1858/2403 | Classification loss: 0.21705 | Regression loss: 0.23827 | Running loss: 0.69816\n","Epoch: 0 | Iteration: 1859/2403 | Classification loss: 0.14110 | Regression loss: 0.24912 | Running loss: 0.69800\n","Epoch: 0 | Iteration: 1860/2403 | Classification loss: 0.15158 | Regression loss: 0.21051 | Running loss: 0.69782\n","Epoch: 0 | Iteration: 1861/2403 | Classification loss: 0.12086 | Regression loss: 0.16192 | Running loss: 0.69759\n","Epoch: 0 | Iteration: 1862/2403 | Classification loss: 0.09304 | Regression loss: 0.16525 | Running loss: 0.69736\n","Epoch: 0 | Iteration: 1863/2403 | Classification loss: 0.21157 | Regression loss: 0.15711 | Running loss: 0.69718\n","Epoch: 0 | Iteration: 1864/2403 | Classification loss: 0.08093 | Regression loss: 0.18501 | Running loss: 0.69695\n","Epoch: 0 | Iteration: 1865/2403 | Classification loss: 0.05995 | Regression loss: 0.12869 | Running loss: 0.69668\n","Epoch: 0 | Iteration: 1866/2403 | Classification loss: 0.08948 | Regression loss: 0.19566 | Running loss: 0.69646\n","Epoch: 0 | Iteration: 1867/2403 | Classification loss: 0.05654 | Regression loss: 0.27591 | Running loss: 0.69626\n","Epoch: 0 | Iteration: 1868/2403 | Classification loss: 0.32075 | Regression loss: 0.71189 | Running loss: 0.69644\n","Epoch: 0 | Iteration: 1869/2403 | Classification loss: 0.03592 | Regression loss: 0.12311 | Running loss: 0.69615\n","Epoch: 0 | Iteration: 1870/2403 | Classification loss: 0.30378 | Regression loss: 0.31258 | Running loss: 0.69611\n","Epoch: 0 | Iteration: 1871/2403 | Classification loss: 0.21293 | Regression loss: 0.26321 | Running loss: 0.69599\n","Epoch: 0 | Iteration: 1872/2403 | Classification loss: 0.12400 | Regression loss: 0.16422 | Running loss: 0.69578\n","Epoch: 0 | Iteration: 1873/2403 | Classification loss: 0.34792 | Regression loss: 0.28724 | Running loss: 0.69574\n","Epoch: 0 | Iteration: 1874/2403 | Classification loss: 0.08372 | Regression loss: 0.22036 | Running loss: 0.69554\n","Epoch: 0 | Iteration: 1875/2403 | Classification loss: 0.36751 | Regression loss: 0.33441 | Running loss: 0.69554\n","Epoch: 0 | Iteration: 1876/2403 | Classification loss: 0.67058 | Regression loss: 0.41414 | Running loss: 0.69575\n","Epoch: 0 | Iteration: 1877/2403 | Classification loss: 0.12188 | Regression loss: 0.38910 | Running loss: 0.69565\n","Epoch: 0 | Iteration: 1878/2403 | Classification loss: 0.15897 | Regression loss: 0.24639 | Running loss: 0.69549\n","Epoch: 0 | Iteration: 1879/2403 | Classification loss: 0.30315 | Regression loss: 0.35462 | Running loss: 0.69547\n","Epoch: 0 | Iteration: 1880/2403 | Classification loss: 0.31294 | Regression loss: 0.29389 | Running loss: 0.69543\n","Epoch: 0 | Iteration: 1881/2403 | Classification loss: 0.10161 | Regression loss: 0.28103 | Running loss: 0.69526\n","Epoch: 0 | Iteration: 1882/2403 | Classification loss: 0.11263 | Regression loss: 0.18007 | Running loss: 0.69505\n","Epoch: 0 | Iteration: 1883/2403 | Classification loss: 0.06034 | Regression loss: 0.19517 | Running loss: 0.69481\n","Epoch: 0 | Iteration: 1884/2403 | Classification loss: 0.07421 | Regression loss: 0.19570 | Running loss: 0.69459\n","Epoch: 0 | Iteration: 1885/2403 | Classification loss: 0.26343 | Regression loss: 0.33384 | Running loss: 0.69454\n","Epoch: 0 | Iteration: 1886/2403 | Classification loss: 0.53704 | Regression loss: 0.26262 | Running loss: 0.69459\n","Epoch: 0 | Iteration: 1887/2403 | Classification loss: 0.16978 | Regression loss: 0.24282 | Running loss: 0.69444\n","Epoch: 0 | Iteration: 1888/2403 | Classification loss: 0.05445 | Regression loss: 0.21785 | Running loss: 0.69422\n","Epoch: 0 | Iteration: 1889/2403 | Classification loss: 0.08227 | Regression loss: 0.16962 | Running loss: 0.69398\n","Epoch: 0 | Iteration: 1890/2403 | Classification loss: 0.08184 | Regression loss: 0.16106 | Running loss: 0.69374\n","Epoch: 0 | Iteration: 1891/2403 | Classification loss: 0.16495 | Regression loss: 0.19931 | Running loss: 0.69357\n","Epoch: 0 | Iteration: 1892/2403 | Classification loss: 0.16853 | Regression loss: 0.19553 | Running loss: 0.69340\n","Epoch: 0 | Iteration: 1893/2403 | Classification loss: 0.33121 | Regression loss: 0.20760 | Running loss: 0.69331\n","Epoch: 0 | Iteration: 1894/2403 | Classification loss: 0.26960 | Regression loss: 0.42675 | Running loss: 0.69332\n","Epoch: 0 | Iteration: 1895/2403 | Classification loss: 0.12125 | Regression loss: 0.20680 | Running loss: 0.69312\n","Epoch: 0 | Iteration: 1896/2403 | Classification loss: 0.12794 | Regression loss: 0.16971 | Running loss: 0.69292\n","Epoch: 0 | Iteration: 1897/2403 | Classification loss: 0.19649 | Regression loss: 0.23124 | Running loss: 0.69278\n","Epoch: 0 | Iteration: 1898/2403 | Classification loss: 0.10818 | Regression loss: 0.25813 | Running loss: 0.69260\n","Epoch: 0 | Iteration: 1899/2403 | Classification loss: 0.15236 | Regression loss: 0.30979 | Running loss: 0.69248\n","Epoch: 0 | Iteration: 1900/2403 | Classification loss: 1.17694 | Regression loss: 0.46812 | Running loss: 0.69298\n","Epoch: 0 | Iteration: 1901/2403 | Classification loss: 0.12220 | Regression loss: 0.16537 | Running loss: 0.69277\n","Epoch: 0 | Iteration: 1902/2403 | Classification loss: 0.08532 | Regression loss: 0.28512 | Running loss: 0.69260\n","Epoch: 0 | Iteration: 1903/2403 | Classification loss: 0.34016 | Regression loss: 0.30879 | Running loss: 0.69258\n","Epoch: 0 | Iteration: 1904/2403 | Classification loss: 0.19107 | Regression loss: 0.13571 | Running loss: 0.69239\n","Epoch: 0 | Iteration: 1905/2403 | Classification loss: 0.22551 | Regression loss: 0.31064 | Running loss: 0.69230\n","Epoch: 0 | Iteration: 1906/2403 | Classification loss: 0.18139 | Regression loss: 0.22797 | Running loss: 0.69216\n","Epoch: 0 | Iteration: 1907/2403 | Classification loss: 0.11054 | Regression loss: 0.29704 | Running loss: 0.69201\n","Epoch: 0 | Iteration: 1908/2403 | Classification loss: 0.07342 | Regression loss: 0.24656 | Running loss: 0.69181\n","Epoch: 0 | Iteration: 1909/2403 | Classification loss: 0.28900 | Regression loss: 0.26298 | Running loss: 0.69174\n","Epoch: 0 | Iteration: 1910/2403 | Classification loss: 0.25781 | Regression loss: 0.22052 | Running loss: 0.69163\n","Epoch: 0 | Iteration: 1911/2403 | Classification loss: 0.13555 | Regression loss: 0.28416 | Running loss: 0.69148\n","Epoch: 0 | Iteration: 1912/2403 | Classification loss: 0.05717 | Regression loss: 0.17669 | Running loss: 0.69124\n","Epoch: 0 | Iteration: 1913/2403 | Classification loss: 0.34511 | Regression loss: 0.25380 | Running loss: 0.69120\n","Epoch: 0 | Iteration: 1914/2403 | Classification loss: 0.07053 | Regression loss: 0.12700 | Running loss: 0.69094\n","Epoch: 0 | Iteration: 1915/2403 | Classification loss: 0.19692 | Regression loss: 0.24002 | Running loss: 0.69081\n","Epoch: 0 | Iteration: 1916/2403 | Classification loss: 0.35515 | Regression loss: 0.32858 | Running loss: 0.69080\n","Epoch: 0 | Iteration: 1917/2403 | Classification loss: 0.16154 | Regression loss: 0.17972 | Running loss: 0.69062\n","Epoch: 0 | Iteration: 1918/2403 | Classification loss: 0.14827 | Regression loss: 0.20960 | Running loss: 0.69045\n","Epoch: 0 | Iteration: 1919/2403 | Classification loss: 0.33717 | Regression loss: 0.22653 | Running loss: 0.69038\n","Epoch: 0 | Iteration: 1920/2403 | Classification loss: 0.24662 | Regression loss: 0.27452 | Running loss: 0.69029\n","Epoch: 0 | Iteration: 1921/2403 | Classification loss: 0.22590 | Regression loss: 0.25476 | Running loss: 0.69018\n","Epoch: 0 | Iteration: 1922/2403 | Classification loss: 0.17273 | Regression loss: 0.23469 | Running loss: 0.69004\n","Epoch: 0 | Iteration: 1923/2403 | Classification loss: 0.14673 | Regression loss: 0.22056 | Running loss: 0.68987\n","Epoch: 0 | Iteration: 1924/2403 | Classification loss: 0.16995 | Regression loss: 0.32895 | Running loss: 0.68977\n","Epoch: 0 | Iteration: 1925/2403 | Classification loss: 1.02133 | Regression loss: 0.37551 | Running loss: 0.69014\n","Epoch: 0 | Iteration: 1926/2403 | Classification loss: 0.30887 | Regression loss: 0.30081 | Running loss: 0.69009\n","Epoch: 0 | Iteration: 1927/2403 | Classification loss: 0.28179 | Regression loss: 0.23518 | Running loss: 0.69000\n","Epoch: 0 | Iteration: 1928/2403 | Classification loss: 0.18982 | Regression loss: 0.25837 | Running loss: 0.68988\n","Epoch: 0 | Iteration: 1929/2403 | Classification loss: 0.06823 | Regression loss: 0.16308 | Running loss: 0.68964\n","Epoch: 0 | Iteration: 1930/2403 | Classification loss: 0.34920 | Regression loss: 0.32671 | Running loss: 0.68963\n","Epoch: 0 | Iteration: 1931/2403 | Classification loss: 0.11620 | Regression loss: 0.21362 | Running loss: 0.68945\n","Epoch: 0 | Iteration: 1932/2403 | Classification loss: 0.09619 | Regression loss: 0.14580 | Running loss: 0.68922\n","Epoch: 0 | Iteration: 1933/2403 | Classification loss: 0.30326 | Regression loss: 0.23926 | Running loss: 0.68914\n","Epoch: 0 | Iteration: 1934/2403 | Classification loss: 0.08636 | Regression loss: 0.14355 | Running loss: 0.68890\n","Epoch: 0 | Iteration: 1935/2403 | Classification loss: 0.59203 | Regression loss: 0.41386 | Running loss: 0.68907\n","Epoch: 0 | Iteration: 1936/2403 | Classification loss: 0.21478 | Regression loss: 0.22982 | Running loss: 0.68894\n","Epoch: 0 | Iteration: 1937/2403 | Classification loss: 0.18220 | Regression loss: 0.22785 | Running loss: 0.68880\n","Epoch: 0 | Iteration: 1938/2403 | Classification loss: 0.21275 | Regression loss: 0.25780 | Running loss: 0.68868\n","Epoch: 0 | Iteration: 1939/2403 | Classification loss: 0.16671 | Regression loss: 0.18738 | Running loss: 0.68851\n","Epoch: 0 | Iteration: 1940/2403 | Classification loss: 0.17573 | Regression loss: 0.18643 | Running loss: 0.68834\n","Epoch: 0 | Iteration: 1941/2403 | Classification loss: 0.22115 | Regression loss: 0.24925 | Running loss: 0.68823\n","Epoch: 0 | Iteration: 1942/2403 | Classification loss: 0.28715 | Regression loss: 0.32921 | Running loss: 0.68819\n","Epoch: 0 | Iteration: 1943/2403 | Classification loss: 0.34639 | Regression loss: 0.25750 | Running loss: 0.68815\n","Epoch: 0 | Iteration: 1944/2403 | Classification loss: 0.14964 | Regression loss: 0.28781 | Running loss: 0.68802\n","Epoch: 0 | Iteration: 1945/2403 | Classification loss: 0.14702 | Regression loss: 0.17250 | Running loss: 0.68783\n","Epoch: 0 | Iteration: 1946/2403 | Classification loss: 0.04675 | Regression loss: 0.19328 | Running loss: 0.68760\n","Epoch: 0 | Iteration: 1947/2403 | Classification loss: 0.51394 | Regression loss: 0.29422 | Running loss: 0.68766\n","Epoch: 0 | Iteration: 1948/2403 | Classification loss: 0.19150 | Regression loss: 0.27449 | Running loss: 0.68755\n","Epoch: 0 | Iteration: 1949/2403 | Classification loss: 0.29864 | Regression loss: 0.24388 | Running loss: 0.68748\n","Epoch: 0 | Iteration: 1950/2403 | Classification loss: 0.25351 | Regression loss: 0.28292 | Running loss: 0.68740\n","Epoch: 0 | Iteration: 1951/2403 | Classification loss: 0.16351 | Regression loss: 0.18453 | Running loss: 0.68722\n","Epoch: 0 | Iteration: 1952/2403 | Classification loss: 0.48779 | Regression loss: 0.34070 | Running loss: 0.68730\n","Epoch: 0 | Iteration: 1953/2403 | Classification loss: 0.40307 | Regression loss: 0.28227 | Running loss: 0.68730\n","Epoch: 0 | Iteration: 1954/2403 | Classification loss: 0.05837 | Regression loss: 0.16278 | Running loss: 0.68706\n","Epoch: 0 | Iteration: 1955/2403 | Classification loss: 0.15381 | Regression loss: 0.18190 | Running loss: 0.68688\n","Epoch: 0 | Iteration: 1956/2403 | Classification loss: 0.13967 | Regression loss: 0.19499 | Running loss: 0.68670\n","Epoch: 0 | Iteration: 1957/2403 | Classification loss: 0.26287 | Regression loss: 0.22044 | Running loss: 0.68659\n","Epoch: 0 | Iteration: 1958/2403 | Classification loss: 0.53533 | Regression loss: 0.27990 | Running loss: 0.68666\n","Epoch: 0 | Iteration: 1959/2403 | Classification loss: 0.34550 | Regression loss: 0.38116 | Running loss: 0.68668\n","Epoch: 0 | Iteration: 1960/2403 | Classification loss: 0.55370 | Regression loss: 0.25179 | Running loss: 0.68674\n","Epoch: 0 | Iteration: 1961/2403 | Classification loss: 0.27238 | Regression loss: 0.21654 | Running loss: 0.68664\n","Epoch: 0 | Iteration: 1962/2403 | Classification loss: 0.10834 | Regression loss: 0.19199 | Running loss: 0.68644\n","Epoch: 0 | Iteration: 1963/2403 | Classification loss: 0.28923 | Regression loss: 0.23330 | Running loss: 0.68636\n","Epoch: 0 | Iteration: 1964/2403 | Classification loss: 0.35896 | Regression loss: 0.25389 | Running loss: 0.68632\n","Epoch: 0 | Iteration: 1965/2403 | Classification loss: 0.28865 | Regression loss: 0.37716 | Running loss: 0.68631\n","Epoch: 0 | Iteration: 1966/2403 | Classification loss: 0.35641 | Regression loss: 0.34204 | Running loss: 0.68632\n","Epoch: 0 | Iteration: 1967/2403 | Classification loss: 0.25224 | Regression loss: 0.25003 | Running loss: 0.68622\n","Epoch: 0 | Iteration: 1968/2403 | Classification loss: 0.27874 | Regression loss: 0.22540 | Running loss: 0.68613\n","Epoch: 0 | Iteration: 1969/2403 | Classification loss: 0.13493 | Regression loss: 0.20005 | Running loss: 0.68595\n","Epoch: 0 | Iteration: 1970/2403 | Classification loss: 0.15156 | Regression loss: 0.22127 | Running loss: 0.68579\n","Epoch: 0 | Iteration: 1971/2403 | Classification loss: 0.39857 | Regression loss: 0.22105 | Running loss: 0.68576\n","Epoch: 0 | Iteration: 1972/2403 | Classification loss: 0.32842 | Regression loss: 0.22732 | Running loss: 0.68569\n","Epoch: 0 | Iteration: 1973/2403 | Classification loss: 0.10549 | Regression loss: 0.12299 | Running loss: 0.68546\n","Epoch: 0 | Iteration: 1974/2403 | Classification loss: 0.53009 | Regression loss: 0.42591 | Running loss: 0.68560\n","Epoch: 0 | Iteration: 1975/2403 | Classification loss: 0.16241 | Regression loss: 0.13720 | Running loss: 0.68540\n","Epoch: 0 | Iteration: 1976/2403 | Classification loss: 0.15526 | Regression loss: 0.25282 | Running loss: 0.68526\n","Epoch: 0 | Iteration: 1977/2403 | Classification loss: 0.63278 | Regression loss: 0.33055 | Running loss: 0.68540\n","Epoch: 0 | Iteration: 1978/2403 | Classification loss: 0.21081 | Regression loss: 0.24230 | Running loss: 0.68529\n","Epoch: 0 | Iteration: 1979/2403 | Classification loss: 0.08867 | Regression loss: 0.20379 | Running loss: 0.68509\n","Epoch: 0 | Iteration: 1980/2403 | Classification loss: 0.11924 | Regression loss: 0.24409 | Running loss: 0.68493\n","Epoch: 0 | Iteration: 1981/2403 | Classification loss: 0.10124 | Regression loss: 0.25714 | Running loss: 0.68476\n","Epoch: 0 | Iteration: 1982/2403 | Classification loss: 8.72068 | Regression loss: 0.37664 | Running loss: 0.68901\n","Epoch: 0 | Iteration: 1983/2403 | Classification loss: 0.09654 | Regression loss: 0.18214 | Running loss: 0.68880\n","Epoch: 0 | Iteration: 1984/2403 | Classification loss: 0.28721 | Regression loss: 0.25479 | Running loss: 0.68872\n","Epoch: 0 | Iteration: 1985/2403 | Classification loss: 0.39593 | Regression loss: 0.24634 | Running loss: 0.68870\n","Epoch: 0 | Iteration: 1986/2403 | Classification loss: 0.17601 | Regression loss: 0.22683 | Running loss: 0.68856\n","Epoch: 0 | Iteration: 1987/2403 | Classification loss: 0.27296 | Regression loss: 0.30179 | Running loss: 0.68850\n","Epoch: 0 | Iteration: 1988/2403 | Classification loss: 0.12310 | Regression loss: 0.25779 | Running loss: 0.68834\n","Epoch: 0 | Iteration: 1989/2403 | Classification loss: 0.35207 | Regression loss: 0.43654 | Running loss: 0.68840\n","Epoch: 0 | Iteration: 1990/2403 | Classification loss: 0.35144 | Regression loss: 0.33623 | Running loss: 0.68839\n","Epoch: 0 | Iteration: 1991/2403 | Classification loss: 0.09079 | Regression loss: 0.21710 | Running loss: 0.68820\n","Epoch: 0 | Iteration: 1992/2403 | Classification loss: 0.25917 | Regression loss: 0.22180 | Running loss: 0.68810\n","Epoch: 0 | Iteration: 1993/2403 | Classification loss: 0.12362 | Regression loss: 0.23679 | Running loss: 0.68794\n","Epoch: 0 | Iteration: 1994/2403 | Classification loss: 0.08832 | Regression loss: 0.19970 | Running loss: 0.68773\n","Epoch: 0 | Iteration: 1995/2403 | Classification loss: 0.25195 | Regression loss: 0.44195 | Running loss: 0.68774\n","Epoch: 0 | Iteration: 1996/2403 | Classification loss: 0.67925 | Regression loss: 0.26142 | Running loss: 0.68786\n","Epoch: 0 | Iteration: 1997/2403 | Classification loss: 0.16695 | Regression loss: 0.33945 | Running loss: 0.68777\n","Epoch: 0 | Iteration: 1998/2403 | Classification loss: 0.09699 | Regression loss: 0.20827 | Running loss: 0.68758\n","Epoch: 0 | Iteration: 1999/2403 | Classification loss: 0.57152 | Regression loss: 0.22412 | Running loss: 0.68764\n","Epoch: 0 | Iteration: 2000/2403 | Classification loss: 0.12600 | Regression loss: 0.18392 | Running loss: 0.68745\n","Epoch: 0 | Iteration: 2001/2403 | Classification loss: 0.39516 | Regression loss: 0.47725 | Running loss: 0.68754\n","Epoch: 0 | Iteration: 2002/2403 | Classification loss: 0.11220 | Regression loss: 0.17865 | Running loss: 0.68734\n","Epoch: 0 | Iteration: 2003/2403 | Classification loss: 0.34331 | Regression loss: 0.23411 | Running loss: 0.68729\n","Epoch: 0 | Iteration: 2004/2403 | Classification loss: 0.15195 | Regression loss: 0.21248 | Running loss: 0.68713\n","Epoch: 0 | Iteration: 2005/2403 | Classification loss: 0.17214 | Regression loss: 0.17159 | Running loss: 0.68695\n","Epoch: 0 | Iteration: 2006/2403 | Classification loss: 0.24630 | Regression loss: 0.26624 | Running loss: 0.68687\n","Epoch: 0 | Iteration: 2007/2403 | Classification loss: 0.24279 | Regression loss: 0.20315 | Running loss: 0.68675\n","Epoch: 0 | Iteration: 2008/2403 | Classification loss: 0.20841 | Regression loss: 0.29155 | Running loss: 0.68665\n","Epoch: 0 | Iteration: 2009/2403 | Classification loss: 0.16362 | Regression loss: 0.17035 | Running loss: 0.68648\n","Epoch: 0 | Iteration: 2010/2403 | Classification loss: 0.25933 | Regression loss: 0.34167 | Running loss: 0.68644\n","Epoch: 0 | Iteration: 2011/2403 | Classification loss: 0.57665 | Regression loss: 0.31463 | Running loss: 0.68654\n","Epoch: 0 | Iteration: 2012/2403 | Classification loss: 0.04546 | Regression loss: 0.14809 | Running loss: 0.68629\n","Epoch: 0 | Iteration: 2013/2403 | Classification loss: 0.16803 | Regression loss: 0.27736 | Running loss: 0.68617\n","Epoch: 0 | Iteration: 2014/2403 | Classification loss: 0.27219 | Regression loss: 0.25035 | Running loss: 0.68609\n","Epoch: 0 | Iteration: 2015/2403 | Classification loss: 0.13964 | Regression loss: 0.25119 | Running loss: 0.68595\n","Epoch: 0 | Iteration: 2016/2403 | Classification loss: 0.12474 | Regression loss: 0.17597 | Running loss: 0.68575\n","Epoch: 0 | Iteration: 2017/2403 | Classification loss: 0.12358 | Regression loss: 0.14409 | Running loss: 0.68555\n","Epoch: 0 | Iteration: 2018/2403 | Classification loss: 0.06027 | Regression loss: 0.17809 | Running loss: 0.68533\n","Epoch: 0 | Iteration: 2019/2403 | Classification loss: 0.16909 | Regression loss: 0.26977 | Running loss: 0.68520\n","Epoch: 0 | Iteration: 2020/2403 | Classification loss: 0.12450 | Regression loss: 0.20513 | Running loss: 0.68503\n","Epoch: 0 | Iteration: 2021/2403 | Classification loss: 0.04878 | Regression loss: 0.14769 | Running loss: 0.68479\n","Epoch: 0 | Iteration: 2022/2403 | Classification loss: 0.04692 | Regression loss: 0.15583 | Running loss: 0.68455\n","Epoch: 0 | Iteration: 2023/2403 | Classification loss: 0.15268 | Regression loss: 0.29811 | Running loss: 0.68443\n","Epoch: 0 | Iteration: 2024/2403 | Classification loss: 0.40910 | Regression loss: 0.30722 | Running loss: 0.68445\n","Epoch: 0 | Iteration: 2025/2403 | Classification loss: 0.08557 | Regression loss: 0.15553 | Running loss: 0.68423\n","Epoch: 0 | Iteration: 2026/2403 | Classification loss: 0.11719 | Regression loss: 0.19875 | Running loss: 0.68405\n","Epoch: 0 | Iteration: 2027/2403 | Classification loss: 0.31977 | Regression loss: 0.31383 | Running loss: 0.68402\n","Epoch: 0 | Iteration: 2028/2403 | Classification loss: 0.51542 | Regression loss: 0.35395 | Running loss: 0.68411\n","Epoch: 0 | Iteration: 2029/2403 | Classification loss: 0.52391 | Regression loss: 0.23098 | Running loss: 0.68415\n","Epoch: 0 | Iteration: 2030/2403 | Classification loss: 0.06570 | Regression loss: 0.18493 | Running loss: 0.68393\n","Epoch: 0 | Iteration: 2031/2403 | Classification loss: 0.37001 | Regression loss: 0.28244 | Running loss: 0.68392\n","Epoch: 0 | Iteration: 2032/2403 | Classification loss: 0.18696 | Regression loss: 0.22351 | Running loss: 0.68378\n","Epoch: 0 | Iteration: 2033/2403 | Classification loss: 0.16757 | Regression loss: 0.27717 | Running loss: 0.68367\n","Epoch: 0 | Iteration: 2034/2403 | Classification loss: 0.21345 | Regression loss: 0.29581 | Running loss: 0.68358\n","Epoch: 0 | Iteration: 2035/2403 | Classification loss: 0.49699 | Regression loss: 0.31721 | Running loss: 0.68365\n","Epoch: 0 | Iteration: 2036/2403 | Classification loss: 0.34897 | Regression loss: 0.19935 | Running loss: 0.68358\n","Epoch: 0 | Iteration: 2037/2403 | Classification loss: 0.65392 | Regression loss: 0.30861 | Running loss: 0.68372\n","Epoch: 0 | Iteration: 2038/2403 | Classification loss: 0.18003 | Regression loss: 0.24023 | Running loss: 0.68359\n","Epoch: 0 | Iteration: 2039/2403 | Classification loss: 0.06722 | Regression loss: 0.20753 | Running loss: 0.68339\n","Epoch: 0 | Iteration: 2040/2403 | Classification loss: 0.53178 | Regression loss: 0.37916 | Running loss: 0.68350\n","Epoch: 0 | Iteration: 2041/2403 | Classification loss: 0.32480 | Regression loss: 0.29360 | Running loss: 0.68347\n","Epoch: 0 | Iteration: 2042/2403 | Classification loss: 0.11050 | Regression loss: 0.24475 | Running loss: 0.68331\n","Epoch: 0 | Iteration: 2043/2403 | Classification loss: 0.23011 | Regression loss: 0.30385 | Running loss: 0.68323\n","Epoch: 0 | Iteration: 2044/2403 | Classification loss: 0.38825 | Regression loss: 0.31564 | Running loss: 0.68324\n","Epoch: 0 | Iteration: 2045/2403 | Classification loss: 0.10772 | Regression loss: 0.19926 | Running loss: 0.68306\n","Epoch: 0 | Iteration: 2046/2403 | Classification loss: 0.31633 | Regression loss: 0.27178 | Running loss: 0.68301\n","Epoch: 0 | Iteration: 2047/2403 | Classification loss: 0.24319 | Regression loss: 0.19574 | Running loss: 0.68289\n","Epoch: 0 | Iteration: 2048/2403 | Classification loss: 0.24368 | Regression loss: 0.34564 | Running loss: 0.68285\n","Epoch: 0 | Iteration: 2049/2403 | Classification loss: 0.16143 | Regression loss: 0.21349 | Running loss: 0.68270\n","Epoch: 0 | Iteration: 2050/2403 | Classification loss: 0.13157 | Regression loss: 0.20736 | Running loss: 0.68253\n","Epoch: 0 | Iteration: 2051/2403 | Classification loss: 0.21894 | Regression loss: 0.40051 | Running loss: 0.68250\n","Epoch: 0 | Iteration: 2052/2403 | Classification loss: 0.15937 | Regression loss: 0.23930 | Running loss: 0.68236\n","Epoch: 0 | Iteration: 2053/2403 | Classification loss: 0.21860 | Regression loss: 0.25180 | Running loss: 0.68226\n","Epoch: 0 | Iteration: 2054/2403 | Classification loss: 0.09197 | Regression loss: 0.18268 | Running loss: 0.68206\n","Epoch: 0 | Iteration: 2055/2403 | Classification loss: 0.22463 | Regression loss: 0.21509 | Running loss: 0.68194\n","Epoch: 0 | Iteration: 2056/2403 | Classification loss: 0.36043 | Regression loss: 0.38298 | Running loss: 0.68197\n","Epoch: 0 | Iteration: 2057/2403 | Classification loss: 0.11923 | Regression loss: 0.16531 | Running loss: 0.68178\n","Epoch: 0 | Iteration: 2058/2403 | Classification loss: 0.48420 | Regression loss: 0.27691 | Running loss: 0.68182\n","Epoch: 0 | Iteration: 2059/2403 | Classification loss: 0.26736 | Regression loss: 0.28510 | Running loss: 0.68175\n","Epoch: 0 | Iteration: 2060/2403 | Classification loss: 0.28792 | Regression loss: 0.28428 | Running loss: 0.68170\n","Epoch: 0 | Iteration: 2061/2403 | Classification loss: 0.25388 | Regression loss: 0.20690 | Running loss: 0.68159\n","Epoch: 0 | Iteration: 2062/2403 | Classification loss: 0.21897 | Regression loss: 0.28047 | Running loss: 0.68150\n","Epoch: 0 | Iteration: 2063/2403 | Classification loss: 0.05932 | Regression loss: 0.17353 | Running loss: 0.68129\n","Epoch: 0 | Iteration: 2064/2403 | Classification loss: 0.38970 | Regression loss: 0.55128 | Running loss: 0.68141\n","Epoch: 0 | Iteration: 2065/2403 | Classification loss: 0.17404 | Regression loss: 0.24186 | Running loss: 0.68128\n","Epoch: 0 | Iteration: 2066/2403 | Classification loss: 0.25287 | Regression loss: 0.35880 | Running loss: 0.68125\n","Epoch: 0 | Iteration: 2067/2403 | Classification loss: 0.16055 | Regression loss: 0.25104 | Running loss: 0.68112\n","Epoch: 0 | Iteration: 2068/2403 | Classification loss: 0.09553 | Regression loss: 0.20764 | Running loss: 0.68094\n","Epoch: 0 | Iteration: 2069/2403 | Classification loss: 2.27167 | Regression loss: 0.22400 | Running loss: 0.68181\n","Epoch: 0 | Iteration: 2070/2403 | Classification loss: 0.14382 | Regression loss: 0.18351 | Running loss: 0.68164\n","Epoch: 0 | Iteration: 2071/2403 | Classification loss: 0.15285 | Regression loss: 0.20101 | Running loss: 0.68148\n","Epoch: 0 | Iteration: 2072/2403 | Classification loss: 0.36683 | Regression loss: 0.48107 | Running loss: 0.68156\n","Epoch: 0 | Iteration: 2073/2403 | Classification loss: 0.09596 | Regression loss: 0.15939 | Running loss: 0.68136\n","Epoch: 0 | Iteration: 2074/2403 | Classification loss: 0.41488 | Regression loss: 0.24787 | Running loss: 0.68135\n","Epoch: 0 | Iteration: 2075/2403 | Classification loss: 0.16377 | Regression loss: 0.23330 | Running loss: 0.68121\n","Epoch: 0 | Iteration: 2076/2403 | Classification loss: 0.19928 | Regression loss: 0.24809 | Running loss: 0.68110\n","Epoch: 0 | Iteration: 2077/2403 | Classification loss: 0.29714 | Regression loss: 0.43457 | Running loss: 0.68112\n","Epoch: 0 | Iteration: 2078/2403 | Classification loss: 0.11615 | Regression loss: 0.18281 | Running loss: 0.68094\n","Epoch: 0 | Iteration: 2079/2403 | Classification loss: 0.24355 | Regression loss: 0.24048 | Running loss: 0.68085\n","Epoch: 0 | Iteration: 2080/2403 | Classification loss: 0.12322 | Regression loss: 0.21557 | Running loss: 0.68068\n","Epoch: 0 | Iteration: 2081/2403 | Classification loss: 0.30786 | Regression loss: 0.33553 | Running loss: 0.68066\n","Epoch: 0 | Iteration: 2082/2403 | Classification loss: 0.20207 | Regression loss: 0.20069 | Running loss: 0.68053\n","Epoch: 0 | Iteration: 2083/2403 | Classification loss: 0.15025 | Regression loss: 0.20312 | Running loss: 0.68037\n","Epoch: 0 | Iteration: 2084/2403 | Classification loss: 0.14517 | Regression loss: 0.22849 | Running loss: 0.68023\n","Epoch: 0 | Iteration: 2085/2403 | Classification loss: 0.46247 | Regression loss: 0.27340 | Running loss: 0.68025\n","Epoch: 0 | Iteration: 2086/2403 | Classification loss: 0.37683 | Regression loss: 0.28949 | Running loss: 0.68025\n","Epoch: 0 | Iteration: 2087/2403 | Classification loss: 0.08537 | Regression loss: 0.18826 | Running loss: 0.68005\n","Epoch: 0 | Iteration: 2088/2403 | Classification loss: 0.21223 | Regression loss: 0.23900 | Running loss: 0.67994\n","Epoch: 0 | Iteration: 2089/2403 | Classification loss: 0.21851 | Regression loss: 0.27602 | Running loss: 0.67985\n","Epoch: 0 | Iteration: 2090/2403 | Classification loss: 0.23746 | Regression loss: 0.34865 | Running loss: 0.67981\n","Epoch: 0 | Iteration: 2091/2403 | Classification loss: 0.16788 | Regression loss: 0.22192 | Running loss: 0.67967\n","Epoch: 0 | Iteration: 2092/2403 | Classification loss: 0.11009 | Regression loss: 0.31329 | Running loss: 0.67955\n","Epoch: 0 | Iteration: 2093/2403 | Classification loss: 0.16992 | Regression loss: 0.24214 | Running loss: 0.67942\n","Epoch: 0 | Iteration: 2094/2403 | Classification loss: 0.17007 | Regression loss: 0.25896 | Running loss: 0.67930\n","Epoch: 0 | Iteration: 2095/2403 | Classification loss: 0.12998 | Regression loss: 0.25920 | Running loss: 0.67916\n","Epoch: 0 | Iteration: 2096/2403 | Classification loss: 0.51368 | Regression loss: 0.24913 | Running loss: 0.67920\n","Epoch: 0 | Iteration: 2097/2403 | Classification loss: 0.15601 | Regression loss: 0.30562 | Running loss: 0.67910\n","Epoch: 0 | Iteration: 2098/2403 | Classification loss: 0.04744 | Regression loss: 0.18111 | Running loss: 0.67888\n","Epoch: 0 | Iteration: 2099/2403 | Classification loss: 0.08333 | Regression loss: 0.17576 | Running loss: 0.67868\n","Epoch: 0 | Iteration: 2100/2403 | Classification loss: 0.11375 | Regression loss: 0.24135 | Running loss: 0.67853\n","Epoch: 0 | Iteration: 2101/2403 | Classification loss: 0.27858 | Regression loss: 0.26797 | Running loss: 0.67847\n","Epoch: 0 | Iteration: 2102/2403 | Classification loss: 0.13480 | Regression loss: 0.20382 | Running loss: 0.67830\n","Epoch: 0 | Iteration: 2103/2403 | Classification loss: 0.11406 | Regression loss: 0.22137 | Running loss: 0.67814\n","Epoch: 0 | Iteration: 2104/2403 | Classification loss: 0.12313 | Regression loss: 0.23352 | Running loss: 0.67799\n","Epoch: 0 | Iteration: 2105/2403 | Classification loss: 0.30961 | Regression loss: 0.26949 | Running loss: 0.67794\n","Epoch: 0 | Iteration: 2106/2403 | Classification loss: 0.27087 | Regression loss: 0.21124 | Running loss: 0.67785\n","Epoch: 0 | Iteration: 2107/2403 | Classification loss: 0.31463 | Regression loss: 0.30542 | Running loss: 0.67782\n","Epoch: 0 | Iteration: 2108/2403 | Classification loss: 0.28309 | Regression loss: 0.24467 | Running loss: 0.67775\n","Epoch: 0 | Iteration: 2109/2403 | Classification loss: 0.34358 | Regression loss: 0.31166 | Running loss: 0.67774\n","Epoch: 0 | Iteration: 2110/2403 | Classification loss: 0.48662 | Regression loss: 0.46706 | Running loss: 0.67787\n","Epoch: 0 | Iteration: 2111/2403 | Classification loss: 0.10988 | Regression loss: 0.17983 | Running loss: 0.67769\n","Epoch: 0 | Iteration: 2112/2403 | Classification loss: 0.08043 | Regression loss: 0.15887 | Running loss: 0.67748\n","Epoch: 0 | Iteration: 2113/2403 | Classification loss: 0.19516 | Regression loss: 0.25397 | Running loss: 0.67737\n","Epoch: 0 | Iteration: 2114/2403 | Classification loss: 0.75554 | Regression loss: 0.38213 | Running loss: 0.67759\n","Epoch: 0 | Iteration: 2115/2403 | Classification loss: 0.13373 | Regression loss: 0.18530 | Running loss: 0.67742\n","Epoch: 0 | Iteration: 2116/2403 | Classification loss: 0.17051 | Regression loss: 0.20719 | Running loss: 0.67728\n","Epoch: 0 | Iteration: 2117/2403 | Classification loss: 0.31746 | Regression loss: 0.33659 | Running loss: 0.67727\n","Epoch: 0 | Iteration: 2118/2403 | Classification loss: 0.22278 | Regression loss: 0.26815 | Running loss: 0.67718\n","Epoch: 0 | Iteration: 2119/2403 | Classification loss: 0.37983 | Regression loss: 0.41700 | Running loss: 0.67723\n","Epoch: 0 | Iteration: 2120/2403 | Classification loss: 0.31935 | Regression loss: 0.34278 | Running loss: 0.67723\n","Epoch: 0 | Iteration: 2121/2403 | Classification loss: 0.24772 | Regression loss: 0.23533 | Running loss: 0.67714\n","Epoch: 0 | Iteration: 2122/2403 | Classification loss: 0.08940 | Regression loss: 0.21757 | Running loss: 0.67696\n","Epoch: 0 | Iteration: 2123/2403 | Classification loss: 0.07515 | Regression loss: 0.19126 | Running loss: 0.67677\n","Epoch: 0 | Iteration: 2124/2403 | Classification loss: 0.36835 | Regression loss: 0.31151 | Running loss: 0.67677\n","Epoch: 0 | Iteration: 2125/2403 | Classification loss: 0.09148 | Regression loss: 0.14609 | Running loss: 0.67656\n","Epoch: 0 | Iteration: 2126/2403 | Classification loss: 0.09707 | Regression loss: 0.17195 | Running loss: 0.67637\n","Epoch: 0 | Iteration: 2127/2403 | Classification loss: 0.26978 | Regression loss: 0.26093 | Running loss: 0.67630\n","Epoch: 0 | Iteration: 2128/2403 | Classification loss: 0.10618 | Regression loss: 0.18641 | Running loss: 0.67612\n","Epoch: 0 | Iteration: 2129/2403 | Classification loss: 0.19176 | Regression loss: 0.25043 | Running loss: 0.67601\n","Epoch: 0 | Iteration: 2130/2403 | Classification loss: 0.26583 | Regression loss: 0.26803 | Running loss: 0.67595\n","Epoch: 0 | Iteration: 2131/2403 | Classification loss: 0.76440 | Regression loss: 0.35342 | Running loss: 0.67615\n","Epoch: 0 | Iteration: 2132/2403 | Classification loss: 0.09995 | Regression loss: 0.24905 | Running loss: 0.67600\n","Epoch: 0 | Iteration: 2133/2403 | Classification loss: 0.09241 | Regression loss: 0.20928 | Running loss: 0.67582\n","Epoch: 0 | Iteration: 2134/2403 | Classification loss: 0.16154 | Regression loss: 0.16627 | Running loss: 0.67566\n","Epoch: 0 | Iteration: 2135/2403 | Classification loss: 0.22589 | Regression loss: 0.23924 | Running loss: 0.67556\n","Epoch: 0 | Iteration: 2136/2403 | Classification loss: 0.33193 | Regression loss: 0.29916 | Running loss: 0.67554\n","Epoch: 0 | Iteration: 2137/2403 | Classification loss: 0.28161 | Regression loss: 0.27455 | Running loss: 0.67549\n","Epoch: 0 | Iteration: 2138/2403 | Classification loss: 0.36445 | Regression loss: 0.29195 | Running loss: 0.67548\n","Epoch: 0 | Iteration: 2139/2403 | Classification loss: 0.11625 | Regression loss: 0.21089 | Running loss: 0.67531\n","Epoch: 0 | Iteration: 2140/2403 | Classification loss: 0.33049 | Regression loss: 0.33463 | Running loss: 0.67531\n","Epoch: 0 | Iteration: 2141/2403 | Classification loss: 0.46329 | Regression loss: 0.25883 | Running loss: 0.67533\n","Epoch: 0 | Iteration: 2142/2403 | Classification loss: 0.58201 | Regression loss: 0.26223 | Running loss: 0.67541\n","Epoch: 0 | Iteration: 2143/2403 | Classification loss: 0.61172 | Regression loss: 0.30014 | Running loss: 0.67552\n","Epoch: 0 | Iteration: 2144/2403 | Classification loss: 0.27336 | Regression loss: 0.28885 | Running loss: 0.67547\n","Epoch: 0 | Iteration: 2145/2403 | Classification loss: 0.39631 | Regression loss: 0.36398 | Running loss: 0.67551\n","Epoch: 0 | Iteration: 2146/2403 | Classification loss: 0.25133 | Regression loss: 0.25420 | Running loss: 0.67543\n","Epoch: 0 | Iteration: 2147/2403 | Classification loss: 0.19551 | Regression loss: 0.25469 | Running loss: 0.67532\n","Epoch: 0 | Iteration: 2148/2403 | Classification loss: 0.22824 | Regression loss: 0.27198 | Running loss: 0.67524\n","Epoch: 0 | Iteration: 2149/2403 | Classification loss: 0.30102 | Regression loss: 0.29154 | Running loss: 0.67520\n","Epoch: 0 | Iteration: 2150/2403 | Classification loss: 0.08758 | Regression loss: 0.18904 | Running loss: 0.67502\n","Epoch: 0 | Iteration: 2151/2403 | Classification loss: 0.11471 | Regression loss: 0.17690 | Running loss: 0.67484\n","Epoch: 0 | Iteration: 2152/2403 | Classification loss: 0.11162 | Regression loss: 0.17941 | Running loss: 0.67466\n","Epoch: 0 | Iteration: 2153/2403 | Classification loss: 0.24031 | Regression loss: 0.25537 | Running loss: 0.67458\n","Epoch: 0 | Iteration: 2154/2403 | Classification loss: 0.09531 | Regression loss: 0.15299 | Running loss: 0.67438\n","Epoch: 0 | Iteration: 2155/2403 | Classification loss: 0.35393 | Regression loss: 0.30500 | Running loss: 0.67437\n","Epoch: 0 | Iteration: 2156/2403 | Classification loss: 0.10660 | Regression loss: 0.17957 | Running loss: 0.67419\n","Epoch: 0 | Iteration: 2157/2403 | Classification loss: 0.47735 | Regression loss: 0.41980 | Running loss: 0.67430\n","Epoch: 0 | Iteration: 2158/2403 | Classification loss: 0.31635 | Regression loss: 0.25985 | Running loss: 0.67425\n","Epoch: 0 | Iteration: 2159/2403 | Classification loss: 0.32249 | Regression loss: 0.24181 | Running loss: 0.67420\n","Epoch: 0 | Iteration: 2160/2403 | Classification loss: 0.16053 | Regression loss: 0.22678 | Running loss: 0.67407\n","Epoch: 0 | Iteration: 2161/2403 | Classification loss: 0.12088 | Regression loss: 0.20523 | Running loss: 0.67391\n","Epoch: 0 | Iteration: 2162/2403 | Classification loss: 0.21372 | Regression loss: 0.22605 | Running loss: 0.67380\n","Epoch: 0 | Iteration: 2163/2403 | Classification loss: 0.12506 | Regression loss: 0.18827 | Running loss: 0.67363\n","Epoch: 0 | Iteration: 2164/2403 | Classification loss: 0.25870 | Regression loss: 0.26186 | Running loss: 0.67356\n","Epoch: 0 | Iteration: 2165/2403 | Classification loss: 0.40952 | Regression loss: 0.34233 | Running loss: 0.67360\n","Epoch: 0 | Iteration: 2166/2403 | Classification loss: 0.26458 | Regression loss: 0.42367 | Running loss: 0.67360\n","Epoch: 0 | Iteration: 2167/2403 | Classification loss: 0.10356 | Regression loss: 0.18565 | Running loss: 0.67343\n","Epoch: 0 | Iteration: 2168/2403 | Classification loss: 0.06611 | Regression loss: 0.18297 | Running loss: 0.67323\n","Epoch: 0 | Iteration: 2169/2403 | Classification loss: 0.70860 | Regression loss: 0.48025 | Running loss: 0.67347\n","Epoch: 0 | Iteration: 2170/2403 | Classification loss: 0.13372 | Regression loss: 0.20732 | Running loss: 0.67331\n","Epoch: 0 | Iteration: 2171/2403 | Classification loss: 0.13340 | Regression loss: 0.17773 | Running loss: 0.67315\n","Epoch: 0 | Iteration: 2172/2403 | Classification loss: 0.16802 | Regression loss: 0.21398 | Running loss: 0.67301\n","Epoch: 0 | Iteration: 2173/2403 | Classification loss: 0.24897 | Regression loss: 0.26338 | Running loss: 0.67294\n","Epoch: 0 | Iteration: 2174/2403 | Classification loss: 0.16925 | Regression loss: 0.19427 | Running loss: 0.67280\n","Epoch: 0 | Iteration: 2175/2403 | Classification loss: 0.11585 | Regression loss: 0.18745 | Running loss: 0.67263\n","Epoch: 0 | Iteration: 2176/2403 | Classification loss: 0.22454 | Regression loss: 0.21104 | Running loss: 0.67252\n","Epoch: 0 | Iteration: 2177/2403 | Classification loss: 0.20629 | Regression loss: 0.26928 | Running loss: 0.67243\n","Epoch: 0 | Iteration: 2178/2403 | Classification loss: 0.15436 | Regression loss: 0.20663 | Running loss: 0.67228\n","Epoch: 0 | Iteration: 2179/2403 | Classification loss: 0.33030 | Regression loss: 0.24453 | Running loss: 0.67224\n","Epoch: 0 | Iteration: 2180/2403 | Classification loss: 0.10305 | Regression loss: 0.25402 | Running loss: 0.67210\n","Epoch: 0 | Iteration: 2181/2403 | Classification loss: 0.28461 | Regression loss: 0.23498 | Running loss: 0.67203\n","Epoch: 0 | Iteration: 2182/2403 | Classification loss: 0.29844 | Regression loss: 0.35784 | Running loss: 0.67202\n","Epoch: 0 | Iteration: 2183/2403 | Classification loss: 0.71536 | Regression loss: 0.32011 | Running loss: 0.67218\n","Epoch: 0 | Iteration: 2184/2403 | Classification loss: 0.17988 | Regression loss: 0.20992 | Running loss: 0.67206\n","Epoch: 0 | Iteration: 2185/2403 | Classification loss: 0.25991 | Regression loss: 0.31139 | Running loss: 0.67201\n","Epoch: 0 | Iteration: 2186/2403 | Classification loss: 0.31795 | Regression loss: 0.28200 | Running loss: 0.67198\n","Epoch: 0 | Iteration: 2187/2403 | Classification loss: 0.34523 | Regression loss: 0.37078 | Running loss: 0.67200\n","Epoch: 0 | Iteration: 2188/2403 | Classification loss: 0.29637 | Regression loss: 0.19692 | Running loss: 0.67191\n","Epoch: 0 | Iteration: 2189/2403 | Classification loss: 0.18917 | Regression loss: 0.22119 | Running loss: 0.67180\n","Epoch: 0 | Iteration: 2190/2403 | Classification loss: 0.14030 | Regression loss: 0.21019 | Running loss: 0.67165\n","Epoch: 0 | Iteration: 2191/2403 | Classification loss: 0.32391 | Regression loss: 0.29579 | Running loss: 0.67162\n","Epoch: 0 | Iteration: 2192/2403 | Classification loss: 0.14287 | Regression loss: 0.24445 | Running loss: 0.67150\n","Epoch: 0 | Iteration: 2193/2403 | Classification loss: 0.35057 | Regression loss: 0.22669 | Running loss: 0.67145\n","Epoch: 0 | Iteration: 2194/2403 | Classification loss: 0.91905 | Regression loss: 0.40533 | Running loss: 0.67175\n","Epoch: 0 | Iteration: 2195/2403 | Classification loss: 0.04339 | Regression loss: 0.16764 | Running loss: 0.67154\n","Epoch: 0 | Iteration: 2196/2403 | Classification loss: 0.31791 | Regression loss: 0.31806 | Running loss: 0.67152\n","Epoch: 0 | Iteration: 2197/2403 | Classification loss: 1.18207 | Regression loss: 0.23735 | Running loss: 0.67186\n","Epoch: 0 | Iteration: 2198/2403 | Classification loss: 0.54859 | Regression loss: 0.58614 | Running loss: 0.67207\n","Epoch: 0 | Iteration: 2199/2403 | Classification loss: 0.46970 | Regression loss: 0.32298 | Running loss: 0.67213\n","Epoch: 0 | Iteration: 2200/2403 | Classification loss: 0.39907 | Regression loss: 0.29140 | Running loss: 0.67214\n","Epoch: 0 | Iteration: 2201/2403 | Classification loss: 0.45585 | Regression loss: 0.24830 | Running loss: 0.67215\n","Epoch: 0 | Iteration: 2202/2403 | Classification loss: 0.30948 | Regression loss: 0.23782 | Running loss: 0.67210\n","Epoch: 0 | Iteration: 2203/2403 | Classification loss: 0.33290 | Regression loss: 0.26549 | Running loss: 0.67206\n","Epoch: 0 | Iteration: 2204/2403 | Classification loss: 0.32810 | Regression loss: 0.29142 | Running loss: 0.67204\n","Epoch: 0 | Iteration: 2205/2403 | Classification loss: 0.14358 | Regression loss: 0.15854 | Running loss: 0.67187\n","Epoch: 0 | Iteration: 2206/2403 | Classification loss: 0.29729 | Regression loss: 0.29410 | Running loss: 0.67183\n","Epoch: 0 | Iteration: 2207/2403 | Classification loss: 0.22829 | Regression loss: 0.16067 | Running loss: 0.67171\n","Epoch: 0 | Iteration: 2208/2403 | Classification loss: 0.83177 | Regression loss: 0.26644 | Running loss: 0.67190\n","Epoch: 0 | Iteration: 2209/2403 | Classification loss: 1.73091 | Regression loss: 0.37082 | Running loss: 0.67255\n","Epoch: 0 | Iteration: 2210/2403 | Classification loss: 0.29722 | Regression loss: 0.17089 | Running loss: 0.67245\n","Epoch: 0 | Iteration: 2211/2403 | Classification loss: 0.32804 | Regression loss: 0.23174 | Running loss: 0.67240\n","Epoch: 0 | Iteration: 2212/2403 | Classification loss: 0.16494 | Regression loss: 0.28388 | Running loss: 0.67230\n","Epoch: 0 | Iteration: 2213/2403 | Classification loss: 0.34577 | Regression loss: 0.32218 | Running loss: 0.67230\n","Epoch: 0 | Iteration: 2214/2403 | Classification loss: 0.62317 | Regression loss: 0.42854 | Running loss: 0.67247\n","Epoch: 0 | Iteration: 2215/2403 | Classification loss: 0.16788 | Regression loss: 0.24582 | Running loss: 0.67235\n","Epoch: 0 | Iteration: 2216/2403 | Classification loss: 0.10688 | Regression loss: 0.15072 | Running loss: 0.67217\n","Epoch: 0 | Iteration: 2217/2403 | Classification loss: 0.14211 | Regression loss: 0.20029 | Running loss: 0.67202\n","Epoch: 0 | Iteration: 2218/2403 | Classification loss: 0.09372 | Regression loss: 0.19943 | Running loss: 0.67185\n","Epoch: 0 | Iteration: 2219/2403 | Classification loss: 0.24343 | Regression loss: 0.24864 | Running loss: 0.67177\n","Epoch: 0 | Iteration: 2220/2403 | Classification loss: 0.05771 | Regression loss: 0.17005 | Running loss: 0.67157\n","Epoch: 0 | Iteration: 2221/2403 | Classification loss: 0.28360 | Regression loss: 0.34283 | Running loss: 0.67155\n","Epoch: 0 | Iteration: 2222/2403 | Classification loss: 0.09295 | Regression loss: 0.19057 | Running loss: 0.67137\n","Epoch: 0 | Iteration: 2223/2403 | Classification loss: 0.07257 | Regression loss: 0.18238 | Running loss: 0.67118\n","Epoch: 0 | Iteration: 2224/2403 | Classification loss: 0.29941 | Regression loss: 0.25463 | Running loss: 0.67113\n","Epoch: 0 | Iteration: 2225/2403 | Classification loss: 0.06543 | Regression loss: 0.16506 | Running loss: 0.67093\n","Epoch: 0 | Iteration: 2226/2403 | Classification loss: 0.21961 | Regression loss: 0.29223 | Running loss: 0.67086\n","Epoch: 0 | Iteration: 2227/2403 | Classification loss: 0.26769 | Regression loss: 0.29306 | Running loss: 0.67081\n","Epoch: 0 | Iteration: 2228/2403 | Classification loss: 0.33616 | Regression loss: 0.37229 | Running loss: 0.67083\n","Epoch: 0 | Iteration: 2229/2403 | Classification loss: 0.31866 | Regression loss: 0.33278 | Running loss: 0.67082\n","Epoch: 0 | Iteration: 2230/2403 | Classification loss: 0.35816 | Regression loss: 0.34703 | Running loss: 0.67084\n","Epoch: 0 | Iteration: 2231/2403 | Classification loss: 0.12391 | Regression loss: 0.25402 | Running loss: 0.67071\n","Epoch: 0 | Iteration: 2232/2403 | Classification loss: 0.05377 | Regression loss: 0.16635 | Running loss: 0.67050\n","Epoch: 0 | Iteration: 2233/2403 | Classification loss: 0.15426 | Regression loss: 0.28454 | Running loss: 0.67040\n","Epoch: 0 | Iteration: 2234/2403 | Classification loss: 0.16699 | Regression loss: 0.24137 | Running loss: 0.67028\n","Epoch: 0 | Iteration: 2235/2403 | Classification loss: 0.07053 | Regression loss: 0.12443 | Running loss: 0.67007\n","Epoch: 0 | Iteration: 2236/2403 | Classification loss: 0.13799 | Regression loss: 0.25205 | Running loss: 0.66994\n","Epoch: 0 | Iteration: 2237/2403 | Classification loss: 0.19814 | Regression loss: 0.13679 | Running loss: 0.66979\n","Epoch: 0 | Iteration: 2238/2403 | Classification loss: 0.37988 | Regression loss: 0.25147 | Running loss: 0.66978\n","Epoch: 0 | Iteration: 2239/2403 | Classification loss: 0.06761 | Regression loss: 0.21560 | Running loss: 0.66960\n","Epoch: 0 | Iteration: 2240/2403 | Classification loss: 0.44291 | Regression loss: 0.33166 | Running loss: 0.66965\n","Epoch: 0 | Iteration: 2241/2403 | Classification loss: 0.19053 | Regression loss: 0.19623 | Running loss: 0.66953\n","Epoch: 0 | Iteration: 2242/2403 | Classification loss: 0.33259 | Regression loss: 0.25907 | Running loss: 0.66949\n","Epoch: 0 | Iteration: 2243/2403 | Classification loss: 0.21153 | Regression loss: 0.19835 | Running loss: 0.66937\n","Epoch: 0 | Iteration: 2244/2403 | Classification loss: 0.79387 | Regression loss: 0.26064 | Running loss: 0.66955\n","Epoch: 0 | Iteration: 2245/2403 | Classification loss: 0.14467 | Regression loss: 0.22119 | Running loss: 0.66941\n","Epoch: 0 | Iteration: 2246/2403 | Classification loss: 0.15436 | Regression loss: 0.23358 | Running loss: 0.66929\n","Epoch: 0 | Iteration: 2247/2403 | Classification loss: 0.19557 | Regression loss: 0.32515 | Running loss: 0.66922\n","Epoch: 0 | Iteration: 2248/2403 | Classification loss: 0.07755 | Regression loss: 0.15798 | Running loss: 0.66903\n","Epoch: 0 | Iteration: 2249/2403 | Classification loss: 0.20324 | Regression loss: 0.27548 | Running loss: 0.66894\n","Epoch: 0 | Iteration: 2250/2403 | Classification loss: 0.09483 | Regression loss: 0.20496 | Running loss: 0.66878\n","Epoch: 0 | Iteration: 2251/2403 | Classification loss: 0.16761 | Regression loss: 0.15468 | Running loss: 0.66862\n","Epoch: 0 | Iteration: 2252/2403 | Classification loss: 0.40778 | Regression loss: 0.32406 | Running loss: 0.66865\n","Epoch: 0 | Iteration: 2253/2403 | Classification loss: 0.08796 | Regression loss: 0.19815 | Running loss: 0.66848\n","Epoch: 0 | Iteration: 2254/2403 | Classification loss: 0.09242 | Regression loss: 0.18357 | Running loss: 0.66831\n","Epoch: 0 | Iteration: 2255/2403 | Classification loss: 0.13200 | Regression loss: 0.20008 | Running loss: 0.66816\n","Epoch: 0 | Iteration: 2256/2403 | Classification loss: 0.12327 | Regression loss: 0.22629 | Running loss: 0.66802\n","Epoch: 0 | Iteration: 2257/2403 | Classification loss: 0.14574 | Regression loss: 0.20488 | Running loss: 0.66788\n","Epoch: 0 | Iteration: 2258/2403 | Classification loss: 0.18974 | Regression loss: 0.17205 | Running loss: 0.66774\n","Epoch: 0 | Iteration: 2259/2403 | Classification loss: 0.28306 | Regression loss: 0.27805 | Running loss: 0.66769\n","Epoch: 0 | Iteration: 2260/2403 | Classification loss: 0.16524 | Regression loss: 0.22000 | Running loss: 0.66757\n","Epoch: 0 | Iteration: 2261/2403 | Classification loss: 0.21519 | Regression loss: 0.20947 | Running loss: 0.66746\n","Epoch: 0 | Iteration: 2262/2403 | Classification loss: 0.34969 | Regression loss: 0.27178 | Running loss: 0.66744\n","Epoch: 0 | Iteration: 2263/2403 | Classification loss: 0.35202 | Regression loss: 0.31314 | Running loss: 0.66744\n","Epoch: 0 | Iteration: 2264/2403 | Classification loss: 0.08377 | Regression loss: 0.20108 | Running loss: 0.66727\n","Epoch: 0 | Iteration: 2265/2403 | Classification loss: 0.42554 | Regression loss: 0.30195 | Running loss: 0.66730\n","Epoch: 0 | Iteration: 2266/2403 | Classification loss: 0.08182 | Regression loss: 0.16998 | Running loss: 0.66712\n","Epoch: 0 | Iteration: 2267/2403 | Classification loss: 0.21122 | Regression loss: 0.30740 | Running loss: 0.66705\n","Epoch: 0 | Iteration: 2268/2403 | Classification loss: 0.44523 | Regression loss: 0.30906 | Running loss: 0.66709\n","Epoch: 0 | Iteration: 2269/2403 | Classification loss: 0.11411 | Regression loss: 0.19736 | Running loss: 0.66693\n","Epoch: 0 | Iteration: 2270/2403 | Classification loss: 1.14604 | Regression loss: 0.44866 | Running loss: 0.66734\n","Epoch: 0 | Iteration: 2271/2403 | Classification loss: 0.05499 | Regression loss: 0.17318 | Running loss: 0.66715\n","Epoch: 0 | Iteration: 2272/2403 | Classification loss: 0.16473 | Regression loss: 0.23137 | Running loss: 0.66703\n","Epoch: 0 | Iteration: 2273/2403 | Classification loss: 0.12486 | Regression loss: 0.17398 | Running loss: 0.66687\n","Epoch: 0 | Iteration: 2274/2403 | Classification loss: 0.31563 | Regression loss: 0.51655 | Running loss: 0.66694\n","Epoch: 0 | Iteration: 2275/2403 | Classification loss: 0.12062 | Regression loss: 0.18032 | Running loss: 0.66678\n","Epoch: 0 | Iteration: 2276/2403 | Classification loss: 0.11658 | Regression loss: 0.18217 | Running loss: 0.66662\n","Epoch: 0 | Iteration: 2277/2403 | Classification loss: 0.41598 | Regression loss: 0.32633 | Running loss: 0.66665\n","Epoch: 0 | Iteration: 2278/2403 | Classification loss: 0.12021 | Regression loss: 0.14089 | Running loss: 0.66647\n","Epoch: 0 | Iteration: 2279/2403 | Classification loss: 0.18495 | Regression loss: 0.32625 | Running loss: 0.66640\n","Epoch: 0 | Iteration: 2280/2403 | Classification loss: 0.32341 | Regression loss: 0.23797 | Running loss: 0.66636\n","Epoch: 0 | Iteration: 2281/2403 | Classification loss: 0.13726 | Regression loss: 0.20779 | Running loss: 0.66622\n","Epoch: 0 | Iteration: 2282/2403 | Classification loss: 0.09470 | Regression loss: 0.19728 | Running loss: 0.66605\n","Epoch: 0 | Iteration: 2283/2403 | Classification loss: 0.34387 | Regression loss: 0.15252 | Running loss: 0.66598\n","Epoch: 0 | Iteration: 2284/2403 | Classification loss: 0.17011 | Regression loss: 0.22052 | Running loss: 0.66586\n","Epoch: 0 | Iteration: 2285/2403 | Classification loss: 0.33422 | Regression loss: 0.28833 | Running loss: 0.66584\n","Epoch: 0 | Iteration: 2286/2403 | Classification loss: 0.28522 | Regression loss: 0.20248 | Running loss: 0.66576\n","Epoch: 0 | Iteration: 2287/2403 | Classification loss: 0.19299 | Regression loss: 0.16802 | Running loss: 0.66563\n","Epoch: 0 | Iteration: 2288/2403 | Classification loss: 0.07852 | Regression loss: 0.19595 | Running loss: 0.66546\n","Epoch: 0 | Iteration: 2289/2403 | Classification loss: 0.19699 | Regression loss: 0.24309 | Running loss: 0.66536\n","Epoch: 0 | Iteration: 2290/2403 | Classification loss: 0.30236 | Regression loss: 0.30083 | Running loss: 0.66533\n","Epoch: 0 | Iteration: 2291/2403 | Classification loss: 0.07356 | Regression loss: 0.16468 | Running loss: 0.66514\n","Epoch: 0 | Iteration: 2292/2403 | Classification loss: 0.79622 | Regression loss: 0.32209 | Running loss: 0.66534\n","Epoch: 0 | Iteration: 2293/2403 | Classification loss: 0.47036 | Regression loss: 0.74462 | Running loss: 0.66558\n","Epoch: 0 | Iteration: 2294/2403 | Classification loss: 0.08180 | Regression loss: 0.16019 | Running loss: 0.66540\n","Epoch: 0 | Iteration: 2295/2403 | Classification loss: 0.08315 | Regression loss: 0.20051 | Running loss: 0.66523\n","Epoch: 0 | Iteration: 2296/2403 | Classification loss: 0.18149 | Regression loss: 0.25620 | Running loss: 0.66513\n","Epoch: 0 | Iteration: 2297/2403 | Classification loss: 0.33853 | Regression loss: 0.28384 | Running loss: 0.66511\n","Epoch: 0 | Iteration: 2298/2403 | Classification loss: 0.12229 | Regression loss: 0.20614 | Running loss: 0.66497\n","Epoch: 0 | Iteration: 2299/2403 | Classification loss: 0.80520 | Regression loss: 0.46571 | Running loss: 0.66523\n","Epoch: 0 | Iteration: 2300/2403 | Classification loss: 0.14286 | Regression loss: 0.21576 | Running loss: 0.66510\n","Epoch: 0 | Iteration: 2301/2403 | Classification loss: 0.39284 | Regression loss: 0.36946 | Running loss: 0.66514\n","Epoch: 0 | Iteration: 2302/2403 | Classification loss: 0.77939 | Regression loss: 0.53521 | Running loss: 0.66542\n","Epoch: 0 | Iteration: 2303/2403 | Classification loss: 0.32779 | Regression loss: 0.22403 | Running loss: 0.66537\n","Epoch: 0 | Iteration: 2304/2403 | Classification loss: 0.24634 | Regression loss: 0.18565 | Running loss: 0.66527\n","Epoch: 0 | Iteration: 2305/2403 | Classification loss: 0.41736 | Regression loss: 0.23840 | Running loss: 0.66527\n","Epoch: 0 | Iteration: 2306/2403 | Classification loss: 0.14597 | Regression loss: 0.16749 | Running loss: 0.66511\n","Epoch: 0 | Iteration: 2307/2403 | Classification loss: 0.08764 | Regression loss: 0.15399 | Running loss: 0.66493\n","Epoch: 0 | Iteration: 2308/2403 | Classification loss: 0.18050 | Regression loss: 0.18716 | Running loss: 0.66480\n","Epoch: 0 | Iteration: 2309/2403 | Classification loss: 0.19251 | Regression loss: 0.30585 | Running loss: 0.66473\n","Epoch: 0 | Iteration: 2310/2403 | Classification loss: 0.21209 | Regression loss: 0.25208 | Running loss: 0.66464\n","Epoch: 0 | Iteration: 2311/2403 | Classification loss: 0.33667 | Regression loss: 0.25065 | Running loss: 0.66461\n","Epoch: 0 | Iteration: 2312/2403 | Classification loss: 0.27083 | Regression loss: 0.33524 | Running loss: 0.66458\n","Epoch: 0 | Iteration: 2313/2403 | Classification loss: 0.72440 | Regression loss: 0.39425 | Running loss: 0.66478\n","Epoch: 0 | Iteration: 2314/2403 | Classification loss: 0.53146 | Regression loss: 0.41865 | Running loss: 0.66490\n","Epoch: 0 | Iteration: 2315/2403 | Classification loss: 0.62350 | Regression loss: 0.33318 | Running loss: 0.66503\n","Epoch: 0 | Iteration: 2316/2403 | Classification loss: 0.33332 | Regression loss: 0.35605 | Running loss: 0.66504\n","Epoch: 0 | Iteration: 2317/2403 | Classification loss: 0.53896 | Regression loss: 0.44511 | Running loss: 0.66518\n","Epoch: 0 | Iteration: 2318/2403 | Classification loss: 0.29087 | Regression loss: 0.33661 | Running loss: 0.66516\n","Epoch: 0 | Iteration: 2319/2403 | Classification loss: 0.28251 | Regression loss: 0.23201 | Running loss: 0.66510\n","Epoch: 0 | Iteration: 2320/2403 | Classification loss: 0.39059 | Regression loss: 0.29071 | Running loss: 0.66510\n","Epoch: 0 | Iteration: 2321/2403 | Classification loss: 0.26700 | Regression loss: 0.23333 | Running loss: 0.66503\n","Epoch: 0 | Iteration: 2322/2403 | Classification loss: 0.25189 | Regression loss: 0.27974 | Running loss: 0.66497\n","Epoch: 0 | Iteration: 2323/2403 | Classification loss: 0.19997 | Regression loss: 0.17173 | Running loss: 0.66485\n","Epoch: 0 | Iteration: 2324/2403 | Classification loss: 0.10206 | Regression loss: 0.14434 | Running loss: 0.66467\n","Epoch: 0 | Iteration: 2325/2403 | Classification loss: 0.38451 | Regression loss: 0.29370 | Running loss: 0.66467\n","Epoch: 0 | Iteration: 2326/2403 | Classification loss: 0.84034 | Regression loss: 0.31004 | Running loss: 0.66488\n","Epoch: 0 | Iteration: 2327/2403 | Classification loss: 0.18415 | Regression loss: 0.22555 | Running loss: 0.66477\n","Epoch: 0 | Iteration: 2328/2403 | Classification loss: 0.21671 | Regression loss: 0.21629 | Running loss: 0.66467\n","Epoch: 0 | Iteration: 2329/2403 | Classification loss: 0.40001 | Regression loss: 0.27709 | Running loss: 0.66468\n","Epoch: 0 | Iteration: 2330/2403 | Classification loss: 0.12822 | Regression loss: 0.19121 | Running loss: 0.66453\n","Epoch: 0 | Iteration: 2331/2403 | Classification loss: 0.22311 | Regression loss: 0.20060 | Running loss: 0.66443\n","Epoch: 0 | Iteration: 2332/2403 | Classification loss: 0.27812 | Regression loss: 0.29419 | Running loss: 0.66439\n","Epoch: 0 | Iteration: 2333/2403 | Classification loss: 0.11316 | Regression loss: 0.25687 | Running loss: 0.66426\n","Epoch: 0 | Iteration: 2334/2403 | Classification loss: 0.25017 | Regression loss: 0.24786 | Running loss: 0.66419\n","Epoch: 0 | Iteration: 2335/2403 | Classification loss: 0.28082 | Regression loss: 0.28125 | Running loss: 0.66415\n","Epoch: 0 | Iteration: 2336/2403 | Classification loss: 0.36905 | Regression loss: 0.35430 | Running loss: 0.66417\n","Epoch: 0 | Iteration: 2337/2403 | Classification loss: 0.15046 | Regression loss: 0.24094 | Running loss: 0.66406\n","Epoch: 0 | Iteration: 2338/2403 | Classification loss: 0.21904 | Regression loss: 0.55263 | Running loss: 0.66410\n","Epoch: 0 | Iteration: 2339/2403 | Classification loss: 0.30594 | Regression loss: 0.27939 | Running loss: 0.66407\n","Epoch: 0 | Iteration: 2340/2403 | Classification loss: 0.50218 | Regression loss: 0.29475 | Running loss: 0.66412\n","Epoch: 0 | Iteration: 2341/2403 | Classification loss: 0.29757 | Regression loss: 0.28576 | Running loss: 0.66409\n","Epoch: 0 | Iteration: 2342/2403 | Classification loss: 0.52338 | Regression loss: 0.27445 | Running loss: 0.66415\n","Epoch: 0 | Iteration: 2343/2403 | Classification loss: 0.17704 | Regression loss: 0.25380 | Running loss: 0.66405\n","Epoch: 0 | Iteration: 2344/2403 | Classification loss: 0.21351 | Regression loss: 0.33321 | Running loss: 0.66400\n","Epoch: 0 | Iteration: 2345/2403 | Classification loss: 0.48487 | Regression loss: 0.46196 | Running loss: 0.66412\n","Epoch: 0 | Iteration: 2346/2403 | Classification loss: 0.45302 | Regression loss: 0.33219 | Running loss: 0.66417\n","Epoch: 0 | Iteration: 2347/2403 | Classification loss: 0.26551 | Regression loss: 0.27624 | Running loss: 0.66412\n","Epoch: 0 | Iteration: 2348/2403 | Classification loss: 0.25690 | Regression loss: 0.20551 | Running loss: 0.66403\n","Epoch: 0 | Iteration: 2349/2403 | Classification loss: 0.18168 | Regression loss: 0.16912 | Running loss: 0.66390\n","Epoch: 0 | Iteration: 2350/2403 | Classification loss: 0.12229 | Regression loss: 0.20239 | Running loss: 0.66375\n","Epoch: 0 | Iteration: 2351/2403 | Classification loss: 0.29968 | Regression loss: 0.29504 | Running loss: 0.66372\n","Epoch: 0 | Iteration: 2352/2403 | Classification loss: 0.22141 | Regression loss: 0.20577 | Running loss: 0.66362\n","Epoch: 0 | Iteration: 2353/2403 | Classification loss: 0.13890 | Regression loss: 0.20029 | Running loss: 0.66349\n","Epoch: 0 | Iteration: 2354/2403 | Classification loss: 0.13421 | Regression loss: 0.20766 | Running loss: 0.66335\n","Epoch: 0 | Iteration: 2355/2403 | Classification loss: 0.27358 | Regression loss: 0.25209 | Running loss: 0.66329\n","Epoch: 0 | Iteration: 2356/2403 | Classification loss: 0.28899 | Regression loss: 0.28316 | Running loss: 0.66325\n","Epoch: 0 | Iteration: 2357/2403 | Classification loss: 0.39449 | Regression loss: 0.29908 | Running loss: 0.66327\n","Epoch: 0 | Iteration: 2358/2403 | Classification loss: 0.40092 | Regression loss: 0.30829 | Running loss: 0.66328\n","Epoch: 0 | Iteration: 2359/2403 | Classification loss: 0.27503 | Regression loss: 0.29383 | Running loss: 0.66324\n","Epoch: 0 | Iteration: 2360/2403 | Classification loss: 0.11773 | Regression loss: 0.14081 | Running loss: 0.66307\n","Epoch: 0 | Iteration: 2361/2403 | Classification loss: 0.21751 | Regression loss: 0.30224 | Running loss: 0.66301\n","Epoch: 0 | Iteration: 2362/2403 | Classification loss: 0.14462 | Regression loss: 0.25305 | Running loss: 0.66290\n","Epoch: 0 | Iteration: 2363/2403 | Classification loss: 0.07868 | Regression loss: 0.17142 | Running loss: 0.66273\n","Epoch: 0 | Iteration: 2364/2403 | Classification loss: 0.17467 | Regression loss: 0.26716 | Running loss: 0.66263\n","Epoch: 0 | Iteration: 2365/2403 | Classification loss: 0.14269 | Regression loss: 0.17365 | Running loss: 0.66249\n","Epoch: 0 | Iteration: 2366/2403 | Classification loss: 0.12908 | Regression loss: 0.15233 | Running loss: 0.66232\n","Epoch: 0 | Iteration: 2367/2403 | Classification loss: 0.09929 | Regression loss: 0.19329 | Running loss: 0.66217\n","Epoch: 0 | Iteration: 2368/2403 | Classification loss: 0.39210 | Regression loss: 0.31195 | Running loss: 0.66219\n","Epoch: 0 | Iteration: 2369/2403 | Classification loss: 0.08936 | Regression loss: 0.12108 | Running loss: 0.66200\n","Epoch: 0 | Iteration: 2370/2403 | Classification loss: 0.19601 | Regression loss: 0.28532 | Running loss: 0.66192\n","Epoch: 0 | Iteration: 2371/2403 | Classification loss: 0.08680 | Regression loss: 0.15627 | Running loss: 0.66174\n","Epoch: 0 | Iteration: 2372/2403 | Classification loss: 0.12985 | Regression loss: 0.20956 | Running loss: 0.66161\n","Epoch: 0 | Iteration: 2373/2403 | Classification loss: 0.05678 | Regression loss: 0.10448 | Running loss: 0.66140\n","Epoch: 0 | Iteration: 2374/2403 | Classification loss: 0.18976 | Regression loss: 0.20680 | Running loss: 0.66128\n","Epoch: 0 | Iteration: 2375/2403 | Classification loss: 0.10973 | Regression loss: 0.26153 | Running loss: 0.66116\n","Epoch: 0 | Iteration: 2376/2403 | Classification loss: 0.05233 | Regression loss: 0.17387 | Running loss: 0.66098\n","Epoch: 0 | Iteration: 2377/2403 | Classification loss: 0.54872 | Regression loss: 0.19237 | Running loss: 0.66101\n","Epoch: 0 | Iteration: 2378/2403 | Classification loss: 0.05933 | Regression loss: 0.18150 | Running loss: 0.66084\n","Epoch: 0 | Iteration: 2379/2403 | Classification loss: 0.15479 | Regression loss: 0.24060 | Running loss: 0.66072\n","Epoch: 0 | Iteration: 2380/2403 | Classification loss: 0.47345 | Regression loss: 0.29650 | Running loss: 0.66077\n","Epoch: 0 | Iteration: 2381/2403 | Classification loss: 0.13503 | Regression loss: 0.20600 | Running loss: 0.66064\n","Epoch: 0 | Iteration: 2382/2403 | Classification loss: 0.26014 | Regression loss: 0.25742 | Running loss: 0.66058\n","Epoch: 0 | Iteration: 2383/2403 | Classification loss: 0.35970 | Regression loss: 0.32731 | Running loss: 0.66059\n","Epoch: 0 | Iteration: 2384/2403 | Classification loss: 0.06513 | Regression loss: 0.13886 | Running loss: 0.66040\n","Epoch: 0 | Iteration: 2385/2403 | Classification loss: 0.42428 | Regression loss: 0.26083 | Running loss: 0.66041\n","Epoch: 0 | Iteration: 2386/2403 | Classification loss: 0.22093 | Regression loss: 0.25376 | Running loss: 0.66033\n","Epoch: 0 | Iteration: 2387/2403 | Classification loss: 0.33099 | Regression loss: 0.28195 | Running loss: 0.66031\n","Epoch: 0 | Iteration: 2388/2403 | Classification loss: 0.09772 | Regression loss: 0.15718 | Running loss: 0.66014\n","Epoch: 0 | Iteration: 2389/2403 | Classification loss: 0.50996 | Regression loss: 0.34663 | Running loss: 0.66022\n","Epoch: 0 | Iteration: 2390/2403 | Classification loss: 0.27811 | Regression loss: 0.18850 | Running loss: 0.66014\n","Epoch: 0 | Iteration: 2391/2403 | Classification loss: 0.14168 | Regression loss: 0.19799 | Running loss: 0.66001\n","Epoch: 0 | Iteration: 2392/2403 | Classification loss: 0.30199 | Regression loss: 0.34261 | Running loss: 0.66000\n","Epoch: 0 | Iteration: 2393/2403 | Classification loss: 0.48314 | Regression loss: 0.31651 | Running loss: 0.66006\n","Epoch: 0 | Iteration: 2394/2403 | Classification loss: 0.16568 | Regression loss: 0.18633 | Running loss: 0.65993\n","Epoch: 0 | Iteration: 2395/2403 | Classification loss: 0.18798 | Regression loss: 0.24642 | Running loss: 0.65983\n","Epoch: 0 | Iteration: 2396/2403 | Classification loss: 0.20355 | Regression loss: 0.23417 | Running loss: 0.65974\n","Epoch: 0 | Iteration: 2397/2403 | Classification loss: 0.28769 | Regression loss: 0.25745 | Running loss: 0.65969\n","Epoch: 0 | Iteration: 2398/2403 | Classification loss: 0.11569 | Regression loss: 0.17509 | Running loss: 0.65954\n","Epoch: 0 | Iteration: 2399/2403 | Classification loss: 0.10920 | Regression loss: 0.21263 | Running loss: 0.65940\n","Epoch: 0 | Iteration: 2400/2403 | Classification loss: 0.26990 | Regression loss: 0.35132 | Running loss: 0.65938\n","Epoch: 0 | Iteration: 2401/2403 | Classification loss: 0.25221 | Regression loss: 0.23535 | Running loss: 0.65931\n","Epoch: 0 | Iteration: 2402/2403 | Classification loss: 0.09490 | Regression loss: 0.17910 | Running loss: 0.65915\n","Epoch: 0 | Iteration: 2403/2403 | Classification loss: 0.12792 | Regression loss: 0.21469 | Running loss: 0.65902\n","\n"," Total Time - 16154\n","\n","Epoch - 1 Started\n","Epoch: 1 | Iteration: 2404/2403 | Classification loss: 0.38778 | Regression loss: 0.35464 | Running loss: 0.74242\n","Epoch: 1 | Iteration: 2405/2403 | Classification loss: 0.09544 | Regression loss: 0.16441 | Running loss: 0.50113\n","Epoch: 1 | Iteration: 2406/2403 | Classification loss: 0.06765 | Regression loss: 0.16992 | Running loss: 0.41328\n","Epoch: 1 | Iteration: 2407/2403 | Classification loss: 0.17706 | Regression loss: 0.23097 | Running loss: 0.41197\n","Epoch: 1 | Iteration: 2408/2403 | Classification loss: 0.09198 | Regression loss: 0.21156 | Running loss: 0.39028\n","Epoch: 1 | Iteration: 2409/2403 | Classification loss: 0.19957 | Regression loss: 0.23537 | Running loss: 0.39772\n","Epoch: 1 | Iteration: 2410/2403 | Classification loss: 0.07723 | Regression loss: 0.17487 | Running loss: 0.37692\n","Epoch: 1 | Iteration: 2411/2403 | Classification loss: 0.28568 | Regression loss: 0.17275 | Running loss: 0.38711\n","Epoch: 1 | Iteration: 2412/2403 | Classification loss: 0.18142 | Regression loss: 0.22130 | Running loss: 0.38884\n","Epoch: 1 | Iteration: 2413/2403 | Classification loss: 0.05579 | Regression loss: 0.09775 | Running loss: 0.36531\n","Epoch: 1 | Iteration: 2414/2403 | Classification loss: 0.10199 | Regression loss: 0.16488 | Running loss: 0.35637\n","Epoch: 1 | Iteration: 2415/2403 | Classification loss: 0.22518 | Regression loss: 0.45883 | Running loss: 0.38367\n","Epoch: 1 | Iteration: 2416/2403 | Classification loss: 0.08010 | Regression loss: 0.12488 | Running loss: 0.36992\n","Epoch: 1 | Iteration: 2417/2403 | Classification loss: 0.23861 | Regression loss: 0.21910 | Running loss: 0.37619\n","Epoch: 1 | Iteration: 2418/2403 | Classification loss: 0.24418 | Regression loss: 0.30133 | Running loss: 0.38748\n","Epoch: 1 | Iteration: 2419/2403 | Classification loss: 0.09902 | Regression loss: 0.17315 | Running loss: 0.38028\n","Epoch: 1 | Iteration: 2420/2403 | Classification loss: 0.21271 | Regression loss: 0.18860 | Running loss: 0.38151\n","Epoch: 1 | Iteration: 2421/2403 | Classification loss: 0.38975 | Regression loss: 0.41946 | Running loss: 0.40527\n","Epoch: 1 | Iteration: 2422/2403 | Classification loss: 0.17738 | Regression loss: 0.22381 | Running loss: 0.40506\n","Epoch: 1 | Iteration: 2423/2403 | Classification loss: 0.23227 | Regression loss: 0.28387 | Running loss: 0.41061\n","Epoch: 1 | Iteration: 2424/2403 | Classification loss: 0.12413 | Regression loss: 0.19980 | Running loss: 0.40648\n","Epoch: 1 | Iteration: 2425/2403 | Classification loss: 0.18983 | Regression loss: 0.22590 | Running loss: 0.40690\n","Epoch: 1 | Iteration: 2426/2403 | Classification loss: 0.24550 | Regression loss: 0.34751 | Running loss: 0.41500\n","Epoch: 1 | Iteration: 2427/2403 | Classification loss: 0.11035 | Regression loss: 0.16668 | Running loss: 0.40925\n","Epoch: 1 | Iteration: 2428/2403 | Classification loss: 0.14987 | Regression loss: 0.19053 | Running loss: 0.40649\n","Epoch: 1 | Iteration: 2429/2403 | Classification loss: 0.07924 | Regression loss: 0.16871 | Running loss: 0.40040\n","Epoch: 1 | Iteration: 2430/2403 | Classification loss: 0.28069 | Regression loss: 0.29907 | Running loss: 0.40704\n","Epoch: 1 | Iteration: 2431/2403 | Classification loss: 0.20540 | Regression loss: 0.25766 | Running loss: 0.40904\n","Epoch: 1 | Iteration: 2432/2403 | Classification loss: 0.13218 | Regression loss: 0.27825 | Running loss: 0.40909\n","Epoch: 1 | Iteration: 2433/2403 | Classification loss: 0.09002 | Regression loss: 0.16511 | Running loss: 0.40396\n","Epoch: 1 | Iteration: 2434/2403 | Classification loss: 0.27770 | Regression loss: 0.24914 | Running loss: 0.40792\n","Epoch: 1 | Iteration: 2435/2403 | Classification loss: 0.40375 | Regression loss: 0.51650 | Running loss: 0.42393\n","Epoch: 1 | Iteration: 2436/2403 | Classification loss: 0.05305 | Regression loss: 0.16961 | Running loss: 0.41783\n","Epoch: 1 | Iteration: 2437/2403 | Classification loss: 0.45422 | Regression loss: 0.33093 | Running loss: 0.42863\n","Epoch: 1 | Iteration: 2438/2403 | Classification loss: 0.08034 | Regression loss: 0.21579 | Running loss: 0.42485\n","Epoch: 1 | Iteration: 2439/2403 | Classification loss: 0.07468 | Regression loss: 0.19179 | Running loss: 0.42045\n","Epoch: 1 | Iteration: 2440/2403 | Classification loss: 0.28472 | Regression loss: 0.25944 | Running loss: 0.42379\n","Epoch: 1 | Iteration: 2441/2403 | Classification loss: 0.07703 | Regression loss: 0.16792 | Running loss: 0.41909\n","Epoch: 1 | Iteration: 2442/2403 | Classification loss: 0.16159 | Regression loss: 0.17050 | Running loss: 0.41686\n","Epoch: 1 | Iteration: 2443/2403 | Classification loss: 0.13845 | Regression loss: 0.20574 | Running loss: 0.41504\n","Epoch: 1 | Iteration: 2444/2403 | Classification loss: 0.05198 | Regression loss: 0.15783 | Running loss: 0.41003\n","Epoch: 1 | Iteration: 2445/2403 | Classification loss: 0.05575 | Regression loss: 0.23022 | Running loss: 0.40708\n","Epoch: 1 | Iteration: 2446/2403 | Classification loss: 0.24640 | Regression loss: 0.13807 | Running loss: 0.40655\n","Epoch: 1 | Iteration: 2447/2403 | Classification loss: 0.10600 | Regression loss: 0.17752 | Running loss: 0.40376\n","Epoch: 1 | Iteration: 2448/2403 | Classification loss: 0.37923 | Regression loss: 0.27014 | Running loss: 0.40921\n","Epoch: 1 | Iteration: 2449/2403 | Classification loss: 0.09605 | Regression loss: 0.24863 | Running loss: 0.40781\n","Epoch: 1 | Iteration: 2450/2403 | Classification loss: 0.21261 | Regression loss: 0.24142 | Running loss: 0.40880\n","Epoch: 1 | Iteration: 2451/2403 | Classification loss: 0.04608 | Regression loss: 0.14099 | Running loss: 0.40418\n","Epoch: 1 | Iteration: 2452/2403 | Classification loss: 0.07792 | Regression loss: 0.14779 | Running loss: 0.40053\n","Epoch: 1 | Iteration: 2453/2403 | Classification loss: 0.46797 | Regression loss: 0.65734 | Running loss: 0.41503\n","Epoch: 1 | Iteration: 2454/2403 | Classification loss: 0.22449 | Regression loss: 0.19200 | Running loss: 0.41506\n","Epoch: 1 | Iteration: 2455/2403 | Classification loss: 0.16541 | Regression loss: 0.20248 | Running loss: 0.41415\n","Epoch: 1 | Iteration: 2456/2403 | Classification loss: 0.05235 | Regression loss: 0.15888 | Running loss: 0.41032\n","Epoch: 1 | Iteration: 2457/2403 | Classification loss: 0.20075 | Regression loss: 0.14404 | Running loss: 0.40911\n","Epoch: 1 | Iteration: 2458/2403 | Classification loss: 0.11422 | Regression loss: 0.21615 | Running loss: 0.40768\n","Epoch: 1 | Iteration: 2459/2403 | Classification loss: 0.17801 | Regression loss: 0.26581 | Running loss: 0.40832\n","Epoch: 1 | Iteration: 2460/2403 | Classification loss: 0.09166 | Regression loss: 0.16743 | Running loss: 0.40570\n","Epoch: 1 | Iteration: 2461/2403 | Classification loss: 0.28223 | Regression loss: 0.19698 | Running loss: 0.40697\n","Epoch: 1 | Iteration: 2462/2403 | Classification loss: 0.11085 | Regression loss: 0.20804 | Running loss: 0.40548\n","Epoch: 1 | Iteration: 2463/2403 | Classification loss: 0.16869 | Regression loss: 0.28117 | Running loss: 0.40622\n","Epoch: 1 | Iteration: 2464/2403 | Classification loss: 0.22368 | Regression loss: 0.18654 | Running loss: 0.40628\n","Epoch: 1 | Iteration: 2465/2403 | Classification loss: 0.07437 | Regression loss: 0.14064 | Running loss: 0.40320\n","Epoch: 1 | Iteration: 2466/2403 | Classification loss: 0.22644 | Regression loss: 0.37557 | Running loss: 0.40635\n","Epoch: 1 | Iteration: 2467/2403 | Classification loss: 0.16803 | Regression loss: 0.17924 | Running loss: 0.40543\n","Epoch: 1 | Iteration: 2468/2403 | Classification loss: 0.14021 | Regression loss: 0.23744 | Running loss: 0.40500\n","Epoch: 1 | Iteration: 2469/2403 | Classification loss: 0.30612 | Regression loss: 0.30419 | Running loss: 0.40811\n","Epoch: 1 | Iteration: 2470/2403 | Classification loss: 0.13291 | Regression loss: 0.33477 | Running loss: 0.40900\n","Epoch: 1 | Iteration: 2471/2403 | Classification loss: 0.10598 | Regression loss: 0.18054 | Running loss: 0.40720\n","Epoch: 1 | Iteration: 2472/2403 | Classification loss: 0.42125 | Regression loss: 0.25826 | Running loss: 0.41115\n","Epoch: 1 | Iteration: 2473/2403 | Classification loss: 0.07331 | Regression loss: 0.22250 | Running loss: 0.40950\n","Epoch: 1 | Iteration: 2474/2403 | Classification loss: 0.11877 | Regression loss: 0.43184 | Running loss: 0.41149\n","Epoch: 1 | Iteration: 2475/2403 | Classification loss: 0.10012 | Regression loss: 0.17383 | Running loss: 0.40958\n","Epoch: 1 | Iteration: 2476/2403 | Classification loss: 0.06342 | Regression loss: 0.17068 | Running loss: 0.40717\n","Epoch: 1 | Iteration: 2477/2403 | Classification loss: 0.14388 | Regression loss: 0.24442 | Running loss: 0.40692\n","Epoch: 1 | Iteration: 2478/2403 | Classification loss: 0.42779 | Regression loss: 0.22505 | Running loss: 0.41020\n","Epoch: 1 | Iteration: 2479/2403 | Classification loss: 0.12105 | Regression loss: 0.17251 | Running loss: 0.40866\n","Epoch: 1 | Iteration: 2480/2403 | Classification loss: 0.32631 | Regression loss: 0.19111 | Running loss: 0.41008\n","Epoch: 1 | Iteration: 2481/2403 | Classification loss: 0.18826 | Regression loss: 0.25101 | Running loss: 0.41045\n","Epoch: 1 | Iteration: 2482/2403 | Classification loss: 0.13050 | Regression loss: 0.18328 | Running loss: 0.40923\n","Epoch: 1 | Iteration: 2483/2403 | Classification loss: 0.09304 | Regression loss: 0.16545 | Running loss: 0.40734\n","Epoch: 1 | Iteration: 2484/2403 | Classification loss: 0.26430 | Regression loss: 0.37677 | Running loss: 0.41023\n","Epoch: 1 | Iteration: 2485/2403 | Classification loss: 0.19417 | Regression loss: 0.42497 | Running loss: 0.41278\n","Epoch: 1 | Iteration: 2486/2403 | Classification loss: 0.11462 | Regression loss: 0.18875 | Running loss: 0.41146\n","Epoch: 1 | Iteration: 2487/2403 | Classification loss: 0.13732 | Regression loss: 0.18184 | Running loss: 0.41036\n","Epoch: 1 | Iteration: 2488/2403 | Classification loss: 0.06902 | Regression loss: 0.17922 | Running loss: 0.40845\n","Epoch: 1 | Iteration: 2489/2403 | Classification loss: 0.29940 | Regression loss: 0.20065 | Running loss: 0.40952\n","Epoch: 1 | Iteration: 2490/2403 | Classification loss: 0.13863 | Regression loss: 0.27084 | Running loss: 0.40952\n","Epoch: 1 | Iteration: 2491/2403 | Classification loss: 0.19266 | Regression loss: 0.25473 | Running loss: 0.40995\n","Epoch: 1 | Iteration: 2492/2403 | Classification loss: 0.08272 | Regression loss: 0.19332 | Running loss: 0.40844\n","Epoch: 1 | Iteration: 2493/2403 | Classification loss: 0.18744 | Regression loss: 0.31573 | Running loss: 0.40949\n","Epoch: 1 | Iteration: 2494/2403 | Classification loss: 0.16910 | Regression loss: 0.24112 | Running loss: 0.40950\n","Epoch: 1 | Iteration: 2495/2403 | Classification loss: 0.09285 | Regression loss: 0.21315 | Running loss: 0.40838\n","Epoch: 1 | Iteration: 2496/2403 | Classification loss: 0.33144 | Regression loss: 0.24381 | Running loss: 0.41017\n","Epoch: 1 | Iteration: 2497/2403 | Classification loss: 0.29041 | Regression loss: 0.32115 | Running loss: 0.41231\n","Epoch: 1 | Iteration: 2498/2403 | Classification loss: 0.21365 | Regression loss: 0.27347 | Running loss: 0.41310\n","Epoch: 1 | Iteration: 2499/2403 | Classification loss: 0.08142 | Regression loss: 0.20390 | Running loss: 0.41177\n","Epoch: 1 | Iteration: 2500/2403 | Classification loss: 0.05926 | Regression loss: 0.16333 | Running loss: 0.40982\n","Epoch: 1 | Iteration: 2501/2403 | Classification loss: 0.30123 | Regression loss: 0.27015 | Running loss: 0.41147\n","Epoch: 1 | Iteration: 2502/2403 | Classification loss: 0.21725 | Regression loss: 0.30971 | Running loss: 0.41264\n","Epoch: 1 | Iteration: 2503/2403 | Classification loss: 0.13410 | Regression loss: 0.21050 | Running loss: 0.41196\n","Epoch: 1 | Iteration: 2504/2403 | Classification loss: 0.18449 | Regression loss: 0.21329 | Running loss: 0.41181\n","Epoch: 1 | Iteration: 2505/2403 | Classification loss: 0.49955 | Regression loss: 0.28503 | Running loss: 0.41547\n","Epoch: 1 | Iteration: 2506/2403 | Classification loss: 0.58760 | Regression loss: 0.37522 | Running loss: 0.42078\n","Epoch: 1 | Iteration: 2507/2403 | Classification loss: 0.22725 | Regression loss: 0.30098 | Running loss: 0.42182\n","Epoch: 1 | Iteration: 2508/2403 | Classification loss: 0.24063 | Regression loss: 0.27157 | Running loss: 0.42268\n","Epoch: 1 | Iteration: 2509/2403 | Classification loss: 0.14918 | Regression loss: 0.27719 | Running loss: 0.42271\n","Epoch: 1 | Iteration: 2510/2403 | Classification loss: 0.11818 | Regression loss: 0.18380 | Running loss: 0.42158\n","Epoch: 1 | Iteration: 2511/2403 | Classification loss: 0.22714 | Regression loss: 0.21966 | Running loss: 0.42182\n","Epoch: 1 | Iteration: 2512/2403 | Classification loss: 0.10937 | Regression loss: 0.23029 | Running loss: 0.42106\n","Epoch: 1 | Iteration: 2513/2403 | Classification loss: 0.64496 | Regression loss: 0.43857 | Running loss: 0.42709\n","Epoch: 1 | Iteration: 2514/2403 | Classification loss: 0.30449 | Regression loss: 0.20270 | Running loss: 0.42781\n","Epoch: 1 | Iteration: 2515/2403 | Classification loss: 0.60742 | Regression loss: 0.35437 | Running loss: 0.43258\n","Epoch: 1 | Iteration: 2516/2403 | Classification loss: 0.11684 | Regression loss: 0.14686 | Running loss: 0.43108\n","Epoch: 1 | Iteration: 2517/2403 | Classification loss: 0.20585 | Regression loss: 0.27499 | Running loss: 0.43152\n","Epoch: 1 | Iteration: 2518/2403 | Classification loss: 0.18774 | Regression loss: 0.16325 | Running loss: 0.43082\n","Epoch: 1 | Iteration: 2519/2403 | Classification loss: 0.58903 | Regression loss: 0.21423 | Running loss: 0.43403\n","Epoch: 1 | Iteration: 2520/2403 | Classification loss: 0.14747 | Regression loss: 0.17602 | Running loss: 0.43308\n","Epoch: 1 | Iteration: 2521/2403 | Classification loss: 0.35336 | Regression loss: 0.30727 | Running loss: 0.43501\n","Epoch: 1 | Iteration: 2522/2403 | Classification loss: 0.08079 | Regression loss: 0.19173 | Running loss: 0.43365\n","Epoch: 1 | Iteration: 2523/2403 | Classification loss: 0.23626 | Regression loss: 0.23972 | Running loss: 0.43400\n","Epoch: 1 | Iteration: 2524/2403 | Classification loss: 0.05288 | Regression loss: 0.14408 | Running loss: 0.43204\n","Epoch: 1 | Iteration: 2525/2403 | Classification loss: 0.13345 | Regression loss: 0.24960 | Running loss: 0.43164\n","Epoch: 1 | Iteration: 2526/2403 | Classification loss: 0.23994 | Regression loss: 0.27072 | Running loss: 0.43228\n","Epoch: 1 | Iteration: 2527/2403 | Classification loss: 0.27573 | Regression loss: 0.30208 | Running loss: 0.43345\n","Epoch: 1 | Iteration: 2528/2403 | Classification loss: 0.14183 | Regression loss: 0.21837 | Running loss: 0.43287\n","Epoch: 1 | Iteration: 2529/2403 | Classification loss: 0.41548 | Regression loss: 0.43419 | Running loss: 0.43618\n","Epoch: 1 | Iteration: 2530/2403 | Classification loss: 0.17141 | Regression loss: 0.25244 | Running loss: 0.43608\n","Epoch: 1 | Iteration: 2531/2403 | Classification loss: 0.12244 | Regression loss: 0.24448 | Running loss: 0.43554\n","Epoch: 1 | Iteration: 2532/2403 | Classification loss: 0.15028 | Regression loss: 0.25267 | Running loss: 0.43529\n","Epoch: 1 | Iteration: 2533/2403 | Classification loss: 0.12019 | Regression loss: 0.34747 | Running loss: 0.43554\n","Epoch: 1 | Iteration: 2534/2403 | Classification loss: 0.15094 | Regression loss: 0.19226 | Running loss: 0.43483\n","Epoch: 1 | Iteration: 2535/2403 | Classification loss: 0.05515 | Regression loss: 0.15438 | Running loss: 0.43312\n","Epoch: 1 | Iteration: 2536/2403 | Classification loss: 0.04331 | Regression loss: 0.18820 | Running loss: 0.43161\n","Epoch: 1 | Iteration: 2537/2403 | Classification loss: 0.39636 | Regression loss: 0.24502 | Running loss: 0.43317\n","Epoch: 1 | Iteration: 2538/2403 | Classification loss: 0.04844 | Regression loss: 0.20728 | Running loss: 0.43186\n","Epoch: 1 | Iteration: 2539/2403 | Classification loss: 0.21635 | Regression loss: 0.27588 | Running loss: 0.43230\n","Epoch: 1 | Iteration: 2540/2403 | Classification loss: 0.15010 | Regression loss: 0.25711 | Running loss: 0.43212\n","Epoch: 1 | Iteration: 2541/2403 | Classification loss: 0.41146 | Regression loss: 0.34405 | Running loss: 0.43446\n","Epoch: 1 | Iteration: 2542/2403 | Classification loss: 0.38648 | Regression loss: 0.38303 | Running loss: 0.43687\n","Epoch: 1 | Iteration: 2543/2403 | Classification loss: 0.12745 | Regression loss: 0.16525 | Running loss: 0.43584\n","Epoch: 1 | Iteration: 2544/2403 | Classification loss: 0.13339 | Regression loss: 0.18146 | Running loss: 0.43499\n","Epoch: 1 | Iteration: 2545/2403 | Classification loss: 0.70758 | Regression loss: 0.23328 | Running loss: 0.43855\n","Epoch: 1 | Iteration: 2546/2403 | Classification loss: 0.23457 | Regression loss: 0.17704 | Running loss: 0.43836\n","Epoch: 1 | Iteration: 2547/2403 | Classification loss: 0.12088 | Regression loss: 0.26603 | Running loss: 0.43800\n","Epoch: 1 | Iteration: 2548/2403 | Classification loss: 0.18580 | Regression loss: 0.26900 | Running loss: 0.43812\n","Epoch: 1 | Iteration: 2549/2403 | Classification loss: 0.11442 | Regression loss: 0.16810 | Running loss: 0.43705\n","Epoch: 1 | Iteration: 2550/2403 | Classification loss: 0.05873 | Regression loss: 0.16110 | Running loss: 0.43557\n","Epoch: 1 | Iteration: 2551/2403 | Classification loss: 0.41508 | Regression loss: 0.27992 | Running loss: 0.43733\n","Epoch: 1 | Iteration: 2552/2403 | Classification loss: 0.16164 | Regression loss: 0.25296 | Running loss: 0.43718\n","Epoch: 1 | Iteration: 2553/2403 | Classification loss: 0.25231 | Regression loss: 0.25273 | Running loss: 0.43763\n","Epoch: 1 | Iteration: 2554/2403 | Classification loss: 0.37955 | Regression loss: 0.26736 | Running loss: 0.43901\n","Epoch: 1 | Iteration: 2555/2403 | Classification loss: 0.07813 | Regression loss: 0.28620 | Running loss: 0.43852\n","Epoch: 1 | Iteration: 2556/2403 | Classification loss: 0.30644 | Regression loss: 0.35495 | Running loss: 0.43998\n","Epoch: 1 | Iteration: 2557/2403 | Classification loss: 0.05125 | Regression loss: 0.23537 | Running loss: 0.43898\n","Epoch: 1 | Iteration: 2558/2403 | Classification loss: 0.34633 | Regression loss: 0.35441 | Running loss: 0.44067\n","Epoch: 1 | Iteration: 2559/2403 | Classification loss: 0.07886 | Regression loss: 0.21653 | Running loss: 0.43974\n","Epoch: 1 | Iteration: 2560/2403 | Classification loss: 0.06573 | Regression loss: 0.14787 | Running loss: 0.43830\n","Epoch: 1 | Iteration: 2561/2403 | Classification loss: 0.27713 | Regression loss: 0.38530 | Running loss: 0.43972\n","Epoch: 1 | Iteration: 2562/2403 | Classification loss: 0.08795 | Regression loss: 0.16047 | Running loss: 0.43852\n","Epoch: 1 | Iteration: 2563/2403 | Classification loss: 0.16741 | Regression loss: 0.24895 | Running loss: 0.43838\n","Epoch: 1 | Iteration: 2564/2403 | Classification loss: 0.08784 | Regression loss: 0.18296 | Running loss: 0.43734\n","Epoch: 1 | Iteration: 2565/2403 | Classification loss: 0.14831 | Regression loss: 0.22644 | Running loss: 0.43695\n","Epoch: 1 | Iteration: 2566/2403 | Classification loss: 0.09835 | Regression loss: 0.27409 | Running loss: 0.43655\n","Epoch: 1 | Iteration: 2567/2403 | Classification loss: 0.15224 | Regression loss: 0.28012 | Running loss: 0.43653\n","Epoch: 1 | Iteration: 2568/2403 | Classification loss: 0.17366 | Regression loss: 0.32730 | Running loss: 0.43692\n","Epoch: 1 | Iteration: 2569/2403 | Classification loss: 0.19897 | Regression loss: 0.23143 | Running loss: 0.43688\n","Epoch: 1 | Iteration: 2570/2403 | Classification loss: 0.26216 | Regression loss: 0.28292 | Running loss: 0.43753\n","Epoch: 1 | Iteration: 2571/2403 | Classification loss: 0.14576 | Regression loss: 0.24270 | Running loss: 0.43724\n","Epoch: 1 | Iteration: 2572/2403 | Classification loss: 0.17974 | Regression loss: 0.18302 | Running loss: 0.43679\n","Epoch: 1 | Iteration: 2573/2403 | Classification loss: 0.07867 | Regression loss: 0.16999 | Running loss: 0.43569\n","Epoch: 1 | Iteration: 2574/2403 | Classification loss: 0.10724 | Regression loss: 0.24190 | Running loss: 0.43518\n","Epoch: 1 | Iteration: 2575/2403 | Classification loss: 0.24227 | Regression loss: 0.27949 | Running loss: 0.43569\n","Epoch: 1 | Iteration: 2576/2403 | Classification loss: 0.08343 | Regression loss: 0.16028 | Running loss: 0.43458\n","Epoch: 1 | Iteration: 2577/2403 | Classification loss: 0.06330 | Regression loss: 0.13538 | Running loss: 0.43322\n","Epoch: 1 | Iteration: 2578/2403 | Classification loss: 0.75181 | Regression loss: 0.28910 | Running loss: 0.43669\n","Epoch: 1 | Iteration: 2579/2403 | Classification loss: 0.20886 | Regression loss: 0.31162 | Running loss: 0.43717\n","Epoch: 1 | Iteration: 2580/2403 | Classification loss: 0.21229 | Regression loss: 0.22844 | Running loss: 0.43719\n","Epoch: 1 | Iteration: 2581/2403 | Classification loss: 0.13948 | Regression loss: 0.15792 | Running loss: 0.43640\n","Epoch: 1 | Iteration: 2582/2403 | Classification loss: 0.25658 | Regression loss: 0.28071 | Running loss: 0.43697\n","Epoch: 1 | Iteration: 2583/2403 | Classification loss: 0.09516 | Regression loss: 0.19219 | Running loss: 0.43614\n","Epoch: 1 | Iteration: 2584/2403 | Classification loss: 0.20618 | Regression loss: 0.28328 | Running loss: 0.43643\n","Epoch: 1 | Iteration: 2585/2403 | Classification loss: 0.32867 | Regression loss: 0.28543 | Running loss: 0.43741\n","Epoch: 1 | Iteration: 2586/2403 | Classification loss: 0.29661 | Regression loss: 0.30231 | Running loss: 0.43829\n","Epoch: 1 | Iteration: 2587/2403 | Classification loss: 0.07401 | Regression loss: 0.16985 | Running loss: 0.43723\n","Epoch: 1 | Iteration: 2588/2403 | Classification loss: 0.23140 | Regression loss: 0.22360 | Running loss: 0.43733\n","Epoch: 1 | Iteration: 2589/2403 | Classification loss: 0.51827 | Regression loss: 0.36196 | Running loss: 0.43971\n","Epoch: 1 | Iteration: 2590/2403 | Classification loss: 0.15757 | Regression loss: 0.18382 | Running loss: 0.43918\n","Epoch: 1 | Iteration: 2591/2403 | Classification loss: 0.33642 | Regression loss: 0.32756 | Running loss: 0.44038\n","Epoch: 1 | Iteration: 2592/2403 | Classification loss: 0.09370 | Regression loss: 0.15463 | Running loss: 0.43936\n","Epoch: 1 | Iteration: 2593/2403 | Classification loss: 0.09332 | Regression loss: 0.20425 | Running loss: 0.43862\n","Epoch: 1 | Iteration: 2594/2403 | Classification loss: 0.25473 | Regression loss: 0.31190 | Running loss: 0.43929\n","Epoch: 1 | Iteration: 2595/2403 | Classification loss: 0.04884 | Regression loss: 0.17652 | Running loss: 0.43817\n","Epoch: 1 | Iteration: 2596/2403 | Classification loss: 0.09865 | Regression loss: 0.23226 | Running loss: 0.43762\n","Epoch: 1 | Iteration: 2597/2403 | Classification loss: 0.23032 | Regression loss: 0.29403 | Running loss: 0.43806\n","Epoch: 1 | Iteration: 2598/2403 | Classification loss: 0.35213 | Regression loss: 0.22739 | Running loss: 0.43879\n","Epoch: 1 | Iteration: 2599/2403 | Classification loss: 0.12302 | Regression loss: 0.17719 | Running loss: 0.43808\n","Epoch: 1 | Iteration: 2600/2403 | Classification loss: 0.14293 | Regression loss: 0.16650 | Running loss: 0.43743\n","Epoch: 1 | Iteration: 2601/2403 | Classification loss: 0.35657 | Regression loss: 0.24712 | Running loss: 0.43827\n","Epoch: 1 | Iteration: 2602/2403 | Classification loss: 0.05612 | Regression loss: 0.17515 | Running loss: 0.43723\n","Epoch: 1 | Iteration: 2603/2403 | Classification loss: 0.11947 | Regression loss: 0.25276 | Running loss: 0.43690\n","Epoch: 1 | Iteration: 2604/2403 | Classification loss: 0.35717 | Regression loss: 0.22559 | Running loss: 0.43763\n","Epoch: 1 | Iteration: 2605/2403 | Classification loss: 0.13581 | Regression loss: 0.15533 | Running loss: 0.43690\n","Epoch: 1 | Iteration: 2606/2403 | Classification loss: 1.26279 | Regression loss: 0.33928 | Running loss: 0.44264\n","Epoch: 1 | Iteration: 2607/2403 | Classification loss: 0.25013 | Regression loss: 0.29003 | Running loss: 0.44312\n","Epoch: 1 | Iteration: 2608/2403 | Classification loss: 0.04249 | Regression loss: 0.17397 | Running loss: 0.44202\n","Epoch: 1 | Iteration: 2609/2403 | Classification loss: 0.19610 | Regression loss: 0.27049 | Running loss: 0.44214\n","Epoch: 1 | Iteration: 2610/2403 | Classification loss: 0.21134 | Regression loss: 0.20585 | Running loss: 0.44202\n","Epoch: 1 | Iteration: 2611/2403 | Classification loss: 0.67768 | Regression loss: 0.19695 | Running loss: 0.44410\n","Epoch: 1 | Iteration: 2612/2403 | Classification loss: 0.20182 | Regression loss: 0.19922 | Running loss: 0.44389\n","Epoch: 1 | Iteration: 2613/2403 | Classification loss: 0.31397 | Regression loss: 0.22863 | Running loss: 0.44436\n","Epoch: 1 | Iteration: 2614/2403 | Classification loss: 0.08893 | Regression loss: 0.15763 | Running loss: 0.44342\n","Epoch: 1 | Iteration: 2615/2403 | Classification loss: 0.26475 | Regression loss: 0.26262 | Running loss: 0.44382\n","Epoch: 1 | Iteration: 2616/2403 | Classification loss: 0.05092 | Regression loss: 0.11477 | Running loss: 0.44251\n","Epoch: 1 | Iteration: 2617/2403 | Classification loss: 0.13760 | Regression loss: 0.21792 | Running loss: 0.44211\n","Epoch: 1 | Iteration: 2618/2403 | Classification loss: 0.08279 | Regression loss: 0.12610 | Running loss: 0.44102\n","Epoch: 1 | Iteration: 2619/2403 | Classification loss: 0.26786 | Regression loss: 0.22521 | Running loss: 0.44126\n","Epoch: 1 | Iteration: 2620/2403 | Classification loss: 1.05581 | Regression loss: 0.33353 | Running loss: 0.44563\n","Epoch: 1 | Iteration: 2621/2403 | Classification loss: 0.17902 | Regression loss: 0.20069 | Running loss: 0.44533\n","Epoch: 1 | Iteration: 2622/2403 | Classification loss: 0.11457 | Regression loss: 0.20478 | Running loss: 0.44475\n","Epoch: 1 | Iteration: 2623/2403 | Classification loss: 0.22367 | Regression loss: 0.28523 | Running loss: 0.44505\n","Epoch: 1 | Iteration: 2624/2403 | Classification loss: 0.10414 | Regression loss: 0.21691 | Running loss: 0.44448\n","Epoch: 1 | Iteration: 2625/2403 | Classification loss: 0.13021 | Regression loss: 0.18874 | Running loss: 0.44392\n","Epoch: 1 | Iteration: 2626/2403 | Classification loss: 0.28594 | Regression loss: 0.35507 | Running loss: 0.44480\n","Epoch: 1 | Iteration: 2627/2403 | Classification loss: 0.08886 | Regression loss: 0.17040 | Running loss: 0.44397\n","Epoch: 1 | Iteration: 2628/2403 | Classification loss: 0.35788 | Regression loss: 0.36804 | Running loss: 0.44523\n","Epoch: 1 | Iteration: 2629/2403 | Classification loss: 0.33514 | Regression loss: 0.37113 | Running loss: 0.44638\n","Epoch: 1 | Iteration: 2630/2403 | Classification loss: 0.47118 | Regression loss: 0.21607 | Running loss: 0.44744\n","Epoch: 1 | Iteration: 2631/2403 | Classification loss: 0.08973 | Regression loss: 0.16503 | Running loss: 0.44660\n","Epoch: 1 | Iteration: 2632/2403 | Classification loss: 0.16790 | Regression loss: 0.18864 | Running loss: 0.44621\n","Epoch: 1 | Iteration: 2633/2403 | Classification loss: 0.31381 | Regression loss: 0.31967 | Running loss: 0.44702\n","Epoch: 1 | Iteration: 2634/2403 | Classification loss: 0.13613 | Regression loss: 0.21722 | Running loss: 0.44661\n","Epoch: 1 | Iteration: 2635/2403 | Classification loss: 0.40029 | Regression loss: 0.29504 | Running loss: 0.44769\n","Epoch: 1 | Iteration: 2636/2403 | Classification loss: 0.20730 | Regression loss: 0.25886 | Running loss: 0.44777\n","Epoch: 1 | Iteration: 2637/2403 | Classification loss: 0.08343 | Regression loss: 0.16366 | Running loss: 0.44691\n","Epoch: 1 | Iteration: 2638/2403 | Classification loss: 0.20566 | Regression loss: 0.19744 | Running loss: 0.44672\n","Epoch: 1 | Iteration: 2639/2403 | Classification loss: 0.07014 | Regression loss: 0.17530 | Running loss: 0.44587\n","Epoch: 1 | Iteration: 2640/2403 | Classification loss: 0.07290 | Regression loss: 0.17648 | Running loss: 0.44504\n","Epoch: 1 | Iteration: 2641/2403 | Classification loss: 0.14239 | Regression loss: 0.21952 | Running loss: 0.44469\n","Epoch: 1 | Iteration: 2642/2403 | Classification loss: 0.11104 | Regression loss: 0.22465 | Running loss: 0.44423\n","Epoch: 1 | Iteration: 2643/2403 | Classification loss: 0.12723 | Regression loss: 0.14383 | Running loss: 0.44351\n","Epoch: 1 | Iteration: 2644/2403 | Classification loss: 0.09097 | Regression loss: 0.18872 | Running loss: 0.44283\n","Epoch: 1 | Iteration: 2645/2403 | Classification loss: 0.25203 | Regression loss: 0.28358 | Running loss: 0.44322\n","Epoch: 1 | Iteration: 2646/2403 | Classification loss: 0.26843 | Regression loss: 0.28414 | Running loss: 0.44367\n","Epoch: 1 | Iteration: 2647/2403 | Classification loss: 0.47518 | Regression loss: 0.37436 | Running loss: 0.44533\n","Epoch: 1 | Iteration: 2648/2403 | Classification loss: 0.08487 | Regression loss: 0.16473 | Running loss: 0.44453\n","Epoch: 1 | Iteration: 2649/2403 | Classification loss: 0.47151 | Regression loss: 0.20376 | Running loss: 0.44547\n","Epoch: 1 | Iteration: 2650/2403 | Classification loss: 0.08291 | Regression loss: 0.17084 | Running loss: 0.44469\n","Epoch: 1 | Iteration: 2651/2403 | Classification loss: 0.20579 | Regression loss: 0.20637 | Running loss: 0.44456\n","Epoch: 1 | Iteration: 2652/2403 | Classification loss: 0.11301 | Regression loss: 0.13604 | Running loss: 0.44378\n","Epoch: 1 | Iteration: 2653/2403 | Classification loss: 0.47414 | Regression loss: 0.32670 | Running loss: 0.44520\n","Epoch: 1 | Iteration: 2654/2403 | Classification loss: 0.32838 | Regression loss: 0.26054 | Running loss: 0.44578\n","Epoch: 1 | Iteration: 2655/2403 | Classification loss: 0.31720 | Regression loss: 0.39976 | Running loss: 0.44685\n","Epoch: 1 | Iteration: 2656/2403 | Classification loss: 0.39175 | Regression loss: 0.25142 | Running loss: 0.44763\n","Epoch: 1 | Iteration: 2657/2403 | Classification loss: 0.17357 | Regression loss: 0.17738 | Running loss: 0.44725\n","Epoch: 1 | Iteration: 2658/2403 | Classification loss: 0.27843 | Regression loss: 0.20109 | Running loss: 0.44737\n","Epoch: 1 | Iteration: 2659/2403 | Classification loss: 0.10860 | Regression loss: 0.19684 | Running loss: 0.44682\n","Epoch: 1 | Iteration: 2660/2403 | Classification loss: 0.15385 | Regression loss: 0.14195 | Running loss: 0.44623\n","Epoch: 1 | Iteration: 2661/2403 | Classification loss: 0.37330 | Regression loss: 0.28357 | Running loss: 0.44705\n","Epoch: 1 | Iteration: 2662/2403 | Classification loss: 0.34870 | Regression loss: 0.28023 | Running loss: 0.44775\n","Epoch: 1 | Iteration: 2663/2403 | Classification loss: 0.28263 | Regression loss: 0.16255 | Running loss: 0.44774\n","Epoch: 1 | Iteration: 2664/2403 | Classification loss: 0.14186 | Regression loss: 0.14636 | Running loss: 0.44713\n","Epoch: 1 | Iteration: 2665/2403 | Classification loss: 0.29582 | Regression loss: 0.23203 | Running loss: 0.44744\n","Epoch: 1 | Iteration: 2666/2403 | Classification loss: 0.34279 | Regression loss: 0.21483 | Running loss: 0.44786\n","Epoch: 1 | Iteration: 2667/2403 | Classification loss: 0.20901 | Regression loss: 0.24294 | Running loss: 0.44787\n","Epoch: 1 | Iteration: 2668/2403 | Classification loss: 0.34516 | Regression loss: 0.16108 | Running loss: 0.44809\n","Epoch: 1 | Iteration: 2669/2403 | Classification loss: 0.10115 | Regression loss: 0.14803 | Running loss: 0.44735\n","Epoch: 1 | Iteration: 2670/2403 | Classification loss: 0.37996 | Regression loss: 0.19332 | Running loss: 0.44782\n","Epoch: 1 | Iteration: 2671/2403 | Classification loss: 0.48568 | Regression loss: 0.30816 | Running loss: 0.44911\n","Epoch: 1 | Iteration: 2672/2403 | Classification loss: 0.27571 | Regression loss: 0.19465 | Running loss: 0.44919\n","Epoch: 1 | Iteration: 2673/2403 | Classification loss: 0.37789 | Regression loss: 0.26214 | Running loss: 0.44989\n","Epoch: 1 | Iteration: 2674/2403 | Classification loss: 0.30512 | Regression loss: 0.38930 | Running loss: 0.45080\n","Epoch: 1 | Iteration: 2675/2403 | Classification loss: 0.14997 | Regression loss: 0.27643 | Running loss: 0.45071\n","Epoch: 1 | Iteration: 2676/2403 | Classification loss: 0.65216 | Regression loss: 0.43299 | Running loss: 0.45303\n","Epoch: 1 | Iteration: 2677/2403 | Classification loss: 0.74890 | Regression loss: 0.55795 | Running loss: 0.45615\n","Epoch: 1 | Iteration: 2678/2403 | Classification loss: 0.22195 | Regression loss: 0.24603 | Running loss: 0.45619\n","Epoch: 1 | Iteration: 2679/2403 | Classification loss: 0.11303 | Regression loss: 0.19015 | Running loss: 0.45564\n","Epoch: 1 | Iteration: 2680/2403 | Classification loss: 0.28041 | Regression loss: 0.31606 | Running loss: 0.45614\n","Epoch: 1 | Iteration: 2681/2403 | Classification loss: 0.17639 | Regression loss: 0.15298 | Running loss: 0.45569\n","Epoch: 1 | Iteration: 2682/2403 | Classification loss: 0.37857 | Regression loss: 0.41705 | Running loss: 0.45691\n","Epoch: 1 | Iteration: 2683/2403 | Classification loss: 0.13953 | Regression loss: 0.19520 | Running loss: 0.45647\n","Epoch: 1 | Iteration: 2684/2403 | Classification loss: 0.09461 | Regression loss: 0.20424 | Running loss: 0.45591\n","Epoch: 1 | Iteration: 2685/2403 | Classification loss: 0.15803 | Regression loss: 0.12222 | Running loss: 0.45529\n","Epoch: 1 | Iteration: 2686/2403 | Classification loss: 0.26134 | Regression loss: 0.28889 | Running loss: 0.45562\n","Epoch: 1 | Iteration: 2687/2403 | Classification loss: 0.11748 | Regression loss: 0.18422 | Running loss: 0.45508\n","Epoch: 1 | Iteration: 2688/2403 | Classification loss: 0.09629 | Regression loss: 0.23814 | Running loss: 0.45466\n","Epoch: 1 | Iteration: 2689/2403 | Classification loss: 0.08468 | Regression loss: 0.19730 | Running loss: 0.45405\n","Epoch: 1 | Iteration: 2690/2403 | Classification loss: 0.21481 | Regression loss: 0.20732 | Running loss: 0.45394\n","Epoch: 1 | Iteration: 2691/2403 | Classification loss: 0.18042 | Regression loss: 0.26836 | Running loss: 0.45392\n","Epoch: 1 | Iteration: 2692/2403 | Classification loss: 0.09636 | Regression loss: 0.19617 | Running loss: 0.45336\n","Epoch: 1 | Iteration: 2693/2403 | Classification loss: 0.27072 | Regression loss: 0.30840 | Running loss: 0.45380\n","Epoch: 1 | Iteration: 2694/2403 | Classification loss: 0.13568 | Regression loss: 0.25593 | Running loss: 0.45358\n","Epoch: 1 | Iteration: 2695/2403 | Classification loss: 0.08577 | Regression loss: 0.14691 | Running loss: 0.45283\n","Epoch: 1 | Iteration: 2696/2403 | Classification loss: 1.31507 | Regression loss: 0.25534 | Running loss: 0.45664\n","Epoch: 1 | Iteration: 2697/2403 | Classification loss: 0.06094 | Regression loss: 0.15787 | Running loss: 0.45583\n","Epoch: 1 | Iteration: 2698/2403 | Classification loss: 0.18510 | Regression loss: 0.23260 | Running loss: 0.45570\n","Epoch: 1 | Iteration: 2699/2403 | Classification loss: 0.09634 | Regression loss: 0.17356 | Running loss: 0.45508\n","Epoch: 1 | Iteration: 2700/2403 | Classification loss: 0.09864 | Regression loss: 0.16748 | Running loss: 0.45444\n","Epoch: 1 | Iteration: 2701/2403 | Classification loss: 0.13415 | Regression loss: 0.14229 | Running loss: 0.45384\n","Epoch: 1 | Iteration: 2702/2403 | Classification loss: 0.22855 | Regression loss: 0.21719 | Running loss: 0.45382\n","Epoch: 1 | Iteration: 2703/2403 | Classification loss: 0.10271 | Regression loss: 0.16588 | Running loss: 0.45320\n","Epoch: 1 | Iteration: 2704/2403 | Classification loss: 0.12052 | Regression loss: 0.21907 | Running loss: 0.45282\n","Epoch: 1 | Iteration: 2705/2403 | Classification loss: 0.10131 | Regression loss: 0.21560 | Running loss: 0.45237\n","Epoch: 1 | Iteration: 2706/2403 | Classification loss: 1.08208 | Regression loss: 0.21340 | Running loss: 0.45515\n","Epoch: 1 | Iteration: 2707/2403 | Classification loss: 0.17415 | Regression loss: 0.16392 | Running loss: 0.45477\n","Epoch: 1 | Iteration: 2708/2403 | Classification loss: 0.18480 | Regression loss: 0.18968 | Running loss: 0.45451\n","Epoch: 1 | Iteration: 2709/2403 | Classification loss: 0.23664 | Regression loss: 0.21819 | Running loss: 0.45451\n","Epoch: 1 | Iteration: 2710/2403 | Classification loss: 0.19588 | Regression loss: 0.25944 | Running loss: 0.45451\n","Epoch: 1 | Iteration: 2711/2403 | Classification loss: 0.11292 | Regression loss: 0.25032 | Running loss: 0.45421\n","Epoch: 1 | Iteration: 2712/2403 | Classification loss: 0.11869 | Regression loss: 0.20815 | Running loss: 0.45380\n","Epoch: 1 | Iteration: 2713/2403 | Classification loss: 0.54717 | Regression loss: 0.31438 | Running loss: 0.45512\n","Epoch: 1 | Iteration: 2714/2403 | Classification loss: 0.08528 | Regression loss: 0.20232 | Running loss: 0.45458\n","Epoch: 1 | Iteration: 2715/2403 | Classification loss: 0.09533 | Regression loss: 0.32475 | Running loss: 0.45447\n","Epoch: 1 | Iteration: 2716/2403 | Classification loss: 0.25766 | Regression loss: 0.30972 | Running loss: 0.45483\n","Epoch: 1 | Iteration: 2717/2403 | Classification loss: 0.05691 | Regression loss: 0.20988 | Running loss: 0.45423\n","Epoch: 1 | Iteration: 2718/2403 | Classification loss: 0.49570 | Regression loss: 0.36547 | Running loss: 0.45552\n","Epoch: 1 | Iteration: 2719/2403 | Classification loss: 0.08589 | Regression loss: 0.19384 | Running loss: 0.45496\n","Epoch: 1 | Iteration: 2720/2403 | Classification loss: 0.15012 | Regression loss: 0.22878 | Running loss: 0.45472\n","Epoch: 1 | Iteration: 2721/2403 | Classification loss: 0.22792 | Regression loss: 0.25464 | Running loss: 0.45481\n","Epoch: 1 | Iteration: 2722/2403 | Classification loss: 0.12769 | Regression loss: 0.23691 | Running loss: 0.45453\n","Epoch: 1 | Iteration: 2723/2403 | Classification loss: 0.12844 | Regression loss: 0.25535 | Running loss: 0.45431\n","Epoch: 1 | Iteration: 2724/2403 | Classification loss: 0.12894 | Regression loss: 0.30995 | Running loss: 0.45426\n","Epoch: 1 | Iteration: 2725/2403 | Classification loss: 0.16981 | Regression loss: 0.21602 | Running loss: 0.45405\n","Epoch: 1 | Iteration: 2726/2403 | Classification loss: 0.46949 | Regression loss: 0.36138 | Running loss: 0.45521\n","Epoch: 1 | Iteration: 2727/2403 | Classification loss: 0.40290 | Regression loss: 0.34039 | Running loss: 0.45610\n","Epoch: 1 | Iteration: 2728/2403 | Classification loss: 0.19503 | Regression loss: 0.24416 | Running loss: 0.45605\n","Epoch: 1 | Iteration: 2729/2403 | Classification loss: 0.19104 | Regression loss: 0.17557 | Running loss: 0.45578\n","Epoch: 1 | Iteration: 2730/2403 | Classification loss: 0.32073 | Regression loss: 0.21302 | Running loss: 0.45601\n","Epoch: 1 | Iteration: 2731/2403 | Classification loss: 2.07646 | Regression loss: 0.42051 | Running loss: 0.46224\n","Epoch: 1 | Iteration: 2732/2403 | Classification loss: 0.09624 | Regression loss: 0.22533 | Running loss: 0.46181\n","Epoch: 1 | Iteration: 2733/2403 | Classification loss: 0.34312 | Regression loss: 0.35793 | Running loss: 0.46253\n","Epoch: 1 | Iteration: 2734/2403 | Classification loss: 0.68100 | Regression loss: 0.49175 | Running loss: 0.46468\n","Epoch: 1 | Iteration: 2735/2403 | Classification loss: 0.17034 | Regression loss: 0.20090 | Running loss: 0.46440\n","Epoch: 1 | Iteration: 2736/2403 | Classification loss: 0.36545 | Regression loss: 0.33199 | Running loss: 0.46510\n","Epoch: 1 | Iteration: 2737/2403 | Classification loss: 0.41715 | Regression loss: 0.20456 | Running loss: 0.46557\n","Epoch: 1 | Iteration: 2738/2403 | Classification loss: 0.21331 | Regression loss: 0.18002 | Running loss: 0.46535\n","Epoch: 1 | Iteration: 2739/2403 | Classification loss: 0.18460 | Regression loss: 0.22904 | Running loss: 0.46520\n","Epoch: 1 | Iteration: 2740/2403 | Classification loss: 0.09238 | Regression loss: 0.18017 | Running loss: 0.46463\n","Epoch: 1 | Iteration: 2741/2403 | Classification loss: 0.10854 | Regression loss: 0.22061 | Running loss: 0.46423\n","Epoch: 1 | Iteration: 2742/2403 | Classification loss: 0.16938 | Regression loss: 0.20040 | Running loss: 0.46395\n","Epoch: 1 | Iteration: 2743/2403 | Classification loss: 0.19817 | Regression loss: 0.19979 | Running loss: 0.46375\n","Epoch: 1 | Iteration: 2744/2403 | Classification loss: 0.21521 | Regression loss: 0.30337 | Running loss: 0.46391\n","Epoch: 1 | Iteration: 2745/2403 | Classification loss: 0.17640 | Regression loss: 0.27074 | Running loss: 0.46386\n","Epoch: 1 | Iteration: 2746/2403 | Classification loss: 0.34077 | Regression loss: 0.32893 | Running loss: 0.46446\n","Epoch: 1 | Iteration: 2747/2403 | Classification loss: 0.29237 | Regression loss: 0.25380 | Running loss: 0.46470\n","Epoch: 1 | Iteration: 2748/2403 | Classification loss: 0.08281 | Regression loss: 0.18998 | Running loss: 0.46415\n","Epoch: 1 | Iteration: 2749/2403 | Classification loss: 0.16712 | Regression loss: 0.27264 | Running loss: 0.46408\n","Epoch: 1 | Iteration: 2750/2403 | Classification loss: 0.09302 | Regression loss: 0.30990 | Running loss: 0.46390\n","Epoch: 1 | Iteration: 2751/2403 | Classification loss: 0.12815 | Regression loss: 0.25763 | Running loss: 0.46367\n","Epoch: 1 | Iteration: 2752/2403 | Classification loss: 0.08837 | Regression loss: 0.18573 | Running loss: 0.46313\n","Epoch: 1 | Iteration: 2753/2403 | Classification loss: 0.14809 | Regression loss: 0.23126 | Running loss: 0.46289\n","Epoch: 1 | Iteration: 2754/2403 | Classification loss: 0.08478 | Regression loss: 0.13957 | Running loss: 0.46221\n","Epoch: 1 | Iteration: 2755/2403 | Classification loss: 0.12548 | Regression loss: 0.18604 | Running loss: 0.46178\n","Epoch: 1 | Iteration: 2756/2403 | Classification loss: 0.91043 | Regression loss: 0.23094 | Running loss: 0.46371\n","Epoch: 1 | Iteration: 2757/2403 | Classification loss: 0.22555 | Regression loss: 0.28371 | Running loss: 0.46384\n","Epoch: 1 | Iteration: 2758/2403 | Classification loss: 0.07518 | Regression loss: 0.24768 | Running loss: 0.46344\n","Epoch: 1 | Iteration: 2759/2403 | Classification loss: 0.06907 | Regression loss: 0.24319 | Running loss: 0.46302\n","Epoch: 1 | Iteration: 2760/2403 | Classification loss: 0.27256 | Regression loss: 0.25076 | Running loss: 0.46319\n","Epoch: 1 | Iteration: 2761/2403 | Classification loss: 0.28172 | Regression loss: 0.21206 | Running loss: 0.46327\n","Epoch: 1 | Iteration: 2762/2403 | Classification loss: 0.12945 | Regression loss: 0.22070 | Running loss: 0.46296\n","Epoch: 1 | Iteration: 2763/2403 | Classification loss: 0.11992 | Regression loss: 0.13621 | Running loss: 0.46238\n","Epoch: 1 | Iteration: 2764/2403 | Classification loss: 0.09685 | Regression loss: 0.19073 | Running loss: 0.46190\n","Epoch: 1 | Iteration: 2765/2403 | Classification loss: 0.14345 | Regression loss: 0.29892 | Running loss: 0.46184\n","Epoch: 1 | Iteration: 2766/2403 | Classification loss: 0.27524 | Regression loss: 0.23982 | Running loss: 0.46199\n","Epoch: 1 | Iteration: 2767/2403 | Classification loss: 0.17825 | Regression loss: 0.28715 | Running loss: 0.46200\n","Epoch: 1 | Iteration: 2768/2403 | Classification loss: 0.22196 | Regression loss: 0.19756 | Running loss: 0.46188\n","Epoch: 1 | Iteration: 2769/2403 | Classification loss: 0.04881 | Regression loss: 0.19526 | Running loss: 0.46129\n","Epoch: 1 | Iteration: 2770/2403 | Classification loss: 0.27982 | Regression loss: 0.28727 | Running loss: 0.46158\n","Epoch: 1 | Iteration: 2771/2403 | Classification loss: 0.09836 | Regression loss: 0.20648 | Running loss: 0.46115\n","Epoch: 1 | Iteration: 2772/2403 | Classification loss: 0.04954 | Regression loss: 0.18876 | Running loss: 0.46055\n","Epoch: 1 | Iteration: 2773/2403 | Classification loss: 0.15942 | Regression loss: 0.27415 | Running loss: 0.46047\n","Epoch: 1 | Iteration: 2774/2403 | Classification loss: 0.52181 | Regression loss: 0.51957 | Running loss: 0.46204\n","Epoch: 1 | Iteration: 2775/2403 | Classification loss: 0.06475 | Regression loss: 0.17652 | Running loss: 0.46145\n","Epoch: 1 | Iteration: 2776/2403 | Classification loss: 0.29578 | Regression loss: 0.35523 | Running loss: 0.46195\n","Epoch: 1 | Iteration: 2777/2403 | Classification loss: 0.21424 | Regression loss: 0.19671 | Running loss: 0.46182\n","Epoch: 1 | Iteration: 2778/2403 | Classification loss: 0.30119 | Regression loss: 0.25979 | Running loss: 0.46208\n","Epoch: 1 | Iteration: 2779/2403 | Classification loss: 0.12012 | Regression loss: 0.22443 | Running loss: 0.46177\n","Epoch: 1 | Iteration: 2780/2403 | Classification loss: 0.24778 | Regression loss: 0.19931 | Running loss: 0.46173\n","Epoch: 1 | Iteration: 2781/2403 | Classification loss: 0.14442 | Regression loss: 0.23589 | Running loss: 0.46151\n","Epoch: 1 | Iteration: 2782/2403 | Classification loss: 0.15436 | Regression loss: 0.16605 | Running loss: 0.46114\n","Epoch: 1 | Iteration: 2783/2403 | Classification loss: 0.43176 | Regression loss: 0.32039 | Running loss: 0.46191\n","Epoch: 1 | Iteration: 2784/2403 | Classification loss: 0.12111 | Regression loss: 0.22901 | Running loss: 0.46162\n","Epoch: 1 | Iteration: 2785/2403 | Classification loss: 0.04745 | Regression loss: 0.16210 | Running loss: 0.46096\n","Epoch: 1 | Iteration: 2786/2403 | Classification loss: 0.28331 | Regression loss: 0.24125 | Running loss: 0.46112\n","Epoch: 1 | Iteration: 2787/2403 | Classification loss: 0.06523 | Regression loss: 0.13082 | Running loss: 0.46043\n","Epoch: 1 | Iteration: 2788/2403 | Classification loss: 0.05023 | Regression loss: 0.14998 | Running loss: 0.45976\n","Epoch: 1 | Iteration: 2789/2403 | Classification loss: 0.08148 | Regression loss: 0.15862 | Running loss: 0.45919\n","Epoch: 1 | Iteration: 2790/2403 | Classification loss: 0.41425 | Regression loss: 0.36788 | Running loss: 0.46002\n","Epoch: 1 | Iteration: 2791/2403 | Classification loss: 0.28153 | Regression loss: 0.24611 | Running loss: 0.46019\n","Epoch: 1 | Iteration: 2792/2403 | Classification loss: 0.13549 | Regression loss: 0.17613 | Running loss: 0.45981\n","Epoch: 1 | Iteration: 2793/2403 | Classification loss: 0.07352 | Regression loss: 0.14187 | Running loss: 0.45919\n","Epoch: 1 | Iteration: 2794/2403 | Classification loss: 0.32255 | Regression loss: 0.32134 | Running loss: 0.45966\n","Epoch: 1 | Iteration: 2795/2403 | Classification loss: 0.17178 | Regression loss: 0.26114 | Running loss: 0.45959\n","Epoch: 1 | Iteration: 2796/2403 | Classification loss: 0.33500 | Regression loss: 0.29528 | Running loss: 0.46002\n","Epoch: 1 | Iteration: 2797/2403 | Classification loss: 0.15165 | Regression loss: 0.19603 | Running loss: 0.45974\n","Epoch: 1 | Iteration: 2798/2403 | Classification loss: 0.08975 | Regression loss: 0.19823 | Running loss: 0.45930\n","Epoch: 1 | Iteration: 2799/2403 | Classification loss: 0.35419 | Regression loss: 0.41135 | Running loss: 0.46008\n","Epoch: 1 | Iteration: 2800/2403 | Classification loss: 0.24887 | Regression loss: 0.23946 | Running loss: 0.46015\n","Epoch: 1 | Iteration: 2801/2403 | Classification loss: 0.26995 | Regression loss: 0.21999 | Running loss: 0.46022\n","Epoch: 1 | Iteration: 2802/2403 | Classification loss: 0.19410 | Regression loss: 0.27377 | Running loss: 0.46024\n","Epoch: 1 | Iteration: 2803/2403 | Classification loss: 0.16027 | Regression loss: 0.23354 | Running loss: 0.46008\n","Epoch: 1 | Iteration: 2804/2403 | Classification loss: 0.38392 | Regression loss: 0.24061 | Running loss: 0.46049\n","Epoch: 1 | Iteration: 2805/2403 | Classification loss: 0.20226 | Regression loss: 0.21659 | Running loss: 0.46038\n","Epoch: 1 | Iteration: 2806/2403 | Classification loss: 0.18831 | Regression loss: 0.16335 | Running loss: 0.46011\n","Epoch: 1 | Iteration: 2807/2403 | Classification loss: 0.37274 | Regression loss: 0.24825 | Running loss: 0.46051\n","Epoch: 1 | Iteration: 2808/2403 | Classification loss: 0.12302 | Regression loss: 0.18912 | Running loss: 0.46015\n","Epoch: 1 | Iteration: 2809/2403 | Classification loss: 0.15780 | Regression loss: 0.20939 | Running loss: 0.45992\n","Epoch: 1 | Iteration: 2810/2403 | Classification loss: 0.26204 | Regression loss: 0.24707 | Running loss: 0.46004\n","Epoch: 1 | Iteration: 2811/2403 | Classification loss: 0.04448 | Regression loss: 0.18657 | Running loss: 0.45948\n","Epoch: 1 | Iteration: 2812/2403 | Classification loss: 0.05827 | Regression loss: 0.15543 | Running loss: 0.45888\n","Epoch: 1 | Iteration: 2813/2403 | Classification loss: 0.46949 | Regression loss: 0.39897 | Running loss: 0.45987\n","Epoch: 1 | Iteration: 2814/2403 | Classification loss: 0.04193 | Regression loss: 0.14107 | Running loss: 0.45920\n","Epoch: 1 | Iteration: 2815/2403 | Classification loss: 0.41000 | Regression loss: 0.34897 | Running loss: 0.45993\n","Epoch: 1 | Iteration: 2816/2403 | Classification loss: 0.12515 | Regression loss: 0.19741 | Running loss: 0.45960\n","Epoch: 1 | Iteration: 2817/2403 | Classification loss: 0.08860 | Regression loss: 0.12067 | Running loss: 0.45899\n","Epoch: 1 | Iteration: 2818/2403 | Classification loss: 0.32671 | Regression loss: 0.22268 | Running loss: 0.45921\n","Epoch: 1 | Iteration: 2819/2403 | Classification loss: 0.03964 | Regression loss: 0.14127 | Running loss: 0.45854\n","Epoch: 1 | Iteration: 2820/2403 | Classification loss: 0.17142 | Regression loss: 0.23278 | Running loss: 0.45841\n","Epoch: 1 | Iteration: 2821/2403 | Classification loss: 0.08877 | Regression loss: 0.14788 | Running loss: 0.45788\n","Epoch: 1 | Iteration: 2822/2403 | Classification loss: 0.17809 | Regression loss: 0.29512 | Running loss: 0.45792\n","Epoch: 1 | Iteration: 2823/2403 | Classification loss: 0.21745 | Regression loss: 0.21016 | Running loss: 0.45784\n","Epoch: 1 | Iteration: 2824/2403 | Classification loss: 0.23245 | Regression loss: 0.27723 | Running loss: 0.45797\n","Epoch: 1 | Iteration: 2825/2403 | Classification loss: 0.44508 | Regression loss: 0.22761 | Running loss: 0.45848\n","Epoch: 1 | Iteration: 2826/2403 | Classification loss: 0.26058 | Regression loss: 0.33644 | Running loss: 0.45880\n","Epoch: 1 | Iteration: 2827/2403 | Classification loss: 0.26989 | Regression loss: 0.26215 | Running loss: 0.45898\n","Epoch: 1 | Iteration: 2828/2403 | Classification loss: 0.06087 | Regression loss: 0.15886 | Running loss: 0.45841\n","Epoch: 1 | Iteration: 2829/2403 | Classification loss: 0.24457 | Regression loss: 0.18080 | Running loss: 0.45834\n","Epoch: 1 | Iteration: 2830/2403 | Classification loss: 0.16836 | Regression loss: 0.25043 | Running loss: 0.45824\n","Epoch: 1 | Iteration: 2831/2403 | Classification loss: 0.08174 | Regression loss: 0.16726 | Running loss: 0.45775\n","Epoch: 1 | Iteration: 2832/2403 | Classification loss: 0.20035 | Regression loss: 0.28660 | Running loss: 0.45782\n","Epoch: 1 | Iteration: 2833/2403 | Classification loss: 0.27644 | Regression loss: 0.24378 | Running loss: 0.45797\n","Epoch: 1 | Iteration: 2834/2403 | Classification loss: 0.28748 | Regression loss: 0.19461 | Running loss: 0.45802\n","Epoch: 1 | Iteration: 2835/2403 | Classification loss: 0.17640 | Regression loss: 0.24066 | Running loss: 0.45793\n","Epoch: 1 | Iteration: 2836/2403 | Classification loss: 0.22925 | Regression loss: 0.31349 | Running loss: 0.45812\n","Epoch: 1 | Iteration: 2837/2403 | Classification loss: 0.15798 | Regression loss: 0.15668 | Running loss: 0.45779\n","Epoch: 1 | Iteration: 2838/2403 | Classification loss: 0.07229 | Regression loss: 0.14540 | Running loss: 0.45724\n","Epoch: 1 | Iteration: 2839/2403 | Classification loss: 0.39233 | Regression loss: 0.20468 | Running loss: 0.45756\n","Epoch: 1 | Iteration: 2840/2403 | Classification loss: 0.04482 | Regression loss: 0.16920 | Running loss: 0.45700\n","Epoch: 1 | Iteration: 2841/2403 | Classification loss: 0.13760 | Regression loss: 0.23030 | Running loss: 0.45680\n","Epoch: 1 | Iteration: 2842/2403 | Classification loss: 0.06584 | Regression loss: 0.16435 | Running loss: 0.45629\n","Epoch: 1 | Iteration: 2843/2403 | Classification loss: 0.32731 | Regression loss: 0.26645 | Running loss: 0.45660\n","Epoch: 1 | Iteration: 2844/2403 | Classification loss: 0.05734 | Regression loss: 0.17593 | Running loss: 0.45609\n","Epoch: 1 | Iteration: 2845/2403 | Classification loss: 0.24470 | Regression loss: 0.30829 | Running loss: 0.45631\n","Epoch: 1 | Iteration: 2846/2403 | Classification loss: 0.49070 | Regression loss: 0.28343 | Running loss: 0.45703\n","Epoch: 1 | Iteration: 2847/2403 | Classification loss: 0.15018 | Regression loss: 0.24906 | Running loss: 0.45690\n","Epoch: 1 | Iteration: 2848/2403 | Classification loss: 0.22657 | Regression loss: 0.29094 | Running loss: 0.45703\n","Epoch: 1 | Iteration: 2849/2403 | Classification loss: 0.34070 | Regression loss: 0.31734 | Running loss: 0.45748\n","Epoch: 1 | Iteration: 2850/2403 | Classification loss: 0.27123 | Regression loss: 0.20772 | Running loss: 0.45753\n","Epoch: 1 | Iteration: 2851/2403 | Classification loss: 0.13024 | Regression loss: 0.21219 | Running loss: 0.45728\n","Epoch: 1 | Iteration: 2852/2403 | Classification loss: 0.17940 | Regression loss: 0.27524 | Running loss: 0.45727\n","Epoch: 1 | Iteration: 2853/2403 | Classification loss: 0.22373 | Regression loss: 0.20353 | Running loss: 0.45720\n","Epoch: 1 | Iteration: 2854/2403 | Classification loss: 0.18782 | Regression loss: 0.15973 | Running loss: 0.45696\n","Epoch: 1 | Iteration: 2855/2403 | Classification loss: 0.11873 | Regression loss: 0.15308 | Running loss: 0.45655\n","Epoch: 1 | Iteration: 2856/2403 | Classification loss: 0.14219 | Regression loss: 0.21987 | Running loss: 0.45634\n","Epoch: 1 | Iteration: 2857/2403 | Classification loss: 0.14085 | Regression loss: 0.22848 | Running loss: 0.45615\n","Epoch: 1 | Iteration: 2858/2403 | Classification loss: 0.18489 | Regression loss: 0.28954 | Running loss: 0.45619\n","Epoch: 1 | Iteration: 2859/2403 | Classification loss: 0.30230 | Regression loss: 0.33594 | Running loss: 0.45659\n","Epoch: 1 | Iteration: 2860/2403 | Classification loss: 0.13629 | Regression loss: 0.27543 | Running loss: 0.45649\n","Epoch: 1 | Iteration: 2861/2403 | Classification loss: 0.07251 | Regression loss: 0.16966 | Running loss: 0.45602\n","Epoch: 1 | Iteration: 2862/2403 | Classification loss: 0.22472 | Regression loss: 0.24894 | Running loss: 0.45606\n","Epoch: 1 | Iteration: 2863/2403 | Classification loss: 0.78953 | Regression loss: 0.34329 | Running loss: 0.45753\n","Epoch: 1 | Iteration: 2864/2403 | Classification loss: 0.10904 | Regression loss: 0.23728 | Running loss: 0.45729\n","Epoch: 1 | Iteration: 2865/2403 | Classification loss: 0.26991 | Regression loss: 0.23401 | Running loss: 0.45739\n","Epoch: 1 | Iteration: 2866/2403 | Classification loss: 0.94227 | Regression loss: 0.50168 | Running loss: 0.45952\n","Epoch: 1 | Iteration: 2867/2403 | Classification loss: 0.22827 | Regression loss: 0.26402 | Running loss: 0.45959\n","Epoch: 1 | Iteration: 2868/2403 | Classification loss: 0.41402 | Regression loss: 0.39864 | Running loss: 0.46035\n","Epoch: 1 | Iteration: 2869/2403 | Classification loss: 0.08911 | Regression loss: 0.17098 | Running loss: 0.45992\n","Epoch: 1 | Iteration: 2870/2403 | Classification loss: 0.12368 | Regression loss: 0.18541 | Running loss: 0.45960\n","Epoch: 1 | Iteration: 2871/2403 | Classification loss: 0.10570 | Regression loss: 0.17463 | Running loss: 0.45922\n","Epoch: 1 | Iteration: 2872/2403 | Classification loss: 0.11277 | Regression loss: 0.22383 | Running loss: 0.45896\n","Epoch: 1 | Iteration: 2873/2403 | Classification loss: 0.21940 | Regression loss: 0.31018 | Running loss: 0.45911\n","Epoch: 1 | Iteration: 2874/2403 | Classification loss: 1.98681 | Regression loss: 0.41157 | Running loss: 0.46322\n","Epoch: 1 | Iteration: 2875/2403 | Classification loss: 0.09939 | Regression loss: 0.17676 | Running loss: 0.46283\n","Epoch: 1 | Iteration: 2876/2403 | Classification loss: 0.24127 | Regression loss: 0.24360 | Running loss: 0.46287\n","Epoch: 1 | Iteration: 2877/2403 | Classification loss: 0.08788 | Regression loss: 0.21889 | Running loss: 0.46254\n","Epoch: 1 | Iteration: 2878/2403 | Classification loss: 0.20310 | Regression loss: 0.24315 | Running loss: 0.46251\n","Epoch: 1 | Iteration: 2879/2403 | Classification loss: 0.29284 | Regression loss: 0.26277 | Running loss: 0.46271\n","Epoch: 1 | Iteration: 2880/2403 | Classification loss: 0.12516 | Regression loss: 0.18469 | Running loss: 0.46239\n","Epoch: 1 | Iteration: 2881/2403 | Classification loss: 0.34565 | Regression loss: 0.31064 | Running loss: 0.46279\n","Epoch: 1 | Iteration: 2882/2403 | Classification loss: 0.17360 | Regression loss: 0.20144 | Running loss: 0.46261\n","Epoch: 1 | Iteration: 2883/2403 | Classification loss: 0.24858 | Regression loss: 0.24449 | Running loss: 0.46267\n","Epoch: 1 | Iteration: 2884/2403 | Classification loss: 0.40952 | Regression loss: 0.31676 | Running loss: 0.46322\n","Epoch: 1 | Iteration: 2885/2403 | Classification loss: 0.26611 | Regression loss: 0.24875 | Running loss: 0.46333\n","Epoch: 1 | Iteration: 2886/2403 | Classification loss: 0.11963 | Regression loss: 0.23645 | Running loss: 0.46310\n","Epoch: 1 | Iteration: 2887/2403 | Classification loss: 0.09137 | Regression loss: 0.16441 | Running loss: 0.46268\n","Epoch: 1 | Iteration: 2888/2403 | Classification loss: 0.28396 | Regression loss: 0.32593 | Running loss: 0.46298\n","Epoch: 1 | Iteration: 2889/2403 | Classification loss: 0.22175 | Regression loss: 0.18180 | Running loss: 0.46286\n","Epoch: 1 | Iteration: 2890/2403 | Classification loss: 0.19824 | Regression loss: 0.20990 | Running loss: 0.46275\n","Epoch: 1 | Iteration: 2891/2403 | Classification loss: 0.59825 | Regression loss: 0.27034 | Running loss: 0.46358\n","Epoch: 1 | Iteration: 2892/2403 | Classification loss: 0.25944 | Regression loss: 0.26622 | Running loss: 0.46370\n","Epoch: 1 | Iteration: 2893/2403 | Classification loss: 0.69600 | Regression loss: 0.15064 | Running loss: 0.46449\n","Epoch: 1 | Iteration: 2894/2403 | Classification loss: 0.19317 | Regression loss: 0.33604 | Running loss: 0.46462\n","Epoch: 1 | Iteration: 2895/2403 | Classification loss: 0.14808 | Regression loss: 0.23056 | Running loss: 0.46444\n","Epoch: 1 | Iteration: 2896/2403 | Classification loss: 0.13734 | Regression loss: 0.20560 | Running loss: 0.46420\n","Epoch: 1 | Iteration: 2897/2403 | Classification loss: 0.20798 | Regression loss: 0.36691 | Running loss: 0.46442\n","Epoch: 1 | Iteration: 2898/2403 | Classification loss: 0.18515 | Regression loss: 0.26482 | Running loss: 0.46439\n","Epoch: 1 | Iteration: 2899/2403 | Classification loss: 0.23746 | Regression loss: 0.22245 | Running loss: 0.46438\n","Epoch: 1 | Iteration: 2900/2403 | Classification loss: 0.15134 | Regression loss: 0.23563 | Running loss: 0.46423\n","Epoch: 1 | Iteration: 2901/2403 | Classification loss: 0.15479 | Regression loss: 0.21674 | Running loss: 0.46404\n","Epoch: 1 | Iteration: 2902/2403 | Classification loss: 0.10671 | Regression loss: 0.19546 | Running loss: 0.46372\n","Epoch: 1 | Iteration: 2903/2403 | Classification loss: 0.06681 | Regression loss: 0.15506 | Running loss: 0.46323\n","Epoch: 1 | Iteration: 2904/2403 | Classification loss: 0.05406 | Regression loss: 0.13657 | Running loss: 0.46269\n","Epoch: 1 | Iteration: 2905/2403 | Classification loss: 0.51767 | Regression loss: 0.15914 | Running loss: 0.46311\n","Epoch: 1 | Iteration: 2906/2403 | Classification loss: 0.36310 | Regression loss: 0.29912 | Running loss: 0.46351\n","Epoch: 1 | Iteration: 2907/2403 | Classification loss: 0.60331 | Regression loss: 0.32716 | Running loss: 0.46444\n","Epoch: 1 | Iteration: 2908/2403 | Classification loss: 0.08341 | Regression loss: 0.17884 | Running loss: 0.46404\n","Epoch: 1 | Iteration: 2909/2403 | Classification loss: 0.34872 | Regression loss: 0.35413 | Running loss: 0.46451\n","Epoch: 1 | Iteration: 2910/2403 | Classification loss: 0.12131 | Regression loss: 0.24379 | Running loss: 0.46431\n","Epoch: 1 | Iteration: 2911/2403 | Classification loss: 0.15189 | Regression loss: 0.23051 | Running loss: 0.46415\n","Epoch: 1 | Iteration: 2912/2403 | Classification loss: 0.21846 | Regression loss: 0.31969 | Running loss: 0.46430\n","Epoch: 1 | Iteration: 2913/2403 | Classification loss: 0.08131 | Regression loss: 0.13063 | Running loss: 0.46380\n","Epoch: 1 | Iteration: 2914/2403 | Classification loss: 0.09220 | Regression loss: 0.13865 | Running loss: 0.46335\n","Epoch: 1 | Iteration: 2915/2403 | Classification loss: 0.19117 | Regression loss: 0.16213 | Running loss: 0.46313\n","Epoch: 1 | Iteration: 2916/2403 | Classification loss: 0.11213 | Regression loss: 0.24316 | Running loss: 0.46292\n","Epoch: 1 | Iteration: 2917/2403 | Classification loss: 0.16427 | Regression loss: 0.29996 | Running loss: 0.46292\n","Epoch: 1 | Iteration: 2918/2403 | Classification loss: 0.04504 | Regression loss: 0.24475 | Running loss: 0.46259\n","Epoch: 1 | Iteration: 2919/2403 | Classification loss: 0.06055 | Regression loss: 0.17285 | Running loss: 0.46214\n","Epoch: 1 | Iteration: 2920/2403 | Classification loss: 0.07953 | Regression loss: 0.17631 | Running loss: 0.46174\n","Epoch: 1 | Iteration: 2921/2403 | Classification loss: 0.04436 | Regression loss: 0.15892 | Running loss: 0.46124\n","Epoch: 1 | Iteration: 2922/2403 | Classification loss: 0.06382 | Regression loss: 0.15874 | Running loss: 0.46078\n","Epoch: 1 | Iteration: 2923/2403 | Classification loss: 0.24765 | Regression loss: 0.28763 | Running loss: 0.46093\n","Epoch: 1 | Iteration: 2924/2403 | Classification loss: 0.13456 | Regression loss: 0.20076 | Running loss: 0.46069\n","Epoch: 1 | Iteration: 2925/2403 | Classification loss: 0.06982 | Regression loss: 0.16668 | Running loss: 0.46026\n","Epoch: 1 | Iteration: 2926/2403 | Classification loss: 0.25767 | Regression loss: 0.34458 | Running loss: 0.46053\n","Epoch: 1 | Iteration: 2927/2403 | Classification loss: 0.15621 | Regression loss: 0.30727 | Running loss: 0.46053\n","Epoch: 1 | Iteration: 2928/2403 | Classification loss: 0.04669 | Regression loss: 0.12283 | Running loss: 0.45998\n","Epoch: 1 | Iteration: 2929/2403 | Classification loss: 0.32556 | Regression loss: 0.42533 | Running loss: 0.46053\n","Epoch: 1 | Iteration: 2930/2403 | Classification loss: 0.12019 | Regression loss: 0.15215 | Running loss: 0.46018\n","Epoch: 1 | Iteration: 2931/2403 | Classification loss: 0.10912 | Regression loss: 0.16989 | Running loss: 0.45983\n","Epoch: 1 | Iteration: 2932/2403 | Classification loss: 0.05656 | Regression loss: 0.16327 | Running loss: 0.45938\n","Epoch: 1 | Iteration: 2933/2403 | Classification loss: 0.69998 | Regression loss: 0.19709 | Running loss: 0.46021\n","Epoch: 1 | Iteration: 2934/2403 | Classification loss: 0.33749 | Regression loss: 0.37272 | Running loss: 0.46068\n","Epoch: 1 | Iteration: 2935/2403 | Classification loss: 0.14081 | Regression loss: 0.19474 | Running loss: 0.46044\n","Epoch: 1 | Iteration: 2936/2403 | Classification loss: 0.42558 | Regression loss: 0.25559 | Running loss: 0.46085\n","Epoch: 1 | Iteration: 2937/2403 | Classification loss: 0.08523 | Regression loss: 0.20989 | Running loss: 0.46054\n","Epoch: 1 | Iteration: 2938/2403 | Classification loss: 0.23485 | Regression loss: 0.24838 | Running loss: 0.46059\n","Epoch: 1 | Iteration: 2939/2403 | Classification loss: 0.24237 | Regression loss: 0.15809 | Running loss: 0.46047\n","Epoch: 1 | Iteration: 2940/2403 | Classification loss: 0.14758 | Regression loss: 0.24013 | Running loss: 0.46034\n","Epoch: 1 | Iteration: 2941/2403 | Classification loss: 0.10690 | Regression loss: 0.18034 | Running loss: 0.46002\n","Epoch: 1 | Iteration: 2942/2403 | Classification loss: 0.37652 | Regression loss: 0.23980 | Running loss: 0.46031\n","Epoch: 1 | Iteration: 2943/2403 | Classification loss: 0.10878 | Regression loss: 0.13310 | Running loss: 0.45990\n","Epoch: 1 | Iteration: 2944/2403 | Classification loss: 0.25148 | Regression loss: 0.28707 | Running loss: 0.46005\n","Epoch: 1 | Iteration: 2945/2403 | Classification loss: 0.20597 | Regression loss: 0.24677 | Running loss: 0.46003\n","Epoch: 1 | Iteration: 2946/2403 | Classification loss: 0.17381 | Regression loss: 0.15869 | Running loss: 0.45980\n","Epoch: 1 | Iteration: 2947/2403 | Classification loss: 0.04661 | Regression loss: 0.12292 | Running loss: 0.45927\n","Epoch: 1 | Iteration: 2948/2403 | Classification loss: 0.12327 | Regression loss: 0.22152 | Running loss: 0.45906\n","Epoch: 1 | Iteration: 2949/2403 | Classification loss: 0.27601 | Regression loss: 0.52778 | Running loss: 0.45969\n","Epoch: 1 | Iteration: 2950/2403 | Classification loss: 0.29135 | Regression loss: 0.41130 | Running loss: 0.46013\n","Epoch: 1 | Iteration: 2951/2403 | Classification loss: 0.08888 | Regression loss: 0.18031 | Running loss: 0.45978\n","Epoch: 1 | Iteration: 2952/2403 | Classification loss: 0.08890 | Regression loss: 0.19584 | Running loss: 0.45946\n","Epoch: 1 | Iteration: 2953/2403 | Classification loss: 0.54930 | Regression loss: 0.29014 | Running loss: 0.46016\n","Epoch: 1 | Iteration: 2954/2403 | Classification loss: 0.36940 | Regression loss: 0.23753 | Running loss: 0.46042\n","Epoch: 1 | Iteration: 2955/2403 | Classification loss: 1.06143 | Regression loss: 0.37084 | Running loss: 0.46218\n","Epoch: 1 | Iteration: 2956/2403 | Classification loss: 0.28831 | Regression loss: 0.29775 | Running loss: 0.46241\n","Epoch: 1 | Iteration: 2957/2403 | Classification loss: 0.20763 | Regression loss: 0.19634 | Running loss: 0.46230\n","Epoch: 1 | Iteration: 2958/2403 | Classification loss: 0.09684 | Regression loss: 0.13394 | Running loss: 0.46188\n","Epoch: 1 | Iteration: 2959/2403 | Classification loss: 0.32991 | Regression loss: 0.30753 | Running loss: 0.46220\n","Epoch: 1 | Iteration: 2960/2403 | Classification loss: 0.23373 | Regression loss: 0.22035 | Running loss: 0.46218\n","Epoch: 1 | Iteration: 2961/2403 | Classification loss: 0.32962 | Regression loss: 0.25151 | Running loss: 0.46240\n","Epoch: 1 | Iteration: 2962/2403 | Classification loss: 0.08808 | Regression loss: 0.20473 | Running loss: 0.46209\n","Epoch: 1 | Iteration: 2963/2403 | Classification loss: 0.23307 | Regression loss: 0.20772 | Running loss: 0.46206\n","Epoch: 1 | Iteration: 2964/2403 | Classification loss: 0.14215 | Regression loss: 0.13887 | Running loss: 0.46173\n","Epoch: 1 | Iteration: 2965/2403 | Classification loss: 0.15689 | Regression loss: 0.20819 | Running loss: 0.46156\n","Epoch: 1 | Iteration: 2966/2403 | Classification loss: 0.14110 | Regression loss: 0.20831 | Running loss: 0.46136\n","Epoch: 1 | Iteration: 2967/2403 | Classification loss: 0.14497 | Regression loss: 0.21140 | Running loss: 0.46118\n","Epoch: 1 | Iteration: 2968/2403 | Classification loss: 0.07433 | Regression loss: 0.13011 | Running loss: 0.46072\n","Epoch: 1 | Iteration: 2969/2403 | Classification loss: 0.71029 | Regression loss: 0.32640 | Running loss: 0.46174\n","Epoch: 1 | Iteration: 2970/2403 | Classification loss: 0.31063 | Regression loss: 0.25318 | Running loss: 0.46192\n","Epoch: 1 | Iteration: 2971/2403 | Classification loss: 0.14825 | Regression loss: 0.15998 | Running loss: 0.46165\n","Epoch: 1 | Iteration: 2972/2403 | Classification loss: 0.27970 | Regression loss: 0.28282 | Running loss: 0.46183\n","Epoch: 1 | Iteration: 2973/2403 | Classification loss: 0.09885 | Regression loss: 0.16787 | Running loss: 0.46148\n","Epoch: 1 | Iteration: 2974/2403 | Classification loss: 0.07239 | Regression loss: 0.12877 | Running loss: 0.46103\n","Epoch: 1 | Iteration: 2975/2403 | Classification loss: 0.10047 | Regression loss: 0.17773 | Running loss: 0.46071\n","Epoch: 1 | Iteration: 2976/2403 | Classification loss: 0.46949 | Regression loss: 0.45398 | Running loss: 0.46152\n","Epoch: 1 | Iteration: 2977/2403 | Classification loss: 0.06365 | Regression loss: 0.17980 | Running loss: 0.46114\n","Epoch: 1 | Iteration: 2978/2403 | Classification loss: 0.37944 | Regression loss: 0.36532 | Running loss: 0.46163\n","Epoch: 1 | Iteration: 2979/2403 | Classification loss: 0.20488 | Regression loss: 0.31829 | Running loss: 0.46174\n","Epoch: 1 | Iteration: 2980/2403 | Classification loss: 0.05929 | Regression loss: 0.14713 | Running loss: 0.46129\n","Epoch: 1 | Iteration: 2981/2403 | Classification loss: 0.05614 | Regression loss: 0.14362 | Running loss: 0.46084\n","Epoch: 1 | Iteration: 2982/2403 | Classification loss: 0.16873 | Regression loss: 0.25953 | Running loss: 0.46079\n","Epoch: 1 | Iteration: 2983/2403 | Classification loss: 0.22928 | Regression loss: 0.18313 | Running loss: 0.46070\n","Epoch: 1 | Iteration: 2984/2403 | Classification loss: 0.29522 | Regression loss: 0.30537 | Running loss: 0.46094\n","Epoch: 1 | Iteration: 2985/2403 | Classification loss: 0.11838 | Regression loss: 0.14806 | Running loss: 0.46061\n","Epoch: 1 | Iteration: 2986/2403 | Classification loss: 0.18740 | Regression loss: 0.23390 | Running loss: 0.46054\n","Epoch: 1 | Iteration: 2987/2403 | Classification loss: 0.11390 | Regression loss: 0.19065 | Running loss: 0.46027\n","Epoch: 1 | Iteration: 2988/2403 | Classification loss: 0.26454 | Regression loss: 0.19784 | Running loss: 0.46028\n","Epoch: 1 | Iteration: 2989/2403 | Classification loss: 0.23986 | Regression loss: 0.16800 | Running loss: 0.46019\n","Epoch: 1 | Iteration: 2990/2403 | Classification loss: 0.12651 | Regression loss: 0.22975 | Running loss: 0.46001\n","Epoch: 1 | Iteration: 2991/2403 | Classification loss: 0.09568 | Regression loss: 0.17183 | Running loss: 0.45968\n","Epoch: 1 | Iteration: 2992/2403 | Classification loss: 0.23024 | Regression loss: 0.21907 | Running loss: 0.45967\n","Epoch: 1 | Iteration: 2993/2403 | Classification loss: 0.06798 | Regression loss: 0.17429 | Running loss: 0.45930\n","Epoch: 1 | Iteration: 2994/2403 | Classification loss: 0.11451 | Regression loss: 0.20100 | Running loss: 0.45905\n","Epoch: 1 | Iteration: 2995/2403 | Classification loss: 0.14491 | Regression loss: 0.18000 | Running loss: 0.45883\n","Epoch: 1 | Iteration: 2996/2403 | Classification loss: 0.75210 | Regression loss: 0.21900 | Running loss: 0.45969\n","Epoch: 1 | Iteration: 2997/2403 | Classification loss: 0.17633 | Regression loss: 0.20121 | Running loss: 0.45955\n","Epoch: 1 | Iteration: 2998/2403 | Classification loss: 0.68781 | Regression loss: 0.28394 | Running loss: 0.46041\n","Epoch: 1 | Iteration: 2999/2403 | Classification loss: 0.33933 | Regression loss: 0.23325 | Running loss: 0.46060\n","Epoch: 1 | Iteration: 3000/2403 | Classification loss: 0.15037 | Regression loss: 0.25898 | Running loss: 0.46052\n","Epoch: 1 | Iteration: 3001/2403 | Classification loss: 0.29465 | Regression loss: 0.33689 | Running loss: 0.46080\n","Epoch: 1 | Iteration: 3002/2403 | Classification loss: 0.13486 | Regression loss: 0.17332 | Running loss: 0.46055\n","Epoch: 1 | Iteration: 3003/2403 | Classification loss: 0.19882 | Regression loss: 0.13545 | Running loss: 0.46034\n","Epoch: 1 | Iteration: 3004/2403 | Classification loss: 0.15514 | Regression loss: 0.17321 | Running loss: 0.46012\n","Epoch: 1 | Iteration: 3005/2403 | Classification loss: 0.27589 | Regression loss: 0.29848 | Running loss: 0.46031\n","Epoch: 1 | Iteration: 3006/2403 | Classification loss: 0.07044 | Regression loss: 0.18177 | Running loss: 0.45996\n","Epoch: 1 | Iteration: 3007/2403 | Classification loss: 0.08713 | Regression loss: 0.19609 | Running loss: 0.45967\n","Epoch: 1 | Iteration: 3008/2403 | Classification loss: 0.23937 | Regression loss: 0.18293 | Running loss: 0.45961\n","Epoch: 1 | Iteration: 3009/2403 | Classification loss: 0.15170 | Regression loss: 0.21086 | Running loss: 0.45945\n","Epoch: 1 | Iteration: 3010/2403 | Classification loss: 0.10586 | Regression loss: 0.12279 | Running loss: 0.45907\n","Epoch: 1 | Iteration: 3011/2403 | Classification loss: 0.21323 | Regression loss: 0.20546 | Running loss: 0.45900\n","Epoch: 1 | Iteration: 3012/2403 | Classification loss: 0.08223 | Regression loss: 0.17197 | Running loss: 0.45866\n","Epoch: 1 | Iteration: 3013/2403 | Classification loss: 0.03700 | Regression loss: 0.10316 | Running loss: 0.45814\n","Epoch: 1 | Iteration: 3014/2403 | Classification loss: 0.74310 | Regression loss: 0.54448 | Running loss: 0.45950\n","Epoch: 1 | Iteration: 3015/2403 | Classification loss: 0.22731 | Regression loss: 0.17408 | Running loss: 0.45941\n","Epoch: 1 | Iteration: 3016/2403 | Classification loss: 0.15178 | Regression loss: 0.16085 | Running loss: 0.45917\n","Epoch: 1 | Iteration: 3017/2403 | Classification loss: 0.20648 | Regression loss: 0.20571 | Running loss: 0.45909\n","Epoch: 1 | Iteration: 3018/2403 | Classification loss: 0.17247 | Regression loss: 0.22873 | Running loss: 0.45900\n","Epoch: 1 | Iteration: 3019/2403 | Classification loss: 0.06061 | Regression loss: 0.12024 | Running loss: 0.45854\n","Epoch: 1 | Iteration: 3020/2403 | Classification loss: 0.22848 | Regression loss: 0.27504 | Running loss: 0.45862\n","Epoch: 1 | Iteration: 3021/2403 | Classification loss: 0.13908 | Regression loss: 0.24965 | Running loss: 0.45850\n","Epoch: 1 | Iteration: 3022/2403 | Classification loss: 0.50144 | Regression loss: 0.32012 | Running loss: 0.45909\n","Epoch: 1 | Iteration: 3023/2403 | Classification loss: 0.09546 | Regression loss: 0.27505 | Running loss: 0.45895\n","Epoch: 1 | Iteration: 3024/2403 | Classification loss: 0.34113 | Regression loss: 0.25371 | Running loss: 0.45917\n","Epoch: 1 | Iteration: 3025/2403 | Classification loss: 0.19058 | Regression loss: 0.21447 | Running loss: 0.45908\n","Epoch: 1 | Iteration: 3026/2403 | Classification loss: 0.33152 | Regression loss: 0.22310 | Running loss: 0.45923\n","Epoch: 1 | Iteration: 3027/2403 | Classification loss: 0.23213 | Regression loss: 0.29190 | Running loss: 0.45934\n","Epoch: 1 | Iteration: 3028/2403 | Classification loss: 0.19606 | Regression loss: 0.26735 | Running loss: 0.45934\n","Epoch: 1 | Iteration: 3029/2403 | Classification loss: 0.29129 | Regression loss: 0.27805 | Running loss: 0.45952\n","Epoch: 1 | Iteration: 3030/2403 | Classification loss: 0.37200 | Regression loss: 0.26269 | Running loss: 0.45980\n","Epoch: 1 | Iteration: 3031/2403 | Classification loss: 0.12534 | Regression loss: 0.21915 | Running loss: 0.45961\n","Epoch: 1 | Iteration: 3032/2403 | Classification loss: 0.17455 | Regression loss: 0.20561 | Running loss: 0.45949\n","Epoch: 1 | Iteration: 3033/2403 | Classification loss: 0.28392 | Regression loss: 0.28706 | Running loss: 0.45966\n","Epoch: 1 | Iteration: 3034/2403 | Classification loss: 0.37923 | Regression loss: 0.29426 | Running loss: 0.46000\n","Epoch: 1 | Iteration: 3035/2403 | Classification loss: 0.32979 | Regression loss: 0.26555 | Running loss: 0.46022\n","Epoch: 1 | Iteration: 3036/2403 | Classification loss: 0.26155 | Regression loss: 0.29580 | Running loss: 0.46037\n","Epoch: 1 | Iteration: 3037/2403 | Classification loss: 0.14418 | Regression loss: 0.12465 | Running loss: 0.46007\n","Epoch: 1 | Iteration: 3038/2403 | Classification loss: 0.09864 | Regression loss: 0.17750 | Running loss: 0.45978\n","Epoch: 1 | Iteration: 3039/2403 | Classification loss: 0.09803 | Regression loss: 0.23193 | Running loss: 0.45958\n","Epoch: 1 | Iteration: 3040/2403 | Classification loss: 0.09290 | Regression loss: 0.16643 | Running loss: 0.45926\n","Epoch: 1 | Iteration: 3041/2403 | Classification loss: 0.07286 | Regression loss: 0.19538 | Running loss: 0.45896\n","Epoch: 1 | Iteration: 3042/2403 | Classification loss: 0.53729 | Regression loss: 0.25839 | Running loss: 0.45949\n","Epoch: 1 | Iteration: 3043/2403 | Classification loss: 0.25873 | Regression loss: 0.29174 | Running loss: 0.45963\n","Epoch: 1 | Iteration: 3044/2403 | Classification loss: 0.55952 | Regression loss: 0.29387 | Running loss: 0.46024\n","Epoch: 1 | Iteration: 3045/2403 | Classification loss: 0.29319 | Regression loss: 0.25288 | Running loss: 0.46038\n","Epoch: 1 | Iteration: 3046/2403 | Classification loss: 0.17067 | Regression loss: 0.18251 | Running loss: 0.46021\n","Epoch: 1 | Iteration: 3047/2403 | Classification loss: 0.25035 | Regression loss: 0.20697 | Running loss: 0.46021\n","Epoch: 1 | Iteration: 3048/2403 | Classification loss: 0.16138 | Regression loss: 0.22499 | Running loss: 0.46009\n","Epoch: 1 | Iteration: 3049/2403 | Classification loss: 0.48037 | Regression loss: 0.35289 | Running loss: 0.46067\n","Epoch: 1 | Iteration: 3050/2403 | Classification loss: 0.09292 | Regression loss: 0.16732 | Running loss: 0.46036\n","Epoch: 1 | Iteration: 3051/2403 | Classification loss: 0.14042 | Regression loss: 0.16104 | Running loss: 0.46012\n","Epoch: 1 | Iteration: 3052/2403 | Classification loss: 0.13454 | Regression loss: 0.20956 | Running loss: 0.45994\n","Epoch: 1 | Iteration: 3053/2403 | Classification loss: 0.50954 | Regression loss: 0.19847 | Running loss: 0.46032\n","Epoch: 1 | Iteration: 3054/2403 | Classification loss: 0.05814 | Regression loss: 0.17788 | Running loss: 0.45997\n","Epoch: 1 | Iteration: 3055/2403 | Classification loss: 0.75561 | Regression loss: 0.19499 | Running loss: 0.46073\n","Epoch: 1 | Iteration: 3056/2403 | Classification loss: 0.06872 | Regression loss: 0.15999 | Running loss: 0.46037\n","Epoch: 1 | Iteration: 3057/2403 | Classification loss: 0.19333 | Regression loss: 0.27531 | Running loss: 0.46038\n","Epoch: 1 | Iteration: 3058/2403 | Classification loss: 0.19961 | Regression loss: 0.23113 | Running loss: 0.46034\n","Epoch: 1 | Iteration: 3059/2403 | Classification loss: 1.76423 | Regression loss: 0.51398 | Running loss: 0.46311\n","Epoch: 1 | Iteration: 3060/2403 | Classification loss: 0.13465 | Regression loss: 0.19984 | Running loss: 0.46291\n","Epoch: 1 | Iteration: 3061/2403 | Classification loss: 0.16822 | Regression loss: 0.25508 | Running loss: 0.46285\n","Epoch: 1 | Iteration: 3062/2403 | Classification loss: 0.06150 | Regression loss: 0.16939 | Running loss: 0.46250\n","Epoch: 1 | Iteration: 3063/2403 | Classification loss: 0.08200 | Regression loss: 0.18991 | Running loss: 0.46221\n","Epoch: 1 | Iteration: 3064/2403 | Classification loss: 0.20271 | Regression loss: 0.20894 | Running loss: 0.46214\n","Epoch: 1 | Iteration: 3065/2403 | Classification loss: 0.11431 | Regression loss: 0.14981 | Running loss: 0.46184\n","Epoch: 1 | Iteration: 3066/2403 | Classification loss: 0.13346 | Regression loss: 0.26302 | Running loss: 0.46174\n","Epoch: 1 | Iteration: 3067/2403 | Classification loss: 0.38720 | Regression loss: 0.30694 | Running loss: 0.46209\n","Epoch: 1 | Iteration: 3068/2403 | Classification loss: 0.09394 | Regression loss: 0.24293 | Running loss: 0.46190\n","Epoch: 1 | Iteration: 3069/2403 | Classification loss: 0.35408 | Regression loss: 0.22329 | Running loss: 0.46207\n","Epoch: 1 | Iteration: 3070/2403 | Classification loss: 0.27239 | Regression loss: 0.23359 | Running loss: 0.46214\n","Epoch: 1 | Iteration: 3071/2403 | Classification loss: 0.20853 | Regression loss: 0.15592 | Running loss: 0.46199\n","Epoch: 1 | Iteration: 3072/2403 | Classification loss: 0.18590 | Regression loss: 0.23287 | Running loss: 0.46193\n","Epoch: 1 | Iteration: 3073/2403 | Classification loss: 0.13546 | Regression loss: 0.17887 | Running loss: 0.46171\n","Epoch: 1 | Iteration: 3074/2403 | Classification loss: 0.13241 | Regression loss: 0.23960 | Running loss: 0.46157\n","Epoch: 1 | Iteration: 3075/2403 | Classification loss: 0.13800 | Regression loss: 0.21164 | Running loss: 0.46141\n","Epoch: 1 | Iteration: 3076/2403 | Classification loss: 0.06572 | Regression loss: 0.12630 | Running loss: 0.46101\n","Epoch: 1 | Iteration: 3077/2403 | Classification loss: 0.22888 | Regression loss: 0.29549 | Running loss: 0.46110\n","Epoch: 1 | Iteration: 3078/2403 | Classification loss: 0.47252 | Regression loss: 0.27176 | Running loss: 0.46152\n","Epoch: 1 | Iteration: 3079/2403 | Classification loss: 0.21669 | Regression loss: 0.22551 | Running loss: 0.46149\n","Epoch: 1 | Iteration: 3080/2403 | Classification loss: 0.03802 | Regression loss: 0.15963 | Running loss: 0.46110\n","Epoch: 1 | Iteration: 3081/2403 | Classification loss: 0.13922 | Regression loss: 0.26577 | Running loss: 0.46102\n","Epoch: 1 | Iteration: 3082/2403 | Classification loss: 0.24971 | Regression loss: 0.23500 | Running loss: 0.46106\n","Epoch: 1 | Iteration: 3083/2403 | Classification loss: 0.20813 | Regression loss: 0.16475 | Running loss: 0.46093\n","Epoch: 1 | Iteration: 3084/2403 | Classification loss: 0.14134 | Regression loss: 0.18009 | Running loss: 0.46072\n","Epoch: 1 | Iteration: 3085/2403 | Classification loss: 0.32598 | Regression loss: 0.25386 | Running loss: 0.46090\n","Epoch: 1 | Iteration: 3086/2403 | Classification loss: 0.43292 | Regression loss: 0.28452 | Running loss: 0.46127\n","Epoch: 1 | Iteration: 3087/2403 | Classification loss: 0.12210 | Regression loss: 0.16865 | Running loss: 0.46102\n","Epoch: 1 | Iteration: 3088/2403 | Classification loss: 0.13974 | Regression loss: 0.20582 | Running loss: 0.46085\n","Epoch: 1 | Iteration: 3089/2403 | Classification loss: 0.33021 | Regression loss: 0.22487 | Running loss: 0.46099\n","Epoch: 1 | Iteration: 3090/2403 | Classification loss: 0.17924 | Regression loss: 0.19210 | Running loss: 0.46086\n","Epoch: 1 | Iteration: 3091/2403 | Classification loss: 0.18706 | Regression loss: 0.17663 | Running loss: 0.46072\n","Epoch: 1 | Iteration: 3092/2403 | Classification loss: 0.18534 | Regression loss: 0.17817 | Running loss: 0.46058\n","Epoch: 1 | Iteration: 3093/2403 | Classification loss: 0.30792 | Regression loss: 0.37562 | Running loss: 0.46090\n","Epoch: 1 | Iteration: 3094/2403 | Classification loss: 0.26343 | Regression loss: 0.24862 | Running loss: 0.46097\n","Epoch: 1 | Iteration: 3095/2403 | Classification loss: 0.25785 | Regression loss: 0.28497 | Running loss: 0.46109\n","Epoch: 1 | Iteration: 3096/2403 | Classification loss: 0.04790 | Regression loss: 0.15978 | Running loss: 0.46073\n","Epoch: 1 | Iteration: 3097/2403 | Classification loss: 0.05051 | Regression loss: 0.17300 | Running loss: 0.46039\n","Epoch: 1 | Iteration: 3098/2403 | Classification loss: 0.06206 | Regression loss: 0.11865 | Running loss: 0.45998\n","Epoch: 1 | Iteration: 3099/2403 | Classification loss: 0.09102 | Regression loss: 0.12918 | Running loss: 0.45964\n","Epoch: 1 | Iteration: 3100/2403 | Classification loss: 0.19616 | Regression loss: 0.22339 | Running loss: 0.45958\n","Epoch: 1 | Iteration: 3101/2403 | Classification loss: 0.18337 | Regression loss: 0.20860 | Running loss: 0.45948\n","Epoch: 1 | Iteration: 3102/2403 | Classification loss: 0.12115 | Regression loss: 0.17011 | Running loss: 0.45924\n","Epoch: 1 | Iteration: 3103/2403 | Classification loss: 0.05228 | Regression loss: 0.16853 | Running loss: 0.45890\n","Epoch: 1 | Iteration: 3104/2403 | Classification loss: 0.15248 | Regression loss: 0.22054 | Running loss: 0.45878\n","Epoch: 1 | Iteration: 3105/2403 | Classification loss: 0.11378 | Regression loss: 0.15812 | Running loss: 0.45851\n","Epoch: 1 | Iteration: 3106/2403 | Classification loss: 0.10736 | Regression loss: 0.13740 | Running loss: 0.45821\n","Epoch: 1 | Iteration: 3107/2403 | Classification loss: 0.21609 | Regression loss: 0.20333 | Running loss: 0.45816\n","Epoch: 1 | Iteration: 3108/2403 | Classification loss: 0.07222 | Regression loss: 0.17832 | Running loss: 0.45786\n","Epoch: 1 | Iteration: 3109/2403 | Classification loss: 0.09833 | Regression loss: 0.23742 | Running loss: 0.45769\n","Epoch: 1 | Iteration: 3110/2403 | Classification loss: 0.19886 | Regression loss: 0.26569 | Running loss: 0.45770\n","Epoch: 1 | Iteration: 3111/2403 | Classification loss: 0.19164 | Regression loss: 0.22471 | Running loss: 0.45764\n","Epoch: 1 | Iteration: 3112/2403 | Classification loss: 0.18980 | Regression loss: 0.21762 | Running loss: 0.45757\n","Epoch: 1 | Iteration: 3113/2403 | Classification loss: 0.29429 | Regression loss: 0.33431 | Running loss: 0.45781\n","Epoch: 1 | Iteration: 3114/2403 | Classification loss: 0.03927 | Regression loss: 0.16995 | Running loss: 0.45746\n","Epoch: 1 | Iteration: 3115/2403 | Classification loss: 0.38302 | Regression loss: 0.29402 | Running loss: 0.45777\n","Epoch: 1 | Iteration: 3116/2403 | Classification loss: 0.45599 | Regression loss: 0.39216 | Running loss: 0.45832\n","Epoch: 1 | Iteration: 3117/2403 | Classification loss: 0.14584 | Regression loss: 0.24387 | Running loss: 0.45822\n","Epoch: 1 | Iteration: 3118/2403 | Classification loss: 0.16613 | Regression loss: 0.19961 | Running loss: 0.45809\n","Epoch: 1 | Iteration: 3119/2403 | Classification loss: 0.05810 | Regression loss: 0.15008 | Running loss: 0.45774\n","Epoch: 1 | Iteration: 3120/2403 | Classification loss: 0.09275 | Regression loss: 0.20382 | Running loss: 0.45752\n","Epoch: 1 | Iteration: 3121/2403 | Classification loss: 0.05253 | Regression loss: 0.17012 | Running loss: 0.45719\n","Epoch: 1 | Iteration: 3122/2403 | Classification loss: 0.19977 | Regression loss: 0.24782 | Running loss: 0.45718\n","Epoch: 1 | Iteration: 3123/2403 | Classification loss: 0.18697 | Regression loss: 0.27997 | Running loss: 0.45719\n","Epoch: 1 | Iteration: 3124/2403 | Classification loss: 0.25866 | Regression loss: 0.30531 | Running loss: 0.45734\n","Epoch: 1 | Iteration: 3125/2403 | Classification loss: 0.14838 | Regression loss: 0.19933 | Running loss: 0.45719\n","Epoch: 1 | Iteration: 3126/2403 | Classification loss: 0.07334 | Regression loss: 0.15113 | Running loss: 0.45686\n","Epoch: 1 | Iteration: 3127/2403 | Classification loss: 0.29042 | Regression loss: 0.32109 | Running loss: 0.45708\n","Epoch: 1 | Iteration: 3128/2403 | Classification loss: 0.28734 | Regression loss: 0.31970 | Running loss: 0.45728\n","Epoch: 1 | Iteration: 3129/2403 | Classification loss: 0.23091 | Regression loss: 0.25555 | Running loss: 0.45732\n","Epoch: 1 | Iteration: 3130/2403 | Classification loss: 0.20618 | Regression loss: 0.23967 | Running loss: 0.45731\n","Epoch: 1 | Iteration: 3131/2403 | Classification loss: 0.21059 | Regression loss: 0.25634 | Running loss: 0.45732\n","Epoch: 1 | Iteration: 3132/2403 | Classification loss: 0.72014 | Regression loss: 0.28141 | Running loss: 0.45807\n","Epoch: 1 | Iteration: 3133/2403 | Classification loss: 0.26028 | Regression loss: 0.28098 | Running loss: 0.45818\n","Epoch: 1 | Iteration: 3134/2403 | Classification loss: 0.05334 | Regression loss: 0.12705 | Running loss: 0.45780\n","Epoch: 1 | Iteration: 3135/2403 | Classification loss: 0.26023 | Regression loss: 0.21412 | Running loss: 0.45782\n","Epoch: 1 | Iteration: 3136/2403 | Classification loss: 0.18015 | Regression loss: 0.14817 | Running loss: 0.45765\n","Epoch: 1 | Iteration: 3137/2403 | Classification loss: 0.07839 | Regression loss: 0.16090 | Running loss: 0.45735\n","Epoch: 1 | Iteration: 3138/2403 | Classification loss: 0.05306 | Regression loss: 0.12625 | Running loss: 0.45697\n","Epoch: 1 | Iteration: 3139/2403 | Classification loss: 0.07432 | Regression loss: 0.17404 | Running loss: 0.45669\n","Epoch: 1 | Iteration: 3140/2403 | Classification loss: 0.16564 | Regression loss: 0.27863 | Running loss: 0.45667\n","Epoch: 1 | Iteration: 3141/2403 | Classification loss: 0.08513 | Regression loss: 0.20453 | Running loss: 0.45645\n","Epoch: 1 | Iteration: 3142/2403 | Classification loss: 0.21225 | Regression loss: 0.26105 | Running loss: 0.45647\n","Epoch: 1 | Iteration: 3143/2403 | Classification loss: 0.27191 | Regression loss: 0.33614 | Running loss: 0.45667\n","Epoch: 1 | Iteration: 3144/2403 | Classification loss: 0.22818 | Regression loss: 0.28462 | Running loss: 0.45675\n","Epoch: 1 | Iteration: 3145/2403 | Classification loss: 0.30243 | Regression loss: 0.25569 | Running loss: 0.45689\n","Epoch: 1 | Iteration: 3146/2403 | Classification loss: 0.19289 | Regression loss: 0.21412 | Running loss: 0.45682\n","Epoch: 1 | Iteration: 3147/2403 | Classification loss: 0.40607 | Regression loss: 0.31128 | Running loss: 0.45717\n","Epoch: 1 | Iteration: 3148/2403 | Classification loss: 0.21661 | Regression loss: 0.26735 | Running loss: 0.45720\n","Epoch: 1 | Iteration: 3149/2403 | Classification loss: 0.11315 | Regression loss: 0.16126 | Running loss: 0.45696\n","Epoch: 1 | Iteration: 3150/2403 | Classification loss: 0.16747 | Regression loss: 0.29450 | Running loss: 0.45697\n","Epoch: 1 | Iteration: 3151/2403 | Classification loss: 0.20679 | Regression loss: 0.30771 | Running loss: 0.45704\n","Epoch: 1 | Iteration: 3152/2403 | Classification loss: 0.30174 | Regression loss: 0.27445 | Running loss: 0.45720\n","Epoch: 1 | Iteration: 3153/2403 | Classification loss: 0.20142 | Regression loss: 0.21082 | Running loss: 0.45714\n","Epoch: 1 | Iteration: 3154/2403 | Classification loss: 0.13471 | Regression loss: 0.23494 | Running loss: 0.45703\n","Epoch: 1 | Iteration: 3155/2403 | Classification loss: 0.66175 | Regression loss: 0.31049 | Running loss: 0.45771\n","Epoch: 1 | Iteration: 3156/2403 | Classification loss: 0.15809 | Regression loss: 0.19063 | Running loss: 0.45757\n","Epoch: 1 | Iteration: 3157/2403 | Classification loss: 0.36834 | Regression loss: 0.34348 | Running loss: 0.45790\n","Epoch: 1 | Iteration: 3158/2403 | Classification loss: 0.27084 | Regression loss: 0.23975 | Running loss: 0.45797\n","Epoch: 1 | Iteration: 3159/2403 | Classification loss: 0.18709 | Regression loss: 0.28493 | Running loss: 0.45799\n","Epoch: 1 | Iteration: 3160/2403 | Classification loss: 0.26139 | Regression loss: 0.36067 | Running loss: 0.45821\n","Epoch: 1 | Iteration: 3161/2403 | Classification loss: 0.09016 | Regression loss: 0.18649 | Running loss: 0.45797\n","Epoch: 1 | Iteration: 3162/2403 | Classification loss: 0.11663 | Regression loss: 0.16265 | Running loss: 0.45773\n","Epoch: 1 | Iteration: 3163/2403 | Classification loss: 0.38543 | Regression loss: 0.29902 | Running loss: 0.45803\n","Epoch: 1 | Iteration: 3164/2403 | Classification loss: 0.07519 | Regression loss: 0.20721 | Running loss: 0.45780\n","Epoch: 1 | Iteration: 3165/2403 | Classification loss: 0.31822 | Regression loss: 0.34578 | Running loss: 0.45807\n","Epoch: 1 | Iteration: 3166/2403 | Classification loss: 0.05747 | Regression loss: 0.16635 | Running loss: 0.45776\n","Epoch: 1 | Iteration: 3167/2403 | Classification loss: 0.29556 | Regression loss: 0.26809 | Running loss: 0.45790\n","Epoch: 1 | Iteration: 3168/2403 | Classification loss: 0.12921 | Regression loss: 0.27488 | Running loss: 0.45783\n","Epoch: 1 | Iteration: 3169/2403 | Classification loss: 0.76942 | Regression loss: 0.18844 | Running loss: 0.45849\n","Epoch: 1 | Iteration: 3170/2403 | Classification loss: 0.12570 | Regression loss: 0.26115 | Running loss: 0.45839\n","Epoch: 1 | Iteration: 3171/2403 | Classification loss: 0.27042 | Regression loss: 0.26430 | Running loss: 0.45849\n","Epoch: 1 | Iteration: 3172/2403 | Classification loss: 0.31542 | Regression loss: 0.26035 | Running loss: 0.45864\n","Epoch: 1 | Iteration: 3173/2403 | Classification loss: 0.07505 | Regression loss: 0.15684 | Running loss: 0.45835\n","Epoch: 1 | Iteration: 3174/2403 | Classification loss: 0.14728 | Regression loss: 0.19704 | Running loss: 0.45820\n","Epoch: 1 | Iteration: 3175/2403 | Classification loss: 0.07820 | Regression loss: 0.18705 | Running loss: 0.45795\n","Epoch: 1 | Iteration: 3176/2403 | Classification loss: 0.10564 | Regression loss: 0.29173 | Running loss: 0.45787\n","Epoch: 1 | Iteration: 3177/2403 | Classification loss: 0.15092 | Regression loss: 0.17097 | Running loss: 0.45770\n","Epoch: 1 | Iteration: 3178/2403 | Classification loss: 0.56819 | Regression loss: 0.25084 | Running loss: 0.45816\n","Epoch: 1 | Iteration: 3179/2403 | Classification loss: 0.30090 | Regression loss: 0.28907 | Running loss: 0.45833\n","Epoch: 1 | Iteration: 3180/2403 | Classification loss: 0.11374 | Regression loss: 0.16178 | Running loss: 0.45810\n","Epoch: 1 | Iteration: 3181/2403 | Classification loss: 0.06548 | Regression loss: 0.11190 | Running loss: 0.45774\n","Epoch: 1 | Iteration: 3182/2403 | Classification loss: 0.28709 | Regression loss: 0.28085 | Running loss: 0.45788\n","Epoch: 1 | Iteration: 3183/2403 | Classification loss: 0.09903 | Regression loss: 0.13423 | Running loss: 0.45759\n","Epoch: 1 | Iteration: 3184/2403 | Classification loss: 0.19590 | Regression loss: 0.24303 | Running loss: 0.45757\n","Epoch: 1 | Iteration: 3185/2403 | Classification loss: 0.34716 | Regression loss: 0.32432 | Running loss: 0.45784\n","Epoch: 1 | Iteration: 3186/2403 | Classification loss: 0.28464 | Regression loss: 0.23296 | Running loss: 0.45792\n","Epoch: 1 | Iteration: 3187/2403 | Classification loss: 0.07038 | Regression loss: 0.14196 | Running loss: 0.45760\n","Epoch: 1 | Iteration: 3188/2403 | Classification loss: 0.16992 | Regression loss: 0.23805 | Running loss: 0.45754\n","Epoch: 1 | Iteration: 3189/2403 | Classification loss: 0.13290 | Regression loss: 0.17160 | Running loss: 0.45735\n","Epoch: 1 | Iteration: 3190/2403 | Classification loss: 0.06760 | Regression loss: 0.14437 | Running loss: 0.45703\n","Epoch: 1 | Iteration: 3191/2403 | Classification loss: 0.42612 | Regression loss: 0.26198 | Running loss: 0.45733\n","Epoch: 1 | Iteration: 3192/2403 | Classification loss: 0.28824 | Regression loss: 0.28283 | Running loss: 0.45747\n","Epoch: 1 | Iteration: 3193/2403 | Classification loss: 0.32734 | Regression loss: 0.29951 | Running loss: 0.45769\n","Epoch: 1 | Iteration: 3194/2403 | Classification loss: 0.17120 | Regression loss: 0.28125 | Running loss: 0.45768\n","Epoch: 1 | Iteration: 3195/2403 | Classification loss: 0.29811 | Regression loss: 0.19026 | Running loss: 0.45772\n","Epoch: 1 | Iteration: 3196/2403 | Classification loss: 0.31898 | Regression loss: 0.23902 | Running loss: 0.45784\n","Epoch: 1 | Iteration: 3197/2403 | Classification loss: 0.17027 | Regression loss: 0.26359 | Running loss: 0.45781\n","Epoch: 1 | Iteration: 3198/2403 | Classification loss: 0.12891 | Regression loss: 0.24790 | Running loss: 0.45771\n","Epoch: 1 | Iteration: 3199/2403 | Classification loss: 0.14650 | Regression loss: 0.21384 | Running loss: 0.45759\n","Epoch: 1 | Iteration: 3200/2403 | Classification loss: 0.07537 | Regression loss: 0.12767 | Running loss: 0.45727\n","Epoch: 1 | Iteration: 3201/2403 | Classification loss: 0.18313 | Regression loss: 0.18782 | Running loss: 0.45716\n","Epoch: 1 | Iteration: 3202/2403 | Classification loss: 0.17694 | Regression loss: 0.14218 | Running loss: 0.45699\n","Epoch: 1 | Iteration: 3203/2403 | Classification loss: 0.42217 | Regression loss: 0.56440 | Running loss: 0.45765\n","Epoch: 1 | Iteration: 3204/2403 | Classification loss: 0.05723 | Regression loss: 0.18076 | Running loss: 0.45738\n","Epoch: 1 | Iteration: 3205/2403 | Classification loss: 0.35408 | Regression loss: 0.29914 | Running loss: 0.45762\n","Epoch: 1 | Iteration: 3206/2403 | Classification loss: 0.35662 | Regression loss: 0.26414 | Running loss: 0.45783\n","Epoch: 1 | Iteration: 3207/2403 | Classification loss: 0.16319 | Regression loss: 0.24079 | Running loss: 0.45776\n","Epoch: 1 | Iteration: 3208/2403 | Classification loss: 0.14658 | Regression loss: 0.18161 | Running loss: 0.45760\n","Epoch: 1 | Iteration: 3209/2403 | Classification loss: 0.15137 | Regression loss: 0.30813 | Running loss: 0.45760\n","Epoch: 1 | Iteration: 3210/2403 | Classification loss: 0.43625 | Regression loss: 0.27991 | Running loss: 0.45792\n","Epoch: 1 | Iteration: 3211/2403 | Classification loss: 0.07008 | Regression loss: 0.11868 | Running loss: 0.45759\n","Epoch: 1 | Iteration: 3212/2403 | Classification loss: 0.20372 | Regression loss: 0.26179 | Running loss: 0.45760\n","Epoch: 1 | Iteration: 3213/2403 | Classification loss: 0.08069 | Regression loss: 0.13539 | Running loss: 0.45730\n","Epoch: 1 | Iteration: 3214/2403 | Classification loss: 0.09878 | Regression loss: 0.13423 | Running loss: 0.45702\n","Epoch: 1 | Iteration: 3215/2403 | Classification loss: 0.36844 | Regression loss: 0.23551 | Running loss: 0.45720\n","Epoch: 1 | Iteration: 3216/2403 | Classification loss: 0.09511 | Regression loss: 0.26098 | Running loss: 0.45708\n","Epoch: 1 | Iteration: 3217/2403 | Classification loss: 0.38126 | Regression loss: 0.37135 | Running loss: 0.45744\n","Epoch: 1 | Iteration: 3218/2403 | Classification loss: 0.07569 | Regression loss: 0.11790 | Running loss: 0.45712\n","Epoch: 1 | Iteration: 3219/2403 | Classification loss: 0.09822 | Regression loss: 0.15548 | Running loss: 0.45687\n","Epoch: 1 | Iteration: 3220/2403 | Classification loss: 0.30621 | Regression loss: 0.28542 | Running loss: 0.45703\n","Epoch: 1 | Iteration: 3221/2403 | Classification loss: 0.22046 | Regression loss: 0.24034 | Running loss: 0.45704\n","Epoch: 1 | Iteration: 3222/2403 | Classification loss: 0.22475 | Regression loss: 0.31665 | Running loss: 0.45714\n","Epoch: 1 | Iteration: 3223/2403 | Classification loss: 0.36026 | Regression loss: 0.20479 | Running loss: 0.45727\n","Epoch: 1 | Iteration: 3224/2403 | Classification loss: 0.38882 | Regression loss: 0.25755 | Running loss: 0.45750\n","Epoch: 1 | Iteration: 3225/2403 | Classification loss: 0.28138 | Regression loss: 0.29036 | Running loss: 0.45764\n","Epoch: 1 | Iteration: 3226/2403 | Classification loss: 0.47394 | Regression loss: 0.39806 | Running loss: 0.45815\n","Epoch: 1 | Iteration: 3227/2403 | Classification loss: 0.25503 | Regression loss: 0.32787 | Running loss: 0.45830\n","Epoch: 1 | Iteration: 3228/2403 | Classification loss: 0.16491 | Regression loss: 0.15842 | Running loss: 0.45813\n","Epoch: 1 | Iteration: 3229/2403 | Classification loss: 0.10451 | Regression loss: 0.15897 | Running loss: 0.45790\n","Epoch: 1 | Iteration: 3230/2403 | Classification loss: 0.26336 | Regression loss: 0.24520 | Running loss: 0.45796\n","Epoch: 1 | Iteration: 3231/2403 | Classification loss: 0.20642 | Regression loss: 0.19201 | Running loss: 0.45789\n","Epoch: 1 | Iteration: 3232/2403 | Classification loss: 0.11662 | Regression loss: 0.17364 | Running loss: 0.45768\n","Epoch: 1 | Iteration: 3233/2403 | Classification loss: 1.28195 | Regression loss: 0.43398 | Running loss: 0.45920\n","Epoch: 1 | Iteration: 3234/2403 | Classification loss: 1.75241 | Regression loss: 0.32350 | Running loss: 0.46115\n","Epoch: 1 | Iteration: 3235/2403 | Classification loss: 0.09173 | Regression loss: 0.23301 | Running loss: 0.46098\n","Epoch: 1 | Iteration: 3236/2403 | Classification loss: 0.20112 | Regression loss: 0.21934 | Running loss: 0.46093\n","Epoch: 1 | Iteration: 3237/2403 | Classification loss: 0.03852 | Regression loss: 0.15629 | Running loss: 0.46061\n","Epoch: 1 | Iteration: 3238/2403 | Classification loss: 0.13257 | Regression loss: 0.20008 | Running loss: 0.46046\n","Epoch: 1 | Iteration: 3239/2403 | Classification loss: 0.04860 | Regression loss: 0.14714 | Running loss: 0.46014\n","Epoch: 1 | Iteration: 3240/2403 | Classification loss: 0.22545 | Regression loss: 0.24444 | Running loss: 0.46016\n","Epoch: 1 | Iteration: 3241/2403 | Classification loss: 0.20961 | Regression loss: 0.20100 | Running loss: 0.46010\n","Epoch: 1 | Iteration: 3242/2403 | Classification loss: 0.34712 | Regression loss: 0.28668 | Running loss: 0.46030\n","Epoch: 1 | Iteration: 3243/2403 | Classification loss: 0.14957 | Regression loss: 0.24567 | Running loss: 0.46023\n","Epoch: 1 | Iteration: 3244/2403 | Classification loss: 0.09193 | Regression loss: 0.20325 | Running loss: 0.46003\n","Epoch: 1 | Iteration: 3245/2403 | Classification loss: 0.44264 | Regression loss: 0.29742 | Running loss: 0.46036\n","Epoch: 1 | Iteration: 3246/2403 | Classification loss: 0.39159 | Regression loss: 0.21490 | Running loss: 0.46054\n","Epoch: 1 | Iteration: 3247/2403 | Classification loss: 0.24389 | Regression loss: 0.24889 | Running loss: 0.46057\n","Epoch: 1 | Iteration: 3248/2403 | Classification loss: 0.22586 | Regression loss: 0.22645 | Running loss: 0.46056\n","Epoch: 1 | Iteration: 3249/2403 | Classification loss: 0.19035 | Regression loss: 0.21002 | Running loss: 0.46049\n","Epoch: 1 | Iteration: 3250/2403 | Classification loss: 0.07267 | Regression loss: 0.17828 | Running loss: 0.46025\n","Epoch: 1 | Iteration: 3251/2403 | Classification loss: 0.11805 | Regression loss: 0.28829 | Running loss: 0.46018\n","Epoch: 1 | Iteration: 3252/2403 | Classification loss: 0.37066 | Regression loss: 0.33392 | Running loss: 0.46047\n","Epoch: 1 | Iteration: 3253/2403 | Classification loss: 0.08304 | Regression loss: 0.12851 | Running loss: 0.46018\n","Epoch: 1 | Iteration: 3254/2403 | Classification loss: 0.48217 | Regression loss: 0.33264 | Running loss: 0.46059\n","Epoch: 1 | Iteration: 3255/2403 | Classification loss: 0.56964 | Regression loss: 0.38820 | Running loss: 0.46118\n","Epoch: 1 | Iteration: 3256/2403 | Classification loss: 0.14536 | Regression loss: 0.25048 | Running loss: 0.46110\n","Epoch: 1 | Iteration: 3257/2403 | Classification loss: 0.20098 | Regression loss: 0.35094 | Running loss: 0.46121\n","Epoch: 1 | Iteration: 3258/2403 | Classification loss: 0.27494 | Regression loss: 0.25879 | Running loss: 0.46129\n","Epoch: 1 | Iteration: 3259/2403 | Classification loss: 0.09285 | Regression loss: 0.19200 | Running loss: 0.46109\n","Epoch: 1 | Iteration: 3260/2403 | Classification loss: 0.07773 | Regression loss: 0.17449 | Running loss: 0.46084\n","Epoch: 1 | Iteration: 3261/2403 | Classification loss: 0.13893 | Regression loss: 0.28210 | Running loss: 0.46080\n","Epoch: 1 | Iteration: 3262/2403 | Classification loss: 0.44054 | Regression loss: 0.37699 | Running loss: 0.46121\n","Epoch: 1 | Iteration: 3263/2403 | Classification loss: 0.06385 | Regression loss: 0.18668 | Running loss: 0.46097\n","Epoch: 1 | Iteration: 3264/2403 | Classification loss: 0.13653 | Regression loss: 0.27079 | Running loss: 0.46090\n","Epoch: 1 | Iteration: 3265/2403 | Classification loss: 0.24276 | Regression loss: 0.17240 | Running loss: 0.46085\n","Epoch: 1 | Iteration: 3266/2403 | Classification loss: 0.09519 | Regression loss: 0.14117 | Running loss: 0.46059\n","Epoch: 1 | Iteration: 3267/2403 | Classification loss: 0.20333 | Regression loss: 0.26958 | Running loss: 0.46061\n","Epoch: 1 | Iteration: 3268/2403 | Classification loss: 0.05145 | Regression loss: 0.16070 | Running loss: 0.46032\n","Epoch: 1 | Iteration: 3269/2403 | Classification loss: 0.09453 | Regression loss: 0.16831 | Running loss: 0.46009\n","Epoch: 1 | Iteration: 3270/2403 | Classification loss: 0.12446 | Regression loss: 0.22282 | Running loss: 0.45996\n","Epoch: 1 | Iteration: 3271/2403 | Classification loss: 0.08144 | Regression loss: 0.23059 | Running loss: 0.45979\n","Epoch: 1 | Iteration: 3272/2403 | Classification loss: 0.38496 | Regression loss: 0.25686 | Running loss: 0.46000\n","Epoch: 1 | Iteration: 3273/2403 | Classification loss: 3.94356 | Regression loss: 0.33887 | Running loss: 0.46439\n","Epoch: 1 | Iteration: 3274/2403 | Classification loss: 0.42706 | Regression loss: 0.35880 | Running loss: 0.46476\n","Epoch: 1 | Iteration: 3275/2403 | Classification loss: 0.25761 | Regression loss: 0.21981 | Running loss: 0.46478\n","Epoch: 1 | Iteration: 3276/2403 | Classification loss: 0.25688 | Regression loss: 0.21860 | Running loss: 0.46479\n","Epoch: 1 | Iteration: 3277/2403 | Classification loss: 0.13845 | Regression loss: 0.13447 | Running loss: 0.46457\n","Epoch: 1 | Iteration: 3278/2403 | Classification loss: 0.18963 | Regression loss: 0.28925 | Running loss: 0.46459\n","Epoch: 1 | Iteration: 3279/2403 | Classification loss: 0.21120 | Regression loss: 0.33184 | Running loss: 0.46468\n","Epoch: 1 | Iteration: 3280/2403 | Classification loss: 0.07641 | Regression loss: 0.17252 | Running loss: 0.46443\n","Epoch: 1 | Iteration: 3281/2403 | Classification loss: 0.35596 | Regression loss: 0.43702 | Running loss: 0.46480\n","Epoch: 1 | Iteration: 3282/2403 | Classification loss: 0.20897 | Regression loss: 0.29739 | Running loss: 0.46485\n","Epoch: 1 | Iteration: 3283/2403 | Classification loss: 0.03481 | Regression loss: 0.16322 | Running loss: 0.46455\n","Epoch: 1 | Iteration: 3284/2403 | Classification loss: 0.09486 | Regression loss: 0.17438 | Running loss: 0.46433\n","Epoch: 1 | Iteration: 3285/2403 | Classification loss: 0.28588 | Regression loss: 0.18003 | Running loss: 0.46433\n","Epoch: 1 | Iteration: 3286/2403 | Classification loss: 0.18930 | Regression loss: 0.18160 | Running loss: 0.46422\n","Epoch: 1 | Iteration: 3287/2403 | Classification loss: 0.03524 | Regression loss: 0.12447 | Running loss: 0.46388\n","Epoch: 1 | Iteration: 3288/2403 | Classification loss: 0.09512 | Regression loss: 0.15045 | Running loss: 0.46363\n","Epoch: 1 | Iteration: 3289/2403 | Classification loss: 0.23487 | Regression loss: 0.17138 | Running loss: 0.46357\n","Epoch: 1 | Iteration: 3290/2403 | Classification loss: 0.21479 | Regression loss: 0.21761 | Running loss: 0.46353\n","Epoch: 1 | Iteration: 3291/2403 | Classification loss: 0.33376 | Regression loss: 0.31162 | Running loss: 0.46374\n","Epoch: 1 | Iteration: 3292/2403 | Classification loss: 0.27491 | Regression loss: 0.24418 | Running loss: 0.46380\n","Epoch: 1 | Iteration: 3293/2403 | Classification loss: 0.65181 | Regression loss: 0.38069 | Running loss: 0.46444\n","Epoch: 1 | Iteration: 3294/2403 | Classification loss: 0.06070 | Regression loss: 0.17947 | Running loss: 0.46418\n","Epoch: 1 | Iteration: 3295/2403 | Classification loss: 0.14095 | Regression loss: 0.24971 | Running loss: 0.46410\n","Epoch: 1 | Iteration: 3296/2403 | Classification loss: 0.28968 | Regression loss: 0.18812 | Running loss: 0.46412\n","Epoch: 1 | Iteration: 3297/2403 | Classification loss: 0.43121 | Regression loss: 0.45665 | Running loss: 0.46459\n","Epoch: 1 | Iteration: 3298/2403 | Classification loss: 0.06634 | Regression loss: 0.18315 | Running loss: 0.46435\n","Epoch: 1 | Iteration: 3299/2403 | Classification loss: 0.39700 | Regression loss: 0.26116 | Running loss: 0.46457\n","Epoch: 1 | Iteration: 3300/2403 | Classification loss: 0.33877 | Regression loss: 0.20746 | Running loss: 0.46466\n","Epoch: 1 | Iteration: 3301/2403 | Classification loss: 0.06917 | Regression loss: 0.19440 | Running loss: 0.46443\n","Epoch: 1 | Iteration: 3302/2403 | Classification loss: 0.07118 | Regression loss: 0.15024 | Running loss: 0.46416\n","Epoch: 1 | Iteration: 3303/2403 | Classification loss: 1.72843 | Regression loss: 0.48295 | Running loss: 0.46611\n","Epoch: 1 | Iteration: 3304/2403 | Classification loss: 0.19972 | Regression loss: 0.26436 | Running loss: 0.46610\n","Epoch: 1 | Iteration: 3305/2403 | Classification loss: 0.94348 | Regression loss: 0.18090 | Running loss: 0.46683\n","Epoch: 1 | Iteration: 3306/2403 | Classification loss: 0.40395 | Regression loss: 0.29937 | Running loss: 0.46710\n","Epoch: 1 | Iteration: 3307/2403 | Classification loss: 0.20918 | Regression loss: 0.21216 | Running loss: 0.46704\n","Epoch: 1 | Iteration: 3308/2403 | Classification loss: 0.03586 | Regression loss: 0.12397 | Running loss: 0.46671\n","Epoch: 1 | Iteration: 3309/2403 | Classification loss: 0.22810 | Regression loss: 0.27924 | Running loss: 0.46675\n","Epoch: 1 | Iteration: 3310/2403 | Classification loss: 0.17164 | Regression loss: 0.25799 | Running loss: 0.46671\n","Epoch: 1 | Iteration: 3311/2403 | Classification loss: 0.16557 | Regression loss: 0.19308 | Running loss: 0.46659\n","Epoch: 1 | Iteration: 3312/2403 | Classification loss: 0.14509 | Regression loss: 0.33943 | Running loss: 0.46661\n","Epoch: 1 | Iteration: 3313/2403 | Classification loss: 0.30802 | Regression loss: 0.22500 | Running loss: 0.46668\n","Epoch: 1 | Iteration: 3314/2403 | Classification loss: 0.19961 | Regression loss: 0.20067 | Running loss: 0.46661\n","Epoch: 1 | Iteration: 3315/2403 | Classification loss: 0.04622 | Regression loss: 0.16305 | Running loss: 0.46633\n","Epoch: 1 | Iteration: 3316/2403 | Classification loss: 0.15034 | Regression loss: 0.31085 | Running loss: 0.46632\n","Epoch: 1 | Iteration: 3317/2403 | Classification loss: 0.05447 | Regression loss: 0.16792 | Running loss: 0.46606\n","Epoch: 1 | Iteration: 3318/2403 | Classification loss: 0.16239 | Regression loss: 0.19509 | Running loss: 0.46594\n","Epoch: 1 | Iteration: 3319/2403 | Classification loss: 0.13873 | Regression loss: 0.24709 | Running loss: 0.46585\n","Epoch: 1 | Iteration: 3320/2403 | Classification loss: 0.22185 | Regression loss: 0.24694 | Running loss: 0.46585\n","Epoch: 1 | Iteration: 3321/2403 | Classification loss: 0.06171 | Regression loss: 0.15817 | Running loss: 0.46558\n","Epoch: 1 | Iteration: 3322/2403 | Classification loss: 0.39902 | Regression loss: 0.18988 | Running loss: 0.46572\n","Epoch: 1 | Iteration: 3323/2403 | Classification loss: 0.10937 | Regression loss: 0.19386 | Running loss: 0.46554\n","Epoch: 1 | Iteration: 3324/2403 | Classification loss: 0.10938 | Regression loss: 0.18791 | Running loss: 0.46536\n","Epoch: 1 | Iteration: 3325/2403 | Classification loss: 0.13264 | Regression loss: 0.19123 | Running loss: 0.46521\n","Epoch: 1 | Iteration: 3326/2403 | Classification loss: 0.08643 | Regression loss: 0.17609 | Running loss: 0.46499\n","Epoch: 1 | Iteration: 3327/2403 | Classification loss: 0.23097 | Regression loss: 0.27084 | Running loss: 0.46503\n","Epoch: 1 | Iteration: 3328/2403 | Classification loss: 0.20806 | Regression loss: 0.27694 | Running loss: 0.46505\n","Epoch: 1 | Iteration: 3329/2403 | Classification loss: 0.28742 | Regression loss: 0.33599 | Running loss: 0.46522\n","Epoch: 1 | Iteration: 3330/2403 | Classification loss: 0.30925 | Regression loss: 0.25344 | Running loss: 0.46532\n","Epoch: 1 | Iteration: 3331/2403 | Classification loss: 0.44061 | Regression loss: 0.50251 | Running loss: 0.46584\n","Epoch: 1 | Iteration: 3332/2403 | Classification loss: 0.03221 | Regression loss: 0.13031 | Running loss: 0.46551\n","Epoch: 1 | Iteration: 3333/2403 | Classification loss: 0.35004 | Regression loss: 0.31682 | Running loss: 0.46573\n","Epoch: 1 | Iteration: 3334/2403 | Classification loss: 0.30286 | Regression loss: 0.30022 | Running loss: 0.46588\n","Epoch: 1 | Iteration: 3335/2403 | Classification loss: 0.22871 | Regression loss: 0.26341 | Running loss: 0.46590\n","Epoch: 1 | Iteration: 3336/2403 | Classification loss: 0.24111 | Regression loss: 0.20707 | Running loss: 0.46589\n","Epoch: 1 | Iteration: 3337/2403 | Classification loss: 0.43165 | Regression loss: 0.22485 | Running loss: 0.46609\n","Epoch: 1 | Iteration: 3338/2403 | Classification loss: 0.21799 | Regression loss: 0.21077 | Running loss: 0.46605\n","Epoch: 1 | Iteration: 3339/2403 | Classification loss: 0.26702 | Regression loss: 0.24778 | Running loss: 0.46610\n","Epoch: 1 | Iteration: 3340/2403 | Classification loss: 0.31854 | Regression loss: 0.21616 | Running loss: 0.46617\n","Epoch: 1 | Iteration: 3341/2403 | Classification loss: 0.08622 | Regression loss: 0.14048 | Running loss: 0.46592\n","Epoch: 1 | Iteration: 3342/2403 | Classification loss: 0.31065 | Regression loss: 0.27801 | Running loss: 0.46605\n","Epoch: 1 | Iteration: 3343/2403 | Classification loss: 0.18896 | Regression loss: 0.26599 | Running loss: 0.46604\n","Epoch: 1 | Iteration: 3344/2403 | Classification loss: 0.06350 | Regression loss: 0.16384 | Running loss: 0.46578\n","Epoch: 1 | Iteration: 3345/2403 | Classification loss: 0.38841 | Regression loss: 0.28979 | Running loss: 0.46601\n","Epoch: 1 | Iteration: 3346/2403 | Classification loss: 0.18111 | Regression loss: 0.19321 | Running loss: 0.46591\n","Epoch: 1 | Iteration: 3347/2403 | Classification loss: 0.10528 | Regression loss: 0.12834 | Running loss: 0.46567\n","Epoch: 1 | Iteration: 3348/2403 | Classification loss: 0.11680 | Regression loss: 0.12833 | Running loss: 0.46543\n","Epoch: 1 | Iteration: 3349/2403 | Classification loss: 0.20218 | Regression loss: 0.17274 | Running loss: 0.46534\n","Epoch: 1 | Iteration: 3350/2403 | Classification loss: 0.33902 | Regression loss: 0.20627 | Running loss: 0.46542\n","Epoch: 1 | Iteration: 3351/2403 | Classification loss: 0.05409 | Regression loss: 0.19085 | Running loss: 0.46519\n","Epoch: 1 | Iteration: 3352/2403 | Classification loss: 0.13596 | Regression loss: 0.20280 | Running loss: 0.46506\n","Epoch: 1 | Iteration: 3353/2403 | Classification loss: 0.13501 | Regression loss: 0.17334 | Running loss: 0.46489\n","Epoch: 1 | Iteration: 3354/2403 | Classification loss: 0.19307 | Regression loss: 0.22516 | Running loss: 0.46484\n","Epoch: 1 | Iteration: 3355/2403 | Classification loss: 0.36166 | Regression loss: 0.25344 | Running loss: 0.46500\n","Epoch: 1 | Iteration: 3356/2403 | Classification loss: 0.06164 | Regression loss: 0.21969 | Running loss: 0.46481\n","Epoch: 1 | Iteration: 3357/2403 | Classification loss: 0.05878 | Regression loss: 0.16380 | Running loss: 0.46455\n","Epoch: 1 | Iteration: 3358/2403 | Classification loss: 0.31459 | Regression loss: 0.29006 | Running loss: 0.46470\n","Epoch: 1 | Iteration: 3359/2403 | Classification loss: 0.23739 | Regression loss: 0.24563 | Running loss: 0.46472\n","Epoch: 1 | Iteration: 3360/2403 | Classification loss: 0.18600 | Regression loss: 0.24421 | Running loss: 0.46468\n","Epoch: 1 | Iteration: 3361/2403 | Classification loss: 0.05746 | Regression loss: 0.13272 | Running loss: 0.46440\n","Epoch: 1 | Iteration: 3362/2403 | Classification loss: 0.35431 | Regression loss: 0.21427 | Running loss: 0.46451\n","Epoch: 1 | Iteration: 3363/2403 | Classification loss: 0.04940 | Regression loss: 0.16012 | Running loss: 0.46424\n","Epoch: 1 | Iteration: 3364/2403 | Classification loss: 0.08010 | Regression loss: 0.22502 | Running loss: 0.46407\n","Epoch: 1 | Iteration: 3365/2403 | Classification loss: 0.11672 | Regression loss: 0.16956 | Running loss: 0.46389\n","Epoch: 1 | Iteration: 3366/2403 | Classification loss: 0.32605 | Regression loss: 0.26143 | Running loss: 0.46402\n","Epoch: 1 | Iteration: 3367/2403 | Classification loss: 0.26092 | Regression loss: 0.26362 | Running loss: 0.46408\n","Epoch: 1 | Iteration: 3368/2403 | Classification loss: 0.11601 | Regression loss: 0.12537 | Running loss: 0.46385\n","Epoch: 1 | Iteration: 3369/2403 | Classification loss: 0.27196 | Regression loss: 0.29376 | Running loss: 0.46396\n","Epoch: 1 | Iteration: 3370/2403 | Classification loss: 0.32603 | Regression loss: 0.32623 | Running loss: 0.46415\n","Epoch: 1 | Iteration: 3371/2403 | Classification loss: 0.21946 | Regression loss: 0.25592 | Running loss: 0.46416\n","Epoch: 1 | Iteration: 3372/2403 | Classification loss: 0.19677 | Regression loss: 0.23484 | Running loss: 0.46413\n","Epoch: 1 | Iteration: 3373/2403 | Classification loss: 0.14094 | Regression loss: 0.12662 | Running loss: 0.46393\n","Epoch: 1 | Iteration: 3374/2403 | Classification loss: 0.10951 | Regression loss: 0.25155 | Running loss: 0.46382\n","Epoch: 1 | Iteration: 3375/2403 | Classification loss: 0.14620 | Regression loss: 0.20409 | Running loss: 0.46370\n","Epoch: 1 | Iteration: 3376/2403 | Classification loss: 0.31428 | Regression loss: 0.25304 | Running loss: 0.46381\n","Epoch: 1 | Iteration: 3377/2403 | Classification loss: 0.11046 | Regression loss: 0.17139 | Running loss: 0.46362\n","Epoch: 1 | Iteration: 3378/2403 | Classification loss: 0.11428 | Regression loss: 0.18296 | Running loss: 0.46345\n","Epoch: 1 | Iteration: 3379/2403 | Classification loss: 0.20776 | Regression loss: 0.21865 | Running loss: 0.46341\n","Epoch: 1 | Iteration: 3380/2403 | Classification loss: 0.24623 | Regression loss: 0.27253 | Running loss: 0.46347\n","Epoch: 1 | Iteration: 3381/2403 | Classification loss: 0.20048 | Regression loss: 0.21484 | Running loss: 0.46342\n","Epoch: 1 | Iteration: 3382/2403 | Classification loss: 0.05470 | Regression loss: 0.15208 | Running loss: 0.46316\n","Epoch: 1 | Iteration: 3383/2403 | Classification loss: 0.13440 | Regression loss: 0.17841 | Running loss: 0.46301\n","Epoch: 1 | Iteration: 3384/2403 | Classification loss: 0.04832 | Regression loss: 0.22873 | Running loss: 0.46282\n","Epoch: 1 | Iteration: 3385/2403 | Classification loss: 0.02172 | Regression loss: 0.09008 | Running loss: 0.46246\n","Epoch: 1 | Iteration: 3386/2403 | Classification loss: 0.50995 | Regression loss: 0.17867 | Running loss: 0.46269\n","Epoch: 1 | Iteration: 3387/2403 | Classification loss: 0.25370 | Regression loss: 0.20342 | Running loss: 0.46268\n","Epoch: 1 | Iteration: 3388/2403 | Classification loss: 0.45396 | Regression loss: 0.31121 | Running loss: 0.46299\n","Epoch: 1 | Iteration: 3389/2403 | Classification loss: 0.17417 | Regression loss: 0.20353 | Running loss: 0.46290\n","Epoch: 1 | Iteration: 3390/2403 | Classification loss: 0.29109 | Regression loss: 0.35804 | Running loss: 0.46309\n","Epoch: 1 | Iteration: 3391/2403 | Classification loss: 0.21621 | Regression loss: 0.24212 | Running loss: 0.46309\n","Epoch: 1 | Iteration: 3392/2403 | Classification loss: 0.33570 | Regression loss: 0.28728 | Running loss: 0.46325\n","Epoch: 1 | Iteration: 3393/2403 | Classification loss: 0.70420 | Regression loss: 0.35500 | Running loss: 0.46385\n","Epoch: 1 | Iteration: 3394/2403 | Classification loss: 0.20950 | Regression loss: 0.24530 | Running loss: 0.46384\n","Epoch: 1 | Iteration: 3395/2403 | Classification loss: 0.34765 | Regression loss: 0.38748 | Running loss: 0.46412\n","Epoch: 1 | Iteration: 3396/2403 | Classification loss: 0.29568 | Regression loss: 0.24469 | Running loss: 0.46419\n","Epoch: 1 | Iteration: 3397/2403 | Classification loss: 0.27630 | Regression loss: 0.24278 | Running loss: 0.46425\n","Epoch: 1 | Iteration: 3398/2403 | Classification loss: 0.09058 | Regression loss: 0.12280 | Running loss: 0.46400\n","Epoch: 1 | Iteration: 3399/2403 | Classification loss: 0.14874 | Regression loss: 0.15195 | Running loss: 0.46383\n","Epoch: 1 | Iteration: 3400/2403 | Classification loss: 1.17937 | Regression loss: 0.36740 | Running loss: 0.46492\n","Epoch: 1 | Iteration: 3401/2403 | Classification loss: 0.07849 | Regression loss: 0.15538 | Running loss: 0.46469\n","Epoch: 1 | Iteration: 3402/2403 | Classification loss: 0.24742 | Regression loss: 0.29504 | Running loss: 0.46476\n","Epoch: 1 | Iteration: 3403/2403 | Classification loss: 0.24833 | Regression loss: 0.26035 | Running loss: 0.46481\n","Epoch: 1 | Iteration: 3404/2403 | Classification loss: 0.37825 | Regression loss: 0.22183 | Running loss: 0.46494\n","Epoch: 1 | Iteration: 3405/2403 | Classification loss: 0.10219 | Regression loss: 0.13627 | Running loss: 0.46472\n","Epoch: 1 | Iteration: 3406/2403 | Classification loss: 0.23510 | Regression loss: 0.20631 | Running loss: 0.46469\n","Epoch: 1 | Iteration: 3407/2403 | Classification loss: 0.18815 | Regression loss: 0.18269 | Running loss: 0.46460\n","Epoch: 1 | Iteration: 3408/2403 | Classification loss: 0.13156 | Regression loss: 0.23281 | Running loss: 0.46450\n","Epoch: 1 | Iteration: 3409/2403 | Classification loss: 0.22488 | Regression loss: 0.23338 | Running loss: 0.46449\n","Epoch: 1 | Iteration: 3410/2403 | Classification loss: 0.09999 | Regression loss: 0.21593 | Running loss: 0.46435\n","Epoch: 1 | Iteration: 3411/2403 | Classification loss: 0.15971 | Regression loss: 0.17810 | Running loss: 0.46422\n","Epoch: 1 | Iteration: 3412/2403 | Classification loss: 0.22759 | Regression loss: 0.41534 | Running loss: 0.46440\n","Epoch: 1 | Iteration: 3413/2403 | Classification loss: 0.04114 | Regression loss: 0.10667 | Running loss: 0.46408\n","Epoch: 1 | Iteration: 3414/2403 | Classification loss: 0.08025 | Regression loss: 0.12389 | Running loss: 0.46383\n","Epoch: 1 | Iteration: 3415/2403 | Classification loss: 0.26586 | Regression loss: 0.29462 | Running loss: 0.46392\n","Epoch: 1 | Iteration: 3416/2403 | Classification loss: 0.11145 | Regression loss: 0.21103 | Running loss: 0.46378\n","Epoch: 1 | Iteration: 3417/2403 | Classification loss: 0.25804 | Regression loss: 0.25704 | Running loss: 0.46383\n","Epoch: 1 | Iteration: 3418/2403 | Classification loss: 0.07895 | Regression loss: 0.19137 | Running loss: 0.46364\n","Epoch: 1 | Iteration: 3419/2403 | Classification loss: 0.13182 | Regression loss: 0.15553 | Running loss: 0.46347\n","Epoch: 1 | Iteration: 3420/2403 | Classification loss: 0.02621 | Regression loss: 0.13945 | Running loss: 0.46318\n","Epoch: 1 | Iteration: 3421/2403 | Classification loss: 0.04828 | Regression loss: 0.13984 | Running loss: 0.46291\n","Epoch: 1 | Iteration: 3422/2403 | Classification loss: 0.07309 | Regression loss: 0.18219 | Running loss: 0.46270\n","Epoch: 1 | Iteration: 3423/2403 | Classification loss: 0.43243 | Regression loss: 0.23148 | Running loss: 0.46290\n","Epoch: 1 | Iteration: 3424/2403 | Classification loss: 0.21453 | Regression loss: 0.17060 | Running loss: 0.46282\n","Epoch: 1 | Iteration: 3425/2403 | Classification loss: 0.01706 | Regression loss: 0.13732 | Running loss: 0.46252\n","Epoch: 1 | Iteration: 3426/2403 | Classification loss: 0.25777 | Regression loss: 0.22222 | Running loss: 0.46254\n","Epoch: 1 | Iteration: 3427/2403 | Classification loss: 0.16519 | Regression loss: 0.23786 | Running loss: 0.46248\n","Epoch: 1 | Iteration: 3428/2403 | Classification loss: 0.48346 | Regression loss: 0.20959 | Running loss: 0.46271\n","Epoch: 1 | Iteration: 3429/2403 | Classification loss: 0.26087 | Regression loss: 0.33970 | Running loss: 0.46284\n","Epoch: 1 | Iteration: 3430/2403 | Classification loss: 0.13243 | Regression loss: 0.23820 | Running loss: 0.46275\n","Epoch: 1 | Iteration: 3431/2403 | Classification loss: 0.26165 | Regression loss: 0.21064 | Running loss: 0.46276\n","Epoch: 1 | Iteration: 3432/2403 | Classification loss: 0.57224 | Regression loss: 0.32501 | Running loss: 0.46318\n","Epoch: 1 | Iteration: 3433/2403 | Classification loss: 0.15614 | Regression loss: 0.28172 | Running loss: 0.46316\n","Epoch: 1 | Iteration: 3434/2403 | Classification loss: 0.41873 | Regression loss: 0.26028 | Running loss: 0.46337\n","Epoch: 1 | Iteration: 3435/2403 | Classification loss: 0.14975 | Regression loss: 0.21218 | Running loss: 0.46327\n","Epoch: 1 | Iteration: 3436/2403 | Classification loss: 0.23422 | Regression loss: 0.17326 | Running loss: 0.46322\n","Epoch: 1 | Iteration: 3437/2403 | Classification loss: 0.23020 | Regression loss: 0.31356 | Running loss: 0.46329\n","Epoch: 1 | Iteration: 3438/2403 | Classification loss: 0.23524 | Regression loss: 0.25008 | Running loss: 0.46331\n","Epoch: 1 | Iteration: 3439/2403 | Classification loss: 0.05573 | Regression loss: 0.14576 | Running loss: 0.46306\n","Epoch: 1 | Iteration: 3440/2403 | Classification loss: 0.18935 | Regression loss: 0.18829 | Running loss: 0.46298\n","Epoch: 1 | Iteration: 3441/2403 | Classification loss: 0.11605 | Regression loss: 0.14872 | Running loss: 0.46279\n","Epoch: 1 | Iteration: 3442/2403 | Classification loss: 0.10028 | Regression loss: 0.24656 | Running loss: 0.46268\n","Epoch: 1 | Iteration: 3443/2403 | Classification loss: 0.09181 | Regression loss: 0.15872 | Running loss: 0.46247\n","Epoch: 1 | Iteration: 3444/2403 | Classification loss: 0.30973 | Regression loss: 0.55204 | Running loss: 0.46286\n","Epoch: 1 | Iteration: 3445/2403 | Classification loss: 0.52699 | Regression loss: 0.30776 | Running loss: 0.46321\n","Epoch: 1 | Iteration: 3446/2403 | Classification loss: 0.38697 | Regression loss: 0.32379 | Running loss: 0.46345\n","Epoch: 1 | Iteration: 3447/2403 | Classification loss: 0.32261 | Regression loss: 0.19982 | Running loss: 0.46351\n","Epoch: 1 | Iteration: 3448/2403 | Classification loss: 0.03531 | Regression loss: 0.11468 | Running loss: 0.46321\n","Epoch: 1 | Iteration: 3449/2403 | Classification loss: 0.18686 | Regression loss: 0.23200 | Running loss: 0.46316\n","Epoch: 1 | Iteration: 3450/2403 | Classification loss: 0.11844 | Regression loss: 0.12518 | Running loss: 0.46295\n","Epoch: 1 | Iteration: 3451/2403 | Classification loss: 0.06839 | Regression loss: 0.18180 | Running loss: 0.46275\n","Epoch: 1 | Iteration: 3452/2403 | Classification loss: 0.24631 | Regression loss: 0.28254 | Running loss: 0.46281\n","Epoch: 1 | Iteration: 3453/2403 | Classification loss: 0.12813 | Regression loss: 0.24582 | Running loss: 0.46273\n","Epoch: 1 | Iteration: 3454/2403 | Classification loss: 0.05343 | Regression loss: 0.16771 | Running loss: 0.46250\n","Epoch: 1 | Iteration: 3455/2403 | Classification loss: 0.04835 | Regression loss: 0.14750 | Running loss: 0.46225\n","Epoch: 1 | Iteration: 3456/2403 | Classification loss: 0.15880 | Regression loss: 0.26464 | Running loss: 0.46221\n","Epoch: 1 | Iteration: 3457/2403 | Classification loss: 0.48752 | Regression loss: 0.24015 | Running loss: 0.46246\n","Epoch: 1 | Iteration: 3458/2403 | Classification loss: 0.22362 | Regression loss: 0.24205 | Running loss: 0.46247\n","Epoch: 1 | Iteration: 3459/2403 | Classification loss: 0.10001 | Regression loss: 0.14183 | Running loss: 0.46226\n","Epoch: 1 | Iteration: 3460/2403 | Classification loss: 0.45235 | Regression loss: 0.24822 | Running loss: 0.46248\n","Epoch: 1 | Iteration: 3461/2403 | Classification loss: 0.14342 | Regression loss: 0.24853 | Running loss: 0.46241\n","Epoch: 1 | Iteration: 3462/2403 | Classification loss: 0.13835 | Regression loss: 0.22846 | Running loss: 0.46232\n","Epoch: 1 | Iteration: 3463/2403 | Classification loss: 0.04280 | Regression loss: 0.14653 | Running loss: 0.46207\n","Epoch: 1 | Iteration: 3464/2403 | Classification loss: 0.02896 | Regression loss: 0.15799 | Running loss: 0.46181\n","Epoch: 1 | Iteration: 3465/2403 | Classification loss: 0.14922 | Regression loss: 0.19467 | Running loss: 0.46170\n","Epoch: 1 | Iteration: 3466/2403 | Classification loss: 0.17739 | Regression loss: 0.16157 | Running loss: 0.46158\n","Epoch: 1 | Iteration: 3467/2403 | Classification loss: 0.30529 | Regression loss: 0.16833 | Running loss: 0.46159\n","Epoch: 1 | Iteration: 3468/2403 | Classification loss: 0.29381 | Regression loss: 0.27751 | Running loss: 0.46170\n","Epoch: 1 | Iteration: 3469/2403 | Classification loss: 0.03472 | Regression loss: 0.13120 | Running loss: 0.46142\n","Epoch: 1 | Iteration: 3470/2403 | Classification loss: 0.15644 | Regression loss: 0.17271 | Running loss: 0.46129\n","Epoch: 1 | Iteration: 3471/2403 | Classification loss: 0.38940 | Regression loss: 0.17599 | Running loss: 0.46139\n","Epoch: 1 | Iteration: 3472/2403 | Classification loss: 0.10602 | Regression loss: 0.21627 | Running loss: 0.46126\n","Epoch: 1 | Iteration: 3473/2403 | Classification loss: 0.16354 | Regression loss: 0.16064 | Running loss: 0.46113\n","Epoch: 1 | Iteration: 3474/2403 | Classification loss: 0.15139 | Regression loss: 0.15456 | Running loss: 0.46099\n","Epoch: 1 | Iteration: 3475/2403 | Classification loss: 0.09220 | Regression loss: 0.15902 | Running loss: 0.46079\n","Epoch: 1 | Iteration: 3476/2403 | Classification loss: 0.03741 | Regression loss: 0.15684 | Running loss: 0.46054\n","Epoch: 1 | Iteration: 3477/2403 | Classification loss: 0.07231 | Regression loss: 0.17998 | Running loss: 0.46035\n","Epoch: 1 | Iteration: 3478/2403 | Classification loss: 0.06184 | Regression loss: 0.18737 | Running loss: 0.46015\n","Epoch: 1 | Iteration: 3479/2403 | Classification loss: 0.56887 | Regression loss: 0.30135 | Running loss: 0.46054\n","Epoch: 1 | Iteration: 3480/2403 | Classification loss: 0.04286 | Regression loss: 0.14459 | Running loss: 0.46028\n","Epoch: 1 | Iteration: 3481/2403 | Classification loss: 0.07526 | Regression loss: 0.17722 | Running loss: 0.46009\n","Epoch: 1 | Iteration: 3482/2403 | Classification loss: 0.53020 | Regression loss: 0.28028 | Running loss: 0.46041\n","Epoch: 1 | Iteration: 3483/2403 | Classification loss: 0.09032 | Regression loss: 0.19485 | Running loss: 0.46025\n","Epoch: 1 | Iteration: 3484/2403 | Classification loss: 0.16308 | Regression loss: 0.26112 | Running loss: 0.46022\n","Epoch: 1 | Iteration: 3485/2403 | Classification loss: 0.25410 | Regression loss: 0.19581 | Running loss: 0.46021\n","Epoch: 1 | Iteration: 3486/2403 | Classification loss: 0.17468 | Regression loss: 0.18490 | Running loss: 0.46012\n","Epoch: 1 | Iteration: 3487/2403 | Classification loss: 0.63513 | Regression loss: 0.45054 | Running loss: 0.46069\n","Epoch: 1 | Iteration: 3488/2403 | Classification loss: 0.17144 | Regression loss: 0.19195 | Running loss: 0.46060\n","Epoch: 1 | Iteration: 3489/2403 | Classification loss: 0.07552 | Regression loss: 0.21251 | Running loss: 0.46044\n","Epoch: 1 | Iteration: 3490/2403 | Classification loss: 0.11941 | Regression loss: 0.14608 | Running loss: 0.46026\n","Epoch: 1 | Iteration: 3491/2403 | Classification loss: 0.05240 | Regression loss: 0.12872 | Running loss: 0.46001\n","Epoch: 1 | Iteration: 3492/2403 | Classification loss: 0.25708 | Regression loss: 0.38278 | Running loss: 0.46017\n","Epoch: 1 | Iteration: 3493/2403 | Classification loss: 0.10900 | Regression loss: 0.16307 | Running loss: 0.46000\n","Epoch: 1 | Iteration: 3494/2403 | Classification loss: 0.31180 | Regression loss: 0.29069 | Running loss: 0.46013\n","Epoch: 1 | Iteration: 3495/2403 | Classification loss: 0.24868 | Regression loss: 0.25242 | Running loss: 0.46017\n","Epoch: 1 | Iteration: 3496/2403 | Classification loss: 0.04896 | Regression loss: 0.12292 | Running loss: 0.45991\n","Epoch: 1 | Iteration: 3497/2403 | Classification loss: 0.06157 | Regression loss: 0.16052 | Running loss: 0.45969\n","Epoch: 1 | Iteration: 3498/2403 | Classification loss: 0.06583 | Regression loss: 0.13619 | Running loss: 0.45945\n","Epoch: 1 | Iteration: 3499/2403 | Classification loss: 0.39872 | Regression loss: 0.28254 | Running loss: 0.45965\n","Epoch: 1 | Iteration: 3500/2403 | Classification loss: 0.10694 | Regression loss: 0.24126 | Running loss: 0.45955\n","Epoch: 1 | Iteration: 3501/2403 | Classification loss: 0.06484 | Regression loss: 0.23473 | Running loss: 0.45941\n","Epoch: 1 | Iteration: 3502/2403 | Classification loss: 0.18455 | Regression loss: 0.25184 | Running loss: 0.45939\n","Epoch: 1 | Iteration: 3503/2403 | Classification loss: 0.18395 | Regression loss: 0.28124 | Running loss: 0.45939\n","Epoch: 1 | Iteration: 3504/2403 | Classification loss: 0.11402 | Regression loss: 0.21426 | Running loss: 0.45927\n","Epoch: 1 | Iteration: 3505/2403 | Classification loss: 0.05768 | Regression loss: 0.15050 | Running loss: 0.45904\n","Epoch: 1 | Iteration: 3506/2403 | Classification loss: 0.02475 | Regression loss: 0.11174 | Running loss: 0.45875\n","Epoch: 1 | Iteration: 3507/2403 | Classification loss: 0.07361 | Regression loss: 0.16134 | Running loss: 0.45855\n","Epoch: 1 | Iteration: 3508/2403 | Classification loss: 0.29746 | Regression loss: 0.33271 | Running loss: 0.45871\n","Epoch: 1 | Iteration: 3509/2403 | Classification loss: 0.18621 | Regression loss: 0.29545 | Running loss: 0.45873\n","Epoch: 1 | Iteration: 3510/2403 | Classification loss: 0.11903 | Regression loss: 0.19265 | Running loss: 0.45859\n","Epoch: 1 | Iteration: 3511/2403 | Classification loss: 0.11329 | Regression loss: 0.22374 | Running loss: 0.45848\n","Epoch: 1 | Iteration: 3512/2403 | Classification loss: 0.09110 | Regression loss: 0.14487 | Running loss: 0.45828\n","Epoch: 1 | Iteration: 3513/2403 | Classification loss: 0.05821 | Regression loss: 0.16395 | Running loss: 0.45807\n","Epoch: 1 | Iteration: 3514/2403 | Classification loss: 0.28003 | Regression loss: 0.21725 | Running loss: 0.45811\n","Epoch: 1 | Iteration: 3515/2403 | Classification loss: 0.07419 | Regression loss: 0.18063 | Running loss: 0.45792\n","Epoch: 1 | Iteration: 3516/2403 | Classification loss: 1.82973 | Regression loss: 0.22977 | Running loss: 0.45936\n","Epoch: 1 | Iteration: 3517/2403 | Classification loss: 0.11948 | Regression loss: 0.24670 | Running loss: 0.45928\n","Epoch: 1 | Iteration: 3518/2403 | Classification loss: 0.13099 | Regression loss: 0.25390 | Running loss: 0.45921\n","Epoch: 1 | Iteration: 3519/2403 | Classification loss: 0.14454 | Regression loss: 0.32258 | Running loss: 0.45922\n","Epoch: 1 | Iteration: 3520/2403 | Classification loss: 0.03393 | Regression loss: 0.13604 | Running loss: 0.45896\n","Epoch: 1 | Iteration: 3521/2403 | Classification loss: 0.18610 | Regression loss: 0.31979 | Running loss: 0.45900\n","Epoch: 1 | Iteration: 3522/2403 | Classification loss: 0.11004 | Regression loss: 0.18603 | Running loss: 0.45886\n","Epoch: 1 | Iteration: 3523/2403 | Classification loss: 0.33118 | Regression loss: 0.34789 | Running loss: 0.45905\n","Epoch: 1 | Iteration: 3524/2403 | Classification loss: 4.95514 | Regression loss: 0.59701 | Running loss: 0.46360\n","Epoch: 1 | Iteration: 3525/2403 | Classification loss: 0.09364 | Regression loss: 0.16721 | Running loss: 0.46341\n","Epoch: 1 | Iteration: 3526/2403 | Classification loss: 0.51274 | Regression loss: 0.52476 | Running loss: 0.46393\n","Epoch: 1 | Iteration: 3527/2403 | Classification loss: 0.06048 | Regression loss: 0.19751 | Running loss: 0.46374\n","Epoch: 1 | Iteration: 3528/2403 | Classification loss: 0.20934 | Regression loss: 0.23248 | Running loss: 0.46372\n","Epoch: 1 | Iteration: 3529/2403 | Classification loss: 0.06082 | Regression loss: 0.20488 | Running loss: 0.46355\n","Epoch: 1 | Iteration: 3530/2403 | Classification loss: 0.33450 | Regression loss: 0.23321 | Running loss: 0.46364\n","Epoch: 1 | Iteration: 3531/2403 | Classification loss: 0.21213 | Regression loss: 0.41811 | Running loss: 0.46379\n","Epoch: 1 | Iteration: 3532/2403 | Classification loss: 0.15530 | Regression loss: 0.16680 | Running loss: 0.46366\n","Epoch: 1 | Iteration: 3533/2403 | Classification loss: 0.12005 | Regression loss: 0.25470 | Running loss: 0.46358\n","Epoch: 1 | Iteration: 3534/2403 | Classification loss: 0.31020 | Regression loss: 0.27849 | Running loss: 0.46369\n","Epoch: 1 | Iteration: 3535/2403 | Classification loss: 0.26464 | Regression loss: 0.25601 | Running loss: 0.46374\n","Epoch: 1 | Iteration: 3536/2403 | Classification loss: 0.20755 | Regression loss: 0.30800 | Running loss: 0.46379\n","Epoch: 1 | Iteration: 3537/2403 | Classification loss: 0.25335 | Regression loss: 0.20503 | Running loss: 0.46379\n","Epoch: 1 | Iteration: 3538/2403 | Classification loss: 0.06451 | Regression loss: 0.17768 | Running loss: 0.46359\n","Epoch: 1 | Iteration: 3539/2403 | Classification loss: 0.10816 | Regression loss: 0.22426 | Running loss: 0.46347\n","Epoch: 1 | Iteration: 3540/2403 | Classification loss: 0.27433 | Regression loss: 0.30650 | Running loss: 0.46358\n","Epoch: 1 | Iteration: 3541/2403 | Classification loss: 0.38384 | Regression loss: 0.24808 | Running loss: 0.46373\n","Epoch: 1 | Iteration: 3542/2403 | Classification loss: 0.15462 | Regression loss: 0.17070 | Running loss: 0.46360\n","Epoch: 1 | Iteration: 3543/2403 | Classification loss: 0.12862 | Regression loss: 0.24776 | Running loss: 0.46353\n","Epoch: 1 | Iteration: 3544/2403 | Classification loss: 0.08198 | Regression loss: 0.22250 | Running loss: 0.46339\n","Epoch: 1 | Iteration: 3545/2403 | Classification loss: 0.14953 | Regression loss: 0.14876 | Running loss: 0.46324\n","Epoch: 1 | Iteration: 3546/2403 | Classification loss: 0.51021 | Regression loss: 0.33161 | Running loss: 0.46357\n","Epoch: 1 | Iteration: 3547/2403 | Classification loss: 0.26009 | Regression loss: 0.18196 | Running loss: 0.46356\n","Epoch: 1 | Iteration: 3548/2403 | Classification loss: 0.21545 | Regression loss: 0.22337 | Running loss: 0.46353\n","Epoch: 1 | Iteration: 3549/2403 | Classification loss: 0.12223 | Regression loss: 0.18229 | Running loss: 0.46340\n","Epoch: 1 | Iteration: 3550/2403 | Classification loss: 0.27849 | Regression loss: 0.20703 | Running loss: 0.46342\n","Epoch: 1 | Iteration: 3551/2403 | Classification loss: 0.08595 | Regression loss: 0.22646 | Running loss: 0.46328\n","Epoch: 1 | Iteration: 3552/2403 | Classification loss: 0.24938 | Regression loss: 0.27622 | Running loss: 0.46334\n","Epoch: 1 | Iteration: 3553/2403 | Classification loss: 0.19337 | Regression loss: 0.22639 | Running loss: 0.46330\n","Epoch: 1 | Iteration: 3554/2403 | Classification loss: 0.33736 | Regression loss: 0.53655 | Running loss: 0.46366\n","Epoch: 1 | Iteration: 3555/2403 | Classification loss: 0.35209 | Regression loss: 0.19071 | Running loss: 0.46373\n","Epoch: 1 | Iteration: 3556/2403 | Classification loss: 0.45632 | Regression loss: 0.38103 | Running loss: 0.46405\n","Epoch: 1 | Iteration: 3557/2403 | Classification loss: 0.35374 | Regression loss: 0.30190 | Running loss: 0.46422\n","Epoch: 1 | Iteration: 3558/2403 | Classification loss: 0.26328 | Regression loss: 0.27682 | Running loss: 0.46428\n","Epoch: 1 | Iteration: 3559/2403 | Classification loss: 0.21807 | Regression loss: 0.24851 | Running loss: 0.46428\n","Epoch: 1 | Iteration: 3560/2403 | Classification loss: 0.27314 | Regression loss: 0.22231 | Running loss: 0.46431\n","Epoch: 1 | Iteration: 3561/2403 | Classification loss: 0.27616 | Regression loss: 0.34393 | Running loss: 0.46444\n","Epoch: 1 | Iteration: 3562/2403 | Classification loss: 0.08847 | Regression loss: 0.16512 | Running loss: 0.46426\n","Epoch: 1 | Iteration: 3563/2403 | Classification loss: 0.29316 | Regression loss: 0.23702 | Running loss: 0.46432\n","Epoch: 1 | Iteration: 3564/2403 | Classification loss: 0.42918 | Regression loss: 0.21712 | Running loss: 0.46448\n","Epoch: 1 | Iteration: 3565/2403 | Classification loss: 0.10823 | Regression loss: 0.13522 | Running loss: 0.46429\n","Epoch: 1 | Iteration: 3566/2403 | Classification loss: 0.22026 | Regression loss: 0.25364 | Running loss: 0.46429\n","Epoch: 1 | Iteration: 3567/2403 | Classification loss: 0.20154 | Regression loss: 0.22534 | Running loss: 0.46426\n","Epoch: 1 | Iteration: 3568/2403 | Classification loss: 0.10991 | Regression loss: 0.16618 | Running loss: 0.46410\n","Epoch: 1 | Iteration: 3569/2403 | Classification loss: 0.10134 | Regression loss: 0.19147 | Running loss: 0.46395\n","Epoch: 1 | Iteration: 3570/2403 | Classification loss: 0.10650 | Regression loss: 0.14737 | Running loss: 0.46377\n","Epoch: 1 | Iteration: 3571/2403 | Classification loss: 0.05533 | Regression loss: 0.11649 | Running loss: 0.46352\n","Epoch: 1 | Iteration: 3572/2403 | Classification loss: 0.25141 | Regression loss: 0.19553 | Running loss: 0.46351\n","Epoch: 1 | Iteration: 3573/2403 | Classification loss: 0.60444 | Regression loss: 0.67323 | Running loss: 0.46421\n","Epoch: 1 | Iteration: 3574/2403 | Classification loss: 0.12015 | Regression loss: 0.17599 | Running loss: 0.46406\n","Epoch: 1 | Iteration: 3575/2403 | Classification loss: 0.14429 | Regression loss: 0.16895 | Running loss: 0.46393\n","Epoch: 1 | Iteration: 3576/2403 | Classification loss: 0.16453 | Regression loss: 0.21243 | Running loss: 0.46386\n","Epoch: 1 | Iteration: 3577/2403 | Classification loss: 0.17163 | Regression loss: 0.27895 | Running loss: 0.46385\n","Epoch: 1 | Iteration: 3578/2403 | Classification loss: 0.08695 | Regression loss: 0.22937 | Running loss: 0.46372\n","Epoch: 1 | Iteration: 3579/2403 | Classification loss: 0.19615 | Regression loss: 0.30935 | Running loss: 0.46376\n","Epoch: 1 | Iteration: 3580/2403 | Classification loss: 0.18158 | Regression loss: 0.24446 | Running loss: 0.46373\n","Epoch: 1 | Iteration: 3581/2403 | Classification loss: 0.06566 | Regression loss: 0.12375 | Running loss: 0.46349\n","Epoch: 1 | Iteration: 3582/2403 | Classification loss: 0.15654 | Regression loss: 0.24645 | Running loss: 0.46344\n","Epoch: 1 | Iteration: 3583/2403 | Classification loss: 0.06700 | Regression loss: 0.13289 | Running loss: 0.46322\n","Epoch: 1 | Iteration: 3584/2403 | Classification loss: 0.09568 | Regression loss: 0.23180 | Running loss: 0.46310\n","Epoch: 1 | Iteration: 3585/2403 | Classification loss: 0.32332 | Regression loss: 0.27704 | Running loss: 0.46322\n","Epoch: 1 | Iteration: 3586/2403 | Classification loss: 0.19365 | Regression loss: 0.09007 | Running loss: 0.46307\n","Epoch: 1 | Iteration: 3587/2403 | Classification loss: 0.11461 | Regression loss: 0.19661 | Running loss: 0.46294\n","Epoch: 1 | Iteration: 3588/2403 | Classification loss: 0.11270 | Regression loss: 0.19213 | Running loss: 0.46281\n","Epoch: 1 | Iteration: 3589/2403 | Classification loss: 0.09169 | Regression loss: 0.19052 | Running loss: 0.46265\n","Epoch: 1 | Iteration: 3590/2403 | Classification loss: 1.71036 | Regression loss: 0.60940 | Running loss: 0.46422\n","Epoch: 1 | Iteration: 3591/2403 | Classification loss: 0.20304 | Regression loss: 0.28601 | Running loss: 0.46424\n","Epoch: 1 | Iteration: 3592/2403 | Classification loss: 0.07946 | Regression loss: 0.13166 | Running loss: 0.46403\n","Epoch: 1 | Iteration: 3593/2403 | Classification loss: 0.07889 | Regression loss: 0.16367 | Running loss: 0.46384\n","Epoch: 1 | Iteration: 3594/2403 | Classification loss: 0.10955 | Regression loss: 0.21783 | Running loss: 0.46373\n","Epoch: 1 | Iteration: 3595/2403 | Classification loss: 0.38252 | Regression loss: 0.19100 | Running loss: 0.46382\n","Epoch: 1 | Iteration: 3596/2403 | Classification loss: 0.18273 | Regression loss: 0.22624 | Running loss: 0.46377\n","Epoch: 1 | Iteration: 3597/2403 | Classification loss: 0.17259 | Regression loss: 0.28903 | Running loss: 0.46377\n","Epoch: 1 | Iteration: 3598/2403 | Classification loss: 0.14960 | Regression loss: 0.21609 | Running loss: 0.46369\n","Epoch: 1 | Iteration: 3599/2403 | Classification loss: 0.12138 | Regression loss: 0.16748 | Running loss: 0.46354\n","Epoch: 1 | Iteration: 3600/2403 | Classification loss: 0.32708 | Regression loss: 0.28319 | Running loss: 0.46366\n","Epoch: 1 | Iteration: 3601/2403 | Classification loss: 0.04782 | Regression loss: 0.14265 | Running loss: 0.46344\n","Epoch: 1 | Iteration: 3602/2403 | Classification loss: 0.14238 | Regression loss: 0.25547 | Running loss: 0.46338\n","Epoch: 1 | Iteration: 3603/2403 | Classification loss: 0.36574 | Regression loss: 0.19438 | Running loss: 0.46346\n","Epoch: 1 | Iteration: 3604/2403 | Classification loss: 0.52451 | Regression loss: 0.34810 | Running loss: 0.46380\n","Epoch: 1 | Iteration: 3605/2403 | Classification loss: 0.12695 | Regression loss: 0.18823 | Running loss: 0.46368\n","Epoch: 1 | Iteration: 3606/2403 | Classification loss: 0.19120 | Regression loss: 0.26332 | Running loss: 0.46367\n","Epoch: 1 | Iteration: 3607/2403 | Classification loss: 0.28524 | Regression loss: 0.22164 | Running loss: 0.46371\n","Epoch: 1 | Iteration: 3608/2403 | Classification loss: 0.19719 | Regression loss: 0.16748 | Running loss: 0.46363\n","Epoch: 1 | Iteration: 3609/2403 | Classification loss: 0.27007 | Regression loss: 0.19868 | Running loss: 0.46363\n","Epoch: 1 | Iteration: 3610/2403 | Classification loss: 0.07605 | Regression loss: 0.16336 | Running loss: 0.46344\n","Epoch: 1 | Iteration: 3611/2403 | Classification loss: 0.11886 | Regression loss: 0.12979 | Running loss: 0.46327\n","Epoch: 1 | Iteration: 3612/2403 | Classification loss: 0.23558 | Regression loss: 0.17469 | Running loss: 0.46322\n","Epoch: 1 | Iteration: 3613/2403 | Classification loss: 0.25339 | Regression loss: 0.29145 | Running loss: 0.46329\n","Epoch: 1 | Iteration: 3614/2403 | Classification loss: 0.18256 | Regression loss: 0.24932 | Running loss: 0.46326\n","Epoch: 1 | Iteration: 3615/2403 | Classification loss: 0.23467 | Regression loss: 0.17270 | Running loss: 0.46322\n","Epoch: 1 | Iteration: 3616/2403 | Classification loss: 0.14807 | Regression loss: 0.17396 | Running loss: 0.46310\n","Epoch: 1 | Iteration: 3617/2403 | Classification loss: 0.24221 | Regression loss: 0.33322 | Running loss: 0.46319\n","Epoch: 1 | Iteration: 3618/2403 | Classification loss: 0.05215 | Regression loss: 0.16365 | Running loss: 0.46299\n","Epoch: 1 | Iteration: 3619/2403 | Classification loss: 0.05810 | Regression loss: 0.10857 | Running loss: 0.46275\n","Epoch: 1 | Iteration: 3620/2403 | Classification loss: 0.06040 | Regression loss: 0.13281 | Running loss: 0.46252\n","Epoch: 1 | Iteration: 3621/2403 | Classification loss: 0.14196 | Regression loss: 0.19665 | Running loss: 0.46242\n","Epoch: 1 | Iteration: 3622/2403 | Classification loss: 0.11043 | Regression loss: 0.16164 | Running loss: 0.46227\n","Epoch: 1 | Iteration: 3623/2403 | Classification loss: 0.13605 | Regression loss: 0.21894 | Running loss: 0.46218\n","Epoch: 1 | Iteration: 3624/2403 | Classification loss: 0.13691 | Regression loss: 0.14197 | Running loss: 0.46203\n","Epoch: 1 | Iteration: 3625/2403 | Classification loss: 0.18366 | Regression loss: 0.23549 | Running loss: 0.46199\n","Epoch: 1 | Iteration: 3626/2403 | Classification loss: 0.08861 | Regression loss: 0.15831 | Running loss: 0.46182\n","Epoch: 1 | Iteration: 3627/2403 | Classification loss: 0.22186 | Regression loss: 0.17651 | Running loss: 0.46177\n","Epoch: 1 | Iteration: 3628/2403 | Classification loss: 0.07878 | Regression loss: 0.17581 | Running loss: 0.46160\n","Epoch: 1 | Iteration: 3629/2403 | Classification loss: 0.21891 | Regression loss: 0.18674 | Running loss: 0.46155\n","Epoch: 1 | Iteration: 3630/2403 | Classification loss: 0.12687 | Regression loss: 0.19246 | Running loss: 0.46144\n","Epoch: 1 | Iteration: 3631/2403 | Classification loss: 0.12546 | Regression loss: 0.29550 | Running loss: 0.46140\n","Epoch: 1 | Iteration: 3632/2403 | Classification loss: 0.09863 | Regression loss: 0.19015 | Running loss: 0.46126\n","Epoch: 1 | Iteration: 3633/2403 | Classification loss: 0.77812 | Regression loss: 0.38366 | Running loss: 0.46183\n","Epoch: 1 | Iteration: 3634/2403 | Classification loss: 0.29627 | Regression loss: 0.26150 | Running loss: 0.46191\n","Epoch: 1 | Iteration: 3635/2403 | Classification loss: 0.26021 | Regression loss: 0.23234 | Running loss: 0.46193\n","Epoch: 1 | Iteration: 3636/2403 | Classification loss: 0.23931 | Regression loss: 0.14436 | Running loss: 0.46187\n","Epoch: 1 | Iteration: 3637/2403 | Classification loss: 0.31193 | Regression loss: 0.30593 | Running loss: 0.46200\n","Epoch: 1 | Iteration: 3638/2403 | Classification loss: 0.08373 | Regression loss: 0.22100 | Running loss: 0.46187\n","Epoch: 1 | Iteration: 3639/2403 | Classification loss: 0.23100 | Regression loss: 0.22487 | Running loss: 0.46186\n","Epoch: 1 | Iteration: 3640/2403 | Classification loss: 0.23883 | Regression loss: 0.23668 | Running loss: 0.46188\n","Epoch: 1 | Iteration: 3641/2403 | Classification loss: 0.16566 | Regression loss: 0.27344 | Running loss: 0.46186\n","Epoch: 1 | Iteration: 3642/2403 | Classification loss: 0.07036 | Regression loss: 0.15567 | Running loss: 0.46167\n","Epoch: 1 | Iteration: 3643/2403 | Classification loss: 0.24251 | Regression loss: 0.32421 | Running loss: 0.46175\n","Epoch: 1 | Iteration: 3644/2403 | Classification loss: 0.07228 | Regression loss: 0.18421 | Running loss: 0.46159\n","Epoch: 1 | Iteration: 3645/2403 | Classification loss: 0.12564 | Regression loss: 0.15238 | Running loss: 0.46144\n","Epoch: 1 | Iteration: 3646/2403 | Classification loss: 0.24650 | Regression loss: 0.24568 | Running loss: 0.46146\n","Epoch: 1 | Iteration: 3647/2403 | Classification loss: 0.19672 | Regression loss: 0.21406 | Running loss: 0.46142\n","Epoch: 1 | Iteration: 3648/2403 | Classification loss: 0.23713 | Regression loss: 0.20266 | Running loss: 0.46141\n","Epoch: 1 | Iteration: 3649/2403 | Classification loss: 0.11444 | Regression loss: 0.19218 | Running loss: 0.46128\n","Epoch: 1 | Iteration: 3650/2403 | Classification loss: 0.35209 | Regression loss: 0.34113 | Running loss: 0.46147\n","Epoch: 1 | Iteration: 3651/2403 | Classification loss: 0.31067 | Regression loss: 0.33088 | Running loss: 0.46161\n","Epoch: 1 | Iteration: 3652/2403 | Classification loss: 0.35179 | Regression loss: 0.29694 | Running loss: 0.46176\n","Epoch: 1 | Iteration: 3653/2403 | Classification loss: 0.16670 | Regression loss: 0.15102 | Running loss: 0.46165\n","Epoch: 1 | Iteration: 3654/2403 | Classification loss: 0.19288 | Regression loss: 0.22349 | Running loss: 0.46161\n","Epoch: 1 | Iteration: 3655/2403 | Classification loss: 0.14095 | Regression loss: 0.18005 | Running loss: 0.46150\n","Epoch: 1 | Iteration: 3656/2403 | Classification loss: 0.16772 | Regression loss: 0.24909 | Running loss: 0.46146\n","Epoch: 1 | Iteration: 3657/2403 | Classification loss: 0.09288 | Regression loss: 0.12430 | Running loss: 0.46127\n","Epoch: 1 | Iteration: 3658/2403 | Classification loss: 0.14854 | Regression loss: 0.14678 | Running loss: 0.46113\n","Epoch: 1 | Iteration: 3659/2403 | Classification loss: 0.17717 | Regression loss: 0.21325 | Running loss: 0.46108\n","Epoch: 1 | Iteration: 3660/2403 | Classification loss: 0.47751 | Regression loss: 0.34592 | Running loss: 0.46137\n","Epoch: 1 | Iteration: 3661/2403 | Classification loss: 0.16564 | Regression loss: 0.34579 | Running loss: 0.46141\n","Epoch: 1 | Iteration: 3662/2403 | Classification loss: 0.10903 | Regression loss: 0.17292 | Running loss: 0.46126\n","Epoch: 1 | Iteration: 3663/2403 | Classification loss: 0.15825 | Regression loss: 0.27286 | Running loss: 0.46124\n","Epoch: 1 | Iteration: 3664/2403 | Classification loss: 0.57372 | Regression loss: 0.39697 | Running loss: 0.46164\n","Epoch: 1 | Iteration: 3665/2403 | Classification loss: 0.02293 | Regression loss: 0.12745 | Running loss: 0.46140\n","Epoch: 1 | Iteration: 3666/2403 | Classification loss: 0.41415 | Regression loss: 0.26649 | Running loss: 0.46157\n","Epoch: 1 | Iteration: 3667/2403 | Classification loss: 0.21928 | Regression loss: 0.18889 | Running loss: 0.46153\n","Epoch: 1 | Iteration: 3668/2403 | Classification loss: 0.22714 | Regression loss: 0.24565 | Running loss: 0.46154\n","Epoch: 1 | Iteration: 3669/2403 | Classification loss: 0.48449 | Regression loss: 0.40610 | Running loss: 0.46188\n","Epoch: 1 | Iteration: 3670/2403 | Classification loss: 0.06237 | Regression loss: 0.17729 | Running loss: 0.46170\n","Epoch: 1 | Iteration: 3671/2403 | Classification loss: 0.15631 | Regression loss: 0.27667 | Running loss: 0.46168\n","Epoch: 1 | Iteration: 3672/2403 | Classification loss: 0.31313 | Regression loss: 0.32087 | Running loss: 0.46181\n","Epoch: 1 | Iteration: 3673/2403 | Classification loss: 0.07582 | Regression loss: 0.16294 | Running loss: 0.46164\n","Epoch: 1 | Iteration: 3674/2403 | Classification loss: 0.14228 | Regression loss: 0.20987 | Running loss: 0.46155\n","Epoch: 1 | Iteration: 3675/2403 | Classification loss: 0.22327 | Regression loss: 0.34652 | Running loss: 0.46164\n","Epoch: 1 | Iteration: 3676/2403 | Classification loss: 0.06396 | Regression loss: 0.11980 | Running loss: 0.46142\n","Epoch: 1 | Iteration: 3677/2403 | Classification loss: 0.29105 | Regression loss: 0.29860 | Running loss: 0.46152\n","Epoch: 1 | Iteration: 3678/2403 | Classification loss: 0.18172 | Regression loss: 0.25672 | Running loss: 0.46150\n","Epoch: 1 | Iteration: 3679/2403 | Classification loss: 0.62055 | Regression loss: 0.46828 | Running loss: 0.46199\n","Epoch: 1 | Iteration: 3680/2403 | Classification loss: 0.21405 | Regression loss: 0.39621 | Running loss: 0.46211\n","Epoch: 1 | Iteration: 3681/2403 | Classification loss: 0.20423 | Regression loss: 0.24718 | Running loss: 0.46210\n","Epoch: 1 | Iteration: 3682/2403 | Classification loss: 0.20980 | Regression loss: 0.32224 | Running loss: 0.46216\n","Epoch: 1 | Iteration: 3683/2403 | Classification loss: 0.05894 | Regression loss: 0.10987 | Running loss: 0.46193\n","Epoch: 1 | Iteration: 3684/2403 | Classification loss: 0.19253 | Regression loss: 0.28005 | Running loss: 0.46194\n","Epoch: 1 | Iteration: 3685/2403 | Classification loss: 0.04042 | Regression loss: 0.13111 | Running loss: 0.46171\n","Epoch: 1 | Iteration: 3686/2403 | Classification loss: 0.30215 | Regression loss: 0.15351 | Running loss: 0.46170\n","Epoch: 1 | Iteration: 3687/2403 | Classification loss: 0.10720 | Regression loss: 0.15242 | Running loss: 0.46155\n","Epoch: 1 | Iteration: 3688/2403 | Classification loss: 0.11158 | Regression loss: 0.26688 | Running loss: 0.46148\n","Epoch: 1 | Iteration: 3689/2403 | Classification loss: 0.33639 | Regression loss: 0.33256 | Running loss: 0.46164\n","Epoch: 1 | Iteration: 3690/2403 | Classification loss: 0.19302 | Regression loss: 0.16950 | Running loss: 0.46157\n","Epoch: 1 | Iteration: 3691/2403 | Classification loss: 0.04670 | Regression loss: 0.16216 | Running loss: 0.46137\n","Epoch: 1 | Iteration: 3692/2403 | Classification loss: 0.60814 | Regression loss: 0.30155 | Running loss: 0.46172\n","Epoch: 1 | Iteration: 3693/2403 | Classification loss: 0.13631 | Regression loss: 0.22955 | Running loss: 0.46164\n","Epoch: 1 | Iteration: 3694/2403 | Classification loss: 0.36850 | Regression loss: 0.25261 | Running loss: 0.46177\n","Epoch: 1 | Iteration: 3695/2403 | Classification loss: 0.15184 | Regression loss: 0.17382 | Running loss: 0.46166\n","Epoch: 1 | Iteration: 3696/2403 | Classification loss: 0.13364 | Regression loss: 0.16378 | Running loss: 0.46153\n","Epoch: 1 | Iteration: 3697/2403 | Classification loss: 0.11495 | Regression loss: 0.15584 | Running loss: 0.46139\n","Epoch: 1 | Iteration: 3698/2403 | Classification loss: 0.13039 | Regression loss: 0.23260 | Running loss: 0.46131\n","Epoch: 1 | Iteration: 3699/2403 | Classification loss: 0.44462 | Regression loss: 0.28296 | Running loss: 0.46152\n","Epoch: 1 | Iteration: 3700/2403 | Classification loss: 0.05645 | Regression loss: 0.16978 | Running loss: 0.46134\n","Epoch: 1 | Iteration: 3701/2403 | Classification loss: 0.18554 | Regression loss: 0.22929 | Running loss: 0.46130\n","Epoch: 1 | Iteration: 3702/2403 | Classification loss: 0.17988 | Regression loss: 0.22767 | Running loss: 0.46126\n","Epoch: 1 | Iteration: 3703/2403 | Classification loss: 0.07951 | Regression loss: 0.16352 | Running loss: 0.46109\n","Epoch: 1 | Iteration: 3704/2403 | Classification loss: 0.07984 | Regression loss: 0.17009 | Running loss: 0.46093\n","Epoch: 1 | Iteration: 3705/2403 | Classification loss: 0.05259 | Regression loss: 0.18818 | Running loss: 0.46076\n","Epoch: 1 | Iteration: 3706/2403 | Classification loss: 0.23326 | Regression loss: 0.35156 | Running loss: 0.46085\n","Epoch: 1 | Iteration: 3707/2403 | Classification loss: 0.10581 | Regression loss: 0.28681 | Running loss: 0.46080\n","Epoch: 1 | Iteration: 3708/2403 | Classification loss: 0.20223 | Regression loss: 0.21242 | Running loss: 0.46077\n","Epoch: 1 | Iteration: 3709/2403 | Classification loss: 0.57275 | Regression loss: 0.32350 | Running loss: 0.46110\n","Epoch: 1 | Iteration: 3710/2403 | Classification loss: 0.54104 | Regression loss: 0.17754 | Running loss: 0.46130\n","Epoch: 1 | Iteration: 3711/2403 | Classification loss: 0.24675 | Regression loss: 0.20612 | Running loss: 0.46129\n","Epoch: 1 | Iteration: 3712/2403 | Classification loss: 0.03909 | Regression loss: 0.14550 | Running loss: 0.46108\n","Epoch: 1 | Iteration: 3713/2403 | Classification loss: 0.55785 | Regression loss: 0.53408 | Running loss: 0.46156\n","Epoch: 1 | Iteration: 3714/2403 | Classification loss: 0.15896 | Regression loss: 0.22782 | Running loss: 0.46150\n","Epoch: 1 | Iteration: 3715/2403 | Classification loss: 0.20686 | Regression loss: 0.24746 | Running loss: 0.46150\n","Epoch: 1 | Iteration: 3716/2403 | Classification loss: 0.37964 | Regression loss: 0.43508 | Running loss: 0.46177\n","Epoch: 1 | Iteration: 3717/2403 | Classification loss: 0.07433 | Regression loss: 0.20977 | Running loss: 0.46163\n","Epoch: 1 | Iteration: 3718/2403 | Classification loss: 0.18392 | Regression loss: 0.28326 | Running loss: 0.46164\n","Epoch: 1 | Iteration: 3719/2403 | Classification loss: 0.15422 | Regression loss: 0.13715 | Running loss: 0.46151\n","Epoch: 1 | Iteration: 3720/2403 | Classification loss: 0.42114 | Regression loss: 0.41939 | Running loss: 0.46179\n","Epoch: 1 | Iteration: 3721/2403 | Classification loss: 0.12070 | Regression loss: 0.18099 | Running loss: 0.46167\n","Epoch: 1 | Iteration: 3722/2403 | Classification loss: 0.28070 | Regression loss: 0.22991 | Running loss: 0.46171\n","Epoch: 1 | Iteration: 3723/2403 | Classification loss: 0.06793 | Regression loss: 0.18270 | Running loss: 0.46155\n","Epoch: 1 | Iteration: 3724/2403 | Classification loss: 0.07333 | Regression loss: 0.16817 | Running loss: 0.46138\n","Epoch: 1 | Iteration: 3725/2403 | Classification loss: 0.36601 | Regression loss: 0.27297 | Running loss: 0.46152\n","Epoch: 1 | Iteration: 3726/2403 | Classification loss: 0.10143 | Regression loss: 0.17485 | Running loss: 0.46138\n","Epoch: 1 | Iteration: 3727/2403 | Classification loss: 0.06932 | Regression loss: 0.16247 | Running loss: 0.46120\n","Epoch: 1 | Iteration: 3728/2403 | Classification loss: 0.20469 | Regression loss: 0.21698 | Running loss: 0.46117\n","Epoch: 1 | Iteration: 3729/2403 | Classification loss: 0.66119 | Regression loss: 0.20264 | Running loss: 0.46148\n","Epoch: 1 | Iteration: 3730/2403 | Classification loss: 0.16160 | Regression loss: 0.22899 | Running loss: 0.46142\n","Epoch: 1 | Iteration: 3731/2403 | Classification loss: 0.05114 | Regression loss: 0.19127 | Running loss: 0.46126\n","Epoch: 1 | Iteration: 3732/2403 | Classification loss: 0.05574 | Regression loss: 0.17652 | Running loss: 0.46109\n","Epoch: 1 | Iteration: 3733/2403 | Classification loss: 0.32307 | Regression loss: 0.36828 | Running loss: 0.46126\n","Epoch: 1 | Iteration: 3734/2403 | Classification loss: 0.09344 | Regression loss: 0.16762 | Running loss: 0.46111\n","Epoch: 1 | Iteration: 3735/2403 | Classification loss: 0.36996 | Regression loss: 0.22189 | Running loss: 0.46121\n","Epoch: 1 | Iteration: 3736/2403 | Classification loss: 0.06807 | Regression loss: 0.17894 | Running loss: 0.46105\n","Epoch: 1 | Iteration: 3737/2403 | Classification loss: 0.10746 | Regression loss: 0.14177 | Running loss: 0.46089\n","Epoch: 1 | Iteration: 3738/2403 | Classification loss: 0.07767 | Regression loss: 0.14769 | Running loss: 0.46071\n","Epoch: 1 | Iteration: 3739/2403 | Classification loss: 0.10314 | Regression loss: 0.20180 | Running loss: 0.46060\n","Epoch: 1 | Iteration: 3740/2403 | Classification loss: 0.12584 | Regression loss: 0.14858 | Running loss: 0.46046\n","Epoch: 1 | Iteration: 3741/2403 | Classification loss: 0.33229 | Regression loss: 0.29768 | Running loss: 0.46058\n","Epoch: 1 | Iteration: 3742/2403 | Classification loss: 0.25091 | Regression loss: 0.16505 | Running loss: 0.46055\n","Epoch: 1 | Iteration: 3743/2403 | Classification loss: 0.09480 | Regression loss: 0.18107 | Running loss: 0.46041\n","Epoch: 1 | Iteration: 3744/2403 | Classification loss: 0.27728 | Regression loss: 0.41575 | Running loss: 0.46059\n","Epoch: 1 | Iteration: 3745/2403 | Classification loss: 0.26312 | Regression loss: 0.23106 | Running loss: 0.46061\n","Epoch: 1 | Iteration: 3746/2403 | Classification loss: 0.27967 | Regression loss: 0.20706 | Running loss: 0.46063\n","Epoch: 1 | Iteration: 3747/2403 | Classification loss: 0.34020 | Regression loss: 0.38330 | Running loss: 0.46083\n","Epoch: 1 | Iteration: 3748/2403 | Classification loss: 0.31400 | Regression loss: 0.33227 | Running loss: 0.46096\n","Epoch: 1 | Iteration: 3749/2403 | Classification loss: 0.47628 | Regression loss: 0.42895 | Running loss: 0.46129\n","Epoch: 1 | Iteration: 3750/2403 | Classification loss: 0.15835 | Regression loss: 0.16339 | Running loss: 0.46119\n","Epoch: 1 | Iteration: 3751/2403 | Classification loss: 0.08862 | Regression loss: 0.13099 | Running loss: 0.46101\n","Epoch: 1 | Iteration: 3752/2403 | Classification loss: 0.15729 | Regression loss: 0.23002 | Running loss: 0.46096\n","Epoch: 1 | Iteration: 3753/2403 | Classification loss: 0.15583 | Regression loss: 0.21140 | Running loss: 0.46089\n","Epoch: 1 | Iteration: 3754/2403 | Classification loss: 0.23403 | Regression loss: 0.19485 | Running loss: 0.46086\n","Epoch: 1 | Iteration: 3755/2403 | Classification loss: 0.07458 | Regression loss: 0.18469 | Running loss: 0.46071\n","Epoch: 1 | Iteration: 3756/2403 | Classification loss: 0.15905 | Regression loss: 0.20371 | Running loss: 0.46064\n","Epoch: 1 | Iteration: 3757/2403 | Classification loss: 0.21775 | Regression loss: 0.18621 | Running loss: 0.46060\n","Epoch: 1 | Iteration: 3758/2403 | Classification loss: 0.10269 | Regression loss: 0.22787 | Running loss: 0.46050\n","Epoch: 1 | Iteration: 3759/2403 | Classification loss: 0.18498 | Regression loss: 0.12034 | Running loss: 0.46039\n","Epoch: 1 | Iteration: 3760/2403 | Classification loss: 0.06681 | Regression loss: 0.15448 | Running loss: 0.46021\n","Epoch: 1 | Iteration: 3761/2403 | Classification loss: 0.08492 | Regression loss: 0.15802 | Running loss: 0.46005\n","Epoch: 1 | Iteration: 3762/2403 | Classification loss: 0.08318 | Regression loss: 0.17877 | Running loss: 0.45991\n","Epoch: 1 | Iteration: 3763/2403 | Classification loss: 0.19887 | Regression loss: 0.17907 | Running loss: 0.45985\n","Epoch: 1 | Iteration: 3764/2403 | Classification loss: 0.05491 | Regression loss: 0.12283 | Running loss: 0.45964\n","Epoch: 1 | Iteration: 3765/2403 | Classification loss: 0.28334 | Regression loss: 0.26195 | Running loss: 0.45970\n","Epoch: 1 | Iteration: 3766/2403 | Classification loss: 0.08620 | Regression loss: 0.16668 | Running loss: 0.45955\n","Epoch: 1 | Iteration: 3767/2403 | Classification loss: 0.37727 | Regression loss: 0.40279 | Running loss: 0.45979\n","Epoch: 1 | Iteration: 3768/2403 | Classification loss: 0.17879 | Regression loss: 0.26118 | Running loss: 0.45977\n","Epoch: 1 | Iteration: 3769/2403 | Classification loss: 0.24850 | Regression loss: 0.32773 | Running loss: 0.45986\n","Epoch: 1 | Iteration: 3770/2403 | Classification loss: 0.12575 | Regression loss: 0.16939 | Running loss: 0.45974\n","Epoch: 1 | Iteration: 3771/2403 | Classification loss: 0.18214 | Regression loss: 0.24243 | Running loss: 0.45971\n","Epoch: 1 | Iteration: 3772/2403 | Classification loss: 0.20886 | Regression loss: 0.30944 | Running loss: 0.45975\n","Epoch: 1 | Iteration: 3773/2403 | Classification loss: 0.09590 | Regression loss: 0.23789 | Running loss: 0.45966\n","Epoch: 1 | Iteration: 3774/2403 | Classification loss: 0.15674 | Regression loss: 0.26544 | Running loss: 0.45963\n","Epoch: 1 | Iteration: 3775/2403 | Classification loss: 0.14883 | Regression loss: 0.22942 | Running loss: 0.45957\n","Epoch: 1 | Iteration: 3776/2403 | Classification loss: 0.20465 | Regression loss: 0.22365 | Running loss: 0.45955\n","Epoch: 1 | Iteration: 3777/2403 | Classification loss: 0.14441 | Regression loss: 0.17954 | Running loss: 0.45945\n","Epoch: 1 | Iteration: 3778/2403 | Classification loss: 0.19555 | Regression loss: 0.23098 | Running loss: 0.45943\n","Epoch: 1 | Iteration: 3779/2403 | Classification loss: 0.37114 | Regression loss: 0.35057 | Running loss: 0.45962\n","Epoch: 1 | Iteration: 3780/2403 | Classification loss: 0.18227 | Regression loss: 0.25519 | Running loss: 0.45960\n","Epoch: 1 | Iteration: 3781/2403 | Classification loss: 0.11262 | Regression loss: 0.20925 | Running loss: 0.45950\n","Epoch: 1 | Iteration: 3782/2403 | Classification loss: 0.13293 | Regression loss: 0.23679 | Running loss: 0.45944\n","Epoch: 1 | Iteration: 3783/2403 | Classification loss: 0.15714 | Regression loss: 0.29156 | Running loss: 0.45943\n","Epoch: 1 | Iteration: 3784/2403 | Classification loss: 0.22355 | Regression loss: 0.22461 | Running loss: 0.45942\n","Epoch: 1 | Iteration: 3785/2403 | Classification loss: 0.09750 | Regression loss: 0.11210 | Running loss: 0.45924\n","Epoch: 1 | Iteration: 3786/2403 | Classification loss: 0.17061 | Regression loss: 0.31167 | Running loss: 0.45926\n","Epoch: 1 | Iteration: 3787/2403 | Classification loss: 0.12671 | Regression loss: 0.24009 | Running loss: 0.45919\n","Epoch: 1 | Iteration: 3788/2403 | Classification loss: 0.08129 | Regression loss: 0.14061 | Running loss: 0.45902\n","Epoch: 1 | Iteration: 3789/2403 | Classification loss: 0.38552 | Regression loss: 0.35240 | Running loss: 0.45922\n","Epoch: 1 | Iteration: 3790/2403 | Classification loss: 0.20659 | Regression loss: 0.23598 | Running loss: 0.45921\n","Epoch: 1 | Iteration: 3791/2403 | Classification loss: 0.05094 | Regression loss: 0.15503 | Running loss: 0.45903\n","Epoch: 1 | Iteration: 3792/2403 | Classification loss: 0.24426 | Regression loss: 0.17028 | Running loss: 0.45900\n","Epoch: 1 | Iteration: 3793/2403 | Classification loss: 0.11100 | Regression loss: 0.16249 | Running loss: 0.45886\n","Epoch: 1 | Iteration: 3794/2403 | Classification loss: 0.32926 | Regression loss: 0.21778 | Running loss: 0.45893\n","Epoch: 1 | Iteration: 3795/2403 | Classification loss: 1.11484 | Regression loss: 0.29238 | Running loss: 0.45961\n","Epoch: 1 | Iteration: 3796/2403 | Classification loss: 0.20234 | Regression loss: 0.18165 | Running loss: 0.45955\n","Epoch: 1 | Iteration: 3797/2403 | Classification loss: 0.37422 | Regression loss: 0.13874 | Running loss: 0.45959\n","Epoch: 1 | Iteration: 3798/2403 | Classification loss: 0.27480 | Regression loss: 0.17544 | Running loss: 0.45958\n","Epoch: 1 | Iteration: 3799/2403 | Classification loss: 0.13816 | Regression loss: 0.18810 | Running loss: 0.45949\n","Epoch: 1 | Iteration: 3800/2403 | Classification loss: 0.21900 | Regression loss: 0.23992 | Running loss: 0.45949\n","Epoch: 1 | Iteration: 3801/2403 | Classification loss: 0.17151 | Regression loss: 0.21456 | Running loss: 0.45944\n","Epoch: 1 | Iteration: 3802/2403 | Classification loss: 0.11499 | Regression loss: 0.25970 | Running loss: 0.45937\n","Epoch: 1 | Iteration: 3803/2403 | Classification loss: 0.22675 | Regression loss: 0.12409 | Running loss: 0.45930\n","Epoch: 1 | Iteration: 3804/2403 | Classification loss: 0.19586 | Regression loss: 0.20830 | Running loss: 0.45926\n","Epoch: 1 | Iteration: 3805/2403 | Classification loss: 0.17404 | Regression loss: 0.28277 | Running loss: 0.45926\n","Epoch: 1 | Iteration: 3806/2403 | Classification loss: 0.08946 | Regression loss: 0.14995 | Running loss: 0.45910\n","Epoch: 1 | Iteration: 3807/2403 | Classification loss: 0.13463 | Regression loss: 0.27689 | Running loss: 0.45907\n","Epoch: 1 | Iteration: 3808/2403 | Classification loss: 0.59906 | Regression loss: 0.15157 | Running loss: 0.45927\n","Epoch: 1 | Iteration: 3809/2403 | Classification loss: 0.11825 | Regression loss: 0.20502 | Running loss: 0.45918\n","Epoch: 1 | Iteration: 3810/2403 | Classification loss: 0.19100 | Regression loss: 0.21183 | Running loss: 0.45914\n","Epoch: 1 | Iteration: 3811/2403 | Classification loss: 0.45655 | Regression loss: 0.35687 | Running loss: 0.45939\n","Epoch: 1 | Iteration: 3812/2403 | Classification loss: 0.09903 | Regression loss: 0.17301 | Running loss: 0.45926\n","Epoch: 1 | Iteration: 3813/2403 | Classification loss: 0.27610 | Regression loss: 0.23821 | Running loss: 0.45929\n","Epoch: 1 | Iteration: 3814/2403 | Classification loss: 0.35384 | Regression loss: 0.26039 | Running loss: 0.45940\n","Epoch: 1 | Iteration: 3815/2403 | Classification loss: 0.15309 | Regression loss: 0.23916 | Running loss: 0.45936\n","Epoch: 1 | Iteration: 3816/2403 | Classification loss: 0.06820 | Regression loss: 0.14298 | Running loss: 0.45918\n","Epoch: 1 | Iteration: 3817/2403 | Classification loss: 0.10579 | Regression loss: 0.16097 | Running loss: 0.45904\n","Epoch: 1 | Iteration: 3818/2403 | Classification loss: 0.26631 | Regression loss: 0.33028 | Running loss: 0.45914\n","Epoch: 1 | Iteration: 3819/2403 | Classification loss: 0.09398 | Regression loss: 0.18342 | Running loss: 0.45901\n","Epoch: 1 | Iteration: 3820/2403 | Classification loss: 1.11513 | Regression loss: 0.38718 | Running loss: 0.45975\n","Epoch: 1 | Iteration: 3821/2403 | Classification loss: 0.53985 | Regression loss: 0.40964 | Running loss: 0.46010\n","Epoch: 1 | Iteration: 3822/2403 | Classification loss: 0.26101 | Regression loss: 0.18423 | Running loss: 0.46008\n","Epoch: 1 | Iteration: 3823/2403 | Classification loss: 0.15884 | Regression loss: 0.16998 | Running loss: 0.45999\n","Epoch: 1 | Iteration: 3824/2403 | Classification loss: 0.33890 | Regression loss: 0.34950 | Running loss: 0.46015\n","Epoch: 1 | Iteration: 3825/2403 | Classification loss: 0.25326 | Regression loss: 0.22362 | Running loss: 0.46016\n","Epoch: 1 | Iteration: 3826/2403 | Classification loss: 0.30680 | Regression loss: 0.13628 | Running loss: 0.46015\n","Epoch: 1 | Iteration: 3827/2403 | Classification loss: 0.08750 | Regression loss: 0.17483 | Running loss: 0.46001\n","Epoch: 1 | Iteration: 3828/2403 | Classification loss: 0.34721 | Regression loss: 0.29039 | Running loss: 0.46014\n","Epoch: 1 | Iteration: 3829/2403 | Classification loss: 0.19741 | Regression loss: 0.28434 | Running loss: 0.46015\n","Epoch: 1 | Iteration: 3830/2403 | Classification loss: 0.13853 | Regression loss: 0.17141 | Running loss: 0.46005\n","Epoch: 1 | Iteration: 3831/2403 | Classification loss: 0.19277 | Regression loss: 0.30170 | Running loss: 0.46007\n","Epoch: 1 | Iteration: 3832/2403 | Classification loss: 0.66299 | Regression loss: 0.23898 | Running loss: 0.46038\n","Epoch: 1 | Iteration: 3833/2403 | Classification loss: 0.53399 | Regression loss: 0.28085 | Running loss: 0.46063\n","Epoch: 1 | Iteration: 3834/2403 | Classification loss: 0.06670 | Regression loss: 0.16216 | Running loss: 0.46047\n","Epoch: 1 | Iteration: 3835/2403 | Classification loss: 0.35433 | Regression loss: 0.22837 | Running loss: 0.46055\n","Epoch: 1 | Iteration: 3836/2403 | Classification loss: 0.13653 | Regression loss: 0.21352 | Running loss: 0.46048\n","Epoch: 1 | Iteration: 3837/2403 | Classification loss: 0.16542 | Regression loss: 0.23378 | Running loss: 0.46043\n","Epoch: 1 | Iteration: 3838/2403 | Classification loss: 0.17327 | Regression loss: 0.17073 | Running loss: 0.46035\n","Epoch: 1 | Iteration: 3839/2403 | Classification loss: 0.12627 | Regression loss: 0.14052 | Running loss: 0.46022\n","Epoch: 1 | Iteration: 3840/2403 | Classification loss: 0.16553 | Regression loss: 0.23212 | Running loss: 0.46017\n","Epoch: 1 | Iteration: 3841/2403 | Classification loss: 0.04925 | Regression loss: 0.12683 | Running loss: 0.45998\n","Epoch: 1 | Iteration: 3842/2403 | Classification loss: 0.21547 | Regression loss: 0.14385 | Running loss: 0.45991\n","Epoch: 1 | Iteration: 3843/2403 | Classification loss: 0.32999 | Regression loss: 0.36653 | Running loss: 0.46007\n","Epoch: 1 | Iteration: 3844/2403 | Classification loss: 0.01814 | Regression loss: 0.12106 | Running loss: 0.45985\n","Epoch: 1 | Iteration: 3845/2403 | Classification loss: 0.03145 | Regression loss: 0.09274 | Running loss: 0.45961\n","Epoch: 1 | Iteration: 3846/2403 | Classification loss: 0.25013 | Regression loss: 0.24248 | Running loss: 0.45964\n","Epoch: 1 | Iteration: 3847/2403 | Classification loss: 0.05217 | Regression loss: 0.13451 | Running loss: 0.45945\n","Epoch: 1 | Iteration: 3848/2403 | Classification loss: 0.04205 | Regression loss: 0.13169 | Running loss: 0.45925\n","Epoch: 1 | Iteration: 3849/2403 | Classification loss: 0.03569 | Regression loss: 0.09846 | Running loss: 0.45903\n","Epoch: 1 | Iteration: 3850/2403 | Classification loss: 0.38336 | Regression loss: 0.23328 | Running loss: 0.45914\n","Epoch: 1 | Iteration: 3851/2403 | Classification loss: 0.09075 | Regression loss: 0.17128 | Running loss: 0.45900\n","Epoch: 1 | Iteration: 3852/2403 | Classification loss: 0.18431 | Regression loss: 0.31347 | Running loss: 0.45903\n","Epoch: 1 | Iteration: 3853/2403 | Classification loss: 0.09046 | Regression loss: 0.22436 | Running loss: 0.45893\n","Epoch: 1 | Iteration: 3854/2403 | Classification loss: 0.04798 | Regression loss: 0.18128 | Running loss: 0.45877\n","Epoch: 1 | Iteration: 3855/2403 | Classification loss: 0.07100 | Regression loss: 0.18191 | Running loss: 0.45863\n","Epoch: 1 | Iteration: 3856/2403 | Classification loss: 0.08951 | Regression loss: 0.22525 | Running loss: 0.45853\n","Epoch: 1 | Iteration: 3857/2403 | Classification loss: 0.36222 | Regression loss: 0.29464 | Running loss: 0.45866\n","Epoch: 1 | Iteration: 3858/2403 | Classification loss: 0.08198 | Regression loss: 0.19095 | Running loss: 0.45854\n","Epoch: 1 | Iteration: 3859/2403 | Classification loss: 0.09450 | Regression loss: 0.20191 | Running loss: 0.45842\n","Epoch: 1 | Iteration: 3860/2403 | Classification loss: 0.05520 | Regression loss: 0.14723 | Running loss: 0.45825\n","Epoch: 1 | Iteration: 3861/2403 | Classification loss: 0.09167 | Regression loss: 0.18631 | Running loss: 0.45813\n","Epoch: 1 | Iteration: 3862/2403 | Classification loss: 0.13713 | Regression loss: 0.20998 | Running loss: 0.45805\n","Epoch: 1 | Iteration: 3863/2403 | Classification loss: 0.65343 | Regression loss: 0.20399 | Running loss: 0.45832\n","Epoch: 1 | Iteration: 3864/2403 | Classification loss: 0.07434 | Regression loss: 0.20841 | Running loss: 0.45820\n","Epoch: 1 | Iteration: 3865/2403 | Classification loss: 0.04748 | Regression loss: 0.18372 | Running loss: 0.45805\n","Epoch: 1 | Iteration: 3866/2403 | Classification loss: 0.25116 | Regression loss: 0.21472 | Running loss: 0.45805\n","Epoch: 1 | Iteration: 3867/2403 | Classification loss: 0.19086 | Regression loss: 0.21134 | Running loss: 0.45801\n","Epoch: 1 | Iteration: 3868/2403 | Classification loss: 0.03478 | Regression loss: 0.10579 | Running loss: 0.45780\n","Epoch: 1 | Iteration: 3869/2403 | Classification loss: 0.10062 | Regression loss: 0.18894 | Running loss: 0.45768\n","Epoch: 1 | Iteration: 3870/2403 | Classification loss: 0.19379 | Regression loss: 0.23863 | Running loss: 0.45767\n","Epoch: 1 | Iteration: 3871/2403 | Classification loss: 0.19601 | Regression loss: 0.29592 | Running loss: 0.45769\n","Epoch: 1 | Iteration: 3872/2403 | Classification loss: 0.13890 | Regression loss: 0.28362 | Running loss: 0.45767\n","Epoch: 1 | Iteration: 3873/2403 | Classification loss: 0.23075 | Regression loss: 0.30493 | Running loss: 0.45772\n","Epoch: 1 | Iteration: 3874/2403 | Classification loss: 0.06546 | Regression loss: 0.14794 | Running loss: 0.45755\n","Epoch: 1 | Iteration: 3875/2403 | Classification loss: 0.20127 | Regression loss: 0.26677 | Running loss: 0.45756\n","Epoch: 1 | Iteration: 3876/2403 | Classification loss: 0.08811 | Regression loss: 0.19430 | Running loss: 0.45744\n","Epoch: 1 | Iteration: 3877/2403 | Classification loss: 0.05477 | Regression loss: 0.18936 | Running loss: 0.45730\n","Epoch: 1 | Iteration: 3878/2403 | Classification loss: 0.06976 | Regression loss: 0.13912 | Running loss: 0.45713\n","Epoch: 1 | Iteration: 3879/2403 | Classification loss: 0.08410 | Regression loss: 0.18724 | Running loss: 0.45700\n","Epoch: 1 | Iteration: 3880/2403 | Classification loss: 0.09975 | Regression loss: 0.13437 | Running loss: 0.45685\n","Epoch: 1 | Iteration: 3881/2403 | Classification loss: 0.15531 | Regression loss: 0.19969 | Running loss: 0.45678\n","Epoch: 1 | Iteration: 3882/2403 | Classification loss: 0.21256 | Regression loss: 0.30004 | Running loss: 0.45682\n","Epoch: 1 | Iteration: 3883/2403 | Classification loss: 0.52292 | Regression loss: 0.27350 | Running loss: 0.45705\n","Epoch: 1 | Iteration: 3884/2403 | Classification loss: 0.07635 | Regression loss: 0.12819 | Running loss: 0.45688\n","Epoch: 1 | Iteration: 3885/2403 | Classification loss: 0.28345 | Regression loss: 0.21729 | Running loss: 0.45691\n","Epoch: 1 | Iteration: 3886/2403 | Classification loss: 0.04279 | Regression loss: 0.19647 | Running loss: 0.45676\n","Epoch: 1 | Iteration: 3887/2403 | Classification loss: 0.44838 | Regression loss: 0.37842 | Running loss: 0.45701\n","Epoch: 1 | Iteration: 3888/2403 | Classification loss: 0.26813 | Regression loss: 0.22159 | Running loss: 0.45703\n","Epoch: 1 | Iteration: 3889/2403 | Classification loss: 0.09303 | Regression loss: 0.14234 | Running loss: 0.45688\n","Epoch: 1 | Iteration: 3890/2403 | Classification loss: 0.11556 | Regression loss: 0.16148 | Running loss: 0.45676\n","Epoch: 1 | Iteration: 3891/2403 | Classification loss: 0.12671 | Regression loss: 0.19480 | Running loss: 0.45667\n","Epoch: 1 | Iteration: 3892/2403 | Classification loss: 0.29044 | Regression loss: 0.24085 | Running loss: 0.45672\n","Epoch: 1 | Iteration: 3893/2403 | Classification loss: 0.21636 | Regression loss: 0.16006 | Running loss: 0.45667\n","Epoch: 1 | Iteration: 3894/2403 | Classification loss: 0.03258 | Regression loss: 0.13801 | Running loss: 0.45648\n","Epoch: 1 | Iteration: 3895/2403 | Classification loss: 0.16118 | Regression loss: 0.29602 | Running loss: 0.45648\n","Epoch: 1 | Iteration: 3896/2403 | Classification loss: 0.09043 | Regression loss: 0.19249 | Running loss: 0.45636\n","Epoch: 1 | Iteration: 3897/2403 | Classification loss: 0.41891 | Regression loss: 0.32594 | Running loss: 0.45655\n","Epoch: 1 | Iteration: 3898/2403 | Classification loss: 0.05830 | Regression loss: 0.18314 | Running loss: 0.45641\n","Epoch: 1 | Iteration: 3899/2403 | Classification loss: 0.14518 | Regression loss: 0.23468 | Running loss: 0.45636\n","Epoch: 1 | Iteration: 3900/2403 | Classification loss: 0.30389 | Regression loss: 0.34409 | Running loss: 0.45649\n","Epoch: 1 | Iteration: 3901/2403 | Classification loss: 0.07639 | Regression loss: 0.13435 | Running loss: 0.45632\n","Epoch: 1 | Iteration: 3902/2403 | Classification loss: 0.15921 | Regression loss: 0.17523 | Running loss: 0.45624\n","Epoch: 1 | Iteration: 3903/2403 | Classification loss: 0.13147 | Regression loss: 0.26421 | Running loss: 0.45620\n","Epoch: 1 | Iteration: 3904/2403 | Classification loss: 0.25863 | Regression loss: 0.27558 | Running loss: 0.45625\n","Epoch: 1 | Iteration: 3905/2403 | Classification loss: 0.09132 | Regression loss: 0.16120 | Running loss: 0.45612\n","Epoch: 1 | Iteration: 3906/2403 | Classification loss: 0.16576 | Regression loss: 0.22361 | Running loss: 0.45607\n","Epoch: 1 | Iteration: 3907/2403 | Classification loss: 0.16346 | Regression loss: 0.24622 | Running loss: 0.45604\n","Epoch: 1 | Iteration: 3908/2403 | Classification loss: 0.09288 | Regression loss: 0.12100 | Running loss: 0.45588\n","Epoch: 1 | Iteration: 3909/2403 | Classification loss: 0.11854 | Regression loss: 0.18094 | Running loss: 0.45578\n","Epoch: 1 | Iteration: 3910/2403 | Classification loss: 0.23921 | Regression loss: 0.23273 | Running loss: 0.45579\n","Epoch: 1 | Iteration: 3911/2403 | Classification loss: 0.04966 | Regression loss: 0.16268 | Running loss: 0.45563\n","Epoch: 1 | Iteration: 3912/2403 | Classification loss: 0.05718 | Regression loss: 0.16470 | Running loss: 0.45547\n","Epoch: 1 | Iteration: 3913/2403 | Classification loss: 0.46058 | Regression loss: 0.22020 | Running loss: 0.45562\n","Epoch: 1 | Iteration: 3914/2403 | Classification loss: 0.43408 | Regression loss: 0.32205 | Running loss: 0.45582\n","Epoch: 1 | Iteration: 3915/2403 | Classification loss: 0.04977 | Regression loss: 0.18797 | Running loss: 0.45568\n","Epoch: 1 | Iteration: 3916/2403 | Classification loss: 0.09458 | Regression loss: 0.16190 | Running loss: 0.45554\n","Epoch: 1 | Iteration: 3917/2403 | Classification loss: 0.10555 | Regression loss: 0.16889 | Running loss: 0.45542\n","Epoch: 1 | Iteration: 3918/2403 | Classification loss: 0.21236 | Regression loss: 0.35957 | Running loss: 0.45550\n","Epoch: 1 | Iteration: 3919/2403 | Classification loss: 0.10267 | Regression loss: 0.23664 | Running loss: 0.45542\n","Epoch: 1 | Iteration: 3920/2403 | Classification loss: 0.17577 | Regression loss: 0.22311 | Running loss: 0.45539\n","Epoch: 1 | Iteration: 3921/2403 | Classification loss: 0.04352 | Regression loss: 0.12830 | Running loss: 0.45520\n","Epoch: 1 | Iteration: 3922/2403 | Classification loss: 0.05717 | Regression loss: 0.15710 | Running loss: 0.45504\n","Epoch: 1 | Iteration: 3923/2403 | Classification loss: 0.13791 | Regression loss: 0.22868 | Running loss: 0.45498\n","Epoch: 1 | Iteration: 3924/2403 | Classification loss: 0.17485 | Regression loss: 0.28068 | Running loss: 0.45498\n","Epoch: 1 | Iteration: 3925/2403 | Classification loss: 0.42184 | Regression loss: 0.32095 | Running loss: 0.45517\n","Epoch: 1 | Iteration: 3926/2403 | Classification loss: 0.55397 | Regression loss: 0.40470 | Running loss: 0.45550\n","Epoch: 1 | Iteration: 3927/2403 | Classification loss: 0.23710 | Regression loss: 0.23216 | Running loss: 0.45551\n","Epoch: 1 | Iteration: 3928/2403 | Classification loss: 0.28621 | Regression loss: 0.23102 | Running loss: 0.45555\n","Epoch: 1 | Iteration: 3929/2403 | Classification loss: 0.20719 | Regression loss: 0.21606 | Running loss: 0.45553\n","Epoch: 1 | Iteration: 3930/2403 | Classification loss: 0.14097 | Regression loss: 0.17566 | Running loss: 0.45544\n","Epoch: 1 | Iteration: 3931/2403 | Classification loss: 0.23046 | Regression loss: 0.28295 | Running loss: 0.45548\n","Epoch: 1 | Iteration: 3932/2403 | Classification loss: 0.12359 | Regression loss: 0.18560 | Running loss: 0.45538\n","Epoch: 1 | Iteration: 3933/2403 | Classification loss: 0.19209 | Regression loss: 0.22161 | Running loss: 0.45536\n","Epoch: 1 | Iteration: 3934/2403 | Classification loss: 0.32205 | Regression loss: 0.30667 | Running loss: 0.45547\n","Epoch: 1 | Iteration: 3935/2403 | Classification loss: 0.06298 | Regression loss: 0.22225 | Running loss: 0.45536\n","Epoch: 1 | Iteration: 3936/2403 | Classification loss: 0.16541 | Regression loss: 0.19669 | Running loss: 0.45530\n","Epoch: 1 | Iteration: 3937/2403 | Classification loss: 0.10012 | Regression loss: 0.27259 | Running loss: 0.45524\n","Epoch: 1 | Iteration: 3938/2403 | Classification loss: 0.25072 | Regression loss: 0.17317 | Running loss: 0.45522\n","Epoch: 1 | Iteration: 3939/2403 | Classification loss: 0.26913 | Regression loss: 0.43428 | Running loss: 0.45538\n","Epoch: 1 | Iteration: 3940/2403 | Classification loss: 0.12917 | Regression loss: 0.15785 | Running loss: 0.45527\n","Epoch: 1 | Iteration: 3941/2403 | Classification loss: 0.21195 | Regression loss: 0.17092 | Running loss: 0.45523\n","Epoch: 1 | Iteration: 3942/2403 | Classification loss: 0.24967 | Regression loss: 0.32307 | Running loss: 0.45530\n","Epoch: 1 | Iteration: 3943/2403 | Classification loss: 0.18713 | Regression loss: 0.19148 | Running loss: 0.45525\n","Epoch: 1 | Iteration: 3944/2403 | Classification loss: 0.07514 | Regression loss: 0.22255 | Running loss: 0.45515\n","Epoch: 1 | Iteration: 3945/2403 | Classification loss: 0.05618 | Regression loss: 0.18625 | Running loss: 0.45501\n","Epoch: 1 | Iteration: 3946/2403 | Classification loss: 0.09659 | Regression loss: 0.18322 | Running loss: 0.45490\n","Epoch: 1 | Iteration: 3947/2403 | Classification loss: 0.31094 | Regression loss: 0.18363 | Running loss: 0.45493\n","Epoch: 1 | Iteration: 3948/2403 | Classification loss: 0.10547 | Regression loss: 0.15924 | Running loss: 0.45480\n","Epoch: 1 | Iteration: 3949/2403 | Classification loss: 0.05859 | Regression loss: 0.18875 | Running loss: 0.45467\n","Epoch: 1 | Iteration: 3950/2403 | Classification loss: 0.42607 | Regression loss: 0.31606 | Running loss: 0.45485\n","Epoch: 1 | Iteration: 3951/2403 | Classification loss: 0.35256 | Regression loss: 0.30698 | Running loss: 0.45499\n","Epoch: 1 | Iteration: 3952/2403 | Classification loss: 0.27158 | Regression loss: 0.23146 | Running loss: 0.45502\n","Epoch: 1 | Iteration: 3953/2403 | Classification loss: 0.25028 | Regression loss: 0.17021 | Running loss: 0.45500\n","Epoch: 1 | Iteration: 3954/2403 | Classification loss: 0.23329 | Regression loss: 0.20810 | Running loss: 0.45499\n","Epoch: 1 | Iteration: 3955/2403 | Classification loss: 0.09117 | Regression loss: 0.15716 | Running loss: 0.45485\n","Epoch: 1 | Iteration: 3956/2403 | Classification loss: 0.46796 | Regression loss: 0.36607 | Running loss: 0.45510\n","Epoch: 1 | Iteration: 3957/2403 | Classification loss: 0.46681 | Regression loss: 0.23971 | Running loss: 0.45526\n","Epoch: 1 | Iteration: 3958/2403 | Classification loss: 0.19143 | Regression loss: 0.25941 | Running loss: 0.45526\n","Epoch: 1 | Iteration: 3959/2403 | Classification loss: 0.07717 | Regression loss: 0.11418 | Running loss: 0.45509\n","Epoch: 1 | Iteration: 3960/2403 | Classification loss: 0.06497 | Regression loss: 0.16498 | Running loss: 0.45494\n","Epoch: 1 | Iteration: 3961/2403 | Classification loss: 0.08779 | Regression loss: 0.16074 | Running loss: 0.45481\n","Epoch: 1 | Iteration: 3962/2403 | Classification loss: 0.24763 | Regression loss: 0.38247 | Running loss: 0.45492\n","Epoch: 1 | Iteration: 3963/2403 | Classification loss: 0.14021 | Regression loss: 0.16742 | Running loss: 0.45483\n","Epoch: 1 | Iteration: 3964/2403 | Classification loss: 0.76130 | Regression loss: 0.21291 | Running loss: 0.45516\n","Epoch: 1 | Iteration: 3965/2403 | Classification loss: 0.51540 | Regression loss: 0.24048 | Running loss: 0.45535\n","Epoch: 1 | Iteration: 3966/2403 | Classification loss: 0.13624 | Regression loss: 0.22945 | Running loss: 0.45530\n","Epoch: 1 | Iteration: 3967/2403 | Classification loss: 0.08254 | Regression loss: 0.17223 | Running loss: 0.45517\n","Epoch: 1 | Iteration: 3968/2403 | Classification loss: 0.28015 | Regression loss: 0.28679 | Running loss: 0.45524\n","Epoch: 1 | Iteration: 3969/2403 | Classification loss: 0.15703 | Regression loss: 0.21233 | Running loss: 0.45518\n","Epoch: 1 | Iteration: 3970/2403 | Classification loss: 0.14344 | Regression loss: 0.20907 | Running loss: 0.45512\n","Epoch: 1 | Iteration: 3971/2403 | Classification loss: 0.23006 | Regression loss: 0.29197 | Running loss: 0.45516\n","Epoch: 1 | Iteration: 3972/2403 | Classification loss: 0.08879 | Regression loss: 0.22534 | Running loss: 0.45507\n","Epoch: 1 | Iteration: 3973/2403 | Classification loss: 0.10161 | Regression loss: 0.11237 | Running loss: 0.45492\n","Epoch: 1 | Iteration: 3974/2403 | Classification loss: 0.44538 | Regression loss: 0.24610 | Running loss: 0.45507\n","Epoch: 1 | Iteration: 3975/2403 | Classification loss: 0.89198 | Regression loss: 0.63209 | Running loss: 0.45575\n","Epoch: 1 | Iteration: 3976/2403 | Classification loss: 0.03385 | Regression loss: 0.12994 | Running loss: 0.45556\n","Epoch: 1 | Iteration: 3977/2403 | Classification loss: 0.11368 | Regression loss: 0.22408 | Running loss: 0.45549\n","Epoch: 1 | Iteration: 3978/2403 | Classification loss: 0.29063 | Regression loss: 0.33965 | Running loss: 0.45560\n","Epoch: 1 | Iteration: 3979/2403 | Classification loss: 0.07208 | Regression loss: 0.09993 | Running loss: 0.45542\n","Epoch: 1 | Iteration: 3980/2403 | Classification loss: 0.15013 | Regression loss: 0.12185 | Running loss: 0.45530\n","Epoch: 1 | Iteration: 3981/2403 | Classification loss: 0.53106 | Regression loss: 0.23590 | Running loss: 0.45550\n","Epoch: 1 | Iteration: 3982/2403 | Classification loss: 0.06895 | Regression loss: 0.15141 | Running loss: 0.45535\n","Epoch: 1 | Iteration: 3983/2403 | Classification loss: 0.25062 | Regression loss: 0.23656 | Running loss: 0.45537\n","Epoch: 1 | Iteration: 3984/2403 | Classification loss: 0.13869 | Regression loss: 0.18141 | Running loss: 0.45529\n","Epoch: 1 | Iteration: 3985/2403 | Classification loss: 0.16518 | Regression loss: 0.23013 | Running loss: 0.45525\n","Epoch: 1 | Iteration: 3986/2403 | Classification loss: 0.06686 | Regression loss: 0.20297 | Running loss: 0.45513\n","Epoch: 1 | Iteration: 3987/2403 | Classification loss: 0.54840 | Regression loss: 0.54980 | Running loss: 0.45554\n","Epoch: 1 | Iteration: 3988/2403 | Classification loss: 0.38084 | Regression loss: 0.28780 | Running loss: 0.45567\n","Epoch: 1 | Iteration: 3989/2403 | Classification loss: 0.69046 | Regression loss: 0.22136 | Running loss: 0.45596\n","Epoch: 1 | Iteration: 3990/2403 | Classification loss: 0.58466 | Regression loss: 0.29420 | Running loss: 0.45623\n","Epoch: 1 | Iteration: 3991/2403 | Classification loss: 0.11538 | Regression loss: 0.17471 | Running loss: 0.45612\n","Epoch: 1 | Iteration: 3992/2403 | Classification loss: 0.14687 | Regression loss: 0.20264 | Running loss: 0.45605\n","Epoch: 1 | Iteration: 3993/2403 | Classification loss: 1.41717 | Regression loss: 0.44801 | Running loss: 0.45694\n","Epoch: 1 | Iteration: 3994/2403 | Classification loss: 0.04188 | Regression loss: 0.12467 | Running loss: 0.45676\n","Epoch: 1 | Iteration: 3995/2403 | Classification loss: 0.38937 | Regression loss: 0.31670 | Running loss: 0.45691\n","Epoch: 1 | Iteration: 3996/2403 | Classification loss: 0.06636 | Regression loss: 0.16103 | Running loss: 0.45677\n","Epoch: 1 | Iteration: 3997/2403 | Classification loss: 0.17365 | Regression loss: 0.30585 | Running loss: 0.45678\n","Epoch: 1 | Iteration: 3998/2403 | Classification loss: 0.39169 | Regression loss: 0.30688 | Running loss: 0.45694\n","Epoch: 1 | Iteration: 3999/2403 | Classification loss: 0.11272 | Regression loss: 0.24729 | Running loss: 0.45688\n","Epoch: 1 | Iteration: 4000/2403 | Classification loss: 0.04811 | Regression loss: 0.14815 | Running loss: 0.45671\n","Epoch: 1 | Iteration: 4001/2403 | Classification loss: 0.13312 | Regression loss: 0.16776 | Running loss: 0.45661\n","Epoch: 1 | Iteration: 4002/2403 | Classification loss: 0.15567 | Regression loss: 0.16577 | Running loss: 0.45653\n","Epoch: 1 | Iteration: 4003/2403 | Classification loss: 0.11806 | Regression loss: 0.15500 | Running loss: 0.45642\n","Epoch: 1 | Iteration: 4004/2403 | Classification loss: 0.12684 | Regression loss: 0.17672 | Running loss: 0.45632\n","Epoch: 1 | Iteration: 4005/2403 | Classification loss: 0.05163 | Regression loss: 0.17336 | Running loss: 0.45618\n","Epoch: 1 | Iteration: 4006/2403 | Classification loss: 0.34800 | Regression loss: 0.14029 | Running loss: 0.45620\n","Epoch: 1 | Iteration: 4007/2403 | Classification loss: 0.10678 | Regression loss: 0.20665 | Running loss: 0.45611\n","Epoch: 1 | Iteration: 4008/2403 | Classification loss: 0.09632 | Regression loss: 0.17191 | Running loss: 0.45599\n","Epoch: 1 | Iteration: 4009/2403 | Classification loss: 0.08763 | Regression loss: 0.19696 | Running loss: 0.45588\n","Epoch: 1 | Iteration: 4010/2403 | Classification loss: 0.14505 | Regression loss: 0.23972 | Running loss: 0.45584\n","Epoch: 1 | Iteration: 4011/2403 | Classification loss: 0.06951 | Regression loss: 0.14666 | Running loss: 0.45569\n","Epoch: 1 | Iteration: 4012/2403 | Classification loss: 0.11734 | Regression loss: 0.22769 | Running loss: 0.45562\n","Epoch: 1 | Iteration: 4013/2403 | Classification loss: 0.11581 | Regression loss: 0.25996 | Running loss: 0.45557\n","Epoch: 1 | Iteration: 4014/2403 | Classification loss: 0.03607 | Regression loss: 0.12815 | Running loss: 0.45539\n","Epoch: 1 | Iteration: 4015/2403 | Classification loss: 0.39262 | Regression loss: 0.25652 | Running loss: 0.45551\n","Epoch: 1 | Iteration: 4016/2403 | Classification loss: 0.40243 | Regression loss: 0.25733 | Running loss: 0.45564\n","Epoch: 1 | Iteration: 4017/2403 | Classification loss: 0.05944 | Regression loss: 0.17880 | Running loss: 0.45550\n","Epoch: 1 | Iteration: 4018/2403 | Classification loss: 2.25691 | Regression loss: 0.33505 | Running loss: 0.45683\n","Epoch: 1 | Iteration: 4019/2403 | Classification loss: 0.15699 | Regression loss: 0.20535 | Running loss: 0.45677\n","Epoch: 1 | Iteration: 4020/2403 | Classification loss: 0.22271 | Regression loss: 0.28032 | Running loss: 0.45680\n","Epoch: 1 | Iteration: 4021/2403 | Classification loss: 0.09951 | Regression loss: 0.16049 | Running loss: 0.45667\n","Epoch: 1 | Iteration: 4022/2403 | Classification loss: 0.12130 | Regression loss: 0.19651 | Running loss: 0.45659\n","Epoch: 1 | Iteration: 4023/2403 | Classification loss: 0.08554 | Regression loss: 0.16701 | Running loss: 0.45646\n","Epoch: 1 | Iteration: 4024/2403 | Classification loss: 0.06316 | Regression loss: 0.25563 | Running loss: 0.45638\n","Epoch: 1 | Iteration: 4025/2403 | Classification loss: 0.36831 | Regression loss: 0.24068 | Running loss: 0.45647\n","Epoch: 1 | Iteration: 4026/2403 | Classification loss: 0.05543 | Regression loss: 0.17454 | Running loss: 0.45633\n","Epoch: 1 | Iteration: 4027/2403 | Classification loss: 0.04997 | Regression loss: 0.18799 | Running loss: 0.45620\n","Epoch: 1 | Iteration: 4028/2403 | Classification loss: 0.09582 | Regression loss: 0.22167 | Running loss: 0.45611\n","Epoch: 1 | Iteration: 4029/2403 | Classification loss: 0.08223 | Regression loss: 0.17628 | Running loss: 0.45599\n","Epoch: 1 | Iteration: 4030/2403 | Classification loss: 2.03834 | Regression loss: 0.26843 | Running loss: 0.45713\n","Epoch: 1 | Iteration: 4031/2403 | Classification loss: 0.05547 | Regression loss: 0.17337 | Running loss: 0.45699\n","Epoch: 1 | Iteration: 4032/2403 | Classification loss: 0.42109 | Regression loss: 0.26567 | Running loss: 0.45713\n","Epoch: 1 | Iteration: 4033/2403 | Classification loss: 0.15342 | Regression loss: 0.30921 | Running loss: 0.45713\n","Epoch: 1 | Iteration: 4034/2403 | Classification loss: 0.33446 | Regression loss: 0.21999 | Running loss: 0.45719\n","Epoch: 1 | Iteration: 4035/2403 | Classification loss: 0.43857 | Regression loss: 0.29772 | Running loss: 0.45736\n","Epoch: 1 | Iteration: 4036/2403 | Classification loss: 0.15268 | Regression loss: 0.23056 | Running loss: 0.45732\n","Epoch: 1 | Iteration: 4037/2403 | Classification loss: 0.18300 | Regression loss: 0.18110 | Running loss: 0.45726\n","Epoch: 1 | Iteration: 4038/2403 | Classification loss: 0.23624 | Regression loss: 0.17554 | Running loss: 0.45723\n","Epoch: 1 | Iteration: 4039/2403 | Classification loss: 0.11114 | Regression loss: 0.17391 | Running loss: 0.45713\n","Epoch: 1 | Iteration: 4040/2403 | Classification loss: 0.13035 | Regression loss: 0.15605 | Running loss: 0.45702\n","Epoch: 1 | Iteration: 4041/2403 | Classification loss: 0.24688 | Regression loss: 0.25986 | Running loss: 0.45705\n","Epoch: 1 | Iteration: 4042/2403 | Classification loss: 0.32953 | Regression loss: 0.31185 | Running loss: 0.45717\n","Epoch: 1 | Iteration: 4043/2403 | Classification loss: 0.17951 | Regression loss: 0.14532 | Running loss: 0.45708\n","Epoch: 1 | Iteration: 4044/2403 | Classification loss: 0.13087 | Regression loss: 0.13394 | Running loss: 0.45697\n","Epoch: 1 | Iteration: 4045/2403 | Classification loss: 0.25644 | Regression loss: 0.19431 | Running loss: 0.45696\n","Epoch: 1 | Iteration: 4046/2403 | Classification loss: 0.10549 | Regression loss: 0.17225 | Running loss: 0.45685\n","Epoch: 1 | Iteration: 4047/2403 | Classification loss: 0.10482 | Regression loss: 0.22981 | Running loss: 0.45678\n","Epoch: 1 | Iteration: 4048/2403 | Classification loss: 0.24090 | Regression loss: 0.26157 | Running loss: 0.45681\n","Epoch: 1 | Iteration: 4049/2403 | Classification loss: 0.22498 | Regression loss: 0.45822 | Running loss: 0.45695\n","Epoch: 1 | Iteration: 4050/2403 | Classification loss: 0.07716 | Regression loss: 0.22504 | Running loss: 0.45685\n","Epoch: 1 | Iteration: 4051/2403 | Classification loss: 0.13228 | Regression loss: 0.25965 | Running loss: 0.45681\n","Epoch: 1 | Iteration: 4052/2403 | Classification loss: 0.16291 | Regression loss: 0.20864 | Running loss: 0.45676\n","Epoch: 1 | Iteration: 4053/2403 | Classification loss: 0.22880 | Regression loss: 0.38422 | Running loss: 0.45686\n","Epoch: 1 | Iteration: 4054/2403 | Classification loss: 0.30320 | Regression loss: 0.33713 | Running loss: 0.45697\n","Epoch: 1 | Iteration: 4055/2403 | Classification loss: 0.09525 | Regression loss: 0.16774 | Running loss: 0.45685\n","Epoch: 1 | Iteration: 4056/2403 | Classification loss: 0.31661 | Regression loss: 0.40898 | Running loss: 0.45701\n","Epoch: 1 | Iteration: 4057/2403 | Classification loss: 0.08643 | Regression loss: 0.18713 | Running loss: 0.45690\n","Epoch: 1 | Iteration: 4058/2403 | Classification loss: 0.53080 | Regression loss: 0.25249 | Running loss: 0.45710\n","Epoch: 1 | Iteration: 4059/2403 | Classification loss: 0.16149 | Regression loss: 0.21875 | Running loss: 0.45705\n","Epoch: 1 | Iteration: 4060/2403 | Classification loss: 0.15928 | Regression loss: 0.20603 | Running loss: 0.45700\n","Epoch: 1 | Iteration: 4061/2403 | Classification loss: 0.32336 | Regression loss: 0.28901 | Running loss: 0.45709\n","Epoch: 1 | Iteration: 4062/2403 | Classification loss: 0.39522 | Regression loss: 0.34260 | Running loss: 0.45726\n","Epoch: 1 | Iteration: 4063/2403 | Classification loss: 0.46533 | Regression loss: 0.40167 | Running loss: 0.45751\n","Epoch: 1 | Iteration: 4064/2403 | Classification loss: 0.19938 | Regression loss: 0.25177 | Running loss: 0.45750\n","Epoch: 1 | Iteration: 4065/2403 | Classification loss: 0.47445 | Regression loss: 0.28691 | Running loss: 0.45769\n","Epoch: 1 | Iteration: 4066/2403 | Classification loss: 0.15696 | Regression loss: 0.10274 | Running loss: 0.45757\n","Epoch: 1 | Iteration: 4067/2403 | Classification loss: 0.25317 | Regression loss: 0.19280 | Running loss: 0.45756\n","Epoch: 1 | Iteration: 4068/2403 | Classification loss: 0.22369 | Regression loss: 0.21197 | Running loss: 0.45755\n","Epoch: 1 | Iteration: 4069/2403 | Classification loss: 0.22648 | Regression loss: 0.30761 | Running loss: 0.45759\n","Epoch: 1 | Iteration: 4070/2403 | Classification loss: 0.17525 | Regression loss: 0.14301 | Running loss: 0.45751\n","Epoch: 1 | Iteration: 4071/2403 | Classification loss: 0.19081 | Regression loss: 0.19993 | Running loss: 0.45747\n","Epoch: 1 | Iteration: 4072/2403 | Classification loss: 0.40642 | Regression loss: 0.36422 | Running loss: 0.45766\n","Epoch: 1 | Iteration: 4073/2403 | Classification loss: 0.17711 | Regression loss: 0.28704 | Running loss: 0.45766\n","Epoch: 1 | Iteration: 4074/2403 | Classification loss: 0.18408 | Regression loss: 0.29757 | Running loss: 0.45767\n","Epoch: 1 | Iteration: 4075/2403 | Classification loss: 0.02686 | Regression loss: 0.09170 | Running loss: 0.45747\n","Epoch: 1 | Iteration: 4076/2403 | Classification loss: 0.12412 | Regression loss: 0.25857 | Running loss: 0.45743\n","Epoch: 1 | Iteration: 4077/2403 | Classification loss: 0.13795 | Regression loss: 0.23841 | Running loss: 0.45738\n","Epoch: 1 | Iteration: 4078/2403 | Classification loss: 0.44184 | Regression loss: 0.54398 | Running loss: 0.45769\n","Epoch: 1 | Iteration: 4079/2403 | Classification loss: 0.10186 | Regression loss: 0.16818 | Running loss: 0.45758\n","Epoch: 1 | Iteration: 4080/2403 | Classification loss: 0.37495 | Regression loss: 0.39080 | Running loss: 0.45777\n","Epoch: 1 | Iteration: 4081/2403 | Classification loss: 0.08853 | Regression loss: 0.15765 | Running loss: 0.45764\n","Epoch: 1 | Iteration: 4082/2403 | Classification loss: 0.11447 | Regression loss: 0.17110 | Running loss: 0.45754\n","Epoch: 1 | Iteration: 4083/2403 | Classification loss: 0.19209 | Regression loss: 0.33536 | Running loss: 0.45758\n","Epoch: 1 | Iteration: 4084/2403 | Classification loss: 0.20789 | Regression loss: 0.18701 | Running loss: 0.45754\n","Epoch: 1 | Iteration: 4085/2403 | Classification loss: 0.24165 | Regression loss: 0.17821 | Running loss: 0.45752\n","Epoch: 1 | Iteration: 4086/2403 | Classification loss: 0.49718 | Regression loss: 0.31509 | Running loss: 0.45773\n","Epoch: 1 | Iteration: 4087/2403 | Classification loss: 0.10787 | Regression loss: 0.22459 | Running loss: 0.45766\n","Epoch: 1 | Iteration: 4088/2403 | Classification loss: 0.13334 | Regression loss: 0.18117 | Running loss: 0.45757\n","Epoch: 1 | Iteration: 4089/2403 | Classification loss: 0.04681 | Regression loss: 0.14473 | Running loss: 0.45741\n","Epoch: 1 | Iteration: 4090/2403 | Classification loss: 0.27689 | Regression loss: 0.25834 | Running loss: 0.45746\n","Epoch: 1 | Iteration: 4091/2403 | Classification loss: 0.07959 | Regression loss: 0.25146 | Running loss: 0.45738\n","Epoch: 1 | Iteration: 4092/2403 | Classification loss: 0.28563 | Regression loss: 0.13655 | Running loss: 0.45736\n","Epoch: 1 | Iteration: 4093/2403 | Classification loss: 0.40987 | Regression loss: 0.27140 | Running loss: 0.45750\n","Epoch: 1 | Iteration: 4094/2403 | Classification loss: 0.06299 | Regression loss: 0.18041 | Running loss: 0.45737\n","Epoch: 1 | Iteration: 4095/2403 | Classification loss: 0.24789 | Regression loss: 0.31038 | Running loss: 0.45743\n","Epoch: 1 | Iteration: 4096/2403 | Classification loss: 0.28526 | Regression loss: 0.24091 | Running loss: 0.45747\n","Epoch: 1 | Iteration: 4097/2403 | Classification loss: 0.12241 | Regression loss: 0.25437 | Running loss: 0.45742\n","Epoch: 1 | Iteration: 4098/2403 | Classification loss: 0.23360 | Regression loss: 0.21235 | Running loss: 0.45741\n","Epoch: 1 | Iteration: 4099/2403 | Classification loss: 0.14297 | Regression loss: 0.21002 | Running loss: 0.45735\n","Epoch: 1 | Iteration: 4100/2403 | Classification loss: 0.07366 | Regression loss: 0.21365 | Running loss: 0.45725\n","Epoch: 1 | Iteration: 4101/2403 | Classification loss: 0.18782 | Regression loss: 0.22432 | Running loss: 0.45723\n","Epoch: 1 | Iteration: 4102/2403 | Classification loss: 0.20852 | Regression loss: 0.24745 | Running loss: 0.45723\n","Epoch: 1 | Iteration: 4103/2403 | Classification loss: 0.33674 | Regression loss: 0.22164 | Running loss: 0.45728\n","Epoch: 1 | Iteration: 4104/2403 | Classification loss: 0.24159 | Regression loss: 0.19453 | Running loss: 0.45727\n","Epoch: 1 | Iteration: 4105/2403 | Classification loss: 0.08210 | Regression loss: 0.25264 | Running loss: 0.45720\n","Epoch: 1 | Iteration: 4106/2403 | Classification loss: 0.31160 | Regression loss: 0.23047 | Running loss: 0.45725\n","Epoch: 1 | Iteration: 4107/2403 | Classification loss: 0.05787 | Regression loss: 0.17386 | Running loss: 0.45712\n","Epoch: 1 | Iteration: 4108/2403 | Classification loss: 0.05733 | Regression loss: 0.18065 | Running loss: 0.45699\n","Epoch: 1 | Iteration: 4109/2403 | Classification loss: 0.05918 | Regression loss: 0.19295 | Running loss: 0.45687\n","Epoch: 1 | Iteration: 4110/2403 | Classification loss: 0.06388 | Regression loss: 0.13543 | Running loss: 0.45672\n","Epoch: 1 | Iteration: 4111/2403 | Classification loss: 0.20438 | Regression loss: 0.18594 | Running loss: 0.45668\n","Epoch: 1 | Iteration: 4112/2403 | Classification loss: 0.09605 | Regression loss: 0.12346 | Running loss: 0.45654\n","Epoch: 1 | Iteration: 4113/2403 | Classification loss: 1.70230 | Regression loss: 0.27781 | Running loss: 0.45743\n","Epoch: 1 | Iteration: 4114/2403 | Classification loss: 0.28585 | Regression loss: 0.31894 | Running loss: 0.45752\n","Epoch: 1 | Iteration: 4115/2403 | Classification loss: 0.23661 | Regression loss: 0.24439 | Running loss: 0.45753\n","Epoch: 1 | Iteration: 4116/2403 | Classification loss: 0.23903 | Regression loss: 0.23303 | Running loss: 0.45754\n","Epoch: 1 | Iteration: 4117/2403 | Classification loss: 0.16788 | Regression loss: 0.18386 | Running loss: 0.45748\n","Epoch: 1 | Iteration: 4118/2403 | Classification loss: 0.30698 | Regression loss: 0.37233 | Running loss: 0.45761\n","Epoch: 1 | Iteration: 4119/2403 | Classification loss: 0.20213 | Regression loss: 0.19876 | Running loss: 0.45757\n","Epoch: 1 | Iteration: 4120/2403 | Classification loss: 0.11453 | Regression loss: 0.14820 | Running loss: 0.45746\n","Epoch: 1 | Iteration: 4121/2403 | Classification loss: 0.20107 | Regression loss: 0.23518 | Running loss: 0.45745\n","Epoch: 1 | Iteration: 4122/2403 | Classification loss: 0.09345 | Regression loss: 0.17402 | Running loss: 0.45734\n","Epoch: 1 | Iteration: 4123/2403 | Classification loss: 0.16881 | Regression loss: 0.23392 | Running loss: 0.45731\n","Epoch: 1 | Iteration: 4124/2403 | Classification loss: 0.22480 | Regression loss: 0.20418 | Running loss: 0.45729\n","Epoch: 1 | Iteration: 4125/2403 | Classification loss: 0.20055 | Regression loss: 0.31205 | Running loss: 0.45732\n","Epoch: 1 | Iteration: 4126/2403 | Classification loss: 7.25147 | Regression loss: 0.21332 | Running loss: 0.46139\n","Epoch: 1 | Iteration: 4127/2403 | Classification loss: 0.18931 | Regression loss: 0.22267 | Running loss: 0.46136\n","Epoch: 1 | Iteration: 4128/2403 | Classification loss: 0.22796 | Regression loss: 0.16977 | Running loss: 0.46132\n","Epoch: 1 | Iteration: 4129/2403 | Classification loss: 0.27001 | Regression loss: 0.27614 | Running loss: 0.46137\n","Epoch: 1 | Iteration: 4130/2403 | Classification loss: 0.18338 | Regression loss: 0.19188 | Running loss: 0.46132\n","Epoch: 1 | Iteration: 4131/2403 | Classification loss: 0.29941 | Regression loss: 0.24850 | Running loss: 0.46137\n","Epoch: 1 | Iteration: 4132/2403 | Classification loss: 0.26673 | Regression loss: 0.20809 | Running loss: 0.46138\n","Epoch: 1 | Iteration: 4133/2403 | Classification loss: 0.26339 | Regression loss: 0.30023 | Running loss: 0.46144\n","Epoch: 1 | Iteration: 4134/2403 | Classification loss: 0.13711 | Regression loss: 0.19013 | Running loss: 0.46136\n","Epoch: 1 | Iteration: 4135/2403 | Classification loss: 0.29009 | Regression loss: 0.28338 | Running loss: 0.46143\n","Epoch: 1 | Iteration: 4136/2403 | Classification loss: 0.09366 | Regression loss: 0.18285 | Running loss: 0.46132\n","Epoch: 1 | Iteration: 4137/2403 | Classification loss: 0.20417 | Regression loss: 0.23211 | Running loss: 0.46131\n","Epoch: 1 | Iteration: 4138/2403 | Classification loss: 0.24848 | Regression loss: 0.20713 | Running loss: 0.46130\n","Epoch: 1 | Iteration: 4139/2403 | Classification loss: 0.10212 | Regression loss: 0.27643 | Running loss: 0.46126\n","Epoch: 1 | Iteration: 4140/2403 | Classification loss: 0.10392 | Regression loss: 0.15970 | Running loss: 0.46114\n","Epoch: 1 | Iteration: 4141/2403 | Classification loss: 0.13305 | Regression loss: 0.18175 | Running loss: 0.46106\n","Epoch: 1 | Iteration: 4142/2403 | Classification loss: 0.04896 | Regression loss: 0.13232 | Running loss: 0.46090\n","Epoch: 1 | Iteration: 4143/2403 | Classification loss: 0.20843 | Regression loss: 0.22476 | Running loss: 0.46088\n","Epoch: 1 | Iteration: 4144/2403 | Classification loss: 0.08094 | Regression loss: 0.21116 | Running loss: 0.46078\n","Epoch: 1 | Iteration: 4145/2403 | Classification loss: 0.65047 | Regression loss: 0.31193 | Running loss: 0.46107\n","Epoch: 1 | Iteration: 4146/2403 | Classification loss: 0.35408 | Regression loss: 0.24520 | Running loss: 0.46115\n","Epoch: 1 | Iteration: 4147/2403 | Classification loss: 0.19409 | Regression loss: 0.36557 | Running loss: 0.46121\n","Epoch: 1 | Iteration: 4148/2403 | Classification loss: 0.20673 | Regression loss: 0.15527 | Running loss: 0.46115\n","Epoch: 1 | Iteration: 4149/2403 | Classification loss: 0.23293 | Regression loss: 0.31911 | Running loss: 0.46120\n","Epoch: 1 | Iteration: 4150/2403 | Classification loss: 0.12900 | Regression loss: 0.18063 | Running loss: 0.46112\n","Epoch: 1 | Iteration: 4151/2403 | Classification loss: 0.10534 | Regression loss: 0.13584 | Running loss: 0.46099\n","Epoch: 1 | Iteration: 4152/2403 | Classification loss: 0.11148 | Regression loss: 0.20905 | Running loss: 0.46091\n","Epoch: 1 | Iteration: 4153/2403 | Classification loss: 0.21596 | Regression loss: 0.37424 | Running loss: 0.46098\n","Epoch: 1 | Iteration: 4154/2403 | Classification loss: 0.03910 | Regression loss: 0.21662 | Running loss: 0.46087\n","Epoch: 1 | Iteration: 4155/2403 | Classification loss: 0.19929 | Regression loss: 0.22194 | Running loss: 0.46084\n","Epoch: 1 | Iteration: 4156/2403 | Classification loss: 0.09682 | Regression loss: 0.20515 | Running loss: 0.46075\n","Epoch: 1 | Iteration: 4157/2403 | Classification loss: 0.16215 | Regression loss: 0.17098 | Running loss: 0.46068\n","Epoch: 1 | Iteration: 4158/2403 | Classification loss: 0.11223 | Regression loss: 0.14847 | Running loss: 0.46057\n","Epoch: 1 | Iteration: 4159/2403 | Classification loss: 0.14372 | Regression loss: 0.17153 | Running loss: 0.46048\n","Epoch: 1 | Iteration: 4160/2403 | Classification loss: 0.08098 | Regression loss: 0.13356 | Running loss: 0.46034\n","Epoch: 1 | Iteration: 4161/2403 | Classification loss: 0.13789 | Regression loss: 0.26566 | Running loss: 0.46031\n","Epoch: 1 | Iteration: 4162/2403 | Classification loss: 0.03321 | Regression loss: 0.13096 | Running loss: 0.46014\n","Epoch: 1 | Iteration: 4163/2403 | Classification loss: 0.78184 | Regression loss: 0.32991 | Running loss: 0.46051\n","Epoch: 1 | Iteration: 4164/2403 | Classification loss: 0.24498 | Regression loss: 0.23893 | Running loss: 0.46053\n","Epoch: 1 | Iteration: 4165/2403 | Classification loss: 0.48087 | Regression loss: 0.17332 | Running loss: 0.46064\n","Epoch: 1 | Iteration: 4166/2403 | Classification loss: 0.29232 | Regression loss: 0.33358 | Running loss: 0.46073\n","Epoch: 1 | Iteration: 4167/2403 | Classification loss: 0.08385 | Regression loss: 0.15579 | Running loss: 0.46060\n","Epoch: 1 | Iteration: 4168/2403 | Classification loss: 0.11335 | Regression loss: 0.15198 | Running loss: 0.46049\n","Epoch: 1 | Iteration: 4169/2403 | Classification loss: 0.18876 | Regression loss: 0.21164 | Running loss: 0.46046\n","Epoch: 1 | Iteration: 4170/2403 | Classification loss: 0.25070 | Regression loss: 0.30424 | Running loss: 0.46051\n","Epoch: 1 | Iteration: 4171/2403 | Classification loss: 0.26265 | Regression loss: 0.17324 | Running loss: 0.46050\n","Epoch: 1 | Iteration: 4172/2403 | Classification loss: 0.39940 | Regression loss: 0.30793 | Running loss: 0.46064\n","Epoch: 1 | Iteration: 4173/2403 | Classification loss: 0.14247 | Regression loss: 0.19545 | Running loss: 0.46057\n","Epoch: 1 | Iteration: 4174/2403 | Classification loss: 0.15826 | Regression loss: 0.27698 | Running loss: 0.46056\n","Epoch: 1 | Iteration: 4175/2403 | Classification loss: 0.07908 | Regression loss: 0.19906 | Running loss: 0.46045\n","Epoch: 1 | Iteration: 4176/2403 | Classification loss: 0.20819 | Regression loss: 0.15930 | Running loss: 0.46040\n","Epoch: 1 | Iteration: 4177/2403 | Classification loss: 0.04817 | Regression loss: 0.15786 | Running loss: 0.46026\n","Epoch: 1 | Iteration: 4178/2403 | Classification loss: 0.15650 | Regression loss: 0.20089 | Running loss: 0.46020\n","Epoch: 1 | Iteration: 4179/2403 | Classification loss: 0.21998 | Regression loss: 0.23568 | Running loss: 0.46020\n","Epoch: 1 | Iteration: 4180/2403 | Classification loss: 0.15228 | Regression loss: 0.20697 | Running loss: 0.46014\n","Epoch: 1 | Iteration: 4181/2403 | Classification loss: 0.36732 | Regression loss: 0.32721 | Running loss: 0.46027\n","Epoch: 1 | Iteration: 4182/2403 | Classification loss: 0.06074 | Regression loss: 0.13139 | Running loss: 0.46012\n","Epoch: 1 | Iteration: 4183/2403 | Classification loss: 0.48537 | Regression loss: 0.40505 | Running loss: 0.46036\n","Epoch: 1 | Iteration: 4184/2403 | Classification loss: 0.30639 | Regression loss: 0.19165 | Running loss: 0.46038\n","Epoch: 1 | Iteration: 4185/2403 | Classification loss: 0.26794 | Regression loss: 0.23559 | Running loss: 0.46041\n","Epoch: 1 | Iteration: 4186/2403 | Classification loss: 0.24587 | Regression loss: 0.18456 | Running loss: 0.46039\n","Epoch: 1 | Iteration: 4187/2403 | Classification loss: 0.40714 | Regression loss: 0.30678 | Running loss: 0.46053\n","Epoch: 1 | Iteration: 4188/2403 | Classification loss: 0.22175 | Regression loss: 0.25177 | Running loss: 0.46054\n","Epoch: 1 | Iteration: 4189/2403 | Classification loss: 0.19837 | Regression loss: 0.20458 | Running loss: 0.46051\n","Epoch: 1 | Iteration: 4190/2403 | Classification loss: 0.08257 | Regression loss: 0.18605 | Running loss: 0.46040\n","Epoch: 1 | Iteration: 4191/2403 | Classification loss: 0.02660 | Regression loss: 0.14432 | Running loss: 0.46024\n","Epoch: 1 | Iteration: 4192/2403 | Classification loss: 0.22921 | Regression loss: 0.18174 | Running loss: 0.46021\n","Epoch: 1 | Iteration: 4193/2403 | Classification loss: 0.09505 | Regression loss: 0.20413 | Running loss: 0.46012\n","Epoch: 1 | Iteration: 4194/2403 | Classification loss: 0.03661 | Regression loss: 0.10344 | Running loss: 0.45994\n","Epoch: 1 | Iteration: 4195/2403 | Classification loss: 0.37643 | Regression loss: 0.33867 | Running loss: 0.46008\n","Epoch: 1 | Iteration: 4196/2403 | Classification loss: 1.14545 | Regression loss: 0.23357 | Running loss: 0.46060\n","Epoch: 1 | Iteration: 4197/2403 | Classification loss: 0.19581 | Regression loss: 0.18516 | Running loss: 0.46055\n","Epoch: 1 | Iteration: 4198/2403 | Classification loss: 0.12156 | Regression loss: 0.19702 | Running loss: 0.46047\n","Epoch: 1 | Iteration: 4199/2403 | Classification loss: 0.18840 | Regression loss: 0.18015 | Running loss: 0.46042\n","Epoch: 1 | Iteration: 4200/2403 | Classification loss: 0.28811 | Regression loss: 0.18590 | Running loss: 0.46043\n","Epoch: 1 | Iteration: 4201/2403 | Classification loss: 0.08363 | Regression loss: 0.16302 | Running loss: 0.46031\n","Epoch: 1 | Iteration: 4202/2403 | Classification loss: 0.28941 | Regression loss: 0.16200 | Running loss: 0.46031\n","Epoch: 1 | Iteration: 4203/2403 | Classification loss: 0.32431 | Regression loss: 0.30544 | Running loss: 0.46040\n","Epoch: 1 | Iteration: 4204/2403 | Classification loss: 0.20812 | Regression loss: 0.23510 | Running loss: 0.46039\n","Epoch: 1 | Iteration: 4205/2403 | Classification loss: 0.09075 | Regression loss: 0.16420 | Running loss: 0.46028\n","Epoch: 1 | Iteration: 4206/2403 | Classification loss: 0.07968 | Regression loss: 0.13023 | Running loss: 0.46014\n","Epoch: 1 | Iteration: 4207/2403 | Classification loss: 0.33950 | Regression loss: 0.33535 | Running loss: 0.46026\n","Epoch: 1 | Iteration: 4208/2403 | Classification loss: 0.09514 | Regression loss: 0.16059 | Running loss: 0.46014\n","Epoch: 1 | Iteration: 4209/2403 | Classification loss: 0.15146 | Regression loss: 0.22303 | Running loss: 0.46010\n","Epoch: 1 | Iteration: 4210/2403 | Classification loss: 0.03828 | Regression loss: 0.14279 | Running loss: 0.45994\n","Epoch: 1 | Iteration: 4211/2403 | Classification loss: 0.08547 | Regression loss: 0.14930 | Running loss: 0.45982\n","Epoch: 1 | Iteration: 4212/2403 | Classification loss: 0.12773 | Regression loss: 0.26141 | Running loss: 0.45978\n","Epoch: 1 | Iteration: 4213/2403 | Classification loss: 1.16640 | Regression loss: 0.41792 | Running loss: 0.46040\n","Epoch: 1 | Iteration: 4214/2403 | Classification loss: 0.11257 | Regression loss: 0.23370 | Running loss: 0.46034\n","Epoch: 1 | Iteration: 4215/2403 | Classification loss: 0.08805 | Regression loss: 0.16664 | Running loss: 0.46022\n","Epoch: 1 | Iteration: 4216/2403 | Classification loss: 0.26726 | Regression loss: 0.28053 | Running loss: 0.46027\n","Epoch: 1 | Iteration: 4217/2403 | Classification loss: 0.07702 | Regression loss: 0.20006 | Running loss: 0.46017\n","Epoch: 1 | Iteration: 4218/2403 | Classification loss: 0.32557 | Regression loss: 0.29464 | Running loss: 0.46026\n","Epoch: 1 | Iteration: 4219/2403 | Classification loss: 0.30214 | Regression loss: 0.27156 | Running loss: 0.46032\n","Epoch: 1 | Iteration: 4220/2403 | Classification loss: 0.54470 | Regression loss: 0.66252 | Running loss: 0.46073\n","Epoch: 1 | Iteration: 4221/2403 | Classification loss: 0.09440 | Regression loss: 0.13738 | Running loss: 0.46061\n","Epoch: 1 | Iteration: 4222/2403 | Classification loss: 0.33394 | Regression loss: 0.31150 | Running loss: 0.46071\n","Epoch: 1 | Iteration: 4223/2403 | Classification loss: 0.13018 | Regression loss: 0.18077 | Running loss: 0.46063\n","Epoch: 1 | Iteration: 4224/2403 | Classification loss: 0.25707 | Regression loss: 0.20388 | Running loss: 0.46063\n","Epoch: 1 | Iteration: 4225/2403 | Classification loss: 0.14096 | Regression loss: 0.20181 | Running loss: 0.46056\n","Epoch: 1 | Iteration: 4226/2403 | Classification loss: 0.19179 | Regression loss: 0.27648 | Running loss: 0.46057\n","Epoch: 1 | Iteration: 4227/2403 | Classification loss: 0.17005 | Regression loss: 0.31823 | Running loss: 0.46058\n","Epoch: 1 | Iteration: 4228/2403 | Classification loss: 0.19611 | Regression loss: 0.24365 | Running loss: 0.46057\n","Epoch: 1 | Iteration: 4229/2403 | Classification loss: 0.13787 | Regression loss: 0.16621 | Running loss: 0.46048\n","Epoch: 1 | Iteration: 4230/2403 | Classification loss: 0.09211 | Regression loss: 0.11935 | Running loss: 0.46035\n","Epoch: 1 | Iteration: 4231/2403 | Classification loss: 0.22895 | Regression loss: 0.23064 | Running loss: 0.46035\n","Epoch: 1 | Iteration: 4232/2403 | Classification loss: 0.07395 | Regression loss: 0.22174 | Running loss: 0.46026\n","Epoch: 1 | Iteration: 4233/2403 | Classification loss: 0.09704 | Regression loss: 0.25063 | Running loss: 0.46020\n","Epoch: 1 | Iteration: 4234/2403 | Classification loss: 2.49754 | Regression loss: 0.23848 | Running loss: 0.46144\n","Epoch: 1 | Iteration: 4235/2403 | Classification loss: 0.07802 | Regression loss: 0.17722 | Running loss: 0.46133\n","Epoch: 1 | Iteration: 4236/2403 | Classification loss: 0.10124 | Regression loss: 0.20927 | Running loss: 0.46124\n","Epoch: 1 | Iteration: 4237/2403 | Classification loss: 0.06960 | Regression loss: 0.20343 | Running loss: 0.46114\n","Epoch: 1 | Iteration: 4238/2403 | Classification loss: 0.16475 | Regression loss: 0.21723 | Running loss: 0.46110\n","Epoch: 1 | Iteration: 4239/2403 | Classification loss: 0.18717 | Regression loss: 0.19081 | Running loss: 0.46105\n","Epoch: 1 | Iteration: 4240/2403 | Classification loss: 0.19758 | Regression loss: 0.28593 | Running loss: 0.46106\n","Epoch: 1 | Iteration: 4241/2403 | Classification loss: 0.07270 | Regression loss: 0.17296 | Running loss: 0.46095\n","Epoch: 1 | Iteration: 4242/2403 | Classification loss: 0.23032 | Regression loss: 0.19608 | Running loss: 0.46093\n","Epoch: 1 | Iteration: 4243/2403 | Classification loss: 0.22068 | Regression loss: 0.21941 | Running loss: 0.46092\n","Epoch: 1 | Iteration: 4244/2403 | Classification loss: 0.49342 | Regression loss: 0.41410 | Running loss: 0.46116\n","Epoch: 1 | Iteration: 4245/2403 | Classification loss: 0.24738 | Regression loss: 0.19998 | Running loss: 0.46115\n","Epoch: 1 | Iteration: 4246/2403 | Classification loss: 0.06748 | Regression loss: 0.11082 | Running loss: 0.46100\n","Epoch: 1 | Iteration: 4247/2403 | Classification loss: 0.11549 | Regression loss: 0.17227 | Running loss: 0.46090\n","Epoch: 1 | Iteration: 4248/2403 | Classification loss: 0.03546 | Regression loss: 0.15671 | Running loss: 0.46076\n","Epoch: 1 | Iteration: 4249/2403 | Classification loss: 0.33401 | Regression loss: 0.33981 | Running loss: 0.46087\n","Epoch: 1 | Iteration: 4250/2403 | Classification loss: 0.06025 | Regression loss: 0.13532 | Running loss: 0.46073\n","Epoch: 1 | Iteration: 4251/2403 | Classification loss: 0.06194 | Regression loss: 0.24601 | Running loss: 0.46065\n","Epoch: 1 | Iteration: 4252/2403 | Classification loss: 0.07273 | Regression loss: 0.17908 | Running loss: 0.46054\n","Epoch: 1 | Iteration: 4253/2403 | Classification loss: 0.67290 | Regression loss: 0.24123 | Running loss: 0.46078\n","Epoch: 1 | Iteration: 4254/2403 | Classification loss: 0.32677 | Regression loss: 0.27476 | Running loss: 0.46086\n","Epoch: 1 | Iteration: 4255/2403 | Classification loss: 0.09476 | Regression loss: 0.20465 | Running loss: 0.46077\n","Epoch: 1 | Iteration: 4256/2403 | Classification loss: 0.13658 | Regression loss: 0.28861 | Running loss: 0.46075\n","Epoch: 1 | Iteration: 4257/2403 | Classification loss: 0.20650 | Regression loss: 0.30623 | Running loss: 0.46078\n","Epoch: 1 | Iteration: 4258/2403 | Classification loss: 0.13999 | Regression loss: 0.30746 | Running loss: 0.46077\n","Epoch: 1 | Iteration: 4259/2403 | Classification loss: 0.13812 | Regression loss: 0.25336 | Running loss: 0.46073\n","Epoch: 1 | Iteration: 4260/2403 | Classification loss: 0.26828 | Regression loss: 0.34106 | Running loss: 0.46081\n","Epoch: 1 | Iteration: 4261/2403 | Classification loss: 0.13255 | Regression loss: 0.18887 | Running loss: 0.46074\n","Epoch: 1 | Iteration: 4262/2403 | Classification loss: 0.23317 | Regression loss: 0.24860 | Running loss: 0.46075\n","Epoch: 1 | Iteration: 4263/2403 | Classification loss: 0.52696 | Regression loss: 0.44695 | Running loss: 0.46103\n","Epoch: 1 | Iteration: 4264/2403 | Classification loss: 0.04739 | Regression loss: 0.19665 | Running loss: 0.46091\n","Epoch: 1 | Iteration: 4265/2403 | Classification loss: 0.04768 | Regression loss: 0.17927 | Running loss: 0.46078\n","Epoch: 1 | Iteration: 4266/2403 | Classification loss: 0.07528 | Regression loss: 0.13863 | Running loss: 0.46065\n","Epoch: 1 | Iteration: 4267/2403 | Classification loss: 0.12832 | Regression loss: 0.17015 | Running loss: 0.46056\n","Epoch: 1 | Iteration: 4268/2403 | Classification loss: 0.06776 | Regression loss: 0.13183 | Running loss: 0.46042\n","Epoch: 1 | Iteration: 4269/2403 | Classification loss: 0.03163 | Regression loss: 0.14856 | Running loss: 0.46027\n","Epoch: 1 | Iteration: 4270/2403 | Classification loss: 0.19967 | Regression loss: 0.17148 | Running loss: 0.46023\n","Epoch: 1 | Iteration: 4271/2403 | Classification loss: 0.10224 | Regression loss: 0.18157 | Running loss: 0.46013\n","Epoch: 1 | Iteration: 4272/2403 | Classification loss: 0.28032 | Regression loss: 0.26438 | Running loss: 0.46018\n","Epoch: 1 | Iteration: 4273/2403 | Classification loss: 0.06757 | Regression loss: 0.15788 | Running loss: 0.46005\n","Epoch: 1 | Iteration: 4274/2403 | Classification loss: 0.06999 | Regression loss: 0.18534 | Running loss: 0.45994\n","Epoch: 1 | Iteration: 4275/2403 | Classification loss: 0.19226 | Regression loss: 0.25026 | Running loss: 0.45993\n","Epoch: 1 | Iteration: 4276/2403 | Classification loss: 0.87671 | Regression loss: 0.19993 | Running loss: 0.46026\n","Epoch: 1 | Iteration: 4277/2403 | Classification loss: 0.10851 | Regression loss: 0.11449 | Running loss: 0.46014\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"rj5JXj8oC_KN"},"source":["torch.save({\n","        'epoch':epoch,\n","        'model_state_dict': model.state_dict(),\n","        'optimizer_state_dict': optimizer.state_dict(),\n","        'loss': loss}, '/content/drive/MyDrive/TrainingData/model'+str(epoch)+'epoch.pth')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"X48Kr6jWM8Kh"},"source":["def intersection_over_union(boxes_preds, boxes_labels, box_format=\"midpoint\"):\n","    \"\"\"\n","    Calculates intersection over union\n","    Parameters:\n","        boxes_preds (tensor): Predictions of Bounding Boxes (BATCH_SIZE, 4)\n","        boxes_labels (tensor): Correct Labels of Boxes (BATCH_SIZE, 4)\n","        box_format (str): midpoint/corners, if boxes (x,y,w,h) or (x1,y1,x2,y2)\n","    Returns:\n","        tensor: Intersection over union for all examples\n","    \"\"\"\n","\n","    # Slicing idx:idx+1 in order to keep tensor dimensionality\n","    # Doing ... in indexing if there would be additional dimensions\n","    # Like for Yolo algorithm which would have (N, S, S, 4) in shape\n","    if box_format == \"midpoint\":\n","        box1_x1 = boxes_preds[..., 0:1] - boxes_preds[..., 2:3] / 2\n","        box1_y1 = boxes_preds[..., 1:2] - boxes_preds[..., 3:4] / 2\n","        box1_x2 = boxes_preds[..., 0:1] + boxes_preds[..., 2:3] / 2\n","        box1_y2 = boxes_preds[..., 1:2] + boxes_preds[..., 3:4] / 2\n","        box2_x1 = boxes_labels[..., 0:1] - boxes_labels[..., 2:3] / 2\n","        box2_y1 = boxes_labels[..., 1:2] - boxes_labels[..., 3:4] / 2\n","        box2_x2 = boxes_labels[..., 0:1] + boxes_labels[..., 2:3] / 2\n","        box2_y2 = boxes_labels[..., 1:2] + boxes_labels[..., 3:4] / 2\n","\n","    elif box_format == \"corners\":\n","        box1_x1 = boxes_preds[..., 0:1]\n","        box1_y1 = boxes_preds[..., 1:2]\n","        box1_x2 = boxes_preds[..., 2:3]\n","        box1_y2 = boxes_preds[..., 3:4]\n","        box2_x1 = boxes_labels[..., 0:1]\n","        box2_y1 = boxes_labels[..., 1:2]\n","        box2_x2 = boxes_labels[..., 2:3]\n","        box2_y2 = boxes_labels[..., 3:4]\n","\n","    x1 = torch.max(box1_x1, box2_x1)\n","    y1 = torch.max(box1_y1, box2_y1)\n","    x2 = torch.min(box1_x2, box2_x2)\n","    y2 = torch.min(box1_y2, box2_y2)\n","\n","    # Need clamp(0) in case they do not intersect, then we want intersection to be 0\n","    intersection = (x2 - x1).clamp(0) * (y2 - y1).clamp(0)\n","    box1_area = abs((box1_x2 - box1_x1) * (box1_y2 - box1_y1))\n","    box2_area = abs((box2_x2 - box2_x1) * (box2_y2 - box2_y1))\n","\n","    return intersection / (box1_area + box2_area - intersection + 1e-6)\n","\n","def nms(y,iou_threshold,threshold,box_format='corners'):\n","    bbx = []\n","    #assert type(boxes) == list\n","    bbox = y['boxes']\n","    labels = y['labels']\n","    scores = y['scores']\n","\n","    for i in range(len(scores)):\n","        bbx.append([labels[i],scores[i],bbox[i]])\n","    #print(\"STOP--- len before\", len(bbx))\n","    bbx = [box for box in bbx if box[1] > threshold]\n","    bbx = sorted(bbx, key=lambda x: x[1], reverse=True)\n","    bbox_after_nms = []\n","    #print(labels)\n","    while bbx:\n","        chosen = bbx.pop(0)\n","        for box in bbx:\n","            if box[0] != chosen[0]:\n","                pass\n","                # print(intersection_over_union(torch.tensor(\n","                #         chosen[2:][0]),\n","                #         torch.tensor(box[2:][0]),\n","                #         box_format = box_format))\n","        bbx = [box for box in bbx\n","                if #box[0] != chosen[0] or #dleted temporary\n","                    (intersection_over_union(torch.tensor(chosen[2:][0]),torch.tensor(box[2:][0]),box_format = box_format)\n","                    > iou_threshold)\n","                ] #not compare different classes\n","\n","        bbox_after_nms.append(chosen)\n","    #here label, score, box\n","    #orig box, label, score\n","\n","    y = {'labels':[],\n","          'score':[],\n","          'boxes':[]\n","          }\n","\n","    for b in bbox_after_nms:\n","        # for el in b:\n","        #     el.cuda()\n","        y['labels'].append(b[0])\n","        y['score'].append(b[1])\n","        y['boxes'].append(b[2])\n","    #print(\"STOP--- len before\", len(bbox_after_nms))\n","    for k,v in y.items():\n","        y[k] = torch.stack(v, dim=0)\n","\n","    return y\n","\n","def view(images, labels, k, std=1, mean=0):\n","    class2id = {\n","        \"deer\": 1,\n","        \"boar\": 2,\n","    }\n","    images = list(images)\n","    labels = list(labels)\n","\n","    for i in range(k):\n","        label_counts = np.bincount(np.array(labels[i]['labels'].cpu()))\n","\n","        #majority vote\n","        print(labels, \"labels\\n\")\n","        print('PREDICTED LABEL: ',[k for k,v in class2id.items() if v == np.argmax(label_counts)][0])\n","        print('_______________')\n","\n","        im = np.array(images[i].cpu()).transpose((1,2,0))\n","        im = np.array(std) * im + np.array(mean)\n","        im = np.clip(im, 0,1)\n","        #img_conc = np.concatenate((img_conc, im), axis = 1)\n","        fig, ax = plt.subplots()\n","        ax.imshow(im)\n","        l = labels[i]['boxes'].cpu().numpy()\n","        # l[:, 2] = l[:, 2] - l[:, 0]\n","        # l[:, 3] = l[:, 3] - l[:, 1]\n","        for j in range(len(l[:,0])):\n","\n","            rect = patches.Rectangle((l[j][0], l[j][1]), l[j][2]-l[j][0],l[j][3]-l[j][1],\n","                                      linewidth=1, edgecolor='r', facecolor='none')\n","            ax.add_patch(rect)\n","        plt.show()\n","\n","    # cv2.imshow(\"Data vizualization\",img_conc.astype(np.uint8))\n","    # cv2.waitKey(0)\n","        # for j in range(len(l)):\n","        #     ax.add_patch(patches.Rectangle((l[j][0], l[j][1]), l[j][2], l[j][3], linewidth=2, edgecolor='w',\n","        #                                    facecolor='none'))\n","\n","def show_losses(vis): #todo implement\n","    def is_num(x):\n","        if x in ['1','2','3','4','5','6','7','8','9','0','.']:\n","            return True\n","        else:\n","            return False\n","\n","    with open('losses.txt', 'r') as f:\n","        losses = [[],[],[],[]] #todo what are the losses?\n","        for line in f:\n","            idx = [i+len('tensor(') for i in range(len(line)) if line.startswith('tensor(', i)]\n","            for j,id in enumerate(idx):\n","                a = line[id]\n","                num = ''\n","                while is_num(a):\n","                    num+=str(a)\n","                    a = line[id+len(num)]\n","                losses[j].append(float(num))\n","    if vis:\n","        read_loss = np.array(losses)\n","        iter_num = range(len(read_loss[0, :]))\n","        # plt.scatter(iter_num, read_loss[0, :])\n","        # plt.scatter(iter_num, read_loss[1, :])\n","        # plt.scatter(iter_num, read_loss[2, :])\n","        rsum = read_loss[0, :]+read_loss[1, :]+read_loss[2, :]\n","        plt.scatter(iter_num, rsum)\n","        plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XcRVYKujXcSv","executionInfo":{"status":"ok","timestamp":1620832948449,"user_tz":-180,"elapsed":44558,"user":{"displayName":"Ilja Pavlovs","photoUrl":"","userId":"13249870573819033434"}},"outputId":"a654b7ac-cc11-4b9c-e401-b1e4dce681fa"},"source":["writer.close()\n","!tensorboard --logdir=runs"],"execution_count":null,"outputs":[{"output_type":"stream","text":["2021-05-12 15:21:48.254488: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n","Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\n","TensorBoard 2.4.1 at http://localhost:6006/ (Press CTRL+C to quit)\n"],"name":"stdout"}]}]}